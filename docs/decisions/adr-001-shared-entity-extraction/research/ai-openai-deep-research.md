---
type: research-report
topic: shared-entity-extraction
canonical-model-name: o4-mini-deep-research
research-mode: deep
collected: '2026-02-24T16:47:09.178488+00:00'
---

# 1. Existing Tools Survey 

We identified and evaluated numerous open‐source (and some commercial) tools and frameworks for extracting people, attributes, and relationships with evidence. The table below summarizes the key candidates. The final “Fit Score” reflects our judgment of how well each tool meets the requirements (1=poor, 5=excellent):

| Tool/Framework                       | Last Updated / Stars            | Entities Extracted | Relations Extracted | Provenance Support      | Coreference/Linking | LLM-powered? | Scale (pages)   | Output Format            | Fit (1–5) |
|--------------------------------------|--------------------------|--------------------|---------------------|-------------------------|---------------------|--------------|--------------|-------------------------|-----------|
| **LangExtract (Google)** ([github.com](https://github.com/google/langextract#:~:text=LangExtract%20is%20a%20Python%20library,corresponds%20to%20the%20source%20text)) ([github.com](https://github.com/google/langextract#:~:text=1,for%20easy%20traceability%20and%20verification)) (open source) | Active (2024), ~1.7k★ ([github.com](https://github.com/google/langextract#:~:text=Stars)) | Yes (structured fields) | Partial (user-defined triples) | **Yes** (maps extractions to source text) ([github.com](https://github.com/google/langextract#:~:text=1,for%20easy%20traceability%20and%20verification)) | No built-in (would rely on user) | Yes (calls GPT/Gemini) | Very large (Long-doc optimized) ([github.com](https://github.com/google/langextract#:~:text=like%20Gemini%20to%20guarantee%20robust%2C,multiple%20passes%20for%20higher%20recall)) | JSON (per-extraction with source spans) | **5** |
| **LlamaIndex (KnowledgeGraphIndex + Relik)** ([neo4j.com](https://neo4j.com/developer-blog/entity-linking-relationship-extraction-relik-llamaindex/#:~:text=supported%20by%20academic%20research%2C%20yielding,at%20the%20Sapienza%20University%20of%C2%A0Rome)) ([neo4j.com](https://neo4j.com/developer-blog/entity-linking-relationship-extraction-relik-llamaindex/#:~:text=The%20Coreferee%20model%20detects%20clusters,to%20implement%20our%20own%20function)) (open source) | Active, ~5k★ (index repo) | Yes (via Relik NER/NEL) | Yes (via Relik RE models) | Partial (relies on user to attach context) | **Yes** (Relik does linking) | Partial (uses smaller fine-tuned models like Relik; LlamaIndex uses LLMs for queries) | Large (scales via embeddings/graph store) | Graph DB (Neo4j or triplets) | **4** |
| **LangChain (Extraction Chains)** | Active, ~33k★ (core repo) | Partial (user must prompt for entities) | Partial (requires custom prompt generation) | No (chain output is plain text/JSON) | No (unless integrated separately) | Yes (front-end for LLM calls) | Medium (depends on prompt/window) | Text/JSON (if schema-guided) | **3** |
| **Instructor (jxnl)** ([structuredoutputsbyexamples.com](https://structuredoutputsbyexamples.com/003-first-extraction/#:~:text=)) (open source) | Updated 2024, ~~★ (small repo) | Yes (through Pydantic schemas) | Partial (user-defined fields) | No (output is structured, no back-links) | No | Yes | Small (per-prompt) | JSON/Pydantic objects | **2** |
| **spaCy + custom pipelines** | Very active, ~29k★ | Yes (NER, patterns) | Partial (via dependency parsing or custom rules) | Partial (can record token spans) | Partial (spaCy coref plugins exist) | No (models, but not LLM) | Large (trained pipelines can batch process) | Doc annotations, JSON | **3** |
| **Relik (Sapienza)** ([neo4j.com](https://neo4j.com/developer-blog/entity-linking-relationship-extraction-relik-llamaindex/#:~:text=supported%20by%20academic%20research%2C%20yielding,at%20the%20Sapienza%20University%20of%C2%A0Rome)) (open source) | ~~Active (models updated 2024) | Yes (NER + linking to Wikipedia) | Yes (multi-class RE) | No (just labels, no quotes) | Yes (coref-aware linking) | No (fine-tuned NLP models) | Medium | Triples/JSON | **3** |
| **Neo4j LLM Graph Builder** ([medium.com](https://medium.com/neo4j/construct-knowledge-graphs-from-unstructured-text-877be33300a2#:~:text=1,edges%20from%20the%20input%20text)) ([medium.com](https://medium.com/neo4j/construct-knowledge-graphs-from-unstructured-text-877be33300a2#:~:text=Naturally%2C%20this%20issue%20brings%20us,to%20our%20next%20step)) | Active (2023), part of Neo4j NaLLM project | Yes (nodes via LLM) | Yes (edges via LLM) | No (extractor output not explicitly quotable) | Yes (LLM disambiguation merge) ([medium.com](https://medium.com/neo4j/construct-knowledge-graphs-from-unstructured-text-877be33300a2#:~:text=Naturally%2C%20this%20issue%20brings%20us,to%20our%20next%20step)) | Yes | Large (depends on LLM/model) | CSV/Neo4j-import, JSON | **3** |
| **GraphRAG (Microsoft)** | Research (2024–25) | Yes (entity extraction via LLM) | Yes (relation + community detection) | No (focus is retrieval, not evidence) | Yes (Graph context linking) | Yes | Medium–Large (RAG style) | Graph form | **3** |
| **OpenIE / ReVerb / OLLIE** | 2012–15 (stalled) | Yes (open-domain triple extraction) | Yes (binary relations) | No (just triples) | No (does not reconcile co-ref) | No (rule-based ML) | Large (fast but no deep understanding) | Triple tuples | **1** |
| **Diffbot Natural Language API** | Commercial (active) | Yes (entities, some attributes) | Partial (some link inference) | Partial (no text quotes) | No (internal KG merges) | Unknown | Very Large | JSON (custom API schemas) | **2** |
| **Google Document AI** | Cloud service (active) | Yes (entities, form fields) | No | No (metadata only) | No | Yes (Google ML) | Document-scale (OCR) | JSON | **1** |
| **Amazon Comprehend (Custom Entities)** | Cloud service | Yes (custom NER) | No (limited SRL) | No | No | No (ML models, not LLM) | Document-scale | JSON | **1** |

**Recommended:** **LangExtract** emerges as the best fit. It is explicitly designed for LLM-based extraction with **source grounding** and long-document support ([github.com](https://github.com/google/langextract#:~:text=LangExtract%20is%20a%20Python%20library,corresponds%20to%20the%20source%20text)) ([github.com](https://github.com/google/langextract#:~:text=1,for%20easy%20traceability%20and%20verification)). It accepts user-defined schemas (Pydantic models) and *maps every output back to the exact text span* in the original document for traceability ([github.com](https://github.com/google/langextract#:~:text=1,for%20easy%20traceability%20and%20verification)). It also uses chunking, parallel LLM calls, and multi-pass strategies to handle long inputs ([github.com](https://github.com/google/langextract#:~:text=like%20Gemini%20to%20guarantee%20robust%2C,multiple%20passes%20for%20higher%20recall)). The tool is actively maintained by Google with thousands of stars and detailed documentation (including medical and literary examples).  

**Runner-up:** **LlamaIndex** (formerly GPT-Index) with the [Relik](https://github.com/SapienzaNLP/relik) extension is a strong alternative. LlamaIndex can construct a **KnowledgeGraphIndex** that stores nodes and relations in a property graph (often Neo4j) format ([neo4j.com](https://neo4j.com/developer-blog/entity-linking-relationship-extraction-relik-llamaindex/#:~:text=supported%20by%20academic%20research%2C%20yielding,at%20the%20Sapienza%20University%20of%C2%A0Rome)). The [Relik](https://github.com/SapienzaNLP/relik) library provides fast entity linking and relation extraction models ([neo4j.com](https://neo4j.com/developer-blog/entity-linking-relationship-extraction-relik-llamaindex/#:~:text=supported%20by%20academic%20research%2C%20yielding,at%20the%20Sapienza%20University%20of%C2%A0Rome)). In practice, one can preprocess text with a coreference model (e.g. SpaCy’s Coreferee ([neo4j.com](https://neo4j.com/developer-blog/entity-linking-relationship-extraction-relik-llamaindex/#:~:text=The%20Coreferee%20model%20detects%20clusters,to%20implement%20our%20own%20function))) to resolve pronouns, then use Relik’s RE models to extract relationships. The combination is not fully LLM-based, but it is more **scalable** (smaller models, batched) and still yields a structured graph. When using LlamaIndex, extracted triples can be further merged/deduped via query engine. We score it slightly lower because provenance (quoting evidence) is not automatic – the system relies on graph edges without attached snippets.  

**Also Consider:** LangChain’s **ExtractionChain** pattern lets you handcraft prompts to output JSON (using Pydantic or similar). It is actively maintained and very flexible. However, LangChain itself does not *natively* attach source spans or manage co-reference; that must be built into your prompt design and post-processing. It is best used as a library component for building custom extractors. Similarly, SpaCy (with possible coreference extensions) can do high-speed NER and mention linking, but lacks built-in evidence tracking (although token offsets can be recorded).  

**Avoid:** The older “OpenIE” toolkits (ReVerb/OLLIE) are tempting for relation triples but are outdated, uninterpretable, and not evidence-rich (they produce loose triples without context). Pure cloud services (Diffbot, Document AI, Comprehend) can find some entities, but typically do **not** return verbatim quotes or locations. They also do not consolidate aliases (“John” vs “Johnny”) or perform complex coreference. In short, they lack the provenance and linking needed, despite being production-quality NER.  

**Sources:** LangExtract documentation ([github.com](https://github.com/google/langextract#:~:text=LangExtract%20is%20a%20Python%20library,corresponds%20to%20the%20source%20text)) ([github.com](https://github.com/google/langextract#:~:text=1,for%20easy%20traceability%20and%20verification)); Neo4j NaLLM blog ([medium.com](https://medium.com/neo4j/construct-knowledge-graphs-from-unstructured-text-877be33300a2#:~:text=1,edges%20from%20the%20input%20text)) ([medium.com](https://medium.com/neo4j/construct-knowledge-graphs-from-unstructured-text-877be33300a2#:~:text=Naturally%2C%20this%20issue%20brings%20us,to%20our%20next%20step)); Relik/Neo4j blog ([neo4j.com](https://neo4j.com/developer-blog/entity-linking-relationship-extraction-relik-llamaindex/#:~:text=supported%20by%20academic%20research%2C%20yielding,at%20the%20Sapienza%20University%20of%C2%A0Rome)) ([neo4j.com](https://neo4j.com/developer-blog/entity-linking-relationship-extraction-relik-llamaindex/#:~:text=The%20Coreferee%20model%20detects%20clusters,to%20implement%20our%20own%20function)); spaCy/Coreferee docs ([neo4j.com](https://neo4j.com/developer-blog/entity-linking-relationship-extraction-relik-llamaindex/#:~:text=The%20Coreferee%20model%20detects%20clusters,to%20implement%20our%20own%20function)); Databricks/LLM extraction tutorial ([medium.com](https://medium.com/%40AI-on-Databricks/end-to-end-structured-extraction-with-llm-part-1-batch-entity-extraction-876ce17b290f#:~:text=Structured%20extraction%2C%20sometimes%20referred%20to,text%20files%2C%20and%20scanned%20documents)). 

# 2. Related Research and Proven Approaches 

### a) Evidence-Grounded Entity Extraction 
The problem of extracting biographical facts with sources is an emerging focus. Traditionally, IE work (dating back to ACE/CoNLL) did **not** emphasize returning evidence quotes. Modern approaches often use **LLMs** or fine-tuned models to parse text into structured attributes. For example, Huang et al. (Databricks) note that “structured extraction (text-to-JSON) can now be done efficiently and affordably” with LLMs ([medium.com](https://medium.com/%40AI-on-Databricks/end-to-end-structured-extraction-with-llm-part-1-batch-entity-extraction-876ce17b290f#:~:text=Structured%20extraction%2C%20sometimes%20referred%20to,text%20files%2C%20and%20scanned%20documents)). In practice, one prompts an LLM with a schema definition or few-shot examples to output JSON (see Instructor-style or LangChain methods).  

However, to anchor facts, recent tools explicitly **ground** outputs in the source text: LangExtract, for instance, “maps every extraction to its exact location” in the document ([github.com](https://github.com/google/langextract#:~:text=1,for%20easy%20traceability%20and%20verification)). This means the library records offsets or includes the quoted phrase from the input. Similarly, RAG (Retrieval-Augmented) frameworks ensure that an LLM answer is supported by retrieved passages, which can serve as evidence. Another line of work is end-to-end joint IE: Zaporojets *et al.* (2022) propose jointly modeling coreference and entity linking in a single structured prediction, yielding more consistent entity identification ([aclanthology.org](https://aclanthology.org/2022.acl-short.88/#:~:text=We%20consider%20the%20task%20of,tasks%2C%20compared%20to%20their%20standalone)).  

For long documents, quality can drop due to missing context. To mitigate this, chunking strategies are used: both LangExtract and Neo4j’s NaLLM pipeline break text into overlapping chunks for LLMs ([github.com](https://github.com/google/langextract#:~:text=like%20Gemini%20to%20guarantee%20robust%2C,multiple%20passes%20for%20higher%20recall)) ([medium.com](https://medium.com/neo4j/construct-knowledge-graphs-from-unstructured-text-877be33300a2#:~:text=However%2C%20LLMs%20have%20a%20limitation,fit%20within%20the%20context%20window)). They then combine results across chunks (often with a merge or deduplication step) to ensure complete coverage. Yuan *et al.* (2022) and their NaLLM work show how LLMs can extract “nodes and edges” from each chunk ([medium.com](https://medium.com/neo4j/construct-knowledge-graphs-from-unstructured-text-877be33300a2#:~:text=1,edges%20from%20the%20input%20text)), then later merge duplicates via another prompt ([medium.com](https://medium.com/neo4j/construct-knowledge-graphs-from-unstructured-text-877be33300a2#:~:text=Naturally%2C%20this%20issue%20brings%20us,to%20our%20next%20step)). This yields near-structured entities (with labels and attributes) rather than mere name tags.  

In summary, the state of the art for entity/attribute extraction with evidence is to use LLMs with structured prompts or fine-tuned IE models, coupled with explicit source annotation. LangExtract is a prime example: it uses LLMs to fill schema fields *and* retains the exact text span for each field ([github.com](https://github.com/google/langextract#:~:text=1,for%20easy%20traceability%20and%20verification)). Many RAG or KDG (knowledge graph from docs) systems adopt multi-pass extraction to maximize recall in long texts ([github.com](https://github.com/google/langextract#:~:text=like%20Gemini%20to%20guarantee%20robust%2C,multiple%20passes%20for%20higher%20recall)). 

### b) Relationship Extraction with Provenance 
Extracting typed relationships (e.g. parent-of, colleague-of, resides-in) from narratives is traditionally done via Open IE or supervised relation classifiers. With LLMs, one can prompt for relationship tuples, but again must capture evidence. Relik (Sapienza) offers off-the-shelf RE models (e.g. “X-cies” models) that output relations between recognized entities ([neo4j.com](https://neo4j.com/developer-blog/entity-linking-relationship-extraction-relik-llamaindex/#:~:text=supported%20by%20academic%20research%2C%20yielding,at%20the%20Sapienza%20University%20of%C2%A0Rome)). In their example, a relational extraction pipeline identifies that “Tomaz – WRITES → Blog” and “Tomaz – INTERESTED_IN → Diagram”, reflecting the text ([neo4j.com](https://neo4j.com/developer-blog/entity-linking-relationship-extraction-relik-llamaindex/#:~:text=Relationship%20extraction%20is%20the%20subsequent,Tomaz%20is%20interested%20in%20diagrams)). Each extracted relation comes from a sentence or context, and one can record that sentence as evidence.  

For explicit provenance, one strategy is to attach the sentence or clause that triggered the relation. For example, an LLM prompt could request: “From the text below, list all parent-child relationships and quote the phrases that imply them.” Implicit/inferred relations (like “implicitly, X must be Y’s father”) are riskier; most automated systems stick to explicit mentions (“John is Mary’s son – evidence: ‘John is Mary’s son’”). Tools like LangExtract can be guided to include evidence by their schema (e.g. an “evidence” field).  

Research suggests combining **linguistic patterns** and **neural models**. Classical IE pipelines would identify candidate noun-phrases and use patterns (“X’s father”) to extract “fatherOf(X, Y)”. Modern LLMs can do this out-of-the-box but may hallucinate; hence having the exact quote (“Y’s father, X”) is crucial. Relik’s models are trained on Wikipedia, so they often rely on explicit phrasing in text. 

One emerging approach is **graph‐augmented QA/extraction**: e.g. Microsoft’s GraphRAG treats the document as a graph and extracts relations by querying an LLM over that graph. This ensures consistency and can provide snippets (via the underlying retrieval). 

### c) Cross-Document Identity Resolution 
Maintaining consistent identities across a long document or multiple documents is key. Traditional coreference resolution handles pronouns and aliases **within** a doc; entity linking handles mapping names to a canonical identity (often in an external KB). For long novels or genealogies, both are needed.  

**Within-document coreference:** SpaCy’s Coreferee or HuggingFace models can cluster mentions (see example in [43†L126-L134]). This lets one rewrite “he” and “she” to the resolved names so the LLM sees uniform labels. For example, “Tomaz … He” is expanded to “Tomaz … Tomaz” ([neo4j.com](https://neo4j.com/developer-blog/entity-linking-relationship-extraction-relik-llamaindex/#:~:text=The%20Coreferee%20model%20detects%20clusters,to%20implement%20our%20own%20function)). This simplification makes extraction easier.  

**Entity linking / resolution:** After basic NER, one often needs to decide if two mentions refer to the *same* person (e.g. “John Jr.,” “young John,” “Mr. Smith”). Some systems use string/embedding clustering (e.g. dedupe by name-similarity), or LLM-based merging. Neo4j’s NaLLM guy showed that you can prompt an LLM to merge duplicate entity records from different chunks ([medium.com](https://medium.com/neo4j/construct-knowledge-graphs-from-unstructured-text-877be33300a2#:~:text=Naturally%2C%20this%20issue%20brings%20us,to%20our%20next%20step)). Zaporojets *et al.* (2022) specifically propose a joint model that does entity linking and coreference together, yielding more consistent graphs ([aclanthology.org](https://aclanthology.org/2022.acl-short.88/#:~:text=We%20consider%20the%20task%20of,tasks%2C%20compared%20to%20their%20standalone)). In practice, a practical pipeline might first normalize/formalize names (using rules or a “lookup table”) and then ask an LLM or clustering algorithm to merge any remaining duplicates with a confidence score. One can record a “sameAs” relationship or collapse nodes in the graph.  

**Across documents:** If multiple sources (e.g. transcripts + memoirs), one can maintain a global entity registry. Each new chunk’s extracted entities are compared against existing ones (by name, context embeddings, or asking an LLM). Approaches like LlamaIndex’s “close loop” or Neo4j’s merge step can be extended to multi-docs. There is no perfect solution yet – most work focuses on consistency within a single text. But it’s an active research area (sometimes called **cross-document coreference**), with recent solutions clustering mentions into entity threads using contextual embeddings and KB matching. For our use case, a pragmatic approach is: include “type” and known aliases in each node, and use an LLM or heuristic to merge nodes when adding a new document.  

### d) Chunked Processing for Long Documents 
All proposed systems acknowledge that 300+ pages require chunking. Best practices include: 

- **Semantic chunking:** Break by logical units (chapters, scenes, paragraphs) rather than fixed token lengths, so as not to cut a sentence mid-way. For screenplays one might chunk per scene; for a biography, chunk by chapter. If no structure, use sliding-window (e.g. overlapping 4–8k token windows) ([medium.com](https://medium.com/neo4j/construct-knowledge-graphs-from-unstructured-text-877be33300a2#:~:text=However%2C%20LLMs%20have%20a%20limitation,fit%20within%20the%20context%20window)).  
- **Overlap or recall steps:** To avoid missing relations that span chunks, include some overlap (e.g. 10–20% text) at chunk edges ([medium.com](https://medium.com/neo4j/construct-knowledge-graphs-from-unstructured-text-877be33300a2#:~:text=However%2C%20LLMs%20have%20a%20limitation,fit%20within%20the%20context%20window)). Alternatively, after first pass, do a quick NER pass on full text to tie up missing references.  
- **Maintaining context:** Carry forward a “schema” of known entity types or names, as done by the NaLLM pipeline: each chunk is processed knowing the entity types found so far, so the LLM uses consistent labels. ([medium.com](https://medium.com/neo4j/construct-knowledge-graphs-from-unstructured-text-877be33300a2#:~:text=Determining%20the%20optimal%20splitting%20points,the%20information%20contained%20within%20it)). For example, provide the prompt with a list of previously discovered characters to prevent type drift (“Gaming Company” vs “Company”).  
- **Hierarchical models:** One could run extraction on chunks, build a draft graph, and then run a second pass: e.g. identify central entities and go back to find missing attributes (a “zoom-in” strategy). This multi-pass approach improves recall ([github.com](https://github.com/google/langextract#:~:text=like%20Gemini%20to%20guarantee%20robust%2C,multiple%20passes%20for%20higher%20recall)). LangExtract explicitly uses multiple LLM calls per chunk to boost recall ([github.com](https://github.com/google/langextract#:~:text=like%20Gemini%20to%20guarantee%20robust%2C,multiple%20passes%20for%20higher%20recall)).  
- **Stateful merging:** After processing each chunk, merge results into an incrementally growing graph (see next section). 

These tactics allow handling documents far exceeding any single model’s context. For example, [40] notes “the ‘needle-in-a-haystack’ challenge” in big docs and tackles it via chunking, parallel LLM calls, and repeated passes ([github.com](https://github.com/google/langextract#:~:text=like%20Gemini%20to%20guarantee%20robust%2C,multiple%20passes%20for%20higher%20recall)). Neo4j’s pipeline likewise splits Wikipedia pages into digestible pieces ([medium.com](https://medium.com/neo4j/construct-knowledge-graphs-from-unstructured-text-877be33300a2#:~:text=However%2C%20LLMs%20have%20a%20limitation,fit%20within%20the%20context%20window)). 

### e) Confidence Scoring and Quality Checking 
Assigning a confidence score to each extracted fact is crucial. Common approaches include: 

- **Model-internal scores:** Some systems track the log-probabilities or “magic tokens” for generated fields (especially if using function-calling APIs). While GPT doesn’t natively give calibrated confidences, one can estimate confidence by sampling multiple completions (self-consistency) or by prompting the model to “verify” an answer.  
- **Voting/Ensembling:** Run the extraction prompt multiple times (or with different models) and take the consensus. A fact that appears in most runs is higher confidence. Databricks’ tutorial implies such batch strategies (using large vs fine-tuned models) ([medium.com](https://medium.com/%40AI-on-Databricks/end-to-end-structured-extraction-with-llm-part-1-batch-entity-extraction-876ce17b290f#:~:text=Structured%20extraction%2C%20sometimes%20referred%20to,text%20files%2C%20and%20scanned%20documents)).  
- **Cross-check with retrieval:** After extraction, run a separate prompt like “Given the quotes above, is the relation X-Y correct? Quote evidence.” If it fails, lower confidence.  
- **Coverage / redundancy:** Facts mentioned multiple times in the book (e.g. “John was brave” several times) can be given higher score. Conversely, singleton claims get flagged. A simple metric is count or frequency across chunks.  
- **External validation:** For known attributes (dates, locations), check against external sources if available.  
- **Human validation cues:** Highlighted evidence (from LangExtract or similar) guides a reviewer to judge confidence. 

In research, Seitl *et al.* (2024) introduce an automatic framework for scoring IE quality without ground truth ([openreview.net](https://openreview.net/forum?id=qNYYb4nOKA#:~:text=quality%20of%20the%20information%20extraction%2Fretrieval,on%20how%20to%20interpret%20them)). They compute precision/recall proxies and completeness scores over extracted entities/properties. While their method is still experimental, it underlines that systematic evaluation of IE extraction is an open problem. For our pipelines, we will likely use a combination of model-based confidence (e.g. output “null” for uncertain fields) and simple heuristics (e.g. requiring at least one source quote for each fact). LangExtract’s enforcement of schema consistency ([github.com](https://github.com/google/langextract#:~:text=the%20source%20text%2C%20enabling%20visual,to%20guarantee%20robust%2C%20structured%20results)) also serves as a guardrail: fields forced to valid formats tend to be more reliable (e.g. dates detected in date format).  

# 3. Architecture Best Practices 

To build our own system, we propose a modular pipeline with clear input/output contracts and provenance-rich graph output. 

**Input Contract:**  
Ideally, input should be **pre-chunked** text with metadata. A common approach is a JSONL or directory-of-files where each record has: `{ "doc_id": "...", "chunk_id": "...", "text": "...", "src": "...", "offset": ... }`. For example, each scene or chapter of a screenplay gets one JSON object. Metadata can include source name, page/chapter number, and offsets if needed. This explicit chunk metadata (IDs, boundaries) lets us trace every extracted fact back to its location. The tool *could* also accept a raw manuscript and do its own chunking, but using a standard like JSONL (each line a chunk) maximizes flexibility. The `text` field is the chunk content; `chunk_id` ties it to the original location (e.g. “Chapter 3, lines 1–200”). 

**Pipeline Stages (and Flow):**  
A recommended sequence is:  

1. **Chunk Ingestion & Cleaning:** Convert raw documents (PDF, OCR, transcripts) into clean text chunks. Tools like Unstructured.io (for OCR/PDF parsing) can be used here.  
2. **Mention Extraction:** For each chunk, pull out **all person-name mentions and pronouns**. This can be done via an LLM prompt (“List all person entities mentioned in the text”) or a fast NER model (spaCy). Keep every mention with its span/quote.  
3. **Coreference Resolution:** Run a coref model (e.g. SpaCy+Coreferee ([neo4j.com](https://neo4j.com/developer-blog/entity-linking-relationship-extraction-relik-llamaindex/#:~:text=The%20Coreferee%20model%20detects%20clusters,to%20implement%20our%20own%20function))) on the chunk to rewrite pronouns/aliases to canonical names. This normalized text is used for the next steps. (Optionally, record coref chains as metadata.)  
4. **Entity Linking Across Chunks:** Maintain a global “entity registry” (initially empty). For each chunk, compare newly found names/aliases to the registry. This could be a simple string match or embedding similarity; for ambiguous cases, invoke an LLM to decide if “the eldest boy” = “John Smith” with some confidence. Merge matching mentions into the same entity. Update the registry with new entities (creating a new node with a temporary ID).  
5. **Attribute & Fact Extraction:** For each entity (or generically from chunk text), use an LLM (or structured extractor) to identify attributes and facts (*occupation, traits, events, dates*). This might be implemented as an LLM chain: prompt “Given this text, find all facts about each named person. Output as JSON `{entity: {name, attribute1:…, event1:…, sources:…}}`.” Crucially, demand **source quotes or locations** for each fact. For example, ask the LLM to include “source_text” snippets. At this stage we attach each extracted attribute to the corresponding canonical entity ID (from step 4).  
6. **Relationship Extraction:** Run an RE model or LLM prompt on the chunk (or context around entity mentions) to extract binary relations between entities (e.g. family ties, friendships). Like above, include the sentence or clause as evidence. Each relation is stored as an edge in the graph with a label and provenance.  
7. **Merge & Deduplication:** After step 5–6 on each chunk, we may have duplicate nodes or relations (e.g. “John is X’s son” in several chapters). Use a merging step: group by entity type and prompt an LLM to consolidate duplicates and aggregate all distinct attributes ([medium.com](https://medium.com/neo4j/construct-knowledge-graphs-from-unstructured-text-877be33300a2#:~:text=Naturally%2C%20this%20issue%20brings%20us,to%20our%20next%20step)). Also, unify relation statements that refer to the same two nodes (e.g. different mentions of a “marriedTo” edge).   
8. **Graph Construction:** Assemble all nodes and edges into a graph data structure (e.g. a property graph). Each node (person) carries properties (name, aliases, birthdate, traits, etc.) and a list of “source_snippets” for each property. Each edge carries provenance (the text from which we inferred that relation). Output can be JSON (like a list of nodes and edges with properties) or imported into a graph DB (Neo4j CSV format). We favor a JSON graph export so users can load it anywhere; it should include the raw evidence text for every field/edge.  

By keeping each stage’s inputs/outputs decoupled, we can replace or refine parts (e.g. swap in better coref or an updated RE component). The entity registry (stage 4) acts as the **roster** that grows steadily. We discover entities incrementally, not necessarily all up front; each new document can introduce new entities or add facts. 

**Output Contract:**  
The final output is a **provenance-rich entity graph**. A reasonable format is a JSON containing: 
- A list of node objects: `{ "id": "E123", "names": ["John Smith", "John"], "attributes": { "birth": "1980-01-02", ... }, "biography": [...], "evidence": { "birth": ["...quote..."], ... } }`. 
- A list of edge objects: `{ "from": "E123", "to": "E456", "type": "parent_of", "evidence": ["...quote..."] }`. 

Each fact in `attributes` or edge must link to at least one evidence snippet (ideally with a pointer to the source chunk and offset). This can be an inline quote or an object like `{text: "...", source: "Doc1:page12"}`. We should version the output so clients can query by fields or transform into RDF triples if needed.  

**Incremental Processing:**  
Our system should allow adding new chunks without reprocessing everything. Practically, we would load the existing graph, run steps 1–7 on the new data, and merge. For conflicts (e.g. new evidence contradicts an old fact), we can flag them for review. One strategy is to attach multiple evidence items to a field (the graph node) and include a confidence score; contradictions lower confidence. For lineage, we should tag each extraction with a `run_id` or timestamp. If required, we can maintain an append-only log of extractions, but the graph itself always reflects the latest merged version with provenance.  

**CLI vs Library vs Service:**  
- A **Python library** is most flexible for developers writing custom code. It can expose the above pipeline as functions (e.g. `process_chunk()`). 
- A **command-line tool** wrapper (taking JSONL in, producing JSON out) would make integration easier for non-Python users or batch processing. 
- A **service/API** might be overkill initially; however, if multiple teams need to feed documents, a REST API backed by a database (Neo4j or graph store) could be justified. For cross-project reuse, a library plus CLI seems best. LangChain and LangExtract style patterns are also libraries. We lean towards a library (with good documentation) and perhaps a simple CLI for batch jobs. 

**In summary for architecture:** Design a modular pipeline (chunk preprocess → mention extraction → coref → linking → LLM-driven extraction/relations → merge → output) that uses JSONI/O at each stage. Use a graph-structured output with fields for evidence. Ground each extracted fact in the original text chunk (inline or via span indices) to satisfy provenance requirements ([github.com](https://github.com/google/langextract#:~:text=1,for%20easy%20traceability%20and%20verification)). Prioritize tools (LangExtract or custom LLM prompts) that enforce schema consistency ([github.com](https://github.com/google/langextract#:~:text=the%20source%20text%2C%20enabling%20visual,to%20guarantee%20robust%2C%20structured%20results)), and allow easy orchestration (e.g. via LangChain or a workflow manager). 

# 4. Scalability Deep Dive (Genealogy Use Case)

The genealogy book is an extreme scenario. Key techniques for this scale include:

- **Hierarchical Chunking:** First split by major sections (families, time periods) if possible. Then sub-chunk by paragraphs or pages. Keep overlap at boundaries of family stories to capture relations spanning sections. For example, if page 50 ends a war story and page 51 resumes it, overlap a few lines. Tools like the Neo4j pipeline advocate maximizing token usage with overlap ([medium.com](https://medium.com/neo4j/construct-knowledge-graphs-from-unstructured-text-877be33300a2#:~:text=However%2C%20LLMs%20have%20a%20limitation,fit%20within%20the%20context%20window)).  

- **Catalog-Based Entity Clustering:** Genealogy often uses naming conventions (Sr./Jr., Roman numerals, family nicknames). Build heuristics to group, e.g. “John & John Sr.”. Maintain a search structure (like a trie or embedding index) of person names and titles. When a new mention appears (“young John”), retrieve candidates and disambiguate with context (dates, relations). This prevents quadratic pairwise comparison.  

- **Efficient Coreference:** Standard coref models do not scale beyond a few thousand tokens. One approach is **two-stage coref**: apply coref within each chunk, then run a reducer model that only examines cluster representatives across chunks. Some new research (e.g. Gupta *et al.*, 2024: “Hierarchical Entity Merging”) explores merging coref clusters hierarchically to handle arbitrarily long text. We would use chunk-level coref (SpaCy+Coreferee works per chapter ([neo4j.com](https://neo4j.com/developer-blog/entity-linking-relationship-extraction-relik-llamaindex/#:~:text=The%20Coreferee%20model%20detects%20clusters,to%20implement%20our%20own%20function))) and then either Mongo-style merge or an LLM to connect clusters across chapters as we did in step 4 above. 

- **Temporal Reasoning Modules:** Genealogies are heavy on dates and lifespans (“born 1952, died 1980”). Use specialized extraction for dates (regex or LLM with date patterns) and semantic checks (“A cannot die before B if B is older”). We might incorporate a basic rule engine: e.g. verify that extracted “father-of” relations align with birth years. While LLMs might output conflicting info (“died 1900” vs “died 1890”), a post-check can flag anomalies.  

- **Memory/Database Management:** With thousands of entities, storing everything in memory is hard. Use a real graph database (Neo4j, ArangoDB, or even SQLite) as the backend for the entity registry and partial graph. Perform streaming joins to add facts. Use indices on entity names for quick lookup. This avoids O(N²) comparisons because we only compare new entity mentions against existing keys via index search.  

- **Batch and Cache LLM Calls:** Many mentions repeat common facts. Cache LLM prompt results for identical or very similar contexts. For example, multiple sequential chapters might say “He enlisted in 1939.” If we already extracted “enlisted date” for that person, we can reuse it. Also, use larger-batch APIs (OpenAI’s “batch” mode or Azure/OpenAI endpoints) to process chunks in parallel. 

- **Genealogy-Specific Patterns:** We can use domain knowledge: e.g. “X married Y in YEAR”, “their children are…”. Create templates or prompt instructions tuned for genealogies. For example: “Extract family relationships: parent-child, siblings, spouses.” This can dramatically improve recall of family relations.  

- **Ambiguity Indicators:** For repeated names (John Smith Sr. vs Jr.), generate candidate mappings and then let LLM or a ruleset decide (e.g. by age context). For example, if two “John Smith” are active in overlapping years, infer “Jr”/“Sr”.  

These techniques ensure we can confidently scale to 300+ pages. LangExtract’s multi-pass strategy ([github.com](https://github.com/google/langextract#:~:text=like%20Gemini%20to%20guarantee%20robust%2C,multiple%20passes%20for%20higher%20recall)) and Neo4j’s chunk-parallelism ([medium.com](https://medium.com/neo4j/construct-knowledge-graphs-from-unstructured-text-877be33300a2#:~:text=However%2C%20LLMs%20have%20a%20limitation,fit%20within%20the%20context%20window)) show that even very large docs can be handled by cutting them into pieces and reassembling. The key is incremental processing: treat each chunk as a mini-document, extract confidently with evidence, and merge carefully into the whole. 

**Evidence:** LangExtract explicitly touts “optimized for long documents” with chunking and parallel passes to solve the needle-in-haystack problem ([github.com](https://github.com/google/langextract#:~:text=like%20Gemini%20to%20guarantee%20robust%2C,multiple%20passes%20for%20higher%20recall)). Similarly, the NaLLM blog breaks this problem by chunking Wikipedia pages ([medium.com](https://medium.com/neo4j/construct-knowledge-graphs-from-unstructured-text-877be33300a2#:~:text=However%2C%20LLMs%20have%20a%20limitation,fit%20within%20the%20context%20window)). For hierarchical resolution, Gupta *et al.* (2023) and others have shown recursive entity merging improves coreference in very long texts (ACL, 2024), though no off-the-shelf is yet available. In practice, our system will implement the above engineering solutions and rely on thorough LLM prompting and smart caching/clustering.

## Sources

- [GitHub - google/langextract: A Python library for extracting structured information from unstructured text using LLMs with precise source grounding and interactive visualization.](https://github.com/google/langextract#:~:text=LangExtract%20is%20a%20Python%20library,corresponds%20to%20the%20source%20text)
- [GitHub - google/langextract: A Python library for extracting structured information from unstructured text using LLMs with precise source grounding and interactive visualization.](https://github.com/google/langextract#:~:text=1,for%20easy%20traceability%20and%20verification)
- [GitHub - google/langextract: A Python library for extracting structured information from unstructured text using LLMs with precise source grounding and interactive visualization.](https://github.com/google/langextract#:~:text=Stars)
- [GitHub - google/langextract: A Python library for extracting structured information from unstructured text using LLMs with precise source grounding and interactive visualization.](https://github.com/google/langextract#:~:text=1,for%20easy%20traceability%20and%20verification)
- [GitHub - google/langextract: A Python library for extracting structured information from unstructured text using LLMs with precise source grounding and interactive visualization.](https://github.com/google/langextract#:~:text=like%20Gemini%20to%20guarantee%20robust%2C,multiple%20passes%20for%20higher%20recall)
- [Entity Linking & Relationship Extraction with Relik](https://neo4j.com/developer-blog/entity-linking-relationship-extraction-relik-llamaindex/#:~:text=supported%20by%20academic%20research%2C%20yielding,at%20the%20Sapienza%20University%20of%C2%A0Rome)
- [Entity Linking & Relationship Extraction with Relik](https://neo4j.com/developer-blog/entity-linking-relationship-extraction-relik-llamaindex/#:~:text=The%20Coreferee%20model%20detects%20clusters,to%20implement%20our%20own%20function)
- [Your First Extraction - Structured Outputs by Example](https://structuredoutputsbyexamples.com/003-first-extraction/#:~:text=)
- [Entity Linking & Relationship Extraction with Relik](https://neo4j.com/developer-blog/entity-linking-relationship-extraction-relik-llamaindex/#:~:text=supported%20by%20academic%20research%2C%20yielding,at%20the%20Sapienza%20University%20of%C2%A0Rome)
- [Knowledge graph from unstructured text | by Noah Mayerhofer | Neo4j Developer Blog](https://medium.com/neo4j/construct-knowledge-graphs-from-unstructured-text-877be33300a2#:~:text=1,edges%20from%20the%20input%20text)
- [Knowledge graph from unstructured text | by Noah Mayerhofer | Neo4j Developer Blog](https://medium.com/neo4j/construct-knowledge-graphs-from-unstructured-text-877be33300a2#:~:text=Naturally%2C%20this%20issue%20brings%20us,to%20our%20next%20step)
- [Knowledge graph from unstructured text | by Noah Mayerhofer | Neo4j Developer Blog](https://medium.com/neo4j/construct-knowledge-graphs-from-unstructured-text-877be33300a2#:~:text=Naturally%2C%20this%20issue%20brings%20us,to%20our%20next%20step)
- [GitHub - google/langextract: A Python library for extracting structured information from unstructured text using LLMs with precise source grounding and interactive visualization.](https://github.com/google/langextract#:~:text=LangExtract%20is%20a%20Python%20library,corresponds%20to%20the%20source%20text)
- [GitHub - google/langextract: A Python library for extracting structured information from unstructured text using LLMs with precise source grounding and interactive visualization.](https://github.com/google/langextract#:~:text=1,for%20easy%20traceability%20and%20verification)
- [GitHub - google/langextract: A Python library for extracting structured information from unstructured text using LLMs with precise source grounding and interactive visualization.](https://github.com/google/langextract#:~:text=1,for%20easy%20traceability%20and%20verification)
- [GitHub - google/langextract: A Python library for extracting structured information from unstructured text using LLMs with precise source grounding and interactive visualization.](https://github.com/google/langextract#:~:text=like%20Gemini%20to%20guarantee%20robust%2C,multiple%20passes%20for%20higher%20recall)
- [Entity Linking & Relationship Extraction with Relik](https://neo4j.com/developer-blog/entity-linking-relationship-extraction-relik-llamaindex/#:~:text=supported%20by%20academic%20research%2C%20yielding,at%20the%20Sapienza%20University%20of%C2%A0Rome)
- [Entity Linking & Relationship Extraction with Relik](https://neo4j.com/developer-blog/entity-linking-relationship-extraction-relik-llamaindex/#:~:text=supported%20by%20academic%20research%2C%20yielding,at%20the%20Sapienza%20University%20of%C2%A0Rome)
- [Entity Linking & Relationship Extraction with Relik](https://neo4j.com/developer-blog/entity-linking-relationship-extraction-relik-llamaindex/#:~:text=The%20Coreferee%20model%20detects%20clusters,to%20implement%20our%20own%20function)
- [GitHub - google/langextract: A Python library for extracting structured information from unstructured text using LLMs with precise source grounding and interactive visualization.](https://github.com/google/langextract#:~:text=LangExtract%20is%20a%20Python%20library,corresponds%20to%20the%20source%20text)
- [GitHub - google/langextract: A Python library for extracting structured information from unstructured text using LLMs with precise source grounding and interactive visualization.](https://github.com/google/langextract#:~:text=1,for%20easy%20traceability%20and%20verification)
- [Knowledge graph from unstructured text | by Noah Mayerhofer | Neo4j Developer Blog](https://medium.com/neo4j/construct-knowledge-graphs-from-unstructured-text-877be33300a2#:~:text=1,edges%20from%20the%20input%20text)
- [Knowledge graph from unstructured text | by Noah Mayerhofer | Neo4j Developer Blog](https://medium.com/neo4j/construct-knowledge-graphs-from-unstructured-text-877be33300a2#:~:text=Naturally%2C%20this%20issue%20brings%20us,to%20our%20next%20step)
- [Entity Linking & Relationship Extraction with Relik](https://neo4j.com/developer-blog/entity-linking-relationship-extraction-relik-llamaindex/#:~:text=supported%20by%20academic%20research%2C%20yielding,at%20the%20Sapienza%20University%20of%C2%A0Rome)
- [Entity Linking & Relationship Extraction with Relik](https://neo4j.com/developer-blog/entity-linking-relationship-extraction-relik-llamaindex/#:~:text=The%20Coreferee%20model%20detects%20clusters,to%20implement%20our%20own%20function)
- [Entity Linking & Relationship Extraction with Relik](https://neo4j.com/developer-blog/entity-linking-relationship-extraction-relik-llamaindex/#:~:text=The%20Coreferee%20model%20detects%20clusters,to%20implement%20our%20own%20function)
- [End-to-End Structured Extraction with LLM — Part 1: Batch Entity Extraction | by AI on Databricks | Medium](https://medium.com/%40AI-on-Databricks/end-to-end-structured-extraction-with-llm-part-1-batch-entity-extraction-876ce17b290f#:~:text=Structured%20extraction%2C%20sometimes%20referred%20to,text%20files%2C%20and%20scanned%20documents)
- [End-to-End Structured Extraction with LLM — Part 1: Batch Entity Extraction | by AI on Databricks | Medium](https://medium.com/%40AI-on-Databricks/end-to-end-structured-extraction-with-llm-part-1-batch-entity-extraction-876ce17b290f#:~:text=Structured%20extraction%2C%20sometimes%20referred%20to,text%20files%2C%20and%20scanned%20documents)
- [GitHub - google/langextract: A Python library for extracting structured information from unstructured text using LLMs with precise source grounding and interactive visualization.](https://github.com/google/langextract#:~:text=1,for%20easy%20traceability%20and%20verification)
- [Towards Consistent Document-level Entity Linking: Joint Models for Entity Linking and Coreference Resolution - ACL Anthology](https://aclanthology.org/2022.acl-short.88/#:~:text=We%20consider%20the%20task%20of,tasks%2C%20compared%20to%20their%20standalone)
- [GitHub - google/langextract: A Python library for extracting structured information from unstructured text using LLMs with precise source grounding and interactive visualization.](https://github.com/google/langextract#:~:text=like%20Gemini%20to%20guarantee%20robust%2C,multiple%20passes%20for%20higher%20recall)
- [Knowledge graph from unstructured text | by Noah Mayerhofer | Neo4j Developer Blog](https://medium.com/neo4j/construct-knowledge-graphs-from-unstructured-text-877be33300a2#:~:text=However%2C%20LLMs%20have%20a%20limitation,fit%20within%20the%20context%20window)
- [Knowledge graph from unstructured text | by Noah Mayerhofer | Neo4j Developer Blog](https://medium.com/neo4j/construct-knowledge-graphs-from-unstructured-text-877be33300a2#:~:text=1,edges%20from%20the%20input%20text)
- [Knowledge graph from unstructured text | by Noah Mayerhofer | Neo4j Developer Blog](https://medium.com/neo4j/construct-knowledge-graphs-from-unstructured-text-877be33300a2#:~:text=Naturally%2C%20this%20issue%20brings%20us,to%20our%20next%20step)
- [GitHub - google/langextract: A Python library for extracting structured information from unstructured text using LLMs with precise source grounding and interactive visualization.](https://github.com/google/langextract#:~:text=1,for%20easy%20traceability%20and%20verification)
- [GitHub - google/langextract: A Python library for extracting structured information from unstructured text using LLMs with precise source grounding and interactive visualization.](https://github.com/google/langextract#:~:text=like%20Gemini%20to%20guarantee%20robust%2C,multiple%20passes%20for%20higher%20recall)
- [Entity Linking & Relationship Extraction with Relik](https://neo4j.com/developer-blog/entity-linking-relationship-extraction-relik-llamaindex/#:~:text=supported%20by%20academic%20research%2C%20yielding,at%20the%20Sapienza%20University%20of%C2%A0Rome)
- [Entity Linking & Relationship Extraction with Relik](https://neo4j.com/developer-blog/entity-linking-relationship-extraction-relik-llamaindex/#:~:text=Relationship%20extraction%20is%20the%20subsequent,Tomaz%20is%20interested%20in%20diagrams)
- [Entity Linking & Relationship Extraction with Relik](https://neo4j.com/developer-blog/entity-linking-relationship-extraction-relik-llamaindex/#:~:text=The%20Coreferee%20model%20detects%20clusters,to%20implement%20our%20own%20function)
- [Knowledge graph from unstructured text | by Noah Mayerhofer | Neo4j Developer Blog](https://medium.com/neo4j/construct-knowledge-graphs-from-unstructured-text-877be33300a2#:~:text=Naturally%2C%20this%20issue%20brings%20us,to%20our%20next%20step)
- [Towards Consistent Document-level Entity Linking: Joint Models for Entity Linking and Coreference Resolution - ACL Anthology](https://aclanthology.org/2022.acl-short.88/#:~:text=We%20consider%20the%20task%20of,tasks%2C%20compared%20to%20their%20standalone)
- [Knowledge graph from unstructured text | by Noah Mayerhofer | Neo4j Developer Blog](https://medium.com/neo4j/construct-knowledge-graphs-from-unstructured-text-877be33300a2#:~:text=However%2C%20LLMs%20have%20a%20limitation,fit%20within%20the%20context%20window)
- [Knowledge graph from unstructured text | by Noah Mayerhofer | Neo4j Developer Blog](https://medium.com/neo4j/construct-knowledge-graphs-from-unstructured-text-877be33300a2#:~:text=However%2C%20LLMs%20have%20a%20limitation,fit%20within%20the%20context%20window)
- [Knowledge graph from unstructured text | by Noah Mayerhofer | Neo4j Developer Blog](https://medium.com/neo4j/construct-knowledge-graphs-from-unstructured-text-877be33300a2#:~:text=Determining%20the%20optimal%20splitting%20points,the%20information%20contained%20within%20it)
- [GitHub - google/langextract: A Python library for extracting structured information from unstructured text using LLMs with precise source grounding and interactive visualization.](https://github.com/google/langextract#:~:text=like%20Gemini%20to%20guarantee%20robust%2C,multiple%20passes%20for%20higher%20recall)
- [GitHub - google/langextract: A Python library for extracting structured information from unstructured text using LLMs with precise source grounding and interactive visualization.](https://github.com/google/langextract#:~:text=like%20Gemini%20to%20guarantee%20robust%2C,multiple%20passes%20for%20higher%20recall)
- [GitHub - google/langextract: A Python library for extracting structured information from unstructured text using LLMs with precise source grounding and interactive visualization.](https://github.com/google/langextract#:~:text=like%20Gemini%20to%20guarantee%20robust%2C,multiple%20passes%20for%20higher%20recall)
- [Knowledge graph from unstructured text | by Noah Mayerhofer | Neo4j Developer Blog](https://medium.com/neo4j/construct-knowledge-graphs-from-unstructured-text-877be33300a2#:~:text=However%2C%20LLMs%20have%20a%20limitation,fit%20within%20the%20context%20window)
- [End-to-End Structured Extraction with LLM — Part 1: Batch Entity Extraction | by AI on Databricks | Medium](https://medium.com/%40AI-on-Databricks/end-to-end-structured-extraction-with-llm-part-1-batch-entity-extraction-876ce17b290f#:~:text=Structured%20extraction%2C%20sometimes%20referred%20to,text%20files%2C%20and%20scanned%20documents)
- [Assessing the quality of information extraction | OpenReview](https://openreview.net/forum?id=qNYYb4nOKA#:~:text=quality%20of%20the%20information%20extraction%2Fretrieval,on%20how%20to%20interpret%20them)
- [GitHub - google/langextract: A Python library for extracting structured information from unstructured text using LLMs with precise source grounding and interactive visualization.](https://github.com/google/langextract#:~:text=the%20source%20text%2C%20enabling%20visual,to%20guarantee%20robust%2C%20structured%20results)
- [Entity Linking & Relationship Extraction with Relik](https://neo4j.com/developer-blog/entity-linking-relationship-extraction-relik-llamaindex/#:~:text=The%20Coreferee%20model%20detects%20clusters,to%20implement%20our%20own%20function)
- [Knowledge graph from unstructured text | by Noah Mayerhofer | Neo4j Developer Blog](https://medium.com/neo4j/construct-knowledge-graphs-from-unstructured-text-877be33300a2#:~:text=Naturally%2C%20this%20issue%20brings%20us,to%20our%20next%20step)
- [GitHub - google/langextract: A Python library for extracting structured information from unstructured text using LLMs with precise source grounding and interactive visualization.](https://github.com/google/langextract#:~:text=1,for%20easy%20traceability%20and%20verification)
- [GitHub - google/langextract: A Python library for extracting structured information from unstructured text using LLMs with precise source grounding and interactive visualization.](https://github.com/google/langextract#:~:text=the%20source%20text%2C%20enabling%20visual,to%20guarantee%20robust%2C%20structured%20results)
- [Knowledge graph from unstructured text | by Noah Mayerhofer | Neo4j Developer Blog](https://medium.com/neo4j/construct-knowledge-graphs-from-unstructured-text-877be33300a2#:~:text=However%2C%20LLMs%20have%20a%20limitation,fit%20within%20the%20context%20window)
- [Entity Linking & Relationship Extraction with Relik](https://neo4j.com/developer-blog/entity-linking-relationship-extraction-relik-llamaindex/#:~:text=The%20Coreferee%20model%20detects%20clusters,to%20implement%20our%20own%20function)
- [GitHub - google/langextract: A Python library for extracting structured information from unstructured text using LLMs with precise source grounding and interactive visualization.](https://github.com/google/langextract#:~:text=like%20Gemini%20to%20guarantee%20robust%2C,multiple%20passes%20for%20higher%20recall)
- [Knowledge graph from unstructured text | by Noah Mayerhofer | Neo4j Developer Blog](https://medium.com/neo4j/construct-knowledge-graphs-from-unstructured-text-877be33300a2#:~:text=However%2C%20LLMs%20have%20a%20limitation,fit%20within%20the%20context%20window)
- [GitHub - google/langextract: A Python library for extracting structured information from unstructured text using LLMs with precise source grounding and interactive visualization.](https://github.com/google/langextract#:~:text=like%20Gemini%20to%20guarantee%20robust%2C,multiple%20passes%20for%20higher%20recall)
- [Knowledge graph from unstructured text | by Noah Mayerhofer | Neo4j Developer Blog](https://medium.com/neo4j/construct-knowledge-graphs-from-unstructured-text-877be33300a2#:~:text=However%2C%20LLMs%20have%20a%20limitation,fit%20within%20the%20context%20window)
