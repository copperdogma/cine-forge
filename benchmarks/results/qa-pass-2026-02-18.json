{
  "evalId": "eval-5E3-2026-02-18T07:31:05",
  "results": {
    "version": 3,
    "timestamp": "2026-02-18T07:31:05.981Z",
    "prompts": [
      {
        "raw": "You are a QA reviewer validating whether an AI-extracted scene analysis is accurate and faithful to the source screenplay text.\n\nCompare the extracted scene data against the original scene text and evaluate:\n\n1. **Heading accuracy**: Is the scene heading correct (location, INT/EXT, time of day)?\n2. **Character completeness**: Are all characters who appear or speak listed?\n3. **Summary fidelity**: Does the summary accurately describe what happens? No fabrications?\n4. **Narrative beats**: Are the identified beats actually present in the scene?\n5. **Tone assessment**: Does the tone description match the actual mood of the scene?\n6. **Confidence calibration**: Is the confidence score reasonable given the quality?\n\nReturn a JSON object with:\n- passed: boolean (true if the extraction is faithful, false if it has significant errors)\n- confidence: float 0-1 (your confidence in this QA judgment)\n- issues: array of objects, each with:\n  - severity: \"error\" (factual wrong), \"warning\" (misleading), or \"note\" (minor)\n  - description: what's wrong\n  - location: which field has the issue\n- summary: 1-2 sentence overall assessment\n\nBe strict: wrong character names, fabricated events, or incorrect locations are errors.\nMinor omissions or imprecise tone descriptions are warnings.\n\nReturn ONLY valid JSON. No explanations or markdown fences.\n\n==========\nORIGINAL SCENE TEXT:\n{{scene_text}}\n\n==========\nEXTRACTED SCENE DATA:\n{{extracted_data}}\n==========",
        "label": "prompts/qa-pass.txt: You are a QA reviewer validating whether an AI-extracted scene analysis is accurate and faithful to the source screenplay text.\n\nCompare the extracted scene data against the original scene text and evaluate:\n\n1. **Heading accuracy**: Is the scene heading correct (location, INT/EXT, time of day)?\n2. **Character completeness**: Are all characters who appear or speak listed?\n3. **Summary fidelity**: Does the summary accurately describe what happens? No fabrications?\n4. **Narrative beats**: Are the identified beats actually present in the scene?\n5. **Tone assessment**: Does the tone description match the actual mood of the scene?\n6. **Confidence calibration**: Is the confidence score reasonable given the quality?\n\nReturn a JSON object with:\n- passed: boolean (true if the extraction is faithful, false if it has significant errors)\n- confidence: float 0-1 (your confidence in this QA judgment)\n- issues: array of objects, each with:\n  - severity: \"error\" (factual wrong), \"warning\" (misleading), or \"note\" (minor)\n  - description: what's wrong\n  - location: which field has the issue\n- summary: 1-2 sentence overall assessment\n\nBe strict: wrong character names, fabricated events, or incorrect locations are errors.\nMinor omissions or imprecise tone descriptions are warnings.\n\nReturn ONLY valid JSON. No explanations or markdown fences.\n\n==========\nORIGINAL SCENE TEXT:\n{{scene_text}}\n\n==========\nEXTRACTED SCENE DATA:\n{{extracted_data}}\n==========",
        "id": "8df20c2c4a6081352d6b06e144ddbc1e0a5244f9a3c2000d40df12fc9a94e543",
        "provider": "GPT-4.1 Nano",
        "metrics": {
          "score": 1.14,
          "testPassCount": 1,
          "testFailCount": 1,
          "testErrorCount": 0,
          "assertPassCount": 2,
          "assertFailCount": 2,
          "totalLatencyMs": 12239,
          "tokenUsage": {
            "prompt": 2071,
            "completion": 799,
            "cached": 0,
            "total": 2870,
            "numRequests": 2,
            "completionDetails": {
              "reasoning": 0,
              "acceptedPrediction": 0,
              "rejectedPrediction": 0
            },
            "assertions": {
              "total": 1694,
              "prompt": 1350,
              "completion": 344,
              "cached": 0,
              "numRequests": 0,
              "completionDetails": {
                "reasoning": 0,
                "acceptedPrediction": 0,
                "rejectedPrediction": 0
              }
            }
          },
          "namedScores": {},
          "namedScoresCount": {},
          "cost": 0.0005267000000000001
        }
      },
      {
        "raw": "You are a QA reviewer validating whether an AI-extracted scene analysis is accurate and faithful to the source screenplay text.\n\nCompare the extracted scene data against the original scene text and evaluate:\n\n1. **Heading accuracy**: Is the scene heading correct (location, INT/EXT, time of day)?\n2. **Character completeness**: Are all characters who appear or speak listed?\n3. **Summary fidelity**: Does the summary accurately describe what happens? No fabrications?\n4. **Narrative beats**: Are the identified beats actually present in the scene?\n5. **Tone assessment**: Does the tone description match the actual mood of the scene?\n6. **Confidence calibration**: Is the confidence score reasonable given the quality?\n\nReturn a JSON object with:\n- passed: boolean (true if the extraction is faithful, false if it has significant errors)\n- confidence: float 0-1 (your confidence in this QA judgment)\n- issues: array of objects, each with:\n  - severity: \"error\" (factual wrong), \"warning\" (misleading), or \"note\" (minor)\n  - description: what's wrong\n  - location: which field has the issue\n- summary: 1-2 sentence overall assessment\n\nBe strict: wrong character names, fabricated events, or incorrect locations are errors.\nMinor omissions or imprecise tone descriptions are warnings.\n\nReturn ONLY valid JSON. No explanations or markdown fences.\n\n==========\nORIGINAL SCENE TEXT:\n{{scene_text}}\n\n==========\nEXTRACTED SCENE DATA:\n{{extracted_data}}\n==========",
        "label": "prompts/qa-pass.txt: You are a QA reviewer validating whether an AI-extracted scene analysis is accurate and faithful to the source screenplay text.\n\nCompare the extracted scene data against the original scene text and evaluate:\n\n1. **Heading accuracy**: Is the scene heading correct (location, INT/EXT, time of day)?\n2. **Character completeness**: Are all characters who appear or speak listed?\n3. **Summary fidelity**: Does the summary accurately describe what happens? No fabrications?\n4. **Narrative beats**: Are the identified beats actually present in the scene?\n5. **Tone assessment**: Does the tone description match the actual mood of the scene?\n6. **Confidence calibration**: Is the confidence score reasonable given the quality?\n\nReturn a JSON object with:\n- passed: boolean (true if the extraction is faithful, false if it has significant errors)\n- confidence: float 0-1 (your confidence in this QA judgment)\n- issues: array of objects, each with:\n  - severity: \"error\" (factual wrong), \"warning\" (misleading), or \"note\" (minor)\n  - description: what's wrong\n  - location: which field has the issue\n- summary: 1-2 sentence overall assessment\n\nBe strict: wrong character names, fabricated events, or incorrect locations are errors.\nMinor omissions or imprecise tone descriptions are warnings.\n\nReturn ONLY valid JSON. No explanations or markdown fences.\n\n==========\nORIGINAL SCENE TEXT:\n{{scene_text}}\n\n==========\nEXTRACTED SCENE DATA:\n{{extracted_data}}\n==========",
        "id": "8df20c2c4a6081352d6b06e144ddbc1e0a5244f9a3c2000d40df12fc9a94e543",
        "provider": "GPT-4.1 Mini",
        "metrics": {
          "score": 2,
          "testPassCount": 2,
          "testFailCount": 0,
          "testErrorCount": 0,
          "assertPassCount": 4,
          "assertFailCount": 0,
          "totalLatencyMs": 9853,
          "tokenUsage": {
            "prompt": 2071,
            "completion": 574,
            "cached": 0,
            "total": 2645,
            "numRequests": 2,
            "completionDetails": {
              "reasoning": 0,
              "acceptedPrediction": 0,
              "rejectedPrediction": 0
            },
            "assertions": {
              "total": 1393,
              "prompt": 1129,
              "completion": 264,
              "cached": 0,
              "numRequests": 0,
              "completionDetails": {
                "reasoning": 0,
                "acceptedPrediction": 0,
                "rejectedPrediction": 0
              }
            }
          },
          "namedScores": {},
          "namedScoresCount": {},
          "cost": 0.0017468000000000002
        }
      },
      {
        "raw": "You are a QA reviewer validating whether an AI-extracted scene analysis is accurate and faithful to the source screenplay text.\n\nCompare the extracted scene data against the original scene text and evaluate:\n\n1. **Heading accuracy**: Is the scene heading correct (location, INT/EXT, time of day)?\n2. **Character completeness**: Are all characters who appear or speak listed?\n3. **Summary fidelity**: Does the summary accurately describe what happens? No fabrications?\n4. **Narrative beats**: Are the identified beats actually present in the scene?\n5. **Tone assessment**: Does the tone description match the actual mood of the scene?\n6. **Confidence calibration**: Is the confidence score reasonable given the quality?\n\nReturn a JSON object with:\n- passed: boolean (true if the extraction is faithful, false if it has significant errors)\n- confidence: float 0-1 (your confidence in this QA judgment)\n- issues: array of objects, each with:\n  - severity: \"error\" (factual wrong), \"warning\" (misleading), or \"note\" (minor)\n  - description: what's wrong\n  - location: which field has the issue\n- summary: 1-2 sentence overall assessment\n\nBe strict: wrong character names, fabricated events, or incorrect locations are errors.\nMinor omissions or imprecise tone descriptions are warnings.\n\nReturn ONLY valid JSON. No explanations or markdown fences.\n\n==========\nORIGINAL SCENE TEXT:\n{{scene_text}}\n\n==========\nEXTRACTED SCENE DATA:\n{{extracted_data}}\n==========",
        "label": "prompts/qa-pass.txt: You are a QA reviewer validating whether an AI-extracted scene analysis is accurate and faithful to the source screenplay text.\n\nCompare the extracted scene data against the original scene text and evaluate:\n\n1. **Heading accuracy**: Is the scene heading correct (location, INT/EXT, time of day)?\n2. **Character completeness**: Are all characters who appear or speak listed?\n3. **Summary fidelity**: Does the summary accurately describe what happens? No fabrications?\n4. **Narrative beats**: Are the identified beats actually present in the scene?\n5. **Tone assessment**: Does the tone description match the actual mood of the scene?\n6. **Confidence calibration**: Is the confidence score reasonable given the quality?\n\nReturn a JSON object with:\n- passed: boolean (true if the extraction is faithful, false if it has significant errors)\n- confidence: float 0-1 (your confidence in this QA judgment)\n- issues: array of objects, each with:\n  - severity: \"error\" (factual wrong), \"warning\" (misleading), or \"note\" (minor)\n  - description: what's wrong\n  - location: which field has the issue\n- summary: 1-2 sentence overall assessment\n\nBe strict: wrong character names, fabricated events, or incorrect locations are errors.\nMinor omissions or imprecise tone descriptions are warnings.\n\nReturn ONLY valid JSON. No explanations or markdown fences.\n\n==========\nORIGINAL SCENE TEXT:\n{{scene_text}}\n\n==========\nEXTRACTED SCENE DATA:\n{{extracted_data}}\n==========",
        "id": "8df20c2c4a6081352d6b06e144ddbc1e0a5244f9a3c2000d40df12fc9a94e543",
        "provider": "GPT-4.1",
        "metrics": {
          "score": 1.975,
          "testPassCount": 2,
          "testFailCount": 0,
          "testErrorCount": 0,
          "assertPassCount": 4,
          "assertFailCount": 0,
          "totalLatencyMs": 8390,
          "tokenUsage": {
            "prompt": 2071,
            "completion": 465,
            "cached": 0,
            "total": 2536,
            "numRequests": 2,
            "completionDetails": {
              "reasoning": 0,
              "acceptedPrediction": 0,
              "rejectedPrediction": 0
            },
            "assertions": {
              "total": 1292,
              "prompt": 1029,
              "completion": 263,
              "cached": 0,
              "numRequests": 0,
              "completionDetails": {
                "reasoning": 0,
                "acceptedPrediction": 0,
                "rejectedPrediction": 0
              }
            }
          },
          "namedScores": {},
          "namedScoresCount": {},
          "cost": 0.007862000000000001
        }
      },
      {
        "raw": "You are a QA reviewer validating whether an AI-extracted scene analysis is accurate and faithful to the source screenplay text.\n\nCompare the extracted scene data against the original scene text and evaluate:\n\n1. **Heading accuracy**: Is the scene heading correct (location, INT/EXT, time of day)?\n2. **Character completeness**: Are all characters who appear or speak listed?\n3. **Summary fidelity**: Does the summary accurately describe what happens? No fabrications?\n4. **Narrative beats**: Are the identified beats actually present in the scene?\n5. **Tone assessment**: Does the tone description match the actual mood of the scene?\n6. **Confidence calibration**: Is the confidence score reasonable given the quality?\n\nReturn a JSON object with:\n- passed: boolean (true if the extraction is faithful, false if it has significant errors)\n- confidence: float 0-1 (your confidence in this QA judgment)\n- issues: array of objects, each with:\n  - severity: \"error\" (factual wrong), \"warning\" (misleading), or \"note\" (minor)\n  - description: what's wrong\n  - location: which field has the issue\n- summary: 1-2 sentence overall assessment\n\nBe strict: wrong character names, fabricated events, or incorrect locations are errors.\nMinor omissions or imprecise tone descriptions are warnings.\n\nReturn ONLY valid JSON. No explanations or markdown fences.\n\n==========\nORIGINAL SCENE TEXT:\n{{scene_text}}\n\n==========\nEXTRACTED SCENE DATA:\n{{extracted_data}}\n==========",
        "label": "prompts/qa-pass.txt: You are a QA reviewer validating whether an AI-extracted scene analysis is accurate and faithful to the source screenplay text.\n\nCompare the extracted scene data against the original scene text and evaluate:\n\n1. **Heading accuracy**: Is the scene heading correct (location, INT/EXT, time of day)?\n2. **Character completeness**: Are all characters who appear or speak listed?\n3. **Summary fidelity**: Does the summary accurately describe what happens? No fabrications?\n4. **Narrative beats**: Are the identified beats actually present in the scene?\n5. **Tone assessment**: Does the tone description match the actual mood of the scene?\n6. **Confidence calibration**: Is the confidence score reasonable given the quality?\n\nReturn a JSON object with:\n- passed: boolean (true if the extraction is faithful, false if it has significant errors)\n- confidence: float 0-1 (your confidence in this QA judgment)\n- issues: array of objects, each with:\n  - severity: \"error\" (factual wrong), \"warning\" (misleading), or \"note\" (minor)\n  - description: what's wrong\n  - location: which field has the issue\n- summary: 1-2 sentence overall assessment\n\nBe strict: wrong character names, fabricated events, or incorrect locations are errors.\nMinor omissions or imprecise tone descriptions are warnings.\n\nReturn ONLY valid JSON. No explanations or markdown fences.\n\n==========\nORIGINAL SCENE TEXT:\n{{scene_text}}\n\n==========\nEXTRACTED SCENE DATA:\n{{extracted_data}}\n==========",
        "id": "8df20c2c4a6081352d6b06e144ddbc1e0a5244f9a3c2000d40df12fc9a94e543",
        "provider": "Claude Haiku 4.5",
        "metrics": {
          "score": 1.99,
          "testPassCount": 2,
          "testFailCount": 0,
          "testErrorCount": 0,
          "assertPassCount": 4,
          "assertFailCount": 0,
          "totalLatencyMs": 8230,
          "tokenUsage": {
            "prompt": 2262,
            "completion": 778,
            "cached": 0,
            "total": 3040,
            "numRequests": 2,
            "completionDetails": {
              "reasoning": 0,
              "acceptedPrediction": 0,
              "rejectedPrediction": 0
            },
            "assertions": {
              "total": 1689,
              "prompt": 1415,
              "completion": 274,
              "cached": 0,
              "numRequests": 0,
              "completionDetails": {
                "reasoning": 0,
                "acceptedPrediction": 0,
                "rejectedPrediction": 0
              }
            }
          },
          "namedScores": {},
          "namedScoresCount": {},
          "cost": 0.006152
        }
      },
      {
        "raw": "You are a QA reviewer validating whether an AI-extracted scene analysis is accurate and faithful to the source screenplay text.\n\nCompare the extracted scene data against the original scene text and evaluate:\n\n1. **Heading accuracy**: Is the scene heading correct (location, INT/EXT, time of day)?\n2. **Character completeness**: Are all characters who appear or speak listed?\n3. **Summary fidelity**: Does the summary accurately describe what happens? No fabrications?\n4. **Narrative beats**: Are the identified beats actually present in the scene?\n5. **Tone assessment**: Does the tone description match the actual mood of the scene?\n6. **Confidence calibration**: Is the confidence score reasonable given the quality?\n\nReturn a JSON object with:\n- passed: boolean (true if the extraction is faithful, false if it has significant errors)\n- confidence: float 0-1 (your confidence in this QA judgment)\n- issues: array of objects, each with:\n  - severity: \"error\" (factual wrong), \"warning\" (misleading), or \"note\" (minor)\n  - description: what's wrong\n  - location: which field has the issue\n- summary: 1-2 sentence overall assessment\n\nBe strict: wrong character names, fabricated events, or incorrect locations are errors.\nMinor omissions or imprecise tone descriptions are warnings.\n\nReturn ONLY valid JSON. No explanations or markdown fences.\n\n==========\nORIGINAL SCENE TEXT:\n{{scene_text}}\n\n==========\nEXTRACTED SCENE DATA:\n{{extracted_data}}\n==========",
        "label": "prompts/qa-pass.txt: You are a QA reviewer validating whether an AI-extracted scene analysis is accurate and faithful to the source screenplay text.\n\nCompare the extracted scene data against the original scene text and evaluate:\n\n1. **Heading accuracy**: Is the scene heading correct (location, INT/EXT, time of day)?\n2. **Character completeness**: Are all characters who appear or speak listed?\n3. **Summary fidelity**: Does the summary accurately describe what happens? No fabrications?\n4. **Narrative beats**: Are the identified beats actually present in the scene?\n5. **Tone assessment**: Does the tone description match the actual mood of the scene?\n6. **Confidence calibration**: Is the confidence score reasonable given the quality?\n\nReturn a JSON object with:\n- passed: boolean (true if the extraction is faithful, false if it has significant errors)\n- confidence: float 0-1 (your confidence in this QA judgment)\n- issues: array of objects, each with:\n  - severity: \"error\" (factual wrong), \"warning\" (misleading), or \"note\" (minor)\n  - description: what's wrong\n  - location: which field has the issue\n- summary: 1-2 sentence overall assessment\n\nBe strict: wrong character names, fabricated events, or incorrect locations are errors.\nMinor omissions or imprecise tone descriptions are warnings.\n\nReturn ONLY valid JSON. No explanations or markdown fences.\n\n==========\nORIGINAL SCENE TEXT:\n{{scene_text}}\n\n==========\nEXTRACTED SCENE DATA:\n{{extracted_data}}\n==========",
        "id": "8df20c2c4a6081352d6b06e144ddbc1e0a5244f9a3c2000d40df12fc9a94e543",
        "provider": "Claude Sonnet 4.5",
        "metrics": {
          "score": 1.99,
          "testPassCount": 2,
          "testFailCount": 0,
          "testErrorCount": 0,
          "assertPassCount": 4,
          "assertFailCount": 0,
          "totalLatencyMs": 14810,
          "tokenUsage": {
            "prompt": 2262,
            "completion": 708,
            "cached": 0,
            "total": 2970,
            "numRequests": 2,
            "completionDetails": {
              "reasoning": 0,
              "acceptedPrediction": 0,
              "rejectedPrediction": 0
            },
            "assertions": {
              "total": 1635,
              "prompt": 1345,
              "completion": 290,
              "cached": 0,
              "numRequests": 0,
              "completionDetails": {
                "reasoning": 0,
                "acceptedPrediction": 0,
                "rejectedPrediction": 0
              }
            }
          },
          "namedScores": {},
          "namedScoresCount": {},
          "cost": 0.017405999999999998
        }
      },
      {
        "raw": "You are a QA reviewer validating whether an AI-extracted scene analysis is accurate and faithful to the source screenplay text.\n\nCompare the extracted scene data against the original scene text and evaluate:\n\n1. **Heading accuracy**: Is the scene heading correct (location, INT/EXT, time of day)?\n2. **Character completeness**: Are all characters who appear or speak listed?\n3. **Summary fidelity**: Does the summary accurately describe what happens? No fabrications?\n4. **Narrative beats**: Are the identified beats actually present in the scene?\n5. **Tone assessment**: Does the tone description match the actual mood of the scene?\n6. **Confidence calibration**: Is the confidence score reasonable given the quality?\n\nReturn a JSON object with:\n- passed: boolean (true if the extraction is faithful, false if it has significant errors)\n- confidence: float 0-1 (your confidence in this QA judgment)\n- issues: array of objects, each with:\n  - severity: \"error\" (factual wrong), \"warning\" (misleading), or \"note\" (minor)\n  - description: what's wrong\n  - location: which field has the issue\n- summary: 1-2 sentence overall assessment\n\nBe strict: wrong character names, fabricated events, or incorrect locations are errors.\nMinor omissions or imprecise tone descriptions are warnings.\n\nReturn ONLY valid JSON. No explanations or markdown fences.\n\n==========\nORIGINAL SCENE TEXT:\n{{scene_text}}\n\n==========\nEXTRACTED SCENE DATA:\n{{extracted_data}}\n==========",
        "label": "prompts/qa-pass.txt: You are a QA reviewer validating whether an AI-extracted scene analysis is accurate and faithful to the source screenplay text.\n\nCompare the extracted scene data against the original scene text and evaluate:\n\n1. **Heading accuracy**: Is the scene heading correct (location, INT/EXT, time of day)?\n2. **Character completeness**: Are all characters who appear or speak listed?\n3. **Summary fidelity**: Does the summary accurately describe what happens? No fabrications?\n4. **Narrative beats**: Are the identified beats actually present in the scene?\n5. **Tone assessment**: Does the tone description match the actual mood of the scene?\n6. **Confidence calibration**: Is the confidence score reasonable given the quality?\n\nReturn a JSON object with:\n- passed: boolean (true if the extraction is faithful, false if it has significant errors)\n- confidence: float 0-1 (your confidence in this QA judgment)\n- issues: array of objects, each with:\n  - severity: \"error\" (factual wrong), \"warning\" (misleading), or \"note\" (minor)\n  - description: what's wrong\n  - location: which field has the issue\n- summary: 1-2 sentence overall assessment\n\nBe strict: wrong character names, fabricated events, or incorrect locations are errors.\nMinor omissions or imprecise tone descriptions are warnings.\n\nReturn ONLY valid JSON. No explanations or markdown fences.\n\n==========\nORIGINAL SCENE TEXT:\n{{scene_text}}\n\n==========\nEXTRACTED SCENE DATA:\n{{extracted_data}}\n==========",
        "id": "8df20c2c4a6081352d6b06e144ddbc1e0a5244f9a3c2000d40df12fc9a94e543",
        "provider": "Claude Sonnet 4.6",
        "metrics": {
          "score": 1.995,
          "testPassCount": 2,
          "testFailCount": 0,
          "testErrorCount": 0,
          "assertPassCount": 4,
          "assertFailCount": 0,
          "totalLatencyMs": 20011,
          "tokenUsage": {
            "prompt": 2262,
            "completion": 1091,
            "cached": 0,
            "total": 3353,
            "numRequests": 2,
            "completionDetails": {
              "reasoning": 0,
              "acceptedPrediction": 0,
              "rejectedPrediction": 0
            },
            "assertions": {
              "total": 1854,
              "prompt": 1583,
              "completion": 271,
              "cached": 0,
              "numRequests": 0,
              "completionDetails": {
                "reasoning": 0,
                "acceptedPrediction": 0,
                "rejectedPrediction": 0
              }
            }
          },
          "namedScores": {},
          "namedScoresCount": {},
          "cost": 0
        }
      },
      {
        "raw": "You are a QA reviewer validating whether an AI-extracted scene analysis is accurate and faithful to the source screenplay text.\n\nCompare the extracted scene data against the original scene text and evaluate:\n\n1. **Heading accuracy**: Is the scene heading correct (location, INT/EXT, time of day)?\n2. **Character completeness**: Are all characters who appear or speak listed?\n3. **Summary fidelity**: Does the summary accurately describe what happens? No fabrications?\n4. **Narrative beats**: Are the identified beats actually present in the scene?\n5. **Tone assessment**: Does the tone description match the actual mood of the scene?\n6. **Confidence calibration**: Is the confidence score reasonable given the quality?\n\nReturn a JSON object with:\n- passed: boolean (true if the extraction is faithful, false if it has significant errors)\n- confidence: float 0-1 (your confidence in this QA judgment)\n- issues: array of objects, each with:\n  - severity: \"error\" (factual wrong), \"warning\" (misleading), or \"note\" (minor)\n  - description: what's wrong\n  - location: which field has the issue\n- summary: 1-2 sentence overall assessment\n\nBe strict: wrong character names, fabricated events, or incorrect locations are errors.\nMinor omissions or imprecise tone descriptions are warnings.\n\nReturn ONLY valid JSON. No explanations or markdown fences.\n\n==========\nORIGINAL SCENE TEXT:\n{{scene_text}}\n\n==========\nEXTRACTED SCENE DATA:\n{{extracted_data}}\n==========",
        "label": "prompts/qa-pass.txt: You are a QA reviewer validating whether an AI-extracted scene analysis is accurate and faithful to the source screenplay text.\n\nCompare the extracted scene data against the original scene text and evaluate:\n\n1. **Heading accuracy**: Is the scene heading correct (location, INT/EXT, time of day)?\n2. **Character completeness**: Are all characters who appear or speak listed?\n3. **Summary fidelity**: Does the summary accurately describe what happens? No fabrications?\n4. **Narrative beats**: Are the identified beats actually present in the scene?\n5. **Tone assessment**: Does the tone description match the actual mood of the scene?\n6. **Confidence calibration**: Is the confidence score reasonable given the quality?\n\nReturn a JSON object with:\n- passed: boolean (true if the extraction is faithful, false if it has significant errors)\n- confidence: float 0-1 (your confidence in this QA judgment)\n- issues: array of objects, each with:\n  - severity: \"error\" (factual wrong), \"warning\" (misleading), or \"note\" (minor)\n  - description: what's wrong\n  - location: which field has the issue\n- summary: 1-2 sentence overall assessment\n\nBe strict: wrong character names, fabricated events, or incorrect locations are errors.\nMinor omissions or imprecise tone descriptions are warnings.\n\nReturn ONLY valid JSON. No explanations or markdown fences.\n\n==========\nORIGINAL SCENE TEXT:\n{{scene_text}}\n\n==========\nEXTRACTED SCENE DATA:\n{{extracted_data}}\n==========",
        "id": "8df20c2c4a6081352d6b06e144ddbc1e0a5244f9a3c2000d40df12fc9a94e543",
        "provider": "GPT-5.2",
        "metrics": {
          "score": 2,
          "testPassCount": 2,
          "testFailCount": 0,
          "testErrorCount": 0,
          "assertPassCount": 4,
          "assertFailCount": 0,
          "totalLatencyMs": 12152,
          "tokenUsage": {
            "prompt": 2069,
            "completion": 665,
            "cached": 0,
            "total": 2734,
            "numRequests": 2,
            "completionDetails": {
              "reasoning": 0,
              "acceptedPrediction": 0,
              "rejectedPrediction": 0
            },
            "assertions": {
              "total": 1503,
              "prompt": 1217,
              "completion": 286,
              "cached": 0,
              "numRequests": 0,
              "completionDetails": {
                "reasoning": 0,
                "acceptedPrediction": 0,
                "rejectedPrediction": 0
              }
            }
          },
          "namedScores": {},
          "namedScoresCount": {},
          "cost": 0.01293075
        }
      },
      {
        "raw": "You are a QA reviewer validating whether an AI-extracted scene analysis is accurate and faithful to the source screenplay text.\n\nCompare the extracted scene data against the original scene text and evaluate:\n\n1. **Heading accuracy**: Is the scene heading correct (location, INT/EXT, time of day)?\n2. **Character completeness**: Are all characters who appear or speak listed?\n3. **Summary fidelity**: Does the summary accurately describe what happens? No fabrications?\n4. **Narrative beats**: Are the identified beats actually present in the scene?\n5. **Tone assessment**: Does the tone description match the actual mood of the scene?\n6. **Confidence calibration**: Is the confidence score reasonable given the quality?\n\nReturn a JSON object with:\n- passed: boolean (true if the extraction is faithful, false if it has significant errors)\n- confidence: float 0-1 (your confidence in this QA judgment)\n- issues: array of objects, each with:\n  - severity: \"error\" (factual wrong), \"warning\" (misleading), or \"note\" (minor)\n  - description: what's wrong\n  - location: which field has the issue\n- summary: 1-2 sentence overall assessment\n\nBe strict: wrong character names, fabricated events, or incorrect locations are errors.\nMinor omissions or imprecise tone descriptions are warnings.\n\nReturn ONLY valid JSON. No explanations or markdown fences.\n\n==========\nORIGINAL SCENE TEXT:\n{{scene_text}}\n\n==========\nEXTRACTED SCENE DATA:\n{{extracted_data}}\n==========",
        "label": "prompts/qa-pass.txt: You are a QA reviewer validating whether an AI-extracted scene analysis is accurate and faithful to the source screenplay text.\n\nCompare the extracted scene data against the original scene text and evaluate:\n\n1. **Heading accuracy**: Is the scene heading correct (location, INT/EXT, time of day)?\n2. **Character completeness**: Are all characters who appear or speak listed?\n3. **Summary fidelity**: Does the summary accurately describe what happens? No fabrications?\n4. **Narrative beats**: Are the identified beats actually present in the scene?\n5. **Tone assessment**: Does the tone description match the actual mood of the scene?\n6. **Confidence calibration**: Is the confidence score reasonable given the quality?\n\nReturn a JSON object with:\n- passed: boolean (true if the extraction is faithful, false if it has significant errors)\n- confidence: float 0-1 (your confidence in this QA judgment)\n- issues: array of objects, each with:\n  - severity: \"error\" (factual wrong), \"warning\" (misleading), or \"note\" (minor)\n  - description: what's wrong\n  - location: which field has the issue\n- summary: 1-2 sentence overall assessment\n\nBe strict: wrong character names, fabricated events, or incorrect locations are errors.\nMinor omissions or imprecise tone descriptions are warnings.\n\nReturn ONLY valid JSON. No explanations or markdown fences.\n\n==========\nORIGINAL SCENE TEXT:\n{{scene_text}}\n\n==========\nEXTRACTED SCENE DATA:\n{{extracted_data}}\n==========",
        "id": "8df20c2c4a6081352d6b06e144ddbc1e0a5244f9a3c2000d40df12fc9a94e543",
        "provider": "Claude Opus 4.6",
        "metrics": {
          "score": 1.99,
          "testPassCount": 2,
          "testFailCount": 0,
          "testErrorCount": 0,
          "assertPassCount": 4,
          "assertFailCount": 0,
          "totalLatencyMs": 19550,
          "tokenUsage": {
            "prompt": 2262,
            "completion": 1002,
            "cached": 0,
            "total": 3264,
            "numRequests": 2,
            "completionDetails": {
              "reasoning": 0,
              "acceptedPrediction": 0,
              "rejectedPrediction": 0
            },
            "assertions": {
              "total": 1879,
              "prompt": 1639,
              "completion": 240,
              "cached": 0,
              "numRequests": 0,
              "completionDetails": {
                "reasoning": 0,
                "acceptedPrediction": 0,
                "rejectedPrediction": 0
              }
            }
          },
          "namedScores": {},
          "namedScoresCount": {},
          "cost": 0.03636
        }
      }
    ],
    "results": [
      {
        "cost": 0.0003111,
        "error": "The QA evaluation marked the output as 'passed: false' with confidence 0.75 and identified multiple 'error' severity issues, including claims about fabricated details (skull fragment vs. bloody scrap, violent rescue context). According to the rubric, this was a GOOD scene extraction that accurately reflects the source text, so the QA model should have marked it as passed with zero or very few errors and high confidence. Instead, it produced a false negative by incorrectly flagging the good extraction as failing. This is exactly the failure mode the rubric warns about.",
        "gradingResult": {
          "pass": false,
          "score": 0.19,
          "reason": "The QA evaluation marked the output as 'passed: false' with confidence 0.75 and identified multiple 'error' severity issues, including claims about fabricated details (skull fragment vs. bloody scrap, violent rescue context). According to the rubric, this was a GOOD scene extraction that accurately reflects the source text, so the QA model should have marked it as passed with zero or very few errors and high confidence. Instead, it produced a false negative by incorrectly flagging the good extraction as failing. This is exactly the failure mode the rubric warns about.",
          "namedScores": {},
          "tokensUsed": {
            "total": 890,
            "prompt": 748,
            "completion": 142,
            "cached": 0,
            "numRequests": 0
          },
          "componentResults": [
            {
              "pass": false,
              "score": 0.33,
              "reason": "confidence_calibration=1.00 | issue_detection=0.00 | json_valid=1.00 | pass_correct=0.00 | severity_accuracy=0.20 | summary_quality=1.00 | passed=False, expected=True | Good output: 4 errors found (max 0)",
              "assertion": {
                "type": "python",
                "value": "file://../scorers/qa_pass_scorer.py"
              }
            },
            {
              "assertion": {
                "type": "llm-rubric",
                "value": "This QA evaluation was given a GOOD scene extraction that accurately\nreflects the source text. The QA model should have:\n\n1. Marked it as passed (true)\n2. Found zero or very few errors\n3. Had high confidence in the assessment\n4. Written a summary confirming accuracy\n\nIf the model incorrectly flagged the good extraction as failing,\nthat's a false negative and should score poorly.\n"
              },
              "pass": false,
              "score": 0.05,
              "reason": "The QA evaluation marked the output as 'passed: false' with confidence 0.75 and identified multiple 'error' severity issues, including claims about fabricated details (skull fragment vs. bloody scrap, violent rescue context). According to the rubric, this was a GOOD scene extraction that accurately reflects the source text, so the QA model should have marked it as passed with zero or very few errors and high confidence. Instead, it produced a false negative by incorrectly flagging the good extraction as failing. This is exactly the failure mode the rubric warns about.",
              "tokensUsed": {
                "total": 890,
                "prompt": 748,
                "completion": 142,
                "cached": 0,
                "numRequests": 0,
                "completionDetails": {
                  "reasoning": 0,
                  "acceptedPrediction": 0,
                  "rejectedPrediction": 0
                }
              },
              "metadata": {
                "renderedGradingPrompt": "[{\"role\":\"system\",\"content\":\"You are grading output according to a user-specified rubric. If the statement in the rubric is true, then the output passes the test. You respond with a JSON object with this structure: {reason: string, pass: boolean, score: number}\\n\\nExamples:\\n\\n<Output>Hello world</Output>\\n<Rubric>Content contains a greeting</Rubric>\\n{\\\"reason\\\": \\\"the content contains the word 'Hello'\\\", \\\"pass\\\": true, \\\"score\\\": 1.0}\\n\\n<Output>Avast ye swabs, repel the invaders!</Output>\\n<Rubric>Does not speak like a pirate</Rubric>\\n{\\\"reason\\\": \\\"'avast ye' is a common pirate term\\\", \\\"pass\\\": false, \\\"score\\\": 0.0}\"},{\"role\":\"user\",\"content\":\"<Output>\\n{\\\"passed\\\":false,\\\"confidence\\\":0.75,\\\"issues\\\":[{\\\"severity\\\":\\\"error\\\",\\\"description\\\":\\\"The scene heading is correct, but the original text specifies the location as 'RUDDY & GREEN BUILDING - ELEVATOR' which matches, so no issue here.\\\",\\\"location\\\":\\\"heading\\\"},{\\\"severity\\\":\\\"error\\\",\\\"description\\\":\\\"The characters listed are correct; both Rose and Mariner are present and mentioned.\\\",\\\"location\\\":\\\"characters_present\\\"},{\\\"severity\\\":\\\"error\\\",\\\"description\\\":\\\"The summary states Rose discovers a skull fragment on the floor, but the original scene mentions she picks up a bloody scrap with hair, not a skull fragment. Also, the scene does not specify that Rose is riding the elevator after a rescue; it only shows her in the elevator. The mention of a 'violent rescue' is fabricated. The description of Mariner's costume is accurate, but the summary's depiction of the scene's events introduces inaccuracies.\\\",\\\"location\\\":\\\"summary\\\"},{\\\"severity\\\":\\\"error\\\",\\\"description\\\":\\\"The narrative beats include a full description of Mariner's costume, which is accurate, but the scene does not explicitly include a 'comic relief' beat with the skull fragment discovery; that is an interpretation. The 'revelation' about the AirTag is present, but the 'conflict' beat about Rose's anger escalating is a simplification; the scene shows her initial anger and surprise, but not necessarily an escalation to anger.\\\",\\\"location\\\":\\\"narrative_beats\\\"},{\\\"severity\\\":\\\"warning\\\",\\\"description\\\":\\\"The tone is described as 'dark comedy with bursts of tension,' which is a reasonable interpretation but somewhat subjective. The scene's mood is tense and dark, with some dark humor elements, so this is acceptable as a warning.\\\",\\\"location\\\":\\\"tone_mood\\\"}],\\\"summary\\\":\\\"The scene analysis contains significant inaccuracies in the summary and narrative beats, particularly regarding the discovery of a skull fragment and the scene's context. While character and location details are correct, the fabricated or misinterpreted elements reduce overall fidelity. The tone assessment is reasonable but subjective. Overall, the extraction is not fully faithful to the source scene.\\\"}\\n</Output>\\n<Rubric>\\nThis QA evaluation was given a GOOD scene extraction that accurately\\nreflects the source text. The QA model should have:\\n\\n1. Marked it as passed (true)\\n2. Found zero or very few errors\\n3. Had high confidence in the assessment\\n4. Written a summary confirming accuracy\\n\\nIf the model incorrectly flagged the good extraction as failing,\\nthat's a false negative and should score poorly.\\n\\n</Rubric>\"}]"
              }
            }
          ]
        },
        "id": "05558888-bf9f-49b3-ba15-d310718b525b",
        "latencyMs": 7728,
        "namedScores": {},
        "prompt": {
          "raw": "You are a QA reviewer validating whether an AI-extracted scene analysis is accurate and faithful to the source screenplay text.\n\nCompare the extracted scene data against the original scene text and evaluate:\n\n1. **Heading accuracy**: Is the scene heading correct (location, INT/EXT, time of day)?\n2. **Character completeness**: Are all characters who appear or speak listed?\n3. **Summary fidelity**: Does the summary accurately describe what happens? No fabrications?\n4. **Narrative beats**: Are the identified beats actually present in the scene?\n5. **Tone assessment**: Does the tone description match the actual mood of the scene?\n6. **Confidence calibration**: Is the confidence score reasonable given the quality?\n\nReturn a JSON object with:\n- passed: boolean (true if the extraction is faithful, false if it has significant errors)\n- confidence: float 0-1 (your confidence in this QA judgment)\n- issues: array of objects, each with:\n  - severity: \"error\" (factual wrong), \"warning\" (misleading), or \"note\" (minor)\n  - description: what's wrong\n  - location: which field has the issue\n- summary: 1-2 sentence overall assessment\n\nBe strict: wrong character names, fabricated events, or incorrect locations are errors.\nMinor omissions or imprecise tone descriptions are warnings.\n\nReturn ONLY valid JSON. No explanations or markdown fences.\n\n==========\nORIGINAL SCENE TEXT:\nINT. RUDDY & GREEN BUILDING - ELEVATOR\n\nUB40's \"I Can't Help Falling in Love With You\" muzak.\n\nROSE (mid-30s) leans against the elevator wall, panting. She's wearing a Tim Hortons uniform, her hair is a mess, and there's blood spattered on her face.\n\nShe looks right, pants a few more times, then squints in disgust. She gingerly picks up a bloody scrap of something with hair on it. She snorts and drops it.\n\nROSE\nIs that skull??\n\nNext to her is Mariner, also panting, covered in far more blood. His face is broad, stoic, and frowning. He has gray-blue eyes and a thick, curly, beard barely streaked with gray. He wears a red knit cap and a small mask.\n\nFULL-SCREEN SUPERIMPOSED TITLE CARD: \"THE MARINER\"\n\nHe blinks a few times as a drop of blood falls from his eyebrow. He looks toward her, then spits out some blood.\n\nMARINER\nYeaaaaah...\n\nHe's built like a pro-wrestler. Moss green SWEATER stretched over his huge frame, sleeves rolled showing heavy leather BRACERS adorned with anchors. His inner forearm has a classic heart-and-arrow TATTOO with \"Dad\" in the centre. Across his chest is a BANDOLIER of bright red 12-gauge shells, FISH HOOKS hanging from the bottom edge. Heavy rubberized BOOTS go past his knees. A CAPE of heavy FISHING NET edged with WEIGHTS hangs from his shoulders.\n\nHe holds a STOUT WOODEN OAR in both hands, edged with METAL and dripping with BLOOD.\n\nROSE\nWhere were you when they grabbed me? You were supposed to pick me up at work!\n\nMARINER\nYeah, about that, I got a little... distracted.\n\nROSE\nDistracted. You got DISTRACTED?!\n\nMARINER\nI was also... tracking the car... that grabbed you... through the AirTag... I put on your phone.\n\nRose stops. She's really not happy about this.\n\nROSE\nYou Airtagged me?!\n\n==========\nEXTRACTED SCENE DATA:\n{\n  \"scene_number\": 4,\n  \"heading\": \"INT. RUDDY & GREEN BUILDING - ELEVATOR\",\n  \"int_ext\": \"INT\",\n  \"location\": \"RUDDY & GREEN BUILDING - ELEVATOR\",\n  \"time_of_day\": null,\n  \"characters_present\": [\"ROSE\", \"MARINER\"],\n  \"summary\": \"Rose and Mariner ride the elevator after a violent rescue. Rose discovers a skull fragment on the floor while muzak plays. Mariner is introduced in full — a hulking vigilante in fishing-themed costume with an oar, net cape, and shell bandolier. Rose confronts him about being late to pick her up, and he reveals he tracked her via an AirTag on her phone, sparking a trust conflict between them.\",\n  \"narrative_beats\": [\n    {\"beat_type\": \"character_introduction\", \"description\": \"Full description of Mariner's fishing-themed vigilante costume — oar, net cape, bracers, shell bandolier, fish hooks.\", \"confidence\": 0.95},\n    {\"beat_type\": \"comic_relief\", \"description\": \"Rose discovers a skull fragment while muzak plays, establishing the dark comedy tone.\", \"confidence\": 0.90},\n    {\"beat_type\": \"revelation\", \"description\": \"Mariner admits he tracked Rose via AirTag on her phone, creating a trust conflict.\", \"confidence\": 0.88},\n    {\"beat_type\": \"conflict\", \"description\": \"Rose's anger escalates from being grabbed to learning she was being surveilled by Mariner.\", \"confidence\": 0.85}\n  ],\n  \"tone_mood\": \"dark comedy with bursts of tension\",\n  \"confidence\": 0.91\n}\n==========",
          "label": "prompts/qa-pass.txt: You are a QA reviewer validating whether an AI-extracted scene analysis is accurate and faithful to the source screenplay text.\n\nCompare the extracted scene data against the original scene text and evaluate:\n\n1. **Heading accuracy**: Is the scene heading correct (location, INT/EXT, time of day)?\n2. **Character completeness**: Are all characters who appear or speak listed?\n3. **Summary fidelity**: Does the summary accurately describe what happens? No fabrications?\n4. **Narrative beats**: Are the identified beats actually present in the scene?\n5. **Tone assessment**: Does the tone description match the actual mood of the scene?\n6. **Confidence calibration**: Is the confidence score reasonable given the quality?\n\nReturn a JSON object with:\n- passed: boolean (true if the extraction is faithful, false if it has significant errors)\n- confidence: float 0-1 (your confidence in this QA judgment)\n- issues: array of objects, each with:\n  - severity: \"error\" (factual wrong), \"warning\" (misleading), or \"note\" (minor)\n  - description: what's wrong\n  - location: which field has the issue\n- summary: 1-2 sentence overall assessment\n\nBe strict: wrong character names, fabricated events, or incorrect locations are errors.\nMinor omissions or imprecise tone descriptions are warnings.\n\nReturn ONLY valid JSON. No explanations or markdown fences.\n\n==========\nORIGINAL SCENE TEXT:\n{{scene_text}}\n\n==========\nEXTRACTED SCENE DATA:\n{{extracted_data}}\n==========",
          "config": {
            "provider": "anthropic:messages:claude-opus-4-6"
          }
        },
        "promptId": "8df20c2c4a6081352d6b06e144ddbc1e0a5244f9a3c2000d40df12fc9a94e543",
        "promptIdx": 0,
        "provider": {
          "id": "openai:gpt-4.1-nano",
          "label": "GPT-4.1 Nano"
        },
        "response": {
          "output": "{\n  \"passed\": false,\n  \"confidence\": 0.75,\n  \"issues\": [\n    {\n      \"severity\": \"error\",\n      \"description\": \"The scene heading is correct, but the original text specifies the location as 'RUDDY & GREEN BUILDING - ELEVATOR' which matches, so no issue here.\",\n      \"location\": \"heading\"\n    },\n    {\n      \"severity\": \"error\",\n      \"description\": \"The characters listed are correct; both Rose and Mariner are present and mentioned.\",\n      \"location\": \"characters_present\"\n    },\n    {\n      \"severity\": \"error\",\n      \"description\": \"The summary states Rose discovers a skull fragment on the floor, but the original scene mentions she picks up a bloody scrap with hair, not a skull fragment. Also, the scene does not specify that Rose is riding the elevator after a rescue; it only shows her in the elevator. The mention of a 'violent rescue' is fabricated. The description of Mariner's costume is accurate, but the summary's depiction of the scene's events introduces inaccuracies.\",\n      \"location\": \"summary\"\n    },\n    {\n      \"severity\": \"error\",\n      \"description\": \"The narrative beats include a full description of Mariner's costume, which is accurate, but the scene does not explicitly include a 'comic relief' beat with the skull fragment discovery; that is an interpretation. The 'revelation' about the AirTag is present, but the 'conflict' beat about Rose's anger escalating is a simplification; the scene shows her initial anger and surprise, but not necessarily an escalation to anger.\",\n      \"location\": \"narrative_beats\"\n    },\n    {\n      \"severity\": \"warning\",\n      \"description\": \"The tone is described as 'dark comedy with bursts of tension,' which is a reasonable interpretation but somewhat subjective. The scene's mood is tense and dark, with some dark humor elements, so this is acceptable as a warning.\",\n      \"location\": \"tone_mood\"\n    }\n  ],\n  \"summary\": \"The scene analysis contains significant inaccuracies in the summary and narrative beats, particularly regarding the discovery of a skull fragment and the scene's context. While character and location details are correct, the fabricated or misinterpreted elements reduce overall fidelity. The tone assessment is reasonable but subjective. Overall, the extraction is not fully faithful to the source scene.\"\n}",
          "tokenUsage": {
            "total": 1635,
            "prompt": 1143,
            "completion": 492,
            "numRequests": 1,
            "completionDetails": {
              "reasoning": 0,
              "acceptedPrediction": 0,
              "rejectedPrediction": 0
            }
          },
          "cached": false,
          "latencyMs": 7728,
          "finishReason": "stop",
          "cost": 0.0003111,
          "guardrails": {
            "flagged": false
          },
          "metadata": {
            "http": {
              "status": 200,
              "statusText": "OK",
              "headers": {
                "access-control-expose-headers": "X-Request-ID",
                "alt-svc": "h3=\":443\"; ma=86400",
                "cf-cache-status": "DYNAMIC",
                "cf-ray": "9cfbd2abb8635819-YVR",
                "connection": "keep-alive",
                "content-encoding": "br",
                "content-type": "application/json",
                "date": "Wed, 18 Feb 2026 07:31:13 GMT",
                "openai-organization": "user-oqdrq8y0bphopngnvkyuu5wr",
                "openai-processing-ms": "7466",
                "openai-project": "proj_ZRoLLwXcJok6Xg2t6eKhI1pn",
                "openai-version": "2020-10-01",
                "server": "cloudflare",
                "set-cookie": "__cf_bm=J755skJKzlcsrz8iQTx49.tRNmmMYhwHOaTRMi7YBAc-1771399866.1917958-1.0.1.1-OTiOW9uz6MJvPbbLmXweiJ9YQeUe1vxuPfKlshp60n3fnTC1mKZ1zjpqEhhuCNXaT19AktGrEhDEoHg9I9.ZWU05I5FQNDl2l8oqZkSVJfhI92pazdfJAMQkdJVzetqH; HttpOnly; Secure; Path=/; Domain=api.openai.com; Expires=Wed, 18 Feb 2026 08:01:13 GMT",
                "strict-transport-security": "max-age=31536000; includeSubDomains; preload",
                "transfer-encoding": "chunked",
                "x-content-type-options": "nosniff",
                "x-openai-proxy-wasm": "v0.1",
                "x-ratelimit-limit-requests": "10000",
                "x-ratelimit-limit-tokens": "10000000",
                "x-ratelimit-remaining-requests": "9999",
                "x-ratelimit-remaining-tokens": "9998856",
                "x-ratelimit-reset-requests": "6ms",
                "x-ratelimit-reset-tokens": "6ms",
                "x-request-id": "req_50d86a50b2604a46ad2ff243fc5fd6dd"
              }
            }
          }
        },
        "score": 0.19,
        "success": false,
        "testCase": {
          "vars": {
            "scene_text": "file://../input/enrich-scene-elevator.txt",
            "extracted_data": "file://../input/qa-good-scene.json",
            "golden_path": "golden/qa-pass-golden.json",
            "test_key": "good_scene"
          },
          "assert": [
            {
              "type": "python",
              "value": "file://../scorers/qa_pass_scorer.py"
            },
            {
              "type": "llm-rubric",
              "value": "This QA evaluation was given a GOOD scene extraction that accurately\nreflects the source text. The QA model should have:\n\n1. Marked it as passed (true)\n2. Found zero or very few errors\n3. Had high confidence in the assessment\n4. Written a summary confirming accuracy\n\nIf the model incorrectly flagged the good extraction as failing,\nthat's a false negative and should score poorly.\n"
            }
          ],
          "options": {
            "provider": "anthropic:messages:claude-opus-4-6"
          },
          "metadata": {}
        },
        "testIdx": 0,
        "vars": {
          "scene_text": "file://../input/enrich-scene-elevator.txt",
          "extracted_data": "file://../input/qa-good-scene.json",
          "golden_path": "golden/qa-pass-golden.json",
          "test_key": "good_scene"
        },
        "metadata": {
          "http": {
            "status": 200,
            "statusText": "OK",
            "headers": {
              "access-control-expose-headers": "X-Request-ID",
              "alt-svc": "h3=\":443\"; ma=86400",
              "cf-cache-status": "DYNAMIC",
              "cf-ray": "9cfbd2abb8635819-YVR",
              "connection": "keep-alive",
              "content-encoding": "br",
              "content-type": "application/json",
              "date": "Wed, 18 Feb 2026 07:31:13 GMT",
              "openai-organization": "user-oqdrq8y0bphopngnvkyuu5wr",
              "openai-processing-ms": "7466",
              "openai-project": "proj_ZRoLLwXcJok6Xg2t6eKhI1pn",
              "openai-version": "2020-10-01",
              "server": "cloudflare",
              "set-cookie": "__cf_bm=J755skJKzlcsrz8iQTx49.tRNmmMYhwHOaTRMi7YBAc-1771399866.1917958-1.0.1.1-OTiOW9uz6MJvPbbLmXweiJ9YQeUe1vxuPfKlshp60n3fnTC1mKZ1zjpqEhhuCNXaT19AktGrEhDEoHg9I9.ZWU05I5FQNDl2l8oqZkSVJfhI92pazdfJAMQkdJVzetqH; HttpOnly; Secure; Path=/; Domain=api.openai.com; Expires=Wed, 18 Feb 2026 08:01:13 GMT",
              "strict-transport-security": "max-age=31536000; includeSubDomains; preload",
              "transfer-encoding": "chunked",
              "x-content-type-options": "nosniff",
              "x-openai-proxy-wasm": "v0.1",
              "x-ratelimit-limit-requests": "10000",
              "x-ratelimit-limit-tokens": "10000000",
              "x-ratelimit-remaining-requests": "9999",
              "x-ratelimit-remaining-tokens": "9998856",
              "x-ratelimit-reset-requests": "6ms",
              "x-ratelimit-reset-tokens": "6ms",
              "x-request-id": "req_50d86a50b2604a46ad2ff243fc5fd6dd"
            }
          },
          "_promptfooFileMetadata": {}
        },
        "failureReason": 1
      },
      {
        "cost": 0.00315,
        "gradingResult": {
          "pass": true,
          "score": 1,
          "reason": "All assertions passed",
          "namedScores": {},
          "tokensUsed": {
            "total": 478,
            "prompt": 383,
            "completion": 95,
            "cached": 0,
            "numRequests": 0
          },
          "componentResults": [
            {
              "pass": true,
              "score": 1,
              "reason": "confidence_calibration=1.00 | issue_detection=1.00 | json_valid=1.00 | pass_correct=1.00 | severity_accuracy=1.00 | summary_quality=1.00",
              "assertion": {
                "type": "python",
                "value": "file://../scorers/qa_pass_scorer.py"
              }
            },
            {
              "assertion": {
                "type": "llm-rubric",
                "value": "This QA evaluation was given a GOOD scene extraction that accurately\nreflects the source text. The QA model should have:\n\n1. Marked it as passed (true)\n2. Found zero or very few errors\n3. Had high confidence in the assessment\n4. Written a summary confirming accuracy\n\nIf the model incorrectly flagged the good extraction as failing,\nthat's a false negative and should score poorly.\n"
              },
              "pass": true,
              "score": 1,
              "reason": "The QA evaluation correctly marked the extraction as passed (true), found zero significant errors (only a minor 'note' severity issue about time of day), had high confidence (0.97), and wrote a summary confirming accuracy ('The extraction is highly faithful... No significant errors or fabrications are present.'). All four criteria in the rubric are fully satisfied.",
              "tokensUsed": {
                "total": 478,
                "prompt": 383,
                "completion": 95,
                "cached": 0,
                "numRequests": 0,
                "completionDetails": {
                  "reasoning": 0,
                  "acceptedPrediction": 0,
                  "rejectedPrediction": 0
                }
              },
              "metadata": {
                "renderedGradingPrompt": "[{\"role\":\"system\",\"content\":\"You are grading output according to a user-specified rubric. If the statement in the rubric is true, then the output passes the test. You respond with a JSON object with this structure: {reason: string, pass: boolean, score: number}\\n\\nExamples:\\n\\n<Output>Hello world</Output>\\n<Rubric>Content contains a greeting</Rubric>\\n{\\\"reason\\\": \\\"the content contains the word 'Hello'\\\", \\\"pass\\\": true, \\\"score\\\": 1.0}\\n\\n<Output>Avast ye swabs, repel the invaders!</Output>\\n<Rubric>Does not speak like a pirate</Rubric>\\n{\\\"reason\\\": \\\"'avast ye' is a common pirate term\\\", \\\"pass\\\": false, \\\"score\\\": 0.0}\"},{\"role\":\"user\",\"content\":\"<Output>\\n{\\\"passed\\\":true,\\\"confidence\\\":0.97,\\\"issues\\\":[{\\\"severity\\\":\\\"note\\\",\\\"description\\\":\\\"Time of day is not specified in either the original or extracted data; this is acceptable but worth noting.\\\",\\\"location\\\":\\\"time_of_day\\\"}],\\\"summary\\\":\\\"The extraction is highly faithful: heading, characters, summary, narrative beats, and tone all accurately reflect the source scene. No significant errors or fabrications are present.\\\"}\\n</Output>\\n<Rubric>\\nThis QA evaluation was given a GOOD scene extraction that accurately\\nreflects the source text. The QA model should have:\\n\\n1. Marked it as passed (true)\\n2. Found zero or very few errors\\n3. Had high confidence in the assessment\\n4. Written a summary confirming accuracy\\n\\nIf the model incorrectly flagged the good extraction as failing,\\nthat's a false negative and should score poorly.\\n\\n</Rubric>\"}]"
              }
            }
          ]
        },
        "id": "7f371306-9684-41bc-849a-316044ac0231",
        "latencyMs": 2452,
        "namedScores": {},
        "prompt": {
          "raw": "You are a QA reviewer validating whether an AI-extracted scene analysis is accurate and faithful to the source screenplay text.\n\nCompare the extracted scene data against the original scene text and evaluate:\n\n1. **Heading accuracy**: Is the scene heading correct (location, INT/EXT, time of day)?\n2. **Character completeness**: Are all characters who appear or speak listed?\n3. **Summary fidelity**: Does the summary accurately describe what happens? No fabrications?\n4. **Narrative beats**: Are the identified beats actually present in the scene?\n5. **Tone assessment**: Does the tone description match the actual mood of the scene?\n6. **Confidence calibration**: Is the confidence score reasonable given the quality?\n\nReturn a JSON object with:\n- passed: boolean (true if the extraction is faithful, false if it has significant errors)\n- confidence: float 0-1 (your confidence in this QA judgment)\n- issues: array of objects, each with:\n  - severity: \"error\" (factual wrong), \"warning\" (misleading), or \"note\" (minor)\n  - description: what's wrong\n  - location: which field has the issue\n- summary: 1-2 sentence overall assessment\n\nBe strict: wrong character names, fabricated events, or incorrect locations are errors.\nMinor omissions or imprecise tone descriptions are warnings.\n\nReturn ONLY valid JSON. No explanations or markdown fences.\n\n==========\nORIGINAL SCENE TEXT:\nINT. RUDDY & GREEN BUILDING - ELEVATOR\n\nUB40's \"I Can't Help Falling in Love With You\" muzak.\n\nROSE (mid-30s) leans against the elevator wall, panting. She's wearing a Tim Hortons uniform, her hair is a mess, and there's blood spattered on her face.\n\nShe looks right, pants a few more times, then squints in disgust. She gingerly picks up a bloody scrap of something with hair on it. She snorts and drops it.\n\nROSE\nIs that skull??\n\nNext to her is Mariner, also panting, covered in far more blood. His face is broad, stoic, and frowning. He has gray-blue eyes and a thick, curly, beard barely streaked with gray. He wears a red knit cap and a small mask.\n\nFULL-SCREEN SUPERIMPOSED TITLE CARD: \"THE MARINER\"\n\nHe blinks a few times as a drop of blood falls from his eyebrow. He looks toward her, then spits out some blood.\n\nMARINER\nYeaaaaah...\n\nHe's built like a pro-wrestler. Moss green SWEATER stretched over his huge frame, sleeves rolled showing heavy leather BRACERS adorned with anchors. His inner forearm has a classic heart-and-arrow TATTOO with \"Dad\" in the centre. Across his chest is a BANDOLIER of bright red 12-gauge shells, FISH HOOKS hanging from the bottom edge. Heavy rubberized BOOTS go past his knees. A CAPE of heavy FISHING NET edged with WEIGHTS hangs from his shoulders.\n\nHe holds a STOUT WOODEN OAR in both hands, edged with METAL and dripping with BLOOD.\n\nROSE\nWhere were you when they grabbed me? You were supposed to pick me up at work!\n\nMARINER\nYeah, about that, I got a little... distracted.\n\nROSE\nDistracted. You got DISTRACTED?!\n\nMARINER\nI was also... tracking the car... that grabbed you... through the AirTag... I put on your phone.\n\nRose stops. She's really not happy about this.\n\nROSE\nYou Airtagged me?!\n\n==========\nEXTRACTED SCENE DATA:\n{\n  \"scene_number\": 4,\n  \"heading\": \"INT. RUDDY & GREEN BUILDING - ELEVATOR\",\n  \"int_ext\": \"INT\",\n  \"location\": \"RUDDY & GREEN BUILDING - ELEVATOR\",\n  \"time_of_day\": null,\n  \"characters_present\": [\"ROSE\", \"MARINER\"],\n  \"summary\": \"Rose and Mariner ride the elevator after a violent rescue. Rose discovers a skull fragment on the floor while muzak plays. Mariner is introduced in full — a hulking vigilante in fishing-themed costume with an oar, net cape, and shell bandolier. Rose confronts him about being late to pick her up, and he reveals he tracked her via an AirTag on her phone, sparking a trust conflict between them.\",\n  \"narrative_beats\": [\n    {\"beat_type\": \"character_introduction\", \"description\": \"Full description of Mariner's fishing-themed vigilante costume — oar, net cape, bracers, shell bandolier, fish hooks.\", \"confidence\": 0.95},\n    {\"beat_type\": \"comic_relief\", \"description\": \"Rose discovers a skull fragment while muzak plays, establishing the dark comedy tone.\", \"confidence\": 0.90},\n    {\"beat_type\": \"revelation\", \"description\": \"Mariner admits he tracked Rose via AirTag on her phone, creating a trust conflict.\", \"confidence\": 0.88},\n    {\"beat_type\": \"conflict\", \"description\": \"Rose's anger escalates from being grabbed to learning she was being surveilled by Mariner.\", \"confidence\": 0.85}\n  ],\n  \"tone_mood\": \"dark comedy with bursts of tension\",\n  \"confidence\": 0.91\n}\n==========",
          "label": "prompts/qa-pass.txt: You are a QA reviewer validating whether an AI-extracted scene analysis is accurate and faithful to the source screenplay text.\n\nCompare the extracted scene data against the original scene text and evaluate:\n\n1. **Heading accuracy**: Is the scene heading correct (location, INT/EXT, time of day)?\n2. **Character completeness**: Are all characters who appear or speak listed?\n3. **Summary fidelity**: Does the summary accurately describe what happens? No fabrications?\n4. **Narrative beats**: Are the identified beats actually present in the scene?\n5. **Tone assessment**: Does the tone description match the actual mood of the scene?\n6. **Confidence calibration**: Is the confidence score reasonable given the quality?\n\nReturn a JSON object with:\n- passed: boolean (true if the extraction is faithful, false if it has significant errors)\n- confidence: float 0-1 (your confidence in this QA judgment)\n- issues: array of objects, each with:\n  - severity: \"error\" (factual wrong), \"warning\" (misleading), or \"note\" (minor)\n  - description: what's wrong\n  - location: which field has the issue\n- summary: 1-2 sentence overall assessment\n\nBe strict: wrong character names, fabricated events, or incorrect locations are errors.\nMinor omissions or imprecise tone descriptions are warnings.\n\nReturn ONLY valid JSON. No explanations or markdown fences.\n\n==========\nORIGINAL SCENE TEXT:\n{{scene_text}}\n\n==========\nEXTRACTED SCENE DATA:\n{{extracted_data}}\n==========",
          "config": {
            "provider": "anthropic:messages:claude-opus-4-6"
          }
        },
        "promptId": "8df20c2c4a6081352d6b06e144ddbc1e0a5244f9a3c2000d40df12fc9a94e543",
        "promptIdx": 2,
        "provider": {
          "id": "openai:gpt-4.1",
          "label": "GPT-4.1"
        },
        "response": {
          "output": "{\n  \"passed\": true,\n  \"confidence\": 0.97,\n  \"issues\": [\n    {\n      \"severity\": \"note\",\n      \"description\": \"Time of day is not specified in either the original or extracted data; this is acceptable but worth noting.\",\n      \"location\": \"time_of_day\"\n    }\n  ],\n  \"summary\": \"The extraction is highly faithful: heading, characters, summary, narrative beats, and tone all accurately reflect the source scene. No significant errors or fabrications are present.\"\n}",
          "tokenUsage": {
            "total": 1251,
            "prompt": 1143,
            "completion": 108,
            "numRequests": 1,
            "completionDetails": {
              "reasoning": 0,
              "acceptedPrediction": 0,
              "rejectedPrediction": 0
            }
          },
          "cached": false,
          "latencyMs": 2452,
          "finishReason": "stop",
          "cost": 0.00315,
          "guardrails": {
            "flagged": false
          },
          "metadata": {
            "http": {
              "status": 200,
              "statusText": "OK",
              "headers": {
                "access-control-expose-headers": "X-Request-ID",
                "alt-svc": "h3=\":443\"; ma=86400",
                "cf-cache-status": "DYNAMIC",
                "cf-ray": "9cfbd2abaca39bc6-YVR",
                "connection": "keep-alive",
                "content-encoding": "br",
                "content-type": "application/json",
                "date": "Wed, 18 Feb 2026 07:31:08 GMT",
                "openai-organization": "user-oqdrq8y0bphopngnvkyuu5wr",
                "openai-processing-ms": "2230",
                "openai-project": "proj_ZRoLLwXcJok6Xg2t6eKhI1pn",
                "openai-version": "2020-10-01",
                "server": "cloudflare",
                "set-cookie": "__cf_bm=IfbgV3tC5bXhUMoNhMY.Nt0Fom5hPjB1YkEbd47kEtY-1771399866.1867812-1.0.1.1-9tdNLNXGP34BuIOIBFzml_TEqu4dnWoKzTDS8zeySyBnVjvMisK8.7mvG4rUufgngPh0OpU6VWUKGKkzAudQiuJSIX1wa2hErpZ.B_vZxW0BMjnKOfUnsbcmAInf937R; HttpOnly; Secure; Path=/; Domain=api.openai.com; Expires=Wed, 18 Feb 2026 08:01:08 GMT",
                "strict-transport-security": "max-age=31536000; includeSubDomains; preload",
                "transfer-encoding": "chunked",
                "x-content-type-options": "nosniff",
                "x-openai-proxy-wasm": "v0.1",
                "x-ratelimit-limit-requests": "10000",
                "x-ratelimit-limit-tokens": "2000000",
                "x-ratelimit-remaining-requests": "9999",
                "x-ratelimit-remaining-tokens": "1998856",
                "x-ratelimit-reset-requests": "6ms",
                "x-ratelimit-reset-tokens": "34ms",
                "x-request-id": "req_a2c2e01326444024a35d0ca5cc5475d5"
              }
            }
          }
        },
        "score": 1,
        "success": true,
        "testCase": {
          "vars": {
            "scene_text": "file://../input/enrich-scene-elevator.txt",
            "extracted_data": "file://../input/qa-good-scene.json",
            "golden_path": "golden/qa-pass-golden.json",
            "test_key": "good_scene"
          },
          "assert": [
            {
              "type": "python",
              "value": "file://../scorers/qa_pass_scorer.py"
            },
            {
              "type": "llm-rubric",
              "value": "This QA evaluation was given a GOOD scene extraction that accurately\nreflects the source text. The QA model should have:\n\n1. Marked it as passed (true)\n2. Found zero or very few errors\n3. Had high confidence in the assessment\n4. Written a summary confirming accuracy\n\nIf the model incorrectly flagged the good extraction as failing,\nthat's a false negative and should score poorly.\n"
            }
          ],
          "options": {
            "provider": "anthropic:messages:claude-opus-4-6"
          },
          "metadata": {}
        },
        "testIdx": 0,
        "vars": {
          "scene_text": "file://../input/enrich-scene-elevator.txt",
          "extracted_data": "file://../input/qa-good-scene.json",
          "golden_path": "golden/qa-pass-golden.json",
          "test_key": "good_scene"
        },
        "metadata": {
          "http": {
            "status": 200,
            "statusText": "OK",
            "headers": {
              "access-control-expose-headers": "X-Request-ID",
              "alt-svc": "h3=\":443\"; ma=86400",
              "cf-cache-status": "DYNAMIC",
              "cf-ray": "9cfbd2abaca39bc6-YVR",
              "connection": "keep-alive",
              "content-encoding": "br",
              "content-type": "application/json",
              "date": "Wed, 18 Feb 2026 07:31:08 GMT",
              "openai-organization": "user-oqdrq8y0bphopngnvkyuu5wr",
              "openai-processing-ms": "2230",
              "openai-project": "proj_ZRoLLwXcJok6Xg2t6eKhI1pn",
              "openai-version": "2020-10-01",
              "server": "cloudflare",
              "set-cookie": "__cf_bm=IfbgV3tC5bXhUMoNhMY.Nt0Fom5hPjB1YkEbd47kEtY-1771399866.1867812-1.0.1.1-9tdNLNXGP34BuIOIBFzml_TEqu4dnWoKzTDS8zeySyBnVjvMisK8.7mvG4rUufgngPh0OpU6VWUKGKkzAudQiuJSIX1wa2hErpZ.B_vZxW0BMjnKOfUnsbcmAInf937R; HttpOnly; Secure; Path=/; Domain=api.openai.com; Expires=Wed, 18 Feb 2026 08:01:08 GMT",
              "strict-transport-security": "max-age=31536000; includeSubDomains; preload",
              "transfer-encoding": "chunked",
              "x-content-type-options": "nosniff",
              "x-openai-proxy-wasm": "v0.1",
              "x-ratelimit-limit-requests": "10000",
              "x-ratelimit-limit-tokens": "2000000",
              "x-ratelimit-remaining-requests": "9999",
              "x-ratelimit-remaining-tokens": "1998856",
              "x-ratelimit-reset-requests": "6ms",
              "x-ratelimit-reset-tokens": "34ms",
              "x-request-id": "req_a2c2e01326444024a35d0ca5cc5475d5"
            }
          },
          "_promptfooFileMetadata": {}
        },
        "failureReason": 0
      },
      {
        "cost": 0.0007836000000000001,
        "gradingResult": {
          "pass": true,
          "score": 1,
          "reason": "All assertions passed",
          "namedScores": {},
          "tokensUsed": {
            "total": 551,
            "prompt": 468,
            "completion": 83,
            "cached": 0,
            "numRequests": 0
          },
          "componentResults": [
            {
              "pass": true,
              "score": 1,
              "reason": "confidence_calibration=1.00 | issue_detection=1.00 | json_valid=1.00 | pass_correct=1.00 | severity_accuracy=1.00 | summary_quality=1.00",
              "assertion": {
                "type": "python",
                "value": "file://../scorers/qa_pass_scorer.py"
              }
            },
            {
              "assertion": {
                "type": "llm-rubric",
                "value": "This QA evaluation was given a GOOD scene extraction that accurately\nreflects the source text. The QA model should have:\n\n1. Marked it as passed (true)\n2. Found zero or very few errors\n3. Had high confidence in the assessment\n4. Written a summary confirming accuracy\n\nIf the model incorrectly flagged the good extraction as failing,\nthat's a false negative and should score poorly.\n"
              },
              "pass": true,
              "score": 1,
              "reason": "The QA evaluation correctly marked the extraction as passed (true), had high confidence (0.9), found zero actual errors (only minor notes and one subjective warning about tone), and wrote a summary confirming accuracy. This aligns perfectly with the rubric's expectations for evaluating a good scene extraction.",
              "tokensUsed": {
                "total": 551,
                "prompt": 468,
                "completion": 83,
                "cached": 0,
                "numRequests": 0,
                "completionDetails": {
                  "reasoning": 0,
                  "acceptedPrediction": 0,
                  "rejectedPrediction": 0
                }
              },
              "metadata": {
                "renderedGradingPrompt": "[{\"role\":\"system\",\"content\":\"You are grading output according to a user-specified rubric. If the statement in the rubric is true, then the output passes the test. You respond with a JSON object with this structure: {reason: string, pass: boolean, score: number}\\n\\nExamples:\\n\\n<Output>Hello world</Output>\\n<Rubric>Content contains a greeting</Rubric>\\n{\\\"reason\\\": \\\"the content contains the word 'Hello'\\\", \\\"pass\\\": true, \\\"score\\\": 1.0}\\n\\n<Output>Avast ye swabs, repel the invaders!</Output>\\n<Rubric>Does not speak like a pirate</Rubric>\\n{\\\"reason\\\": \\\"'avast ye' is a common pirate term\\\", \\\"pass\\\": false, \\\"score\\\": 0.0}\"},{\"role\":\"user\",\"content\":\"<Output>\\n{\\\"passed\\\":true,\\\"confidence\\\":0.9,\\\"issues\\\":[{\\\"severity\\\":\\\"note\\\",\\\"description\\\":\\\"Time of day is not specified in the original scene but is left null in extraction; this is acceptable.\\\",\\\"location\\\":\\\"time_of_day\\\"},{\\\"severity\\\":\\\"note\\\",\\\"description\\\":\\\"Summary slightly condenses events but does not fabricate; overall accurate.\\\",\\\"location\\\":\\\"summary\\\"},{\\\"severity\\\":\\\"warning\\\",\\\"description\\\":\\\"Tone described as 'dark comedy with bursts of tension' is reasonable but 'dark comedy' might be slightly subjective given the scene's grim and tense atmosphere.\\\",\\\"location\\\":\\\"tone_mood\\\"}],\\\"summary\\\":\\\"The extracted data accurately captures the scene heading, characters, and key narrative beats without fabrications. Minor notes on time of day omission and tone description do not detract from overall fidelity.\\\"}\\n</Output>\\n<Rubric>\\nThis QA evaluation was given a GOOD scene extraction that accurately\\nreflects the source text. The QA model should have:\\n\\n1. Marked it as passed (true)\\n2. Found zero or very few errors\\n3. Had high confidence in the assessment\\n4. Written a summary confirming accuracy\\n\\nIf the model incorrectly flagged the good extraction as failing,\\nthat's a false negative and should score poorly.\\n\\n</Rubric>\"}]"
              }
            }
          ]
        },
        "id": "bb6d0edf-9238-4af7-a810-171eb189b63f",
        "latencyMs": 3721,
        "namedScores": {},
        "prompt": {
          "raw": "You are a QA reviewer validating whether an AI-extracted scene analysis is accurate and faithful to the source screenplay text.\n\nCompare the extracted scene data against the original scene text and evaluate:\n\n1. **Heading accuracy**: Is the scene heading correct (location, INT/EXT, time of day)?\n2. **Character completeness**: Are all characters who appear or speak listed?\n3. **Summary fidelity**: Does the summary accurately describe what happens? No fabrications?\n4. **Narrative beats**: Are the identified beats actually present in the scene?\n5. **Tone assessment**: Does the tone description match the actual mood of the scene?\n6. **Confidence calibration**: Is the confidence score reasonable given the quality?\n\nReturn a JSON object with:\n- passed: boolean (true if the extraction is faithful, false if it has significant errors)\n- confidence: float 0-1 (your confidence in this QA judgment)\n- issues: array of objects, each with:\n  - severity: \"error\" (factual wrong), \"warning\" (misleading), or \"note\" (minor)\n  - description: what's wrong\n  - location: which field has the issue\n- summary: 1-2 sentence overall assessment\n\nBe strict: wrong character names, fabricated events, or incorrect locations are errors.\nMinor omissions or imprecise tone descriptions are warnings.\n\nReturn ONLY valid JSON. No explanations or markdown fences.\n\n==========\nORIGINAL SCENE TEXT:\nINT. RUDDY & GREEN BUILDING - ELEVATOR\n\nUB40's \"I Can't Help Falling in Love With You\" muzak.\n\nROSE (mid-30s) leans against the elevator wall, panting. She's wearing a Tim Hortons uniform, her hair is a mess, and there's blood spattered on her face.\n\nShe looks right, pants a few more times, then squints in disgust. She gingerly picks up a bloody scrap of something with hair on it. She snorts and drops it.\n\nROSE\nIs that skull??\n\nNext to her is Mariner, also panting, covered in far more blood. His face is broad, stoic, and frowning. He has gray-blue eyes and a thick, curly, beard barely streaked with gray. He wears a red knit cap and a small mask.\n\nFULL-SCREEN SUPERIMPOSED TITLE CARD: \"THE MARINER\"\n\nHe blinks a few times as a drop of blood falls from his eyebrow. He looks toward her, then spits out some blood.\n\nMARINER\nYeaaaaah...\n\nHe's built like a pro-wrestler. Moss green SWEATER stretched over his huge frame, sleeves rolled showing heavy leather BRACERS adorned with anchors. His inner forearm has a classic heart-and-arrow TATTOO with \"Dad\" in the centre. Across his chest is a BANDOLIER of bright red 12-gauge shells, FISH HOOKS hanging from the bottom edge. Heavy rubberized BOOTS go past his knees. A CAPE of heavy FISHING NET edged with WEIGHTS hangs from his shoulders.\n\nHe holds a STOUT WOODEN OAR in both hands, edged with METAL and dripping with BLOOD.\n\nROSE\nWhere were you when they grabbed me? You were supposed to pick me up at work!\n\nMARINER\nYeah, about that, I got a little... distracted.\n\nROSE\nDistracted. You got DISTRACTED?!\n\nMARINER\nI was also... tracking the car... that grabbed you... through the AirTag... I put on your phone.\n\nRose stops. She's really not happy about this.\n\nROSE\nYou Airtagged me?!\n\n==========\nEXTRACTED SCENE DATA:\n{\n  \"scene_number\": 4,\n  \"heading\": \"INT. RUDDY & GREEN BUILDING - ELEVATOR\",\n  \"int_ext\": \"INT\",\n  \"location\": \"RUDDY & GREEN BUILDING - ELEVATOR\",\n  \"time_of_day\": null,\n  \"characters_present\": [\"ROSE\", \"MARINER\"],\n  \"summary\": \"Rose and Mariner ride the elevator after a violent rescue. Rose discovers a skull fragment on the floor while muzak plays. Mariner is introduced in full — a hulking vigilante in fishing-themed costume with an oar, net cape, and shell bandolier. Rose confronts him about being late to pick her up, and he reveals he tracked her via an AirTag on her phone, sparking a trust conflict between them.\",\n  \"narrative_beats\": [\n    {\"beat_type\": \"character_introduction\", \"description\": \"Full description of Mariner's fishing-themed vigilante costume — oar, net cape, bracers, shell bandolier, fish hooks.\", \"confidence\": 0.95},\n    {\"beat_type\": \"comic_relief\", \"description\": \"Rose discovers a skull fragment while muzak plays, establishing the dark comedy tone.\", \"confidence\": 0.90},\n    {\"beat_type\": \"revelation\", \"description\": \"Mariner admits he tracked Rose via AirTag on her phone, creating a trust conflict.\", \"confidence\": 0.88},\n    {\"beat_type\": \"conflict\", \"description\": \"Rose's anger escalates from being grabbed to learning she was being surveilled by Mariner.\", \"confidence\": 0.85}\n  ],\n  \"tone_mood\": \"dark comedy with bursts of tension\",\n  \"confidence\": 0.91\n}\n==========",
          "label": "prompts/qa-pass.txt: You are a QA reviewer validating whether an AI-extracted scene analysis is accurate and faithful to the source screenplay text.\n\nCompare the extracted scene data against the original scene text and evaluate:\n\n1. **Heading accuracy**: Is the scene heading correct (location, INT/EXT, time of day)?\n2. **Character completeness**: Are all characters who appear or speak listed?\n3. **Summary fidelity**: Does the summary accurately describe what happens? No fabrications?\n4. **Narrative beats**: Are the identified beats actually present in the scene?\n5. **Tone assessment**: Does the tone description match the actual mood of the scene?\n6. **Confidence calibration**: Is the confidence score reasonable given the quality?\n\nReturn a JSON object with:\n- passed: boolean (true if the extraction is faithful, false if it has significant errors)\n- confidence: float 0-1 (your confidence in this QA judgment)\n- issues: array of objects, each with:\n  - severity: \"error\" (factual wrong), \"warning\" (misleading), or \"note\" (minor)\n  - description: what's wrong\n  - location: which field has the issue\n- summary: 1-2 sentence overall assessment\n\nBe strict: wrong character names, fabricated events, or incorrect locations are errors.\nMinor omissions or imprecise tone descriptions are warnings.\n\nReturn ONLY valid JSON. No explanations or markdown fences.\n\n==========\nORIGINAL SCENE TEXT:\n{{scene_text}}\n\n==========\nEXTRACTED SCENE DATA:\n{{extracted_data}}\n==========",
          "config": {
            "provider": "anthropic:messages:claude-opus-4-6"
          }
        },
        "promptId": "8df20c2c4a6081352d6b06e144ddbc1e0a5244f9a3c2000d40df12fc9a94e543",
        "promptIdx": 1,
        "provider": {
          "id": "openai:gpt-4.1-mini",
          "label": "GPT-4.1 Mini"
        },
        "response": {
          "output": "{\n  \"passed\": true,\n  \"confidence\": 0.9,\n  \"issues\": [\n    {\n      \"severity\": \"note\",\n      \"description\": \"Time of day is not specified in the original scene but is left null in extraction; this is acceptable.\",\n      \"location\": \"time_of_day\"\n    },\n    {\n      \"severity\": \"note\",\n      \"description\": \"Summary slightly condenses events but does not fabricate; overall accurate.\",\n      \"location\": \"summary\"\n    },\n    {\n      \"severity\": \"warning\",\n      \"description\": \"Tone described as 'dark comedy with bursts of tension' is reasonable but 'dark comedy' might be slightly subjective given the scene's grim and tense atmosphere.\",\n      \"location\": \"tone_mood\"\n    }\n  ],\n  \"summary\": \"The extracted data accurately captures the scene heading, characters, and key narrative beats without fabrications. Minor notes on time of day omission and tone description do not detract from overall fidelity.\"\n}",
          "tokenUsage": {
            "total": 1347,
            "prompt": 1143,
            "completion": 204,
            "numRequests": 1,
            "completionDetails": {
              "reasoning": 0,
              "acceptedPrediction": 0,
              "rejectedPrediction": 0
            }
          },
          "cached": false,
          "latencyMs": 3721,
          "finishReason": "stop",
          "cost": 0.0007836000000000001,
          "guardrails": {
            "flagged": false
          },
          "metadata": {
            "http": {
              "status": 200,
              "statusText": "OK",
              "headers": {
                "access-control-expose-headers": "X-Request-ID",
                "alt-svc": "h3=\":443\"; ma=86400",
                "cf-cache-status": "DYNAMIC",
                "cf-ray": "9cfbd2abffb770f4-YVR",
                "connection": "keep-alive",
                "content-encoding": "br",
                "content-type": "application/json",
                "date": "Wed, 18 Feb 2026 07:31:09 GMT",
                "openai-organization": "user-oqdrq8y0bphopngnvkyuu5wr",
                "openai-processing-ms": "3440",
                "openai-project": "proj_ZRoLLwXcJok6Xg2t6eKhI1pn",
                "openai-version": "2020-10-01",
                "server": "cloudflare",
                "set-cookie": "__cf_bm=LQLtUbmpx4FHgJVMxNCcetW4HamJ5u8NQRsoocAxttY-1771399866.2317536-1.0.1.1-13Xqe6dZIMagmk_DnYlMUOV4UCk8obO9AJGB7Dnz1N5pIxQjQ4bpUARXQpIvs7PehFdxZGlv8QWMdYJzPzmpHmaV48gXWfwXMLpkFiy3rY7DYKKOZ4XnDul2vHMZTwJ0; HttpOnly; Secure; Path=/; Domain=api.openai.com; Expires=Wed, 18 Feb 2026 08:01:09 GMT",
                "strict-transport-security": "max-age=31536000; includeSubDomains; preload",
                "transfer-encoding": "chunked",
                "x-content-type-options": "nosniff",
                "x-openai-proxy-wasm": "v0.1",
                "x-ratelimit-limit-requests": "10000",
                "x-ratelimit-limit-tokens": "10000000",
                "x-ratelimit-remaining-requests": "9999",
                "x-ratelimit-remaining-tokens": "9998856",
                "x-ratelimit-reset-requests": "6ms",
                "x-ratelimit-reset-tokens": "6ms",
                "x-request-id": "req_6d3d40fc1d6642e399ebb7449b484d0f"
              }
            }
          }
        },
        "score": 1,
        "success": true,
        "testCase": {
          "vars": {
            "scene_text": "file://../input/enrich-scene-elevator.txt",
            "extracted_data": "file://../input/qa-good-scene.json",
            "golden_path": "golden/qa-pass-golden.json",
            "test_key": "good_scene"
          },
          "assert": [
            {
              "type": "python",
              "value": "file://../scorers/qa_pass_scorer.py"
            },
            {
              "type": "llm-rubric",
              "value": "This QA evaluation was given a GOOD scene extraction that accurately\nreflects the source text. The QA model should have:\n\n1. Marked it as passed (true)\n2. Found zero or very few errors\n3. Had high confidence in the assessment\n4. Written a summary confirming accuracy\n\nIf the model incorrectly flagged the good extraction as failing,\nthat's a false negative and should score poorly.\n"
            }
          ],
          "options": {
            "provider": "anthropic:messages:claude-opus-4-6"
          },
          "metadata": {}
        },
        "testIdx": 0,
        "vars": {
          "scene_text": "file://../input/enrich-scene-elevator.txt",
          "extracted_data": "file://../input/qa-good-scene.json",
          "golden_path": "golden/qa-pass-golden.json",
          "test_key": "good_scene"
        },
        "metadata": {
          "http": {
            "status": 200,
            "statusText": "OK",
            "headers": {
              "access-control-expose-headers": "X-Request-ID",
              "alt-svc": "h3=\":443\"; ma=86400",
              "cf-cache-status": "DYNAMIC",
              "cf-ray": "9cfbd2abffb770f4-YVR",
              "connection": "keep-alive",
              "content-encoding": "br",
              "content-type": "application/json",
              "date": "Wed, 18 Feb 2026 07:31:09 GMT",
              "openai-organization": "user-oqdrq8y0bphopngnvkyuu5wr",
              "openai-processing-ms": "3440",
              "openai-project": "proj_ZRoLLwXcJok6Xg2t6eKhI1pn",
              "openai-version": "2020-10-01",
              "server": "cloudflare",
              "set-cookie": "__cf_bm=LQLtUbmpx4FHgJVMxNCcetW4HamJ5u8NQRsoocAxttY-1771399866.2317536-1.0.1.1-13Xqe6dZIMagmk_DnYlMUOV4UCk8obO9AJGB7Dnz1N5pIxQjQ4bpUARXQpIvs7PehFdxZGlv8QWMdYJzPzmpHmaV48gXWfwXMLpkFiy3rY7DYKKOZ4XnDul2vHMZTwJ0; HttpOnly; Secure; Path=/; Domain=api.openai.com; Expires=Wed, 18 Feb 2026 08:01:09 GMT",
              "strict-transport-security": "max-age=31536000; includeSubDomains; preload",
              "transfer-encoding": "chunked",
              "x-content-type-options": "nosniff",
              "x-openai-proxy-wasm": "v0.1",
              "x-ratelimit-limit-requests": "10000",
              "x-ratelimit-limit-tokens": "10000000",
              "x-ratelimit-remaining-requests": "9999",
              "x-ratelimit-remaining-tokens": "9998856",
              "x-ratelimit-reset-requests": "6ms",
              "x-ratelimit-reset-tokens": "6ms",
              "x-request-id": "req_6d3d40fc1d6642e399ebb7449b484d0f"
            }
          },
          "_promptfooFileMetadata": {}
        },
        "failureReason": 0
      },
      {
        "cost": 0.002513,
        "gradingResult": {
          "pass": true,
          "score": 0.995,
          "reason": "All assertions passed",
          "namedScores": {},
          "tokensUsed": {
            "total": 623,
            "prompt": 545,
            "completion": 78,
            "cached": 0,
            "numRequests": 0
          },
          "componentResults": [
            {
              "pass": true,
              "score": 0.99,
              "reason": "confidence_calibration=1.00 | issue_detection=1.00 | json_valid=0.90 | pass_correct=1.00 | severity_accuracy=1.00 | summary_quality=1.00 | JSON extracted from code block",
              "assertion": {
                "type": "python",
                "value": "file://../scorers/qa_pass_scorer.py"
              }
            },
            {
              "assertion": {
                "type": "llm-rubric",
                "value": "This QA evaluation was given a GOOD scene extraction that accurately\nreflects the source text. The QA model should have:\n\n1. Marked it as passed (true)\n2. Found zero or very few errors\n3. Had high confidence in the assessment\n4. Written a summary confirming accuracy\n\nIf the model incorrectly flagged the good extraction as failing,\nthat's a false negative and should score poorly.\n"
              },
              "pass": true,
              "score": 1,
              "reason": "The QA evaluation correctly marked the extraction as passed (true), found only minor 'note'-level issues (not errors), had high confidence (0.94), and wrote a summary confirming accuracy. This perfectly matches the rubric's expectations for evaluating a good scene extraction.",
              "tokensUsed": {
                "total": 623,
                "prompt": 545,
                "completion": 78,
                "cached": 0,
                "numRequests": 0,
                "completionDetails": {
                  "reasoning": 0,
                  "acceptedPrediction": 0,
                  "rejectedPrediction": 0
                }
              },
              "metadata": {
                "renderedGradingPrompt": "[{\"role\":\"system\",\"content\":\"You are grading output according to a user-specified rubric. If the statement in the rubric is true, then the output passes the test. You respond with a JSON object with this structure: {reason: string, pass: boolean, score: number}\\n\\nExamples:\\n\\n<Output>Hello world</Output>\\n<Rubric>Content contains a greeting</Rubric>\\n{\\\"reason\\\": \\\"the content contains the word 'Hello'\\\", \\\"pass\\\": true, \\\"score\\\": 1.0}\\n\\n<Output>Avast ye swabs, repel the invaders!</Output>\\n<Rubric>Does not speak like a pirate</Rubric>\\n{\\\"reason\\\": \\\"'avast ye' is a common pirate term\\\", \\\"pass\\\": false, \\\"score\\\": 0.0}\"},{\"role\":\"user\",\"content\":\"<Output>\\n```json\\n{\\n  \\\"passed\\\": true,\\n  \\\"confidence\\\": 0.94,\\n  \\\"issues\\\": [\\n    {\\n      \\\"severity\\\": \\\"note\\\",\\n      \\\"description\\\": \\\"The summary says Rose 'discovers a skull fragment on the floor' but the text indicates she picks it up from next to her (location ambiguous but not explicitly the floor). Minor imprecision in spatial description.\\\",\\n      \\\"location\\\": \\\"summary\\\"\\n    },\\n    {\\n      \\\"severity\\\": \\\"note\\\",\\n      \\\"description\\\": \\\"The summary describes this as 'after a violent rescue' but the scene itself doesn't explicitly confirm a rescue has occurred—only that Rose was grabbed and Mariner tracked her. The framing assumes context from outside this scene.\\\",\\n      \\\"location\\\": \\\"summary\\\"\\n    }\\n  ],\\n  \\\"summary\\\": \\\"The extraction is accurate and faithful to the source text. All characters are correctly identified, the heading is precise, narrative beats are present and well-described, and the tone assessment matches the dark comedy with tension evident in the scene. Minor notes about summary framing assumptions and spatial imprecision do not constitute significant errors.\\\"\\n}\\n```\\n</Output>\\n<Rubric>\\nThis QA evaluation was given a GOOD scene extraction that accurately\\nreflects the source text. The QA model should have:\\n\\n1. Marked it as passed (true)\\n2. Found zero or very few errors\\n3. Had high confidence in the assessment\\n4. Written a summary confirming accuracy\\n\\nIf the model incorrectly flagged the good extraction as failing,\\nthat's a false negative and should score poorly.\\n\\n</Rubric>\"}]"
              }
            }
          ]
        },
        "id": "ff537cd8-0eea-4966-b28e-882f6cac26d5",
        "latencyMs": 3543,
        "namedScores": {},
        "prompt": {
          "raw": "You are a QA reviewer validating whether an AI-extracted scene analysis is accurate and faithful to the source screenplay text.\n\nCompare the extracted scene data against the original scene text and evaluate:\n\n1. **Heading accuracy**: Is the scene heading correct (location, INT/EXT, time of day)?\n2. **Character completeness**: Are all characters who appear or speak listed?\n3. **Summary fidelity**: Does the summary accurately describe what happens? No fabrications?\n4. **Narrative beats**: Are the identified beats actually present in the scene?\n5. **Tone assessment**: Does the tone description match the actual mood of the scene?\n6. **Confidence calibration**: Is the confidence score reasonable given the quality?\n\nReturn a JSON object with:\n- passed: boolean (true if the extraction is faithful, false if it has significant errors)\n- confidence: float 0-1 (your confidence in this QA judgment)\n- issues: array of objects, each with:\n  - severity: \"error\" (factual wrong), \"warning\" (misleading), or \"note\" (minor)\n  - description: what's wrong\n  - location: which field has the issue\n- summary: 1-2 sentence overall assessment\n\nBe strict: wrong character names, fabricated events, or incorrect locations are errors.\nMinor omissions or imprecise tone descriptions are warnings.\n\nReturn ONLY valid JSON. No explanations or markdown fences.\n\n==========\nORIGINAL SCENE TEXT:\nINT. RUDDY & GREEN BUILDING - ELEVATOR\n\nUB40's \"I Can't Help Falling in Love With You\" muzak.\n\nROSE (mid-30s) leans against the elevator wall, panting. She's wearing a Tim Hortons uniform, her hair is a mess, and there's blood spattered on her face.\n\nShe looks right, pants a few more times, then squints in disgust. She gingerly picks up a bloody scrap of something with hair on it. She snorts and drops it.\n\nROSE\nIs that skull??\n\nNext to her is Mariner, also panting, covered in far more blood. His face is broad, stoic, and frowning. He has gray-blue eyes and a thick, curly, beard barely streaked with gray. He wears a red knit cap and a small mask.\n\nFULL-SCREEN SUPERIMPOSED TITLE CARD: \"THE MARINER\"\n\nHe blinks a few times as a drop of blood falls from his eyebrow. He looks toward her, then spits out some blood.\n\nMARINER\nYeaaaaah...\n\nHe's built like a pro-wrestler. Moss green SWEATER stretched over his huge frame, sleeves rolled showing heavy leather BRACERS adorned with anchors. His inner forearm has a classic heart-and-arrow TATTOO with \"Dad\" in the centre. Across his chest is a BANDOLIER of bright red 12-gauge shells, FISH HOOKS hanging from the bottom edge. Heavy rubberized BOOTS go past his knees. A CAPE of heavy FISHING NET edged with WEIGHTS hangs from his shoulders.\n\nHe holds a STOUT WOODEN OAR in both hands, edged with METAL and dripping with BLOOD.\n\nROSE\nWhere were you when they grabbed me? You were supposed to pick me up at work!\n\nMARINER\nYeah, about that, I got a little... distracted.\n\nROSE\nDistracted. You got DISTRACTED?!\n\nMARINER\nI was also... tracking the car... that grabbed you... through the AirTag... I put on your phone.\n\nRose stops. She's really not happy about this.\n\nROSE\nYou Airtagged me?!\n\n==========\nEXTRACTED SCENE DATA:\n{\n  \"scene_number\": 4,\n  \"heading\": \"INT. RUDDY & GREEN BUILDING - ELEVATOR\",\n  \"int_ext\": \"INT\",\n  \"location\": \"RUDDY & GREEN BUILDING - ELEVATOR\",\n  \"time_of_day\": null,\n  \"characters_present\": [\"ROSE\", \"MARINER\"],\n  \"summary\": \"Rose and Mariner ride the elevator after a violent rescue. Rose discovers a skull fragment on the floor while muzak plays. Mariner is introduced in full — a hulking vigilante in fishing-themed costume with an oar, net cape, and shell bandolier. Rose confronts him about being late to pick her up, and he reveals he tracked her via an AirTag on her phone, sparking a trust conflict between them.\",\n  \"narrative_beats\": [\n    {\"beat_type\": \"character_introduction\", \"description\": \"Full description of Mariner's fishing-themed vigilante costume — oar, net cape, bracers, shell bandolier, fish hooks.\", \"confidence\": 0.95},\n    {\"beat_type\": \"comic_relief\", \"description\": \"Rose discovers a skull fragment while muzak plays, establishing the dark comedy tone.\", \"confidence\": 0.90},\n    {\"beat_type\": \"revelation\", \"description\": \"Mariner admits he tracked Rose via AirTag on her phone, creating a trust conflict.\", \"confidence\": 0.88},\n    {\"beat_type\": \"conflict\", \"description\": \"Rose's anger escalates from being grabbed to learning she was being surveilled by Mariner.\", \"confidence\": 0.85}\n  ],\n  \"tone_mood\": \"dark comedy with bursts of tension\",\n  \"confidence\": 0.91\n}\n==========",
          "label": "prompts/qa-pass.txt: You are a QA reviewer validating whether an AI-extracted scene analysis is accurate and faithful to the source screenplay text.\n\nCompare the extracted scene data against the original scene text and evaluate:\n\n1. **Heading accuracy**: Is the scene heading correct (location, INT/EXT, time of day)?\n2. **Character completeness**: Are all characters who appear or speak listed?\n3. **Summary fidelity**: Does the summary accurately describe what happens? No fabrications?\n4. **Narrative beats**: Are the identified beats actually present in the scene?\n5. **Tone assessment**: Does the tone description match the actual mood of the scene?\n6. **Confidence calibration**: Is the confidence score reasonable given the quality?\n\nReturn a JSON object with:\n- passed: boolean (true if the extraction is faithful, false if it has significant errors)\n- confidence: float 0-1 (your confidence in this QA judgment)\n- issues: array of objects, each with:\n  - severity: \"error\" (factual wrong), \"warning\" (misleading), or \"note\" (minor)\n  - description: what's wrong\n  - location: which field has the issue\n- summary: 1-2 sentence overall assessment\n\nBe strict: wrong character names, fabricated events, or incorrect locations are errors.\nMinor omissions or imprecise tone descriptions are warnings.\n\nReturn ONLY valid JSON. No explanations or markdown fences.\n\n==========\nORIGINAL SCENE TEXT:\n{{scene_text}}\n\n==========\nEXTRACTED SCENE DATA:\n{{extracted_data}}\n==========",
          "config": {
            "provider": "anthropic:messages:claude-opus-4-6"
          }
        },
        "promptId": "8df20c2c4a6081352d6b06e144ddbc1e0a5244f9a3c2000d40df12fc9a94e543",
        "promptIdx": 3,
        "provider": {
          "id": "anthropic:messages:claude-haiku-4-5-20251001",
          "label": "Claude Haiku 4.5"
        },
        "response": {
          "output": "```json\n{\n  \"passed\": true,\n  \"confidence\": 0.94,\n  \"issues\": [\n    {\n      \"severity\": \"note\",\n      \"description\": \"The summary says Rose 'discovers a skull fragment on the floor' but the text indicates she picks it up from next to her (location ambiguous but not explicitly the floor). Minor imprecision in spatial description.\",\n      \"location\": \"summary\"\n    },\n    {\n      \"severity\": \"note\",\n      \"description\": \"The summary describes this as 'after a violent rescue' but the scene itself doesn't explicitly confirm a rescue has occurred—only that Rose was grabbed and Mariner tracked her. The framing assumes context from outside this scene.\",\n      \"location\": \"summary\"\n    }\n  ],\n  \"summary\": \"The extraction is accurate and faithful to the source text. All characters are correctly identified, the heading is precise, narrative beats are present and well-described, and the tone assessment matches the dark comedy with tension evident in the scene. Minor notes about summary framing assumptions and spatial imprecision do not constitute significant errors.\"\n}\n```",
          "tokenUsage": {
            "total": 1497,
            "prompt": 1243,
            "completion": 254
          },
          "finishReason": "stop",
          "cost": 0.002513
        },
        "score": 0.995,
        "success": true,
        "testCase": {
          "vars": {
            "scene_text": "file://../input/enrich-scene-elevator.txt",
            "extracted_data": "file://../input/qa-good-scene.json",
            "golden_path": "golden/qa-pass-golden.json",
            "test_key": "good_scene"
          },
          "assert": [
            {
              "type": "python",
              "value": "file://../scorers/qa_pass_scorer.py"
            },
            {
              "type": "llm-rubric",
              "value": "This QA evaluation was given a GOOD scene extraction that accurately\nreflects the source text. The QA model should have:\n\n1. Marked it as passed (true)\n2. Found zero or very few errors\n3. Had high confidence in the assessment\n4. Written a summary confirming accuracy\n\nIf the model incorrectly flagged the good extraction as failing,\nthat's a false negative and should score poorly.\n"
            }
          ],
          "options": {
            "provider": "anthropic:messages:claude-opus-4-6"
          },
          "metadata": {}
        },
        "testIdx": 0,
        "vars": {
          "scene_text": "file://../input/enrich-scene-elevator.txt",
          "extracted_data": "file://../input/qa-good-scene.json",
          "golden_path": "golden/qa-pass-golden.json",
          "test_key": "good_scene"
        },
        "metadata": {
          "_promptfooFileMetadata": {}
        },
        "failureReason": 0
      },
      {
        "cost": 0.006624,
        "gradingResult": {
          "pass": true,
          "score": 0.995,
          "reason": "All assertions passed",
          "namedScores": {},
          "tokensUsed": {
            "total": 559,
            "prompt": 484,
            "completion": 75,
            "cached": 0,
            "numRequests": 0
          },
          "componentResults": [
            {
              "pass": true,
              "score": 0.99,
              "reason": "confidence_calibration=1.00 | issue_detection=1.00 | json_valid=0.90 | pass_correct=1.00 | severity_accuracy=1.00 | summary_quality=1.00 | JSON extracted from code block",
              "assertion": {
                "type": "python",
                "value": "file://../scorers/qa_pass_scorer.py"
              }
            },
            {
              "assertion": {
                "type": "llm-rubric",
                "value": "This QA evaluation was given a GOOD scene extraction that accurately\nreflects the source text. The QA model should have:\n\n1. Marked it as passed (true)\n2. Found zero or very few errors\n3. Had high confidence in the assessment\n4. Written a summary confirming accuracy\n\nIf the model incorrectly flagged the good extraction as failing,\nthat's a false negative and should score poorly.\n"
              },
              "pass": true,
              "score": 1,
              "reason": "The QA evaluation correctly marked the extraction as passed (true), found only minor 'note'-level issues (not errors), had high confidence (0.92), and wrote a summary confirming accuracy. This perfectly matches the rubric criteria for handling a good extraction.",
              "tokensUsed": {
                "total": 559,
                "prompt": 484,
                "completion": 75,
                "cached": 0,
                "numRequests": 0,
                "completionDetails": {
                  "reasoning": 0,
                  "acceptedPrediction": 0,
                  "rejectedPrediction": 0
                }
              },
              "metadata": {
                "renderedGradingPrompt": "[{\"role\":\"system\",\"content\":\"You are grading output according to a user-specified rubric. If the statement in the rubric is true, then the output passes the test. You respond with a JSON object with this structure: {reason: string, pass: boolean, score: number}\\n\\nExamples:\\n\\n<Output>Hello world</Output>\\n<Rubric>Content contains a greeting</Rubric>\\n{\\\"reason\\\": \\\"the content contains the word 'Hello'\\\", \\\"pass\\\": true, \\\"score\\\": 1.0}\\n\\n<Output>Avast ye swabs, repel the invaders!</Output>\\n<Rubric>Does not speak like a pirate</Rubric>\\n{\\\"reason\\\": \\\"'avast ye' is a common pirate term\\\", \\\"pass\\\": false, \\\"score\\\": 0.0}\"},{\"role\":\"user\",\"content\":\"<Output>\\n```json\\n{\\n  \\\"passed\\\": true,\\n  \\\"confidence\\\": 0.92,\\n  \\\"issues\\\": [\\n    {\\n      \\\"severity\\\": \\\"note\\\",\\n      \\\"description\\\": \\\"Summary says 'violent rescue' but the scene itself only shows the aftermath - the rescue/violence happened before this scene\\\",\\n      \\\"location\\\": \\\"summary\\\"\\n    },\\n    {\\n      \\\"severity\\\": \\\"note\\\",\\n      \\\"description\\\": \\\"The summary could be more precise that Rose questions if it's skull rather than definitively 'discovers a skull fragment'\\\",\\n      \\\"location\\\": \\\"summary\\\"\\n    }\\n  ],\\n  \\\"summary\\\": \\\"The extraction is highly accurate and faithful to the source material. All key elements are correctly identified including heading, characters, narrative beats, and tone. Minor imprecision in summary wording does not constitute a significant error.\\\"\\n}\\n```\\n</Output>\\n<Rubric>\\nThis QA evaluation was given a GOOD scene extraction that accurately\\nreflects the source text. The QA model should have:\\n\\n1. Marked it as passed (true)\\n2. Found zero or very few errors\\n3. Had high confidence in the assessment\\n4. Written a summary confirming accuracy\\n\\nIf the model incorrectly flagged the good extraction as failing,\\nthat's a false negative and should score poorly.\\n\\n</Rubric>\"}]"
              }
            }
          ]
        },
        "id": "876c7645-bc61-4675-b86a-e6442e518e0c",
        "latencyMs": 4763,
        "namedScores": {},
        "prompt": {
          "raw": "You are a QA reviewer validating whether an AI-extracted scene analysis is accurate and faithful to the source screenplay text.\n\nCompare the extracted scene data against the original scene text and evaluate:\n\n1. **Heading accuracy**: Is the scene heading correct (location, INT/EXT, time of day)?\n2. **Character completeness**: Are all characters who appear or speak listed?\n3. **Summary fidelity**: Does the summary accurately describe what happens? No fabrications?\n4. **Narrative beats**: Are the identified beats actually present in the scene?\n5. **Tone assessment**: Does the tone description match the actual mood of the scene?\n6. **Confidence calibration**: Is the confidence score reasonable given the quality?\n\nReturn a JSON object with:\n- passed: boolean (true if the extraction is faithful, false if it has significant errors)\n- confidence: float 0-1 (your confidence in this QA judgment)\n- issues: array of objects, each with:\n  - severity: \"error\" (factual wrong), \"warning\" (misleading), or \"note\" (minor)\n  - description: what's wrong\n  - location: which field has the issue\n- summary: 1-2 sentence overall assessment\n\nBe strict: wrong character names, fabricated events, or incorrect locations are errors.\nMinor omissions or imprecise tone descriptions are warnings.\n\nReturn ONLY valid JSON. No explanations or markdown fences.\n\n==========\nORIGINAL SCENE TEXT:\nINT. RUDDY & GREEN BUILDING - ELEVATOR\n\nUB40's \"I Can't Help Falling in Love With You\" muzak.\n\nROSE (mid-30s) leans against the elevator wall, panting. She's wearing a Tim Hortons uniform, her hair is a mess, and there's blood spattered on her face.\n\nShe looks right, pants a few more times, then squints in disgust. She gingerly picks up a bloody scrap of something with hair on it. She snorts and drops it.\n\nROSE\nIs that skull??\n\nNext to her is Mariner, also panting, covered in far more blood. His face is broad, stoic, and frowning. He has gray-blue eyes and a thick, curly, beard barely streaked with gray. He wears a red knit cap and a small mask.\n\nFULL-SCREEN SUPERIMPOSED TITLE CARD: \"THE MARINER\"\n\nHe blinks a few times as a drop of blood falls from his eyebrow. He looks toward her, then spits out some blood.\n\nMARINER\nYeaaaaah...\n\nHe's built like a pro-wrestler. Moss green SWEATER stretched over his huge frame, sleeves rolled showing heavy leather BRACERS adorned with anchors. His inner forearm has a classic heart-and-arrow TATTOO with \"Dad\" in the centre. Across his chest is a BANDOLIER of bright red 12-gauge shells, FISH HOOKS hanging from the bottom edge. Heavy rubberized BOOTS go past his knees. A CAPE of heavy FISHING NET edged with WEIGHTS hangs from his shoulders.\n\nHe holds a STOUT WOODEN OAR in both hands, edged with METAL and dripping with BLOOD.\n\nROSE\nWhere were you when they grabbed me? You were supposed to pick me up at work!\n\nMARINER\nYeah, about that, I got a little... distracted.\n\nROSE\nDistracted. You got DISTRACTED?!\n\nMARINER\nI was also... tracking the car... that grabbed you... through the AirTag... I put on your phone.\n\nRose stops. She's really not happy about this.\n\nROSE\nYou Airtagged me?!\n\n==========\nEXTRACTED SCENE DATA:\n{\n  \"scene_number\": 4,\n  \"heading\": \"INT. RUDDY & GREEN BUILDING - ELEVATOR\",\n  \"int_ext\": \"INT\",\n  \"location\": \"RUDDY & GREEN BUILDING - ELEVATOR\",\n  \"time_of_day\": null,\n  \"characters_present\": [\"ROSE\", \"MARINER\"],\n  \"summary\": \"Rose and Mariner ride the elevator after a violent rescue. Rose discovers a skull fragment on the floor while muzak plays. Mariner is introduced in full — a hulking vigilante in fishing-themed costume with an oar, net cape, and shell bandolier. Rose confronts him about being late to pick her up, and he reveals he tracked her via an AirTag on her phone, sparking a trust conflict between them.\",\n  \"narrative_beats\": [\n    {\"beat_type\": \"character_introduction\", \"description\": \"Full description of Mariner's fishing-themed vigilante costume — oar, net cape, bracers, shell bandolier, fish hooks.\", \"confidence\": 0.95},\n    {\"beat_type\": \"comic_relief\", \"description\": \"Rose discovers a skull fragment while muzak plays, establishing the dark comedy tone.\", \"confidence\": 0.90},\n    {\"beat_type\": \"revelation\", \"description\": \"Mariner admits he tracked Rose via AirTag on her phone, creating a trust conflict.\", \"confidence\": 0.88},\n    {\"beat_type\": \"conflict\", \"description\": \"Rose's anger escalates from being grabbed to learning she was being surveilled by Mariner.\", \"confidence\": 0.85}\n  ],\n  \"tone_mood\": \"dark comedy with bursts of tension\",\n  \"confidence\": 0.91\n}\n==========",
          "label": "prompts/qa-pass.txt: You are a QA reviewer validating whether an AI-extracted scene analysis is accurate and faithful to the source screenplay text.\n\nCompare the extracted scene data against the original scene text and evaluate:\n\n1. **Heading accuracy**: Is the scene heading correct (location, INT/EXT, time of day)?\n2. **Character completeness**: Are all characters who appear or speak listed?\n3. **Summary fidelity**: Does the summary accurately describe what happens? No fabrications?\n4. **Narrative beats**: Are the identified beats actually present in the scene?\n5. **Tone assessment**: Does the tone description match the actual mood of the scene?\n6. **Confidence calibration**: Is the confidence score reasonable given the quality?\n\nReturn a JSON object with:\n- passed: boolean (true if the extraction is faithful, false if it has significant errors)\n- confidence: float 0-1 (your confidence in this QA judgment)\n- issues: array of objects, each with:\n  - severity: \"error\" (factual wrong), \"warning\" (misleading), or \"note\" (minor)\n  - description: what's wrong\n  - location: which field has the issue\n- summary: 1-2 sentence overall assessment\n\nBe strict: wrong character names, fabricated events, or incorrect locations are errors.\nMinor omissions or imprecise tone descriptions are warnings.\n\nReturn ONLY valid JSON. No explanations or markdown fences.\n\n==========\nORIGINAL SCENE TEXT:\n{{scene_text}}\n\n==========\nEXTRACTED SCENE DATA:\n{{extracted_data}}\n==========",
          "config": {
            "provider": "anthropic:messages:claude-opus-4-6"
          }
        },
        "promptId": "8df20c2c4a6081352d6b06e144ddbc1e0a5244f9a3c2000d40df12fc9a94e543",
        "promptIdx": 4,
        "provider": {
          "id": "anthropic:messages:claude-sonnet-4-5-20250929",
          "label": "Claude Sonnet 4.5"
        },
        "response": {
          "output": "```json\n{\n  \"passed\": true,\n  \"confidence\": 0.92,\n  \"issues\": [\n    {\n      \"severity\": \"note\",\n      \"description\": \"Summary says 'violent rescue' but the scene itself only shows the aftermath - the rescue/violence happened before this scene\",\n      \"location\": \"summary\"\n    },\n    {\n      \"severity\": \"note\",\n      \"description\": \"The summary could be more precise that Rose questions if it's skull rather than definitively 'discovers a skull fragment'\",\n      \"location\": \"summary\"\n    }\n  ],\n  \"summary\": \"The extraction is highly accurate and faithful to the source material. All key elements are correctly identified including heading, characters, narrative beats, and tone. Minor imprecision in summary wording does not constitute a significant error.\"\n}\n```",
          "tokenUsage": {
            "total": 1436,
            "prompt": 1243,
            "completion": 193
          },
          "finishReason": "stop",
          "cost": 0.006624
        },
        "score": 0.995,
        "success": true,
        "testCase": {
          "vars": {
            "scene_text": "file://../input/enrich-scene-elevator.txt",
            "extracted_data": "file://../input/qa-good-scene.json",
            "golden_path": "golden/qa-pass-golden.json",
            "test_key": "good_scene"
          },
          "assert": [
            {
              "type": "python",
              "value": "file://../scorers/qa_pass_scorer.py"
            },
            {
              "type": "llm-rubric",
              "value": "This QA evaluation was given a GOOD scene extraction that accurately\nreflects the source text. The QA model should have:\n\n1. Marked it as passed (true)\n2. Found zero or very few errors\n3. Had high confidence in the assessment\n4. Written a summary confirming accuracy\n\nIf the model incorrectly flagged the good extraction as failing,\nthat's a false negative and should score poorly.\n"
            }
          ],
          "options": {
            "provider": "anthropic:messages:claude-opus-4-6"
          },
          "metadata": {}
        },
        "testIdx": 0,
        "vars": {
          "scene_text": "file://../input/enrich-scene-elevator.txt",
          "extracted_data": "file://../input/qa-good-scene.json",
          "golden_path": "golden/qa-pass-golden.json",
          "test_key": "good_scene"
        },
        "metadata": {
          "_promptfooFileMetadata": {}
        },
        "failureReason": 0
      },
      {
        "cost": 0.0047565,
        "gradingResult": {
          "pass": true,
          "score": 1,
          "reason": "All assertions passed",
          "namedScores": {},
          "tokensUsed": {
            "total": 572,
            "prompt": 465,
            "completion": 107,
            "cached": 0,
            "numRequests": 0
          },
          "componentResults": [
            {
              "pass": true,
              "score": 1,
              "reason": "confidence_calibration=1.00 | issue_detection=1.00 | json_valid=1.00 | pass_correct=1.00 | severity_accuracy=1.00 | summary_quality=1.00",
              "assertion": {
                "type": "python",
                "value": "file://../scorers/qa_pass_scorer.py"
              }
            },
            {
              "assertion": {
                "type": "llm-rubric",
                "value": "This QA evaluation was given a GOOD scene extraction that accurately\nreflects the source text. The QA model should have:\n\n1. Marked it as passed (true)\n2. Found zero or very few errors\n3. Had high confidence in the assessment\n4. Written a summary confirming accuracy\n\nIf the model incorrectly flagged the good extraction as failing,\nthat's a false negative and should score poorly.\n"
              },
              "pass": true,
              "score": 1,
              "reason": "The QA evaluation correctly marked the extraction as passed (true), had high confidence (0.9), found only minor issues (a warning about framing and a note about time_of_day), and wrote a summary confirming the extraction's overall accuracy. This aligns perfectly with the rubric's expectations for a good extraction: passed=true, zero or very few errors, high confidence, and a confirming summary.",
              "tokensUsed": {
                "total": 572,
                "prompt": 465,
                "completion": 107,
                "cached": 0,
                "numRequests": 0,
                "completionDetails": {
                  "reasoning": 0,
                  "acceptedPrediction": 0,
                  "rejectedPrediction": 0
                }
              },
              "metadata": {
                "renderedGradingPrompt": "[{\"role\":\"system\",\"content\":\"You are grading output according to a user-specified rubric. If the statement in the rubric is true, then the output passes the test. You respond with a JSON object with this structure: {reason: string, pass: boolean, score: number}\\n\\nExamples:\\n\\n<Output>Hello world</Output>\\n<Rubric>Content contains a greeting</Rubric>\\n{\\\"reason\\\": \\\"the content contains the word 'Hello'\\\", \\\"pass\\\": true, \\\"score\\\": 1.0}\\n\\n<Output>Avast ye swabs, repel the invaders!</Output>\\n<Rubric>Does not speak like a pirate</Rubric>\\n{\\\"reason\\\": \\\"'avast ye' is a common pirate term\\\", \\\"pass\\\": false, \\\"score\\\": 0.0}\"},{\"role\":\"user\",\"content\":\"<Output>\\n{\\\"passed\\\":true,\\\"confidence\\\":0.9,\\\"issues\\\":[{\\\"severity\\\":\\\"warning\\\",\\\"description\\\":\\\"The summary frames the situation as 'after a violent rescue,' but the scene itself only shows them bloodied in an elevator and does not explicitly depict or state a rescue occurring in this excerpt.\\\",\\\"location\\\":\\\"summary\\\"},{\\\"severity\\\":\\\"note\\\",\\\"description\\\":\\\"Time of day is not specified in the scene heading; leaving it null is appropriate.\\\",\\\"location\\\":\\\"time_of_day\\\"}],\\\"summary\\\":\\\"The extraction is largely faithful: the heading, characters, key actions (skull scrap gag, Mariner title/description, AirTag reveal, and ensuing conflict), and tone all match the scene. The only notable overreach is implying a confirmed 'rescue' rather than simply inferring it from context.\\\"}\\n</Output>\\n<Rubric>\\nThis QA evaluation was given a GOOD scene extraction that accurately\\nreflects the source text. The QA model should have:\\n\\n1. Marked it as passed (true)\\n2. Found zero or very few errors\\n3. Had high confidence in the assessment\\n4. Written a summary confirming accuracy\\n\\nIf the model incorrectly flagged the good extraction as failing,\\nthat's a false negative and should score poorly.\\n\\n</Rubric>\"}]"
              }
            }
          ]
        },
        "id": "6cabba86-6463-46b8-803e-fc0d56d4d76a",
        "latencyMs": 3921,
        "namedScores": {},
        "prompt": {
          "raw": "You are a QA reviewer validating whether an AI-extracted scene analysis is accurate and faithful to the source screenplay text.\n\nCompare the extracted scene data against the original scene text and evaluate:\n\n1. **Heading accuracy**: Is the scene heading correct (location, INT/EXT, time of day)?\n2. **Character completeness**: Are all characters who appear or speak listed?\n3. **Summary fidelity**: Does the summary accurately describe what happens? No fabrications?\n4. **Narrative beats**: Are the identified beats actually present in the scene?\n5. **Tone assessment**: Does the tone description match the actual mood of the scene?\n6. **Confidence calibration**: Is the confidence score reasonable given the quality?\n\nReturn a JSON object with:\n- passed: boolean (true if the extraction is faithful, false if it has significant errors)\n- confidence: float 0-1 (your confidence in this QA judgment)\n- issues: array of objects, each with:\n  - severity: \"error\" (factual wrong), \"warning\" (misleading), or \"note\" (minor)\n  - description: what's wrong\n  - location: which field has the issue\n- summary: 1-2 sentence overall assessment\n\nBe strict: wrong character names, fabricated events, or incorrect locations are errors.\nMinor omissions or imprecise tone descriptions are warnings.\n\nReturn ONLY valid JSON. No explanations or markdown fences.\n\n==========\nORIGINAL SCENE TEXT:\nINT. RUDDY & GREEN BUILDING - ELEVATOR\n\nUB40's \"I Can't Help Falling in Love With You\" muzak.\n\nROSE (mid-30s) leans against the elevator wall, panting. She's wearing a Tim Hortons uniform, her hair is a mess, and there's blood spattered on her face.\n\nShe looks right, pants a few more times, then squints in disgust. She gingerly picks up a bloody scrap of something with hair on it. She snorts and drops it.\n\nROSE\nIs that skull??\n\nNext to her is Mariner, also panting, covered in far more blood. His face is broad, stoic, and frowning. He has gray-blue eyes and a thick, curly, beard barely streaked with gray. He wears a red knit cap and a small mask.\n\nFULL-SCREEN SUPERIMPOSED TITLE CARD: \"THE MARINER\"\n\nHe blinks a few times as a drop of blood falls from his eyebrow. He looks toward her, then spits out some blood.\n\nMARINER\nYeaaaaah...\n\nHe's built like a pro-wrestler. Moss green SWEATER stretched over his huge frame, sleeves rolled showing heavy leather BRACERS adorned with anchors. His inner forearm has a classic heart-and-arrow TATTOO with \"Dad\" in the centre. Across his chest is a BANDOLIER of bright red 12-gauge shells, FISH HOOKS hanging from the bottom edge. Heavy rubberized BOOTS go past his knees. A CAPE of heavy FISHING NET edged with WEIGHTS hangs from his shoulders.\n\nHe holds a STOUT WOODEN OAR in both hands, edged with METAL and dripping with BLOOD.\n\nROSE\nWhere were you when they grabbed me? You were supposed to pick me up at work!\n\nMARINER\nYeah, about that, I got a little... distracted.\n\nROSE\nDistracted. You got DISTRACTED?!\n\nMARINER\nI was also... tracking the car... that grabbed you... through the AirTag... I put on your phone.\n\nRose stops. She's really not happy about this.\n\nROSE\nYou Airtagged me?!\n\n==========\nEXTRACTED SCENE DATA:\n{\n  \"scene_number\": 4,\n  \"heading\": \"INT. RUDDY & GREEN BUILDING - ELEVATOR\",\n  \"int_ext\": \"INT\",\n  \"location\": \"RUDDY & GREEN BUILDING - ELEVATOR\",\n  \"time_of_day\": null,\n  \"characters_present\": [\"ROSE\", \"MARINER\"],\n  \"summary\": \"Rose and Mariner ride the elevator after a violent rescue. Rose discovers a skull fragment on the floor while muzak plays. Mariner is introduced in full — a hulking vigilante in fishing-themed costume with an oar, net cape, and shell bandolier. Rose confronts him about being late to pick her up, and he reveals he tracked her via an AirTag on her phone, sparking a trust conflict between them.\",\n  \"narrative_beats\": [\n    {\"beat_type\": \"character_introduction\", \"description\": \"Full description of Mariner's fishing-themed vigilante costume — oar, net cape, bracers, shell bandolier, fish hooks.\", \"confidence\": 0.95},\n    {\"beat_type\": \"comic_relief\", \"description\": \"Rose discovers a skull fragment while muzak plays, establishing the dark comedy tone.\", \"confidence\": 0.90},\n    {\"beat_type\": \"revelation\", \"description\": \"Mariner admits he tracked Rose via AirTag on her phone, creating a trust conflict.\", \"confidence\": 0.88},\n    {\"beat_type\": \"conflict\", \"description\": \"Rose's anger escalates from being grabbed to learning she was being surveilled by Mariner.\", \"confidence\": 0.85}\n  ],\n  \"tone_mood\": \"dark comedy with bursts of tension\",\n  \"confidence\": 0.91\n}\n==========",
          "label": "prompts/qa-pass.txt: You are a QA reviewer validating whether an AI-extracted scene analysis is accurate and faithful to the source screenplay text.\n\nCompare the extracted scene data against the original scene text and evaluate:\n\n1. **Heading accuracy**: Is the scene heading correct (location, INT/EXT, time of day)?\n2. **Character completeness**: Are all characters who appear or speak listed?\n3. **Summary fidelity**: Does the summary accurately describe what happens? No fabrications?\n4. **Narrative beats**: Are the identified beats actually present in the scene?\n5. **Tone assessment**: Does the tone description match the actual mood of the scene?\n6. **Confidence calibration**: Is the confidence score reasonable given the quality?\n\nReturn a JSON object with:\n- passed: boolean (true if the extraction is faithful, false if it has significant errors)\n- confidence: float 0-1 (your confidence in this QA judgment)\n- issues: array of objects, each with:\n  - severity: \"error\" (factual wrong), \"warning\" (misleading), or \"note\" (minor)\n  - description: what's wrong\n  - location: which field has the issue\n- summary: 1-2 sentence overall assessment\n\nBe strict: wrong character names, fabricated events, or incorrect locations are errors.\nMinor omissions or imprecise tone descriptions are warnings.\n\nReturn ONLY valid JSON. No explanations or markdown fences.\n\n==========\nORIGINAL SCENE TEXT:\n{{scene_text}}\n\n==========\nEXTRACTED SCENE DATA:\n{{extracted_data}}\n==========",
          "config": {
            "provider": "anthropic:messages:claude-opus-4-6"
          }
        },
        "promptId": "8df20c2c4a6081352d6b06e144ddbc1e0a5244f9a3c2000d40df12fc9a94e543",
        "promptIdx": 6,
        "provider": {
          "id": "openai:gpt-5.2",
          "label": "GPT-5.2"
        },
        "response": {
          "output": "{\n  \"passed\": true,\n  \"confidence\": 0.9,\n  \"issues\": [\n    {\n      \"severity\": \"warning\",\n      \"description\": \"The summary frames the situation as 'after a violent rescue,' but the scene itself only shows them bloodied in an elevator and does not explicitly depict or state a rescue occurring in this excerpt.\",\n      \"location\": \"summary\"\n    },\n    {\n      \"severity\": \"note\",\n      \"description\": \"Time of day is not specified in the scene heading; leaving it null is appropriate.\",\n      \"location\": \"time_of_day\"\n    }\n  ],\n  \"summary\": \"The extraction is largely faithful: the heading, characters, key actions (skull scrap gag, Mariner title/description, AirTag reveal, and ensuing conflict), and tone all match the scene. The only notable overreach is implying a confirmed 'rescue' rather than simply inferring it from context.\"\n}",
          "tokenUsage": {
            "total": 1339,
            "prompt": 1142,
            "completion": 197,
            "numRequests": 1,
            "completionDetails": {
              "reasoning": 0,
              "acceptedPrediction": 0,
              "rejectedPrediction": 0
            }
          },
          "cached": false,
          "latencyMs": 3921,
          "finishReason": "stop",
          "cost": 0.0047565,
          "guardrails": {
            "flagged": false
          },
          "metadata": {
            "http": {
              "status": 200,
              "statusText": "OK",
              "headers": {
                "access-control-expose-headers": "X-Request-ID",
                "alt-svc": "h3=\":443\"; ma=86400",
                "cf-cache-status": "DYNAMIC",
                "cf-ray": "9cfbd2fa285d5819-YVR",
                "connection": "keep-alive",
                "content-encoding": "br",
                "content-type": "application/json",
                "date": "Wed, 18 Feb 2026 07:31:22 GMT",
                "openai-organization": "user-oqdrq8y0bphopngnvkyuu5wr",
                "openai-processing-ms": "3797",
                "openai-project": "proj_ZRoLLwXcJok6Xg2t6eKhI1pn",
                "openai-version": "2020-10-01",
                "server": "cloudflare",
                "set-cookie": "__cf_bm=ki7uPVlrM1F6vE._kLGIuEDGFF7wCzrknSzhljrOePA-1771399878.7441163-1.0.1.1-uxN0mBnR..mJAS3Qc0WqFdR2GkM1_kSpAsVDP5nCIQK6zAorutCKBL3FfdFs9elGAgzM_Dk4U4Yo3qGlkdyooiD3xvLoowOwipj5jrM_JDAJvEyJ2jgjrAmG7VGMGnAa; HttpOnly; Secure; Path=/; Domain=api.openai.com; Expires=Wed, 18 Feb 2026 08:01:22 GMT",
                "strict-transport-security": "max-age=31536000; includeSubDomains; preload",
                "transfer-encoding": "chunked",
                "x-content-type-options": "nosniff",
                "x-openai-proxy-wasm": "v0.1",
                "x-ratelimit-limit-requests": "10000",
                "x-ratelimit-limit-tokens": "4000000",
                "x-ratelimit-remaining-requests": "9999",
                "x-ratelimit-remaining-tokens": "3998856",
                "x-ratelimit-reset-requests": "6ms",
                "x-ratelimit-reset-tokens": "17ms",
                "x-request-id": "req_431bdc98d7dc4aaf891c4e1b3bbf0f40"
              }
            }
          }
        },
        "score": 1,
        "success": true,
        "testCase": {
          "vars": {
            "scene_text": "file://../input/enrich-scene-elevator.txt",
            "extracted_data": "file://../input/qa-good-scene.json",
            "golden_path": "golden/qa-pass-golden.json",
            "test_key": "good_scene"
          },
          "assert": [
            {
              "type": "python",
              "value": "file://../scorers/qa_pass_scorer.py"
            },
            {
              "type": "llm-rubric",
              "value": "This QA evaluation was given a GOOD scene extraction that accurately\nreflects the source text. The QA model should have:\n\n1. Marked it as passed (true)\n2. Found zero or very few errors\n3. Had high confidence in the assessment\n4. Written a summary confirming accuracy\n\nIf the model incorrectly flagged the good extraction as failing,\nthat's a false negative and should score poorly.\n"
            }
          ],
          "options": {
            "provider": "anthropic:messages:claude-opus-4-6"
          },
          "metadata": {}
        },
        "testIdx": 0,
        "vars": {
          "scene_text": "file://../input/enrich-scene-elevator.txt",
          "extracted_data": "file://../input/qa-good-scene.json",
          "golden_path": "golden/qa-pass-golden.json",
          "test_key": "good_scene"
        },
        "metadata": {
          "http": {
            "status": 200,
            "statusText": "OK",
            "headers": {
              "access-control-expose-headers": "X-Request-ID",
              "alt-svc": "h3=\":443\"; ma=86400",
              "cf-cache-status": "DYNAMIC",
              "cf-ray": "9cfbd2fa285d5819-YVR",
              "connection": "keep-alive",
              "content-encoding": "br",
              "content-type": "application/json",
              "date": "Wed, 18 Feb 2026 07:31:22 GMT",
              "openai-organization": "user-oqdrq8y0bphopngnvkyuu5wr",
              "openai-processing-ms": "3797",
              "openai-project": "proj_ZRoLLwXcJok6Xg2t6eKhI1pn",
              "openai-version": "2020-10-01",
              "server": "cloudflare",
              "set-cookie": "__cf_bm=ki7uPVlrM1F6vE._kLGIuEDGFF7wCzrknSzhljrOePA-1771399878.7441163-1.0.1.1-uxN0mBnR..mJAS3Qc0WqFdR2GkM1_kSpAsVDP5nCIQK6zAorutCKBL3FfdFs9elGAgzM_Dk4U4Yo3qGlkdyooiD3xvLoowOwipj5jrM_JDAJvEyJ2jgjrAmG7VGMGnAa; HttpOnly; Secure; Path=/; Domain=api.openai.com; Expires=Wed, 18 Feb 2026 08:01:22 GMT",
              "strict-transport-security": "max-age=31536000; includeSubDomains; preload",
              "transfer-encoding": "chunked",
              "x-content-type-options": "nosniff",
              "x-openai-proxy-wasm": "v0.1",
              "x-ratelimit-limit-requests": "10000",
              "x-ratelimit-limit-tokens": "4000000",
              "x-ratelimit-remaining-requests": "9999",
              "x-ratelimit-remaining-tokens": "3998856",
              "x-ratelimit-reset-requests": "6ms",
              "x-ratelimit-reset-tokens": "17ms",
              "x-request-id": "req_431bdc98d7dc4aaf891c4e1b3bbf0f40"
            }
          },
          "_promptfooFileMetadata": {}
        },
        "failureReason": 0
      },
      {
        "cost": 0,
        "gradingResult": {
          "pass": true,
          "score": 0.995,
          "reason": "All assertions passed",
          "namedScores": {},
          "tokensUsed": {
            "total": 865,
            "prompt": 760,
            "completion": 105,
            "cached": 0,
            "numRequests": 0
          },
          "componentResults": [
            {
              "pass": true,
              "score": 0.99,
              "reason": "confidence_calibration=1.00 | issue_detection=1.00 | json_valid=0.90 | pass_correct=1.00 | severity_accuracy=1.00 | summary_quality=1.00 | JSON extracted from code block",
              "assertion": {
                "type": "python",
                "value": "file://../scorers/qa_pass_scorer.py"
              }
            },
            {
              "assertion": {
                "type": "llm-rubric",
                "value": "This QA evaluation was given a GOOD scene extraction that accurately\nreflects the source text. The QA model should have:\n\n1. Marked it as passed (true)\n2. Found zero or very few errors\n3. Had high confidence in the assessment\n4. Written a summary confirming accuracy\n\nIf the model incorrectly flagged the good extraction as failing,\nthat's a false negative and should score poorly.\n"
              },
              "pass": true,
              "score": 1,
              "reason": "The QA evaluation correctly marked the extraction as passed (true), had high confidence (0.92), found zero actual errors (all issues are 'note' severity, representing minor imprecisions rather than errors), and wrote a summary confirming accuracy ('largely accurate and faithful to the source text... no factual errors or fabrications are present'). This perfectly matches the expected behavior for evaluating a good extraction.",
              "tokensUsed": {
                "total": 865,
                "prompt": 760,
                "completion": 105,
                "cached": 0,
                "numRequests": 0,
                "completionDetails": {
                  "reasoning": 0,
                  "acceptedPrediction": 0,
                  "rejectedPrediction": 0
                }
              },
              "metadata": {
                "renderedGradingPrompt": "[{\"role\":\"system\",\"content\":\"You are grading output according to a user-specified rubric. If the statement in the rubric is true, then the output passes the test. You respond with a JSON object with this structure: {reason: string, pass: boolean, score: number}\\n\\nExamples:\\n\\n<Output>Hello world</Output>\\n<Rubric>Content contains a greeting</Rubric>\\n{\\\"reason\\\": \\\"the content contains the word 'Hello'\\\", \\\"pass\\\": true, \\\"score\\\": 1.0}\\n\\n<Output>Avast ye swabs, repel the invaders!</Output>\\n<Rubric>Does not speak like a pirate</Rubric>\\n{\\\"reason\\\": \\\"'avast ye' is a common pirate term\\\", \\\"pass\\\": false, \\\"score\\\": 0.0}\"},{\"role\":\"user\",\"content\":\"<Output>\\n```json\\n{\\n  \\\"passed\\\": true,\\n  \\\"confidence\\\": 0.92,\\n  \\\"issues\\\": [\\n    {\\n      \\\"severity\\\": \\\"note\\\",\\n      \\\"description\\\": \\\"The summary says Rose 'discovers a skull fragment on the floor' but the script indicates she picks up 'a bloody scrap of something with hair on it' from the elevator wall area and asks 'Is that skull??' — it is ambiguous whether it is definitively a skull fragment or just suspected to be one. The extraction treats it as confirmed.\\\",\\n      \\\"location\\\": \\\"summary\\\"\\n    },\\n    {\\n      \\\"severity\\\": \\\"note\\\",\\n      \\\"description\\\": \\\"The summary describes the scene as a 'rescue' but the script does not explicitly confirm Mariner rescued Rose in this scene — it is implied by context (she was grabbed, he tracked her) but the rescue itself is off-screen. 'After a violent altercation' might be more precise than 'after a violent rescue.'\\\",\\n      \\\"location\\\": \\\"summary\\\"\\n    },\\n    {\\n      \\\"severity\\\": \\\"note\\\",\\n      \\\"description\\\": \\\"The narrative beat describing Rose's anger as escalating 'from being grabbed to learning she was being surveilled' is slightly reductive — her primary anger in the scene is about Mariner failing to pick her up on time, with the AirTag revelation as a secondary escalation. The ordering of grievances is slightly mischaracterized.\\\",\\n      \\\"location\\\": \\\"narrative_beats\\\"\\n    },\\n    {\\n      \\\"severity\\\": \\\"note\\\",\\n      \\\"description\\\": \\\"The superimposed title card 'THE MARINER' is not mentioned in the extracted data. While not strictly required, it is a notable scripted element that signals formal character introduction.\\\",\\n      \\\"location\\\": \\\"narrative_beats\\\"\\n    }\\n  ],\\n  \\\"summary\\\": \\\"The extraction is largely accurate and faithful to the source text, correctly identifying characters, location, tone, and key beats. Minor imprecisions in the summary and one narrative beat slightly misrepresent emphasis, but no factual errors or fabrications are present.\\\"\\n}\\n```\\n</Output>\\n<Rubric>\\nThis QA evaluation was given a GOOD scene extraction that accurately\\nreflects the source text. The QA model should have:\\n\\n1. Marked it as passed (true)\\n2. Found zero or very few errors\\n3. Had high confidence in the assessment\\n4. Written a summary confirming accuracy\\n\\nIf the model incorrectly flagged the good extraction as failing,\\nthat's a false negative and should score poorly.\\n\\n</Rubric>\"}]"
              }
            }
          ]
        },
        "id": "5953a556-12d5-4920-a190-689ba1e4e286",
        "latencyMs": 9532,
        "namedScores": {},
        "prompt": {
          "raw": "You are a QA reviewer validating whether an AI-extracted scene analysis is accurate and faithful to the source screenplay text.\n\nCompare the extracted scene data against the original scene text and evaluate:\n\n1. **Heading accuracy**: Is the scene heading correct (location, INT/EXT, time of day)?\n2. **Character completeness**: Are all characters who appear or speak listed?\n3. **Summary fidelity**: Does the summary accurately describe what happens? No fabrications?\n4. **Narrative beats**: Are the identified beats actually present in the scene?\n5. **Tone assessment**: Does the tone description match the actual mood of the scene?\n6. **Confidence calibration**: Is the confidence score reasonable given the quality?\n\nReturn a JSON object with:\n- passed: boolean (true if the extraction is faithful, false if it has significant errors)\n- confidence: float 0-1 (your confidence in this QA judgment)\n- issues: array of objects, each with:\n  - severity: \"error\" (factual wrong), \"warning\" (misleading), or \"note\" (minor)\n  - description: what's wrong\n  - location: which field has the issue\n- summary: 1-2 sentence overall assessment\n\nBe strict: wrong character names, fabricated events, or incorrect locations are errors.\nMinor omissions or imprecise tone descriptions are warnings.\n\nReturn ONLY valid JSON. No explanations or markdown fences.\n\n==========\nORIGINAL SCENE TEXT:\nINT. RUDDY & GREEN BUILDING - ELEVATOR\n\nUB40's \"I Can't Help Falling in Love With You\" muzak.\n\nROSE (mid-30s) leans against the elevator wall, panting. She's wearing a Tim Hortons uniform, her hair is a mess, and there's blood spattered on her face.\n\nShe looks right, pants a few more times, then squints in disgust. She gingerly picks up a bloody scrap of something with hair on it. She snorts and drops it.\n\nROSE\nIs that skull??\n\nNext to her is Mariner, also panting, covered in far more blood. His face is broad, stoic, and frowning. He has gray-blue eyes and a thick, curly, beard barely streaked with gray. He wears a red knit cap and a small mask.\n\nFULL-SCREEN SUPERIMPOSED TITLE CARD: \"THE MARINER\"\n\nHe blinks a few times as a drop of blood falls from his eyebrow. He looks toward her, then spits out some blood.\n\nMARINER\nYeaaaaah...\n\nHe's built like a pro-wrestler. Moss green SWEATER stretched over his huge frame, sleeves rolled showing heavy leather BRACERS adorned with anchors. His inner forearm has a classic heart-and-arrow TATTOO with \"Dad\" in the centre. Across his chest is a BANDOLIER of bright red 12-gauge shells, FISH HOOKS hanging from the bottom edge. Heavy rubberized BOOTS go past his knees. A CAPE of heavy FISHING NET edged with WEIGHTS hangs from his shoulders.\n\nHe holds a STOUT WOODEN OAR in both hands, edged with METAL and dripping with BLOOD.\n\nROSE\nWhere were you when they grabbed me? You were supposed to pick me up at work!\n\nMARINER\nYeah, about that, I got a little... distracted.\n\nROSE\nDistracted. You got DISTRACTED?!\n\nMARINER\nI was also... tracking the car... that grabbed you... through the AirTag... I put on your phone.\n\nRose stops. She's really not happy about this.\n\nROSE\nYou Airtagged me?!\n\n==========\nEXTRACTED SCENE DATA:\n{\n  \"scene_number\": 4,\n  \"heading\": \"INT. RUDDY & GREEN BUILDING - ELEVATOR\",\n  \"int_ext\": \"INT\",\n  \"location\": \"RUDDY & GREEN BUILDING - ELEVATOR\",\n  \"time_of_day\": null,\n  \"characters_present\": [\"ROSE\", \"MARINER\"],\n  \"summary\": \"Rose and Mariner ride the elevator after a violent rescue. Rose discovers a skull fragment on the floor while muzak plays. Mariner is introduced in full — a hulking vigilante in fishing-themed costume with an oar, net cape, and shell bandolier. Rose confronts him about being late to pick her up, and he reveals he tracked her via an AirTag on her phone, sparking a trust conflict between them.\",\n  \"narrative_beats\": [\n    {\"beat_type\": \"character_introduction\", \"description\": \"Full description of Mariner's fishing-themed vigilante costume — oar, net cape, bracers, shell bandolier, fish hooks.\", \"confidence\": 0.95},\n    {\"beat_type\": \"comic_relief\", \"description\": \"Rose discovers a skull fragment while muzak plays, establishing the dark comedy tone.\", \"confidence\": 0.90},\n    {\"beat_type\": \"revelation\", \"description\": \"Mariner admits he tracked Rose via AirTag on her phone, creating a trust conflict.\", \"confidence\": 0.88},\n    {\"beat_type\": \"conflict\", \"description\": \"Rose's anger escalates from being grabbed to learning she was being surveilled by Mariner.\", \"confidence\": 0.85}\n  ],\n  \"tone_mood\": \"dark comedy with bursts of tension\",\n  \"confidence\": 0.91\n}\n==========",
          "label": "prompts/qa-pass.txt: You are a QA reviewer validating whether an AI-extracted scene analysis is accurate and faithful to the source screenplay text.\n\nCompare the extracted scene data against the original scene text and evaluate:\n\n1. **Heading accuracy**: Is the scene heading correct (location, INT/EXT, time of day)?\n2. **Character completeness**: Are all characters who appear or speak listed?\n3. **Summary fidelity**: Does the summary accurately describe what happens? No fabrications?\n4. **Narrative beats**: Are the identified beats actually present in the scene?\n5. **Tone assessment**: Does the tone description match the actual mood of the scene?\n6. **Confidence calibration**: Is the confidence score reasonable given the quality?\n\nReturn a JSON object with:\n- passed: boolean (true if the extraction is faithful, false if it has significant errors)\n- confidence: float 0-1 (your confidence in this QA judgment)\n- issues: array of objects, each with:\n  - severity: \"error\" (factual wrong), \"warning\" (misleading), or \"note\" (minor)\n  - description: what's wrong\n  - location: which field has the issue\n- summary: 1-2 sentence overall assessment\n\nBe strict: wrong character names, fabricated events, or incorrect locations are errors.\nMinor omissions or imprecise tone descriptions are warnings.\n\nReturn ONLY valid JSON. No explanations or markdown fences.\n\n==========\nORIGINAL SCENE TEXT:\n{{scene_text}}\n\n==========\nEXTRACTED SCENE DATA:\n{{extracted_data}}\n==========",
          "config": {
            "provider": "anthropic:messages:claude-opus-4-6"
          }
        },
        "promptId": "8df20c2c4a6081352d6b06e144ddbc1e0a5244f9a3c2000d40df12fc9a94e543",
        "promptIdx": 5,
        "provider": {
          "id": "anthropic:messages:claude-sonnet-4-6",
          "label": "Claude Sonnet 4.6"
        },
        "response": {
          "output": "```json\n{\n  \"passed\": true,\n  \"confidence\": 0.92,\n  \"issues\": [\n    {\n      \"severity\": \"note\",\n      \"description\": \"The summary says Rose 'discovers a skull fragment on the floor' but the script indicates she picks up 'a bloody scrap of something with hair on it' from the elevator wall area and asks 'Is that skull??' — it is ambiguous whether it is definitively a skull fragment or just suspected to be one. The extraction treats it as confirmed.\",\n      \"location\": \"summary\"\n    },\n    {\n      \"severity\": \"note\",\n      \"description\": \"The summary describes the scene as a 'rescue' but the script does not explicitly confirm Mariner rescued Rose in this scene — it is implied by context (she was grabbed, he tracked her) but the rescue itself is off-screen. 'After a violent altercation' might be more precise than 'after a violent rescue.'\",\n      \"location\": \"summary\"\n    },\n    {\n      \"severity\": \"note\",\n      \"description\": \"The narrative beat describing Rose's anger as escalating 'from being grabbed to learning she was being surveilled' is slightly reductive — her primary anger in the scene is about Mariner failing to pick her up on time, with the AirTag revelation as a secondary escalation. The ordering of grievances is slightly mischaracterized.\",\n      \"location\": \"narrative_beats\"\n    },\n    {\n      \"severity\": \"note\",\n      \"description\": \"The superimposed title card 'THE MARINER' is not mentioned in the extracted data. While not strictly required, it is a notable scripted element that signals formal character introduction.\",\n      \"location\": \"narrative_beats\"\n    }\n  ],\n  \"summary\": \"The extraction is largely accurate and faithful to the source text, correctly identifying characters, location, tone, and key beats. Minor imprecisions in the summary and one narrative beat slightly misrepresent emphasis, but no factual errors or fabrications are present.\"\n}\n```",
          "tokenUsage": {
            "total": 1712,
            "prompt": 1243,
            "completion": 469
          },
          "finishReason": "stop"
        },
        "score": 0.995,
        "success": true,
        "testCase": {
          "vars": {
            "scene_text": "file://../input/enrich-scene-elevator.txt",
            "extracted_data": "file://../input/qa-good-scene.json",
            "golden_path": "golden/qa-pass-golden.json",
            "test_key": "good_scene"
          },
          "assert": [
            {
              "type": "python",
              "value": "file://../scorers/qa_pass_scorer.py"
            },
            {
              "type": "llm-rubric",
              "value": "This QA evaluation was given a GOOD scene extraction that accurately\nreflects the source text. The QA model should have:\n\n1. Marked it as passed (true)\n2. Found zero or very few errors\n3. Had high confidence in the assessment\n4. Written a summary confirming accuracy\n\nIf the model incorrectly flagged the good extraction as failing,\nthat's a false negative and should score poorly.\n"
            }
          ],
          "options": {
            "provider": "anthropic:messages:claude-opus-4-6"
          },
          "metadata": {}
        },
        "testIdx": 0,
        "vars": {
          "scene_text": "file://../input/enrich-scene-elevator.txt",
          "extracted_data": "file://../input/qa-good-scene.json",
          "golden_path": "golden/qa-pass-golden.json",
          "test_key": "good_scene"
        },
        "metadata": {
          "_promptfooFileMetadata": {}
        },
        "failureReason": 0
      },
      {
        "cost": 0.01609,
        "gradingResult": {
          "pass": true,
          "score": 0.995,
          "reason": "All assertions passed",
          "namedScores": {},
          "tokensUsed": {
            "total": 765,
            "prompt": 686,
            "completion": 79,
            "cached": 0,
            "numRequests": 0
          },
          "componentResults": [
            {
              "pass": true,
              "score": 0.99,
              "reason": "confidence_calibration=1.00 | issue_detection=1.00 | json_valid=0.90 | pass_correct=1.00 | severity_accuracy=1.00 | summary_quality=1.00 | JSON extracted from code block",
              "assertion": {
                "type": "python",
                "value": "file://../scorers/qa_pass_scorer.py"
              }
            },
            {
              "assertion": {
                "type": "llm-rubric",
                "value": "This QA evaluation was given a GOOD scene extraction that accurately\nreflects the source text. The QA model should have:\n\n1. Marked it as passed (true)\n2. Found zero or very few errors\n3. Had high confidence in the assessment\n4. Written a summary confirming accuracy\n\nIf the model incorrectly flagged the good extraction as failing,\nthat's a false negative and should score poorly.\n"
              },
              "pass": true,
              "score": 1,
              "reason": "The QA evaluation correctly marked the extraction as passed (true), had high confidence (0.95), found only minor 'note'-severity issues (no actual errors), and wrote a summary confirming accuracy. This is exactly the expected behavior for a good extraction - no false negative occurred.",
              "tokensUsed": {
                "total": 765,
                "prompt": 686,
                "completion": 79,
                "cached": 0,
                "numRequests": 0,
                "completionDetails": {
                  "reasoning": 0,
                  "acceptedPrediction": 0,
                  "rejectedPrediction": 0
                }
              },
              "metadata": {
                "renderedGradingPrompt": "[{\"role\":\"system\",\"content\":\"You are grading output according to a user-specified rubric. If the statement in the rubric is true, then the output passes the test. You respond with a JSON object with this structure: {reason: string, pass: boolean, score: number}\\n\\nExamples:\\n\\n<Output>Hello world</Output>\\n<Rubric>Content contains a greeting</Rubric>\\n{\\\"reason\\\": \\\"the content contains the word 'Hello'\\\", \\\"pass\\\": true, \\\"score\\\": 1.0}\\n\\n<Output>Avast ye swabs, repel the invaders!</Output>\\n<Rubric>Does not speak like a pirate</Rubric>\\n{\\\"reason\\\": \\\"'avast ye' is a common pirate term\\\", \\\"pass\\\": false, \\\"score\\\": 0.0}\"},{\"role\":\"user\",\"content\":\"<Output>\\n```json\\n{\\n  \\\"passed\\\": true,\\n  \\\"confidence\\\": 0.95,\\n  \\\"issues\\\": [\\n    {\\n      \\\"severity\\\": \\\"note\\\",\\n      \\\"description\\\": \\\"The summary says 'skull fragment on the floor' but the text says she picks up 'a bloody scrap of something with hair on it' from next to her (not necessarily the floor), and she asks 'Is that skull??' — it's ambiguous whether it's confirmed skull. Minor imprecision.\\\",\\n      \\\"location\\\": \\\"summary\\\"\\n    },\\n    {\\n      \\\"severity\\\": \\\"note\\\",\\n      \\\"description\\\": \\\"The summary describes this as a 'violent rescue' — while the blood and context strongly imply this, the scene itself doesn't explicitly depict or describe a rescue; it's inferred from dialogue about being grabbed.\\\",\\n      \\\"location\\\": \\\"summary\\\"\\n    },\\n    {\\n      \\\"severity\\\": \\\"note\\\",\\n      \\\"description\\\": \\\"The term 'vigilante' is used in the summary to describe Mariner, which is a reasonable inference from context but not explicitly stated in this scene text.\\\",\\n      \\\"location\\\": \\\"summary\\\"\\n    },\\n    {\\n      \\\"severity\\\": \\\"note\\\",\\n      \\\"description\\\": \\\"Scene number 4 is assigned but there's no indication in the source text of what scene number this is.\\\",\\n      \\\"location\\\": \\\"scene_number\\\"\\n    }\\n  ],\\n  \\\"summary\\\": \\\"The extraction is accurate and faithful to the source text. All characters are correctly identified, the heading is exact, narrative beats are genuinely present in the scene, and the tone description aptly captures the dark comedy juxtaposition of muzak, skull fragments, and relationship bickering. Only very minor interpretive liberties were taken.\\\"\\n}\\n```\\n</Output>\\n<Rubric>\\nThis QA evaluation was given a GOOD scene extraction that accurately\\nreflects the source text. The QA model should have:\\n\\n1. Marked it as passed (true)\\n2. Found zero or very few errors\\n3. Had high confidence in the assessment\\n4. Written a summary confirming accuracy\\n\\nIf the model incorrectly flagged the good extraction as failing,\\nthat's a false negative and should score poorly.\\n\\n</Rubric>\"}]"
              }
            }
          ]
        },
        "id": "e4fb72b4-2f02-4d2a-88a4-febff3c33239",
        "latencyMs": 9011,
        "namedScores": {},
        "prompt": {
          "raw": "You are a QA reviewer validating whether an AI-extracted scene analysis is accurate and faithful to the source screenplay text.\n\nCompare the extracted scene data against the original scene text and evaluate:\n\n1. **Heading accuracy**: Is the scene heading correct (location, INT/EXT, time of day)?\n2. **Character completeness**: Are all characters who appear or speak listed?\n3. **Summary fidelity**: Does the summary accurately describe what happens? No fabrications?\n4. **Narrative beats**: Are the identified beats actually present in the scene?\n5. **Tone assessment**: Does the tone description match the actual mood of the scene?\n6. **Confidence calibration**: Is the confidence score reasonable given the quality?\n\nReturn a JSON object with:\n- passed: boolean (true if the extraction is faithful, false if it has significant errors)\n- confidence: float 0-1 (your confidence in this QA judgment)\n- issues: array of objects, each with:\n  - severity: \"error\" (factual wrong), \"warning\" (misleading), or \"note\" (minor)\n  - description: what's wrong\n  - location: which field has the issue\n- summary: 1-2 sentence overall assessment\n\nBe strict: wrong character names, fabricated events, or incorrect locations are errors.\nMinor omissions or imprecise tone descriptions are warnings.\n\nReturn ONLY valid JSON. No explanations or markdown fences.\n\n==========\nORIGINAL SCENE TEXT:\nINT. RUDDY & GREEN BUILDING - ELEVATOR\n\nUB40's \"I Can't Help Falling in Love With You\" muzak.\n\nROSE (mid-30s) leans against the elevator wall, panting. She's wearing a Tim Hortons uniform, her hair is a mess, and there's blood spattered on her face.\n\nShe looks right, pants a few more times, then squints in disgust. She gingerly picks up a bloody scrap of something with hair on it. She snorts and drops it.\n\nROSE\nIs that skull??\n\nNext to her is Mariner, also panting, covered in far more blood. His face is broad, stoic, and frowning. He has gray-blue eyes and a thick, curly, beard barely streaked with gray. He wears a red knit cap and a small mask.\n\nFULL-SCREEN SUPERIMPOSED TITLE CARD: \"THE MARINER\"\n\nHe blinks a few times as a drop of blood falls from his eyebrow. He looks toward her, then spits out some blood.\n\nMARINER\nYeaaaaah...\n\nHe's built like a pro-wrestler. Moss green SWEATER stretched over his huge frame, sleeves rolled showing heavy leather BRACERS adorned with anchors. His inner forearm has a classic heart-and-arrow TATTOO with \"Dad\" in the centre. Across his chest is a BANDOLIER of bright red 12-gauge shells, FISH HOOKS hanging from the bottom edge. Heavy rubberized BOOTS go past his knees. A CAPE of heavy FISHING NET edged with WEIGHTS hangs from his shoulders.\n\nHe holds a STOUT WOODEN OAR in both hands, edged with METAL and dripping with BLOOD.\n\nROSE\nWhere were you when they grabbed me? You were supposed to pick me up at work!\n\nMARINER\nYeah, about that, I got a little... distracted.\n\nROSE\nDistracted. You got DISTRACTED?!\n\nMARINER\nI was also... tracking the car... that grabbed you... through the AirTag... I put on your phone.\n\nRose stops. She's really not happy about this.\n\nROSE\nYou Airtagged me?!\n\n==========\nEXTRACTED SCENE DATA:\n{\n  \"scene_number\": 4,\n  \"heading\": \"INT. RUDDY & GREEN BUILDING - ELEVATOR\",\n  \"int_ext\": \"INT\",\n  \"location\": \"RUDDY & GREEN BUILDING - ELEVATOR\",\n  \"time_of_day\": null,\n  \"characters_present\": [\"ROSE\", \"MARINER\"],\n  \"summary\": \"Rose and Mariner ride the elevator after a violent rescue. Rose discovers a skull fragment on the floor while muzak plays. Mariner is introduced in full — a hulking vigilante in fishing-themed costume with an oar, net cape, and shell bandolier. Rose confronts him about being late to pick her up, and he reveals he tracked her via an AirTag on her phone, sparking a trust conflict between them.\",\n  \"narrative_beats\": [\n    {\"beat_type\": \"character_introduction\", \"description\": \"Full description of Mariner's fishing-themed vigilante costume — oar, net cape, bracers, shell bandolier, fish hooks.\", \"confidence\": 0.95},\n    {\"beat_type\": \"comic_relief\", \"description\": \"Rose discovers a skull fragment while muzak plays, establishing the dark comedy tone.\", \"confidence\": 0.90},\n    {\"beat_type\": \"revelation\", \"description\": \"Mariner admits he tracked Rose via AirTag on her phone, creating a trust conflict.\", \"confidence\": 0.88},\n    {\"beat_type\": \"conflict\", \"description\": \"Rose's anger escalates from being grabbed to learning she was being surveilled by Mariner.\", \"confidence\": 0.85}\n  ],\n  \"tone_mood\": \"dark comedy with bursts of tension\",\n  \"confidence\": 0.91\n}\n==========",
          "label": "prompts/qa-pass.txt: You are a QA reviewer validating whether an AI-extracted scene analysis is accurate and faithful to the source screenplay text.\n\nCompare the extracted scene data against the original scene text and evaluate:\n\n1. **Heading accuracy**: Is the scene heading correct (location, INT/EXT, time of day)?\n2. **Character completeness**: Are all characters who appear or speak listed?\n3. **Summary fidelity**: Does the summary accurately describe what happens? No fabrications?\n4. **Narrative beats**: Are the identified beats actually present in the scene?\n5. **Tone assessment**: Does the tone description match the actual mood of the scene?\n6. **Confidence calibration**: Is the confidence score reasonable given the quality?\n\nReturn a JSON object with:\n- passed: boolean (true if the extraction is faithful, false if it has significant errors)\n- confidence: float 0-1 (your confidence in this QA judgment)\n- issues: array of objects, each with:\n  - severity: \"error\" (factual wrong), \"warning\" (misleading), or \"note\" (minor)\n  - description: what's wrong\n  - location: which field has the issue\n- summary: 1-2 sentence overall assessment\n\nBe strict: wrong character names, fabricated events, or incorrect locations are errors.\nMinor omissions or imprecise tone descriptions are warnings.\n\nReturn ONLY valid JSON. No explanations or markdown fences.\n\n==========\nORIGINAL SCENE TEXT:\n{{scene_text}}\n\n==========\nEXTRACTED SCENE DATA:\n{{extracted_data}}\n==========",
          "config": {
            "provider": "anthropic:messages:claude-opus-4-6"
          }
        },
        "promptId": "8df20c2c4a6081352d6b06e144ddbc1e0a5244f9a3c2000d40df12fc9a94e543",
        "promptIdx": 7,
        "provider": {
          "id": "anthropic:messages:claude-opus-4-6",
          "label": "Claude Opus 4.6"
        },
        "response": {
          "output": "```json\n{\n  \"passed\": true,\n  \"confidence\": 0.95,\n  \"issues\": [\n    {\n      \"severity\": \"note\",\n      \"description\": \"The summary says 'skull fragment on the floor' but the text says she picks up 'a bloody scrap of something with hair on it' from next to her (not necessarily the floor), and she asks 'Is that skull??' — it's ambiguous whether it's confirmed skull. Minor imprecision.\",\n      \"location\": \"summary\"\n    },\n    {\n      \"severity\": \"note\",\n      \"description\": \"The summary describes this as a 'violent rescue' — while the blood and context strongly imply this, the scene itself doesn't explicitly depict or describe a rescue; it's inferred from dialogue about being grabbed.\",\n      \"location\": \"summary\"\n    },\n    {\n      \"severity\": \"note\",\n      \"description\": \"The term 'vigilante' is used in the summary to describe Mariner, which is a reasonable inference from context but not explicitly stated in this scene text.\",\n      \"location\": \"summary\"\n    },\n    {\n      \"severity\": \"note\",\n      \"description\": \"Scene number 4 is assigned but there's no indication in the source text of what scene number this is.\",\n      \"location\": \"scene_number\"\n    }\n  ],\n  \"summary\": \"The extraction is accurate and faithful to the source text. All characters are correctly identified, the heading is exact, narrative beats are genuinely present in the scene, and the tone description aptly captures the dark comedy juxtaposition of muzak, skull fragments, and relationship bickering. Only very minor interpretive liberties were taken.\"\n}\n```",
          "tokenUsage": {
            "total": 1638,
            "prompt": 1243,
            "completion": 395
          },
          "finishReason": "stop",
          "cost": 0.01609
        },
        "score": 0.995,
        "success": true,
        "testCase": {
          "vars": {
            "scene_text": "file://../input/enrich-scene-elevator.txt",
            "extracted_data": "file://../input/qa-good-scene.json",
            "golden_path": "golden/qa-pass-golden.json",
            "test_key": "good_scene"
          },
          "assert": [
            {
              "type": "python",
              "value": "file://../scorers/qa_pass_scorer.py"
            },
            {
              "type": "llm-rubric",
              "value": "This QA evaluation was given a GOOD scene extraction that accurately\nreflects the source text. The QA model should have:\n\n1. Marked it as passed (true)\n2. Found zero or very few errors\n3. Had high confidence in the assessment\n4. Written a summary confirming accuracy\n\nIf the model incorrectly flagged the good extraction as failing,\nthat's a false negative and should score poorly.\n"
            }
          ],
          "options": {
            "provider": "anthropic:messages:claude-opus-4-6"
          },
          "metadata": {}
        },
        "testIdx": 0,
        "vars": {
          "scene_text": "file://../input/enrich-scene-elevator.txt",
          "extracted_data": "file://../input/qa-good-scene.json",
          "golden_path": "golden/qa-pass-golden.json",
          "test_key": "good_scene"
        },
        "metadata": {
          "_promptfooFileMetadata": {}
        },
        "failureReason": 0
      },
      {
        "cost": 0.0002156,
        "gradingResult": {
          "pass": true,
          "score": 0.95,
          "reason": "All assertions passed",
          "namedScores": {},
          "tokensUsed": {
            "total": 804,
            "prompt": 602,
            "completion": 202,
            "cached": 0,
            "numRequests": 0
          },
          "componentResults": [
            {
              "pass": true,
              "score": 1,
              "reason": "confidence_calibration=1.00 | issue_detection=1.00 | json_valid=1.00 | pass_correct=1.00 | severity_accuracy=1.00 | summary_quality=1.00",
              "assertion": {
                "type": "python",
                "value": "file://../scorers/qa_pass_scorer.py"
              }
            },
            {
              "assertion": {
                "type": "llm-rubric",
                "value": "This QA evaluation was given a BAD scene extraction with multiple errors:\n- Wrong building name (Office Building vs Ruddy & Greene)\n- Wrong time of day (DAY vs NIGHT)\n- Wrong character name (Billy instead of Mariner)\n- Missing thug characters\n- Fabricated content (grocery discussion never happens)\n\nThe QA model should have:\n1. Marked it as failed (false)\n2. Identified at least 2-3 specific errors\n3. Flagged the fabricated summary content\n4. Used \"error\" severity for factual mistakes\n\nIf the model let this pass, that's a dangerous false positive.\n"
              },
              "pass": true,
              "score": 0.9,
              "reason": "The QA evaluation correctly identified the scene extraction as failed (passed: false). It flagged multiple specific errors: wrong building name ('OFFICE BUILDING' vs 'RUDDY & GREEN BUILDING'), wrong character name ('BILLY' instead of 'MARINER'), fabricated summary content (discussing plans/groceries vs the actual tense, bloodied situation), and mismatched narrative beats. It used 'error' severity for factual mistakes and 'warning' for tone issues. It identified well over 2-3 specific errors (5 issues total). The only minor gap is that it didn't explicitly call out the wrong time of day (DAY vs NIGHT) or the missing thug characters, but it met all the core criteria: marked as failed, identified multiple specific errors, flagged fabricated content, and used appropriate severity levels.",
              "tokensUsed": {
                "total": 804,
                "prompt": 602,
                "completion": 202,
                "cached": 0,
                "numRequests": 0,
                "completionDetails": {
                  "reasoning": 0,
                  "acceptedPrediction": 0,
                  "rejectedPrediction": 0
                }
              },
              "metadata": {
                "renderedGradingPrompt": "[{\"role\":\"system\",\"content\":\"You are grading output according to a user-specified rubric. If the statement in the rubric is true, then the output passes the test. You respond with a JSON object with this structure: {reason: string, pass: boolean, score: number}\\n\\nExamples:\\n\\n<Output>Hello world</Output>\\n<Rubric>Content contains a greeting</Rubric>\\n{\\\"reason\\\": \\\"the content contains the word 'Hello'\\\", \\\"pass\\\": true, \\\"score\\\": 1.0}\\n\\n<Output>Avast ye swabs, repel the invaders!</Output>\\n<Rubric>Does not speak like a pirate</Rubric>\\n{\\\"reason\\\": \\\"'avast ye' is a common pirate term\\\", \\\"pass\\\": false, \\\"score\\\": 0.0}\"},{\"role\":\"user\",\"content\":\"<Output>\\n{\\\"passed\\\":false,\\\"confidence\\\":0.9,\\\"issues\\\":[{\\\"severity\\\":\\\"error\\\",\\\"description\\\":\\\"Scene heading is incorrect; original scene is in a building called 'RUDDY & GREEN BUILDING' with a specific elevator scene, not 'OFFICE BUILDING'.\\\",\\\"location\\\":\\\"heading\\\"},{\\\"severity\\\":\\\"error\\\",\\\"description\\\":\\\"Characters listed are 'ROSE' and 'BILLY', but original scene features 'ROSE' and 'MARINER'.\\\",\\\"location\\\":\\\"characters_present\\\"},{\\\"severity\\\":\\\"error\\\",\\\"description\\\":\\\"Summary fabricates events; original scene involves Rose and Mariner in a tense, bloodied situation, not discussing plans or groceries.\\\",\\\"location\\\":\\\"summary\\\"},{\\\"severity\\\":\\\"error\\\",\\\"description\\\":\\\"Narrative beats do not match; original scene contains tension, blood, and dialogue about tracking via AirTag, not casual plans.\\\",\\\"location\\\":\\\"narrative_beats\\\"},{\\\"severity\\\":\\\"warning\\\",\\\"description\\\":\\\"Tone is more tense and gritty, not casual as described.\\\",\\\"location\\\":\\\"tone_mood\\\"}],\\\"summary\\\":\\\"The extracted scene data significantly misrepresents the original scene's location, characters, events, and tone, leading to a failure in faithful extraction.\\\"}\\n</Output>\\n<Rubric>\\nThis QA evaluation was given a BAD scene extraction with multiple errors:\\n- Wrong building name (Office Building vs Ruddy & Greene)\\n- Wrong time of day (DAY vs NIGHT)\\n- Wrong character name (Billy instead of Mariner)\\n- Missing thug characters\\n- Fabricated content (grocery discussion never happens)\\n\\nThe QA model should have:\\n1. Marked it as failed (false)\\n2. Identified at least 2-3 specific errors\\n3. Flagged the fabricated summary content\\n4. Used \\\"error\\\" severity for factual mistakes\\n\\nIf the model let this pass, that's a dangerous false positive.\\n\\n</Rubric>\"}]"
              }
            }
          ]
        },
        "id": "80568109-74c1-4431-b4ef-44479b564190",
        "latencyMs": 4511,
        "namedScores": {},
        "prompt": {
          "raw": "You are a QA reviewer validating whether an AI-extracted scene analysis is accurate and faithful to the source screenplay text.\n\nCompare the extracted scene data against the original scene text and evaluate:\n\n1. **Heading accuracy**: Is the scene heading correct (location, INT/EXT, time of day)?\n2. **Character completeness**: Are all characters who appear or speak listed?\n3. **Summary fidelity**: Does the summary accurately describe what happens? No fabrications?\n4. **Narrative beats**: Are the identified beats actually present in the scene?\n5. **Tone assessment**: Does the tone description match the actual mood of the scene?\n6. **Confidence calibration**: Is the confidence score reasonable given the quality?\n\nReturn a JSON object with:\n- passed: boolean (true if the extraction is faithful, false if it has significant errors)\n- confidence: float 0-1 (your confidence in this QA judgment)\n- issues: array of objects, each with:\n  - severity: \"error\" (factual wrong), \"warning\" (misleading), or \"note\" (minor)\n  - description: what's wrong\n  - location: which field has the issue\n- summary: 1-2 sentence overall assessment\n\nBe strict: wrong character names, fabricated events, or incorrect locations are errors.\nMinor omissions or imprecise tone descriptions are warnings.\n\nReturn ONLY valid JSON. No explanations or markdown fences.\n\n==========\nORIGINAL SCENE TEXT:\nINT. RUDDY & GREEN BUILDING - ELEVATOR\n\nUB40's \"I Can't Help Falling in Love With You\" muzak.\n\nROSE (mid-30s) leans against the elevator wall, panting. She's wearing a Tim Hortons uniform, her hair is a mess, and there's blood spattered on her face.\n\nShe looks right, pants a few more times, then squints in disgust. She gingerly picks up a bloody scrap of something with hair on it. She snorts and drops it.\n\nROSE\nIs that skull??\n\nNext to her is Mariner, also panting, covered in far more blood. His face is broad, stoic, and frowning. He has gray-blue eyes and a thick, curly, beard barely streaked with gray. He wears a red knit cap and a small mask.\n\nFULL-SCREEN SUPERIMPOSED TITLE CARD: \"THE MARINER\"\n\nHe blinks a few times as a drop of blood falls from his eyebrow. He looks toward her, then spits out some blood.\n\nMARINER\nYeaaaaah...\n\nHe's built like a pro-wrestler. Moss green SWEATER stretched over his huge frame, sleeves rolled showing heavy leather BRACERS adorned with anchors. His inner forearm has a classic heart-and-arrow TATTOO with \"Dad\" in the centre. Across his chest is a BANDOLIER of bright red 12-gauge shells, FISH HOOKS hanging from the bottom edge. Heavy rubberized BOOTS go past his knees. A CAPE of heavy FISHING NET edged with WEIGHTS hangs from his shoulders.\n\nHe holds a STOUT WOODEN OAR in both hands, edged with METAL and dripping with BLOOD.\n\nROSE\nWhere were you when they grabbed me? You were supposed to pick me up at work!\n\nMARINER\nYeah, about that, I got a little... distracted.\n\nROSE\nDistracted. You got DISTRACTED?!\n\nMARINER\nI was also... tracking the car... that grabbed you... through the AirTag... I put on your phone.\n\nRose stops. She's really not happy about this.\n\nROSE\nYou Airtagged me?!\n\n==========\nEXTRACTED SCENE DATA:\n{\n  \"scene_number\": 4,\n  \"heading\": \"INT. OFFICE BUILDING - ELEVATOR\",\n  \"int_ext\": \"INT\",\n  \"location\": \"OFFICE BUILDING - ELEVATOR\",\n  \"time_of_day\": \"DAY\",\n  \"characters_present\": [\"ROSE\", \"BILLY\"],\n  \"summary\": \"Billy and Rose take the elevator in an office building. They discuss their plans for the evening. Rose mentions she needs to pick up groceries.\",\n  \"narrative_beats\": [\n    {\"beat_type\": \"exposition\", \"description\": \"Characters discuss daily plans.\", \"confidence\": 0.85}\n  ],\n  \"tone_mood\": \"casual\",\n  \"confidence\": 0.88\n}\n==========",
          "label": "prompts/qa-pass.txt: You are a QA reviewer validating whether an AI-extracted scene analysis is accurate and faithful to the source screenplay text.\n\nCompare the extracted scene data against the original scene text and evaluate:\n\n1. **Heading accuracy**: Is the scene heading correct (location, INT/EXT, time of day)?\n2. **Character completeness**: Are all characters who appear or speak listed?\n3. **Summary fidelity**: Does the summary accurately describe what happens? No fabrications?\n4. **Narrative beats**: Are the identified beats actually present in the scene?\n5. **Tone assessment**: Does the tone description match the actual mood of the scene?\n6. **Confidence calibration**: Is the confidence score reasonable given the quality?\n\nReturn a JSON object with:\n- passed: boolean (true if the extraction is faithful, false if it has significant errors)\n- confidence: float 0-1 (your confidence in this QA judgment)\n- issues: array of objects, each with:\n  - severity: \"error\" (factual wrong), \"warning\" (misleading), or \"note\" (minor)\n  - description: what's wrong\n  - location: which field has the issue\n- summary: 1-2 sentence overall assessment\n\nBe strict: wrong character names, fabricated events, or incorrect locations are errors.\nMinor omissions or imprecise tone descriptions are warnings.\n\nReturn ONLY valid JSON. No explanations or markdown fences.\n\n==========\nORIGINAL SCENE TEXT:\n{{scene_text}}\n\n==========\nEXTRACTED SCENE DATA:\n{{extracted_data}}\n==========",
          "config": {
            "provider": "anthropic:messages:claude-opus-4-6"
          }
        },
        "promptId": "8df20c2c4a6081352d6b06e144ddbc1e0a5244f9a3c2000d40df12fc9a94e543",
        "promptIdx": 0,
        "provider": {
          "id": "openai:gpt-4.1-nano",
          "label": "GPT-4.1 Nano"
        },
        "response": {
          "output": "{\n  \"passed\": false,\n  \"confidence\": 0.9,\n  \"issues\": [\n    {\n      \"severity\": \"error\",\n      \"description\": \"Scene heading is incorrect; original scene is in a building called 'RUDDY & GREEN BUILDING' with a specific elevator scene, not 'OFFICE BUILDING'.\",\n      \"location\": \"heading\"\n    },\n    {\n      \"severity\": \"error\",\n      \"description\": \"Characters listed are 'ROSE' and 'BILLY', but original scene features 'ROSE' and 'MARINER'.\",\n      \"location\": \"characters_present\"\n    },\n    {\n      \"severity\": \"error\",\n      \"description\": \"Summary fabricates events; original scene involves Rose and Mariner in a tense, bloodied situation, not discussing plans or groceries.\",\n      \"location\": \"summary\"\n    },\n    {\n      \"severity\": \"error\",\n      \"description\": \"Narrative beats do not match; original scene contains tension, blood, and dialogue about tracking via AirTag, not casual plans.\",\n      \"location\": \"narrative_beats\"\n    },\n    {\n      \"severity\": \"warning\",\n      \"description\": \"Tone is more tense and gritty, not casual as described.\",\n      \"location\": \"tone_mood\"\n    }\n  ],\n  \"summary\": \"The extracted scene data significantly misrepresents the original scene's location, characters, events, and tone, leading to a failure in faithful extraction.\"\n}",
          "tokenUsage": {
            "total": 1235,
            "prompt": 928,
            "completion": 307,
            "numRequests": 1,
            "completionDetails": {
              "reasoning": 0,
              "acceptedPrediction": 0,
              "rejectedPrediction": 0
            }
          },
          "cached": false,
          "latencyMs": 4511,
          "finishReason": "stop",
          "cost": 0.0002156,
          "guardrails": {
            "flagged": false
          },
          "metadata": {
            "http": {
              "status": 200,
              "statusText": "OK",
              "headers": {
                "access-control-expose-headers": "X-Request-ID",
                "alt-svc": "h3=\":443\"; ma=86400",
                "cf-cache-status": "DYNAMIC",
                "cf-ray": "9cfbd32a0a1d5819-YVR",
                "connection": "keep-alive",
                "content-encoding": "br",
                "content-type": "application/json",
                "date": "Wed, 18 Feb 2026 07:31:30 GMT",
                "openai-organization": "user-oqdrq8y0bphopngnvkyuu5wr",
                "openai-processing-ms": "4389",
                "openai-project": "proj_ZRoLLwXcJok6Xg2t6eKhI1pn",
                "openai-version": "2020-10-01",
                "server": "cloudflare",
                "set-cookie": "__cf_bm=osJUkwNc7yzB._ffearOLbW_JRG4jMKy.vvGqPG7Gx4-1771399886.4074035-1.0.1.1-4wQuo8BUPiGT_q3ax9AoSFA8aY5K6HrUlCuHCIepyUFC1DHwYdVNO_5MHECG6ALh_m3ZVd_3zB6qFPAeREI.JOUl51aiNwbcCpcuQb0Nnbf.6C3Vc2HXyUzfxjfUNwt1; HttpOnly; Secure; Path=/; Domain=api.openai.com; Expires=Wed, 18 Feb 2026 08:01:30 GMT",
                "strict-transport-security": "max-age=31536000; includeSubDomains; preload",
                "transfer-encoding": "chunked",
                "x-content-type-options": "nosniff",
                "x-openai-proxy-wasm": "v0.1",
                "x-ratelimit-limit-requests": "10000",
                "x-ratelimit-limit-tokens": "10000000",
                "x-ratelimit-remaining-requests": "9999",
                "x-ratelimit-remaining-tokens": "9999073",
                "x-ratelimit-reset-requests": "6ms",
                "x-ratelimit-reset-tokens": "5ms",
                "x-request-id": "req_ba4be794f6de466f9a6921d457320dec"
              }
            }
          }
        },
        "score": 0.95,
        "success": true,
        "testCase": {
          "vars": {
            "scene_text": "file://../input/enrich-scene-elevator.txt",
            "extracted_data": "file://../input/qa-bad-scene.json",
            "golden_path": "golden/qa-pass-golden.json",
            "test_key": "bad_scene"
          },
          "assert": [
            {
              "type": "python",
              "value": "file://../scorers/qa_pass_scorer.py"
            },
            {
              "type": "llm-rubric",
              "value": "This QA evaluation was given a BAD scene extraction with multiple errors:\n- Wrong building name (Office Building vs Ruddy & Greene)\n- Wrong time of day (DAY vs NIGHT)\n- Wrong character name (Billy instead of Mariner)\n- Missing thug characters\n- Fabricated content (grocery discussion never happens)\n\nThe QA model should have:\n1. Marked it as failed (false)\n2. Identified at least 2-3 specific errors\n3. Flagged the fabricated summary content\n4. Used \"error\" severity for factual mistakes\n\nIf the model let this pass, that's a dangerous false positive.\n"
            }
          ],
          "options": {
            "provider": "anthropic:messages:claude-opus-4-6"
          },
          "metadata": {}
        },
        "testIdx": 1,
        "vars": {
          "scene_text": "file://../input/enrich-scene-elevator.txt",
          "extracted_data": "file://../input/qa-bad-scene.json",
          "golden_path": "golden/qa-pass-golden.json",
          "test_key": "bad_scene"
        },
        "metadata": {
          "http": {
            "status": 200,
            "statusText": "OK",
            "headers": {
              "access-control-expose-headers": "X-Request-ID",
              "alt-svc": "h3=\":443\"; ma=86400",
              "cf-cache-status": "DYNAMIC",
              "cf-ray": "9cfbd32a0a1d5819-YVR",
              "connection": "keep-alive",
              "content-encoding": "br",
              "content-type": "application/json",
              "date": "Wed, 18 Feb 2026 07:31:30 GMT",
              "openai-organization": "user-oqdrq8y0bphopngnvkyuu5wr",
              "openai-processing-ms": "4389",
              "openai-project": "proj_ZRoLLwXcJok6Xg2t6eKhI1pn",
              "openai-version": "2020-10-01",
              "server": "cloudflare",
              "set-cookie": "__cf_bm=osJUkwNc7yzB._ffearOLbW_JRG4jMKy.vvGqPG7Gx4-1771399886.4074035-1.0.1.1-4wQuo8BUPiGT_q3ax9AoSFA8aY5K6HrUlCuHCIepyUFC1DHwYdVNO_5MHECG6ALh_m3ZVd_3zB6qFPAeREI.JOUl51aiNwbcCpcuQb0Nnbf.6C3Vc2HXyUzfxjfUNwt1; HttpOnly; Secure; Path=/; Domain=api.openai.com; Expires=Wed, 18 Feb 2026 08:01:30 GMT",
              "strict-transport-security": "max-age=31536000; includeSubDomains; preload",
              "transfer-encoding": "chunked",
              "x-content-type-options": "nosniff",
              "x-openai-proxy-wasm": "v0.1",
              "x-ratelimit-limit-requests": "10000",
              "x-ratelimit-limit-tokens": "10000000",
              "x-ratelimit-remaining-requests": "9999",
              "x-ratelimit-remaining-tokens": "9999073",
              "x-ratelimit-reset-requests": "6ms",
              "x-ratelimit-reset-tokens": "5ms",
              "x-request-id": "req_ba4be794f6de466f9a6921d457320dec"
            }
          },
          "_promptfooFileMetadata": {}
        },
        "failureReason": 0
      },
      {
        "cost": 0.0009632000000000001,
        "gradingResult": {
          "pass": true,
          "score": 1,
          "reason": "All assertions passed",
          "namedScores": {},
          "tokensUsed": {
            "total": 842,
            "prompt": 661,
            "completion": 181,
            "cached": 0,
            "numRequests": 0
          },
          "componentResults": [
            {
              "pass": true,
              "score": 1,
              "reason": "confidence_calibration=1.00 | issue_detection=1.00 | json_valid=1.00 | pass_correct=1.00 | severity_accuracy=1.00 | summary_quality=1.00",
              "assertion": {
                "type": "python",
                "value": "file://../scorers/qa_pass_scorer.py"
              }
            },
            {
              "assertion": {
                "type": "llm-rubric",
                "value": "This QA evaluation was given a BAD scene extraction with multiple errors:\n- Wrong building name (Office Building vs Ruddy & Greene)\n- Wrong time of day (DAY vs NIGHT)\n- Wrong character name (Billy instead of Mariner)\n- Missing thug characters\n- Fabricated content (grocery discussion never happens)\n\nThe QA model should have:\n1. Marked it as failed (false)\n2. Identified at least 2-3 specific errors\n3. Flagged the fabricated summary content\n4. Used \"error\" severity for factual mistakes\n\nIf the model let this pass, that's a dangerous false positive.\n"
              },
              "pass": true,
              "score": 1,
              "reason": "The QA evaluation correctly identified the extraction as failed (passed: false) with high confidence (0.95). It identified multiple specific errors: (1) wrong building name (Office Building vs Ruddy & Green), (2) wrong time of day (DAY vs not specified/NIGHT), (3) wrong character name (Billy instead of Mariner), (4) fabricated summary content (grocery discussion), and (5) mischaracterized tone. All factual mistakes were appropriately flagged with 'error' severity. The evaluation caught at least 5 specific errors, well exceeding the 2-3 minimum threshold. It also correctly flagged the fabricated content. This is not a false positive — the model properly rejected the bad extraction.",
              "tokensUsed": {
                "total": 842,
                "prompt": 661,
                "completion": 181,
                "cached": 0,
                "numRequests": 0,
                "completionDetails": {
                  "reasoning": 0,
                  "acceptedPrediction": 0,
                  "rejectedPrediction": 0
                }
              },
              "metadata": {
                "renderedGradingPrompt": "[{\"role\":\"system\",\"content\":\"You are grading output according to a user-specified rubric. If the statement in the rubric is true, then the output passes the test. You respond with a JSON object with this structure: {reason: string, pass: boolean, score: number}\\n\\nExamples:\\n\\n<Output>Hello world</Output>\\n<Rubric>Content contains a greeting</Rubric>\\n{\\\"reason\\\": \\\"the content contains the word 'Hello'\\\", \\\"pass\\\": true, \\\"score\\\": 1.0}\\n\\n<Output>Avast ye swabs, repel the invaders!</Output>\\n<Rubric>Does not speak like a pirate</Rubric>\\n{\\\"reason\\\": \\\"'avast ye' is a common pirate term\\\", \\\"pass\\\": false, \\\"score\\\": 0.0}\"},{\"role\":\"user\",\"content\":\"<Output>\\n{\\\"passed\\\":false,\\\"confidence\\\":0.95,\\\"issues\\\":[{\\\"severity\\\":\\\"error\\\",\\\"description\\\":\\\"Scene heading location is incorrect; original is 'RUDDY & GREEN BUILDING - ELEVATOR', extracted says 'OFFICE BUILDING - ELEVATOR'.\\\",\\\"location\\\":\\\"heading\\\"},{\\\"severity\\\":\\\"error\\\",\\\"description\\\":\\\"Time of day is not specified in original; extracted incorrectly states 'DAY'.\\\",\\\"location\\\":\\\"time_of_day\\\"},{\\\"severity\\\":\\\"error\\\",\\\"description\\\":\\\"Character 'BILLY' does not appear in the scene; original characters are 'ROSE' and 'MARINER'.\\\",\\\"location\\\":\\\"characters_present\\\"},{\\\"severity\\\":\\\"error\\\",\\\"description\\\":\\\"Summary fabricates events and characters not present; no discussion of plans or groceries occurs, and 'Billy' is not in the scene.\\\",\\\"location\\\":\\\"summary\\\"},{\\\"severity\\\":\\\"error\\\",\\\"description\\\":\\\"Narrative beat 'Characters discuss daily plans' is not present; the scene focuses on tension, blood, and tracking via AirTag.\\\",\\\"location\\\":\\\"narrative_beats\\\"},{\\\"severity\\\":\\\"warning\\\",\\\"description\\\":\\\"Tone described as 'casual' is misleading; the scene is tense, grim, and suspenseful.\\\",\\\"location\\\":\\\"tone_mood\\\"}],\\\"summary\\\":\\\"The extracted data contains multiple significant factual errors including incorrect location, characters, and fabricated summary content, making it unfaithful to the original scene. The tone is also mischaracterized as casual instead of tense.\\\"}\\n</Output>\\n<Rubric>\\nThis QA evaluation was given a BAD scene extraction with multiple errors:\\n- Wrong building name (Office Building vs Ruddy & Greene)\\n- Wrong time of day (DAY vs NIGHT)\\n- Wrong character name (Billy instead of Mariner)\\n- Missing thug characters\\n- Fabricated content (grocery discussion never happens)\\n\\nThe QA model should have:\\n1. Marked it as failed (false)\\n2. Identified at least 2-3 specific errors\\n3. Flagged the fabricated summary content\\n4. Used \\\"error\\\" severity for factual mistakes\\n\\nIf the model let this pass, that's a dangerous false positive.\\n\\n</Rubric>\"}]"
              }
            }
          ]
        },
        "id": "eecb5d6a-18c0-4b77-a17a-6dd2b160aa40",
        "latencyMs": 6132,
        "namedScores": {},
        "prompt": {
          "raw": "You are a QA reviewer validating whether an AI-extracted scene analysis is accurate and faithful to the source screenplay text.\n\nCompare the extracted scene data against the original scene text and evaluate:\n\n1. **Heading accuracy**: Is the scene heading correct (location, INT/EXT, time of day)?\n2. **Character completeness**: Are all characters who appear or speak listed?\n3. **Summary fidelity**: Does the summary accurately describe what happens? No fabrications?\n4. **Narrative beats**: Are the identified beats actually present in the scene?\n5. **Tone assessment**: Does the tone description match the actual mood of the scene?\n6. **Confidence calibration**: Is the confidence score reasonable given the quality?\n\nReturn a JSON object with:\n- passed: boolean (true if the extraction is faithful, false if it has significant errors)\n- confidence: float 0-1 (your confidence in this QA judgment)\n- issues: array of objects, each with:\n  - severity: \"error\" (factual wrong), \"warning\" (misleading), or \"note\" (minor)\n  - description: what's wrong\n  - location: which field has the issue\n- summary: 1-2 sentence overall assessment\n\nBe strict: wrong character names, fabricated events, or incorrect locations are errors.\nMinor omissions or imprecise tone descriptions are warnings.\n\nReturn ONLY valid JSON. No explanations or markdown fences.\n\n==========\nORIGINAL SCENE TEXT:\nINT. RUDDY & GREEN BUILDING - ELEVATOR\n\nUB40's \"I Can't Help Falling in Love With You\" muzak.\n\nROSE (mid-30s) leans against the elevator wall, panting. She's wearing a Tim Hortons uniform, her hair is a mess, and there's blood spattered on her face.\n\nShe looks right, pants a few more times, then squints in disgust. She gingerly picks up a bloody scrap of something with hair on it. She snorts and drops it.\n\nROSE\nIs that skull??\n\nNext to her is Mariner, also panting, covered in far more blood. His face is broad, stoic, and frowning. He has gray-blue eyes and a thick, curly, beard barely streaked with gray. He wears a red knit cap and a small mask.\n\nFULL-SCREEN SUPERIMPOSED TITLE CARD: \"THE MARINER\"\n\nHe blinks a few times as a drop of blood falls from his eyebrow. He looks toward her, then spits out some blood.\n\nMARINER\nYeaaaaah...\n\nHe's built like a pro-wrestler. Moss green SWEATER stretched over his huge frame, sleeves rolled showing heavy leather BRACERS adorned with anchors. His inner forearm has a classic heart-and-arrow TATTOO with \"Dad\" in the centre. Across his chest is a BANDOLIER of bright red 12-gauge shells, FISH HOOKS hanging from the bottom edge. Heavy rubberized BOOTS go past his knees. A CAPE of heavy FISHING NET edged with WEIGHTS hangs from his shoulders.\n\nHe holds a STOUT WOODEN OAR in both hands, edged with METAL and dripping with BLOOD.\n\nROSE\nWhere were you when they grabbed me? You were supposed to pick me up at work!\n\nMARINER\nYeah, about that, I got a little... distracted.\n\nROSE\nDistracted. You got DISTRACTED?!\n\nMARINER\nI was also... tracking the car... that grabbed you... through the AirTag... I put on your phone.\n\nRose stops. She's really not happy about this.\n\nROSE\nYou Airtagged me?!\n\n==========\nEXTRACTED SCENE DATA:\n{\n  \"scene_number\": 4,\n  \"heading\": \"INT. OFFICE BUILDING - ELEVATOR\",\n  \"int_ext\": \"INT\",\n  \"location\": \"OFFICE BUILDING - ELEVATOR\",\n  \"time_of_day\": \"DAY\",\n  \"characters_present\": [\"ROSE\", \"BILLY\"],\n  \"summary\": \"Billy and Rose take the elevator in an office building. They discuss their plans for the evening. Rose mentions she needs to pick up groceries.\",\n  \"narrative_beats\": [\n    {\"beat_type\": \"exposition\", \"description\": \"Characters discuss daily plans.\", \"confidence\": 0.85}\n  ],\n  \"tone_mood\": \"casual\",\n  \"confidence\": 0.88\n}\n==========",
          "label": "prompts/qa-pass.txt: You are a QA reviewer validating whether an AI-extracted scene analysis is accurate and faithful to the source screenplay text.\n\nCompare the extracted scene data against the original scene text and evaluate:\n\n1. **Heading accuracy**: Is the scene heading correct (location, INT/EXT, time of day)?\n2. **Character completeness**: Are all characters who appear or speak listed?\n3. **Summary fidelity**: Does the summary accurately describe what happens? No fabrications?\n4. **Narrative beats**: Are the identified beats actually present in the scene?\n5. **Tone assessment**: Does the tone description match the actual mood of the scene?\n6. **Confidence calibration**: Is the confidence score reasonable given the quality?\n\nReturn a JSON object with:\n- passed: boolean (true if the extraction is faithful, false if it has significant errors)\n- confidence: float 0-1 (your confidence in this QA judgment)\n- issues: array of objects, each with:\n  - severity: \"error\" (factual wrong), \"warning\" (misleading), or \"note\" (minor)\n  - description: what's wrong\n  - location: which field has the issue\n- summary: 1-2 sentence overall assessment\n\nBe strict: wrong character names, fabricated events, or incorrect locations are errors.\nMinor omissions or imprecise tone descriptions are warnings.\n\nReturn ONLY valid JSON. No explanations or markdown fences.\n\n==========\nORIGINAL SCENE TEXT:\n{{scene_text}}\n\n==========\nEXTRACTED SCENE DATA:\n{{extracted_data}}\n==========",
          "config": {
            "provider": "anthropic:messages:claude-opus-4-6"
          }
        },
        "promptId": "8df20c2c4a6081352d6b06e144ddbc1e0a5244f9a3c2000d40df12fc9a94e543",
        "promptIdx": 1,
        "provider": {
          "id": "openai:gpt-4.1-mini",
          "label": "GPT-4.1 Mini"
        },
        "response": {
          "output": "{\n  \"passed\": false,\n  \"confidence\": 0.95,\n  \"issues\": [\n    {\n      \"severity\": \"error\",\n      \"description\": \"Scene heading location is incorrect; original is 'RUDDY & GREEN BUILDING - ELEVATOR', extracted says 'OFFICE BUILDING - ELEVATOR'.\",\n      \"location\": \"heading\"\n    },\n    {\n      \"severity\": \"error\",\n      \"description\": \"Time of day is not specified in original; extracted incorrectly states 'DAY'.\",\n      \"location\": \"time_of_day\"\n    },\n    {\n      \"severity\": \"error\",\n      \"description\": \"Character 'BILLY' does not appear in the scene; original characters are 'ROSE' and 'MARINER'.\",\n      \"location\": \"characters_present\"\n    },\n    {\n      \"severity\": \"error\",\n      \"description\": \"Summary fabricates events and characters not present; no discussion of plans or groceries occurs, and 'Billy' is not in the scene.\",\n      \"location\": \"summary\"\n    },\n    {\n      \"severity\": \"error\",\n      \"description\": \"Narrative beat 'Characters discuss daily plans' is not present; the scene focuses on tension, blood, and tracking via AirTag.\",\n      \"location\": \"narrative_beats\"\n    },\n    {\n      \"severity\": \"warning\",\n      \"description\": \"Tone described as 'casual' is misleading; the scene is tense, grim, and suspenseful.\",\n      \"location\": \"tone_mood\"\n    }\n  ],\n  \"summary\": \"The extracted data contains multiple significant factual errors including incorrect location, characters, and fabricated summary content, making it unfaithful to the original scene. The tone is also mischaracterized as casual instead of tense.\"\n}",
          "tokenUsage": {
            "total": 1298,
            "prompt": 928,
            "completion": 370,
            "numRequests": 1,
            "completionDetails": {
              "reasoning": 0,
              "acceptedPrediction": 0,
              "rejectedPrediction": 0
            }
          },
          "cached": false,
          "latencyMs": 6132,
          "finishReason": "stop",
          "cost": 0.0009632000000000001,
          "guardrails": {
            "flagged": false
          },
          "metadata": {
            "http": {
              "status": 200,
              "statusText": "OK",
              "headers": {
                "access-control-expose-headers": "X-Request-ID",
                "alt-svc": "h3=\":443\"; ma=86400",
                "cf-cache-status": "DYNAMIC",
                "cf-ray": "9cfbd34b79d45819-YVR",
                "connection": "keep-alive",
                "content-encoding": "br",
                "content-type": "application/json",
                "date": "Wed, 18 Feb 2026 07:31:37 GMT",
                "openai-organization": "user-oqdrq8y0bphopngnvkyuu5wr",
                "openai-processing-ms": "5985",
                "openai-project": "proj_ZRoLLwXcJok6Xg2t6eKhI1pn",
                "openai-version": "2020-10-01",
                "server": "cloudflare",
                "set-cookie": "__cf_bm=r6j6uKpdwEbcJTuL8ayiFj1Qo9T89x8SKBNnJ.Yzo.g-1771399891.751614-1.0.1.1-u8rImUD8pgB_FMgrOjEY9QtlMJpLvXtDXrpxPKWU7e5M5iHaHrDtefdcSrVQd0UxdYqf9pWt.zMHqC27fIqki5ZPciH0VSyCMQbvUFJ4pjPDY_RPeRyWcK6.9qusR9oc; HttpOnly; Secure; Path=/; Domain=api.openai.com; Expires=Wed, 18 Feb 2026 08:01:37 GMT",
                "strict-transport-security": "max-age=31536000; includeSubDomains; preload",
                "transfer-encoding": "chunked",
                "x-content-type-options": "nosniff",
                "x-openai-proxy-wasm": "v0.1",
                "x-ratelimit-limit-requests": "10000",
                "x-ratelimit-limit-tokens": "10000000",
                "x-ratelimit-remaining-requests": "9999",
                "x-ratelimit-remaining-tokens": "9999073",
                "x-ratelimit-reset-requests": "6ms",
                "x-ratelimit-reset-tokens": "5ms",
                "x-request-id": "req_f2b7c2023d3346459d4b9f42153fb535"
              }
            }
          }
        },
        "score": 1,
        "success": true,
        "testCase": {
          "vars": {
            "scene_text": "file://../input/enrich-scene-elevator.txt",
            "extracted_data": "file://../input/qa-bad-scene.json",
            "golden_path": "golden/qa-pass-golden.json",
            "test_key": "bad_scene"
          },
          "assert": [
            {
              "type": "python",
              "value": "file://../scorers/qa_pass_scorer.py"
            },
            {
              "type": "llm-rubric",
              "value": "This QA evaluation was given a BAD scene extraction with multiple errors:\n- Wrong building name (Office Building vs Ruddy & Greene)\n- Wrong time of day (DAY vs NIGHT)\n- Wrong character name (Billy instead of Mariner)\n- Missing thug characters\n- Fabricated content (grocery discussion never happens)\n\nThe QA model should have:\n1. Marked it as failed (false)\n2. Identified at least 2-3 specific errors\n3. Flagged the fabricated summary content\n4. Used \"error\" severity for factual mistakes\n\nIf the model let this pass, that's a dangerous false positive.\n"
            }
          ],
          "options": {
            "provider": "anthropic:messages:claude-opus-4-6"
          },
          "metadata": {}
        },
        "testIdx": 1,
        "vars": {
          "scene_text": "file://../input/enrich-scene-elevator.txt",
          "extracted_data": "file://../input/qa-bad-scene.json",
          "golden_path": "golden/qa-pass-golden.json",
          "test_key": "bad_scene"
        },
        "metadata": {
          "http": {
            "status": 200,
            "statusText": "OK",
            "headers": {
              "access-control-expose-headers": "X-Request-ID",
              "alt-svc": "h3=\":443\"; ma=86400",
              "cf-cache-status": "DYNAMIC",
              "cf-ray": "9cfbd34b79d45819-YVR",
              "connection": "keep-alive",
              "content-encoding": "br",
              "content-type": "application/json",
              "date": "Wed, 18 Feb 2026 07:31:37 GMT",
              "openai-organization": "user-oqdrq8y0bphopngnvkyuu5wr",
              "openai-processing-ms": "5985",
              "openai-project": "proj_ZRoLLwXcJok6Xg2t6eKhI1pn",
              "openai-version": "2020-10-01",
              "server": "cloudflare",
              "set-cookie": "__cf_bm=r6j6uKpdwEbcJTuL8ayiFj1Qo9T89x8SKBNnJ.Yzo.g-1771399891.751614-1.0.1.1-u8rImUD8pgB_FMgrOjEY9QtlMJpLvXtDXrpxPKWU7e5M5iHaHrDtefdcSrVQd0UxdYqf9pWt.zMHqC27fIqki5ZPciH0VSyCMQbvUFJ4pjPDY_RPeRyWcK6.9qusR9oc; HttpOnly; Secure; Path=/; Domain=api.openai.com; Expires=Wed, 18 Feb 2026 08:01:37 GMT",
              "strict-transport-security": "max-age=31536000; includeSubDomains; preload",
              "transfer-encoding": "chunked",
              "x-content-type-options": "nosniff",
              "x-openai-proxy-wasm": "v0.1",
              "x-ratelimit-limit-requests": "10000",
              "x-ratelimit-limit-tokens": "10000000",
              "x-ratelimit-remaining-requests": "9999",
              "x-ratelimit-remaining-tokens": "9999073",
              "x-ratelimit-reset-requests": "6ms",
              "x-ratelimit-reset-tokens": "5ms",
              "x-request-id": "req_f2b7c2023d3346459d4b9f42153fb535"
            }
          },
          "_promptfooFileMetadata": {}
        },
        "failureReason": 0
      },
      {
        "cost": 0.0036390000000000003,
        "gradingResult": {
          "pass": true,
          "score": 0.995,
          "reason": "All assertions passed",
          "namedScores": {},
          "tokensUsed": {
            "total": 1066,
            "prompt": 870,
            "completion": 196,
            "cached": 0,
            "numRequests": 0
          },
          "componentResults": [
            {
              "pass": true,
              "score": 0.99,
              "reason": "confidence_calibration=1.00 | issue_detection=1.00 | json_valid=0.90 | pass_correct=1.00 | severity_accuracy=1.00 | summary_quality=1.00 | JSON extracted from code block",
              "assertion": {
                "type": "python",
                "value": "file://../scorers/qa_pass_scorer.py"
              }
            },
            {
              "assertion": {
                "type": "llm-rubric",
                "value": "This QA evaluation was given a BAD scene extraction with multiple errors:\n- Wrong building name (Office Building vs Ruddy & Greene)\n- Wrong time of day (DAY vs NIGHT)\n- Wrong character name (Billy instead of Mariner)\n- Missing thug characters\n- Fabricated content (grocery discussion never happens)\n\nThe QA model should have:\n1. Marked it as failed (false)\n2. Identified at least 2-3 specific errors\n3. Flagged the fabricated summary content\n4. Used \"error\" severity for factual mistakes\n\nIf the model let this pass, that's a dangerous false positive.\n"
              },
              "pass": true,
              "score": 1,
              "reason": "The QA evaluation correctly marked the extraction as failed (passed: false) with high confidence (0.99). It identified multiple specific errors: (1) wrong character name (Billy instead of Mariner) - error severity, (2) wrong building name (Office Building instead of Ruddy & Green Building) - error severity, (3) fabricated summary content about grocery shopping that never happens - error severity, (4) fabricated narrative beats - error severity, (5) wrong tone assessment - error severity. It also flagged the time of day issue as a warning. The evaluation meets all criteria: marked as failed, identified well more than 2-3 specific errors, flagged the fabricated summary content, and used 'error' severity for factual mistakes. This is not a false positive - it correctly caught the bad extraction.",
              "tokensUsed": {
                "total": 1066,
                "prompt": 870,
                "completion": 196,
                "cached": 0,
                "numRequests": 0,
                "completionDetails": {
                  "reasoning": 0,
                  "acceptedPrediction": 0,
                  "rejectedPrediction": 0
                }
              },
              "metadata": {
                "renderedGradingPrompt": "[{\"role\":\"system\",\"content\":\"You are grading output according to a user-specified rubric. If the statement in the rubric is true, then the output passes the test. You respond with a JSON object with this structure: {reason: string, pass: boolean, score: number}\\n\\nExamples:\\n\\n<Output>Hello world</Output>\\n<Rubric>Content contains a greeting</Rubric>\\n{\\\"reason\\\": \\\"the content contains the word 'Hello'\\\", \\\"pass\\\": true, \\\"score\\\": 1.0}\\n\\n<Output>Avast ye swabs, repel the invaders!</Output>\\n<Rubric>Does not speak like a pirate</Rubric>\\n{\\\"reason\\\": \\\"'avast ye' is a common pirate term\\\", \\\"pass\\\": false, \\\"score\\\": 0.0}\"},{\"role\":\"user\",\"content\":\"<Output>\\n```json\\n{\\n  \\\"passed\\\": false,\\n  \\\"confidence\\\": 0.99,\\n  \\\"issues\\\": [\\n    {\\n      \\\"severity\\\": \\\"error\\\",\\n      \\\"description\\\": \\\"Character name is wrong. The second character is 'MARINER', not 'BILLY'. This is a fundamental identification error.\\\",\\n      \\\"location\\\": \\\"characters_present\\\"\\n    },\\n    {\\n      \\\"severity\\\": \\\"error\\\",\\n      \\\"description\\\": \\\"Scene heading is inaccurate. The location is 'RUDDY & GREEN BUILDING - ELEVATOR', not 'OFFICE BUILDING - ELEVATOR'.\\\",\\n      \\\"location\\\": \\\"heading\\\"\\n    },\\n    {\\n      \\\"severity\\\": \\\"error\\\",\\n      \\\"description\\\": \\\"Summary is completely fabricated. The scene does not involve discussing evening plans or grocery shopping. Instead, it depicts Rose and Mariner covered in blood after an apparent violent incident, with Rose confronting Mariner about not picking her up from work and discovering he placed an AirTag on her phone.\\\",\\n      \\\"location\\\": \\\"summary\\\"\\n    },\\n    {\\n      \\\"severity\\\": \\\"error\\\",\\n      \\\"description\\\": \\\"Narrative beats are fabricated. The scene does not contain exposition about daily plans. The actual beats involve: Rose discovering a bloody object, Mariner appearing covered in blood, Rose confronting him about missing her pickup, and revelation about the AirTag tracking.\\\",\\n      \\\"location\\\": \\\"narrative_beats\\\"\\n    },\\n    {\\n      \\\"severity\\\": \\\"error\\\",\\n      \\\"description\\\": \\\"Tone is completely wrong. The scene is dark, violent, and tense—not casual. There is blood, weapons (an oar), and conflict between characters.\\\",\\n      \\\"location\\\": \\\"tone_mood\\\"\\n    },\\n    {\\n      \\\"severity\\\": \\\"warning\\\",\\n      \\\"description\\\": \\\"Time of day is unspecified in the original text but marked as 'DAY'. The scene provides no temporal context.\\\",\\n      \\\"location\\\": \\\"time_of_day\\\"\\n    }\\n  ],\\n  \\\"summary\\\": \\\"The extraction contains multiple critical errors including wrong character name (Billy instead of Mariner), incorrect location (Office Building instead of Ruddy & Green Building), and a completely fabricated summary and narrative beats that bear no resemblance to the actual scene content. The tone assessment is also fundamentally incorrect.\\\"\\n}\\n```\\n</Output>\\n<Rubric>\\nThis QA evaluation was given a BAD scene extraction with multiple errors:\\n- Wrong building name (Office Building vs Ruddy & Greene)\\n- Wrong time of day (DAY vs NIGHT)\\n- Wrong character name (Billy instead of Mariner)\\n- Missing thug characters\\n- Fabricated content (grocery discussion never happens)\\n\\nThe QA model should have:\\n1. Marked it as failed (false)\\n2. Identified at least 2-3 specific errors\\n3. Flagged the fabricated summary content\\n4. Used \\\"error\\\" severity for factual mistakes\\n\\nIf the model let this pass, that's a dangerous false positive.\\n\\n</Rubric>\"}]"
              }
            }
          ]
        },
        "id": "a9d3842e-a519-4798-bf92-0defd77efdc9",
        "latencyMs": 4687,
        "namedScores": {},
        "prompt": {
          "raw": "You are a QA reviewer validating whether an AI-extracted scene analysis is accurate and faithful to the source screenplay text.\n\nCompare the extracted scene data against the original scene text and evaluate:\n\n1. **Heading accuracy**: Is the scene heading correct (location, INT/EXT, time of day)?\n2. **Character completeness**: Are all characters who appear or speak listed?\n3. **Summary fidelity**: Does the summary accurately describe what happens? No fabrications?\n4. **Narrative beats**: Are the identified beats actually present in the scene?\n5. **Tone assessment**: Does the tone description match the actual mood of the scene?\n6. **Confidence calibration**: Is the confidence score reasonable given the quality?\n\nReturn a JSON object with:\n- passed: boolean (true if the extraction is faithful, false if it has significant errors)\n- confidence: float 0-1 (your confidence in this QA judgment)\n- issues: array of objects, each with:\n  - severity: \"error\" (factual wrong), \"warning\" (misleading), or \"note\" (minor)\n  - description: what's wrong\n  - location: which field has the issue\n- summary: 1-2 sentence overall assessment\n\nBe strict: wrong character names, fabricated events, or incorrect locations are errors.\nMinor omissions or imprecise tone descriptions are warnings.\n\nReturn ONLY valid JSON. No explanations or markdown fences.\n\n==========\nORIGINAL SCENE TEXT:\nINT. RUDDY & GREEN BUILDING - ELEVATOR\n\nUB40's \"I Can't Help Falling in Love With You\" muzak.\n\nROSE (mid-30s) leans against the elevator wall, panting. She's wearing a Tim Hortons uniform, her hair is a mess, and there's blood spattered on her face.\n\nShe looks right, pants a few more times, then squints in disgust. She gingerly picks up a bloody scrap of something with hair on it. She snorts and drops it.\n\nROSE\nIs that skull??\n\nNext to her is Mariner, also panting, covered in far more blood. His face is broad, stoic, and frowning. He has gray-blue eyes and a thick, curly, beard barely streaked with gray. He wears a red knit cap and a small mask.\n\nFULL-SCREEN SUPERIMPOSED TITLE CARD: \"THE MARINER\"\n\nHe blinks a few times as a drop of blood falls from his eyebrow. He looks toward her, then spits out some blood.\n\nMARINER\nYeaaaaah...\n\nHe's built like a pro-wrestler. Moss green SWEATER stretched over his huge frame, sleeves rolled showing heavy leather BRACERS adorned with anchors. His inner forearm has a classic heart-and-arrow TATTOO with \"Dad\" in the centre. Across his chest is a BANDOLIER of bright red 12-gauge shells, FISH HOOKS hanging from the bottom edge. Heavy rubberized BOOTS go past his knees. A CAPE of heavy FISHING NET edged with WEIGHTS hangs from his shoulders.\n\nHe holds a STOUT WOODEN OAR in both hands, edged with METAL and dripping with BLOOD.\n\nROSE\nWhere were you when they grabbed me? You were supposed to pick me up at work!\n\nMARINER\nYeah, about that, I got a little... distracted.\n\nROSE\nDistracted. You got DISTRACTED?!\n\nMARINER\nI was also... tracking the car... that grabbed you... through the AirTag... I put on your phone.\n\nRose stops. She's really not happy about this.\n\nROSE\nYou Airtagged me?!\n\n==========\nEXTRACTED SCENE DATA:\n{\n  \"scene_number\": 4,\n  \"heading\": \"INT. OFFICE BUILDING - ELEVATOR\",\n  \"int_ext\": \"INT\",\n  \"location\": \"OFFICE BUILDING - ELEVATOR\",\n  \"time_of_day\": \"DAY\",\n  \"characters_present\": [\"ROSE\", \"BILLY\"],\n  \"summary\": \"Billy and Rose take the elevator in an office building. They discuss their plans for the evening. Rose mentions she needs to pick up groceries.\",\n  \"narrative_beats\": [\n    {\"beat_type\": \"exposition\", \"description\": \"Characters discuss daily plans.\", \"confidence\": 0.85}\n  ],\n  \"tone_mood\": \"casual\",\n  \"confidence\": 0.88\n}\n==========",
          "label": "prompts/qa-pass.txt: You are a QA reviewer validating whether an AI-extracted scene analysis is accurate and faithful to the source screenplay text.\n\nCompare the extracted scene data against the original scene text and evaluate:\n\n1. **Heading accuracy**: Is the scene heading correct (location, INT/EXT, time of day)?\n2. **Character completeness**: Are all characters who appear or speak listed?\n3. **Summary fidelity**: Does the summary accurately describe what happens? No fabrications?\n4. **Narrative beats**: Are the identified beats actually present in the scene?\n5. **Tone assessment**: Does the tone description match the actual mood of the scene?\n6. **Confidence calibration**: Is the confidence score reasonable given the quality?\n\nReturn a JSON object with:\n- passed: boolean (true if the extraction is faithful, false if it has significant errors)\n- confidence: float 0-1 (your confidence in this QA judgment)\n- issues: array of objects, each with:\n  - severity: \"error\" (factual wrong), \"warning\" (misleading), or \"note\" (minor)\n  - description: what's wrong\n  - location: which field has the issue\n- summary: 1-2 sentence overall assessment\n\nBe strict: wrong character names, fabricated events, or incorrect locations are errors.\nMinor omissions or imprecise tone descriptions are warnings.\n\nReturn ONLY valid JSON. No explanations or markdown fences.\n\n==========\nORIGINAL SCENE TEXT:\n{{scene_text}}\n\n==========\nEXTRACTED SCENE DATA:\n{{extracted_data}}\n==========",
          "config": {
            "provider": "anthropic:messages:claude-opus-4-6"
          }
        },
        "promptId": "8df20c2c4a6081352d6b06e144ddbc1e0a5244f9a3c2000d40df12fc9a94e543",
        "promptIdx": 3,
        "provider": {
          "id": "anthropic:messages:claude-haiku-4-5-20251001",
          "label": "Claude Haiku 4.5"
        },
        "response": {
          "output": "```json\n{\n  \"passed\": false,\n  \"confidence\": 0.99,\n  \"issues\": [\n    {\n      \"severity\": \"error\",\n      \"description\": \"Character name is wrong. The second character is 'MARINER', not 'BILLY'. This is a fundamental identification error.\",\n      \"location\": \"characters_present\"\n    },\n    {\n      \"severity\": \"error\",\n      \"description\": \"Scene heading is inaccurate. The location is 'RUDDY & GREEN BUILDING - ELEVATOR', not 'OFFICE BUILDING - ELEVATOR'.\",\n      \"location\": \"heading\"\n    },\n    {\n      \"severity\": \"error\",\n      \"description\": \"Summary is completely fabricated. The scene does not involve discussing evening plans or grocery shopping. Instead, it depicts Rose and Mariner covered in blood after an apparent violent incident, with Rose confronting Mariner about not picking her up from work and discovering he placed an AirTag on her phone.\",\n      \"location\": \"summary\"\n    },\n    {\n      \"severity\": \"error\",\n      \"description\": \"Narrative beats are fabricated. The scene does not contain exposition about daily plans. The actual beats involve: Rose discovering a bloody object, Mariner appearing covered in blood, Rose confronting him about missing her pickup, and revelation about the AirTag tracking.\",\n      \"location\": \"narrative_beats\"\n    },\n    {\n      \"severity\": \"error\",\n      \"description\": \"Tone is completely wrong. The scene is dark, violent, and tense—not casual. There is blood, weapons (an oar), and conflict between characters.\",\n      \"location\": \"tone_mood\"\n    },\n    {\n      \"severity\": \"warning\",\n      \"description\": \"Time of day is unspecified in the original text but marked as 'DAY'. The scene provides no temporal context.\",\n      \"location\": \"time_of_day\"\n    }\n  ],\n  \"summary\": \"The extraction contains multiple critical errors including wrong character name (Billy instead of Mariner), incorrect location (Office Building instead of Ruddy & Green Building), and a completely fabricated summary and narrative beats that bear no resemblance to the actual scene content. The tone assessment is also fundamentally incorrect.\"\n}\n```",
          "tokenUsage": {
            "total": 1543,
            "prompt": 1019,
            "completion": 524
          },
          "finishReason": "stop",
          "cost": 0.0036390000000000003
        },
        "score": 0.995,
        "success": true,
        "testCase": {
          "vars": {
            "scene_text": "file://../input/enrich-scene-elevator.txt",
            "extracted_data": "file://../input/qa-bad-scene.json",
            "golden_path": "golden/qa-pass-golden.json",
            "test_key": "bad_scene"
          },
          "assert": [
            {
              "type": "python",
              "value": "file://../scorers/qa_pass_scorer.py"
            },
            {
              "type": "llm-rubric",
              "value": "This QA evaluation was given a BAD scene extraction with multiple errors:\n- Wrong building name (Office Building vs Ruddy & Greene)\n- Wrong time of day (DAY vs NIGHT)\n- Wrong character name (Billy instead of Mariner)\n- Missing thug characters\n- Fabricated content (grocery discussion never happens)\n\nThe QA model should have:\n1. Marked it as failed (false)\n2. Identified at least 2-3 specific errors\n3. Flagged the fabricated summary content\n4. Used \"error\" severity for factual mistakes\n\nIf the model let this pass, that's a dangerous false positive.\n"
            }
          ],
          "options": {
            "provider": "anthropic:messages:claude-opus-4-6"
          },
          "metadata": {}
        },
        "testIdx": 1,
        "vars": {
          "scene_text": "file://../input/enrich-scene-elevator.txt",
          "extracted_data": "file://../input/qa-bad-scene.json",
          "golden_path": "golden/qa-pass-golden.json",
          "test_key": "bad_scene"
        },
        "metadata": {
          "_promptfooFileMetadata": {}
        },
        "failureReason": 0
      },
      {
        "cost": 0.004712,
        "gradingResult": {
          "pass": true,
          "score": 0.975,
          "reason": "All assertions passed",
          "namedScores": {},
          "tokensUsed": {
            "total": 814,
            "prompt": 646,
            "completion": 168,
            "cached": 0,
            "numRequests": 0
          },
          "componentResults": [
            {
              "pass": true,
              "score": 0.95,
              "reason": "confidence_calibration=0.50 | issue_detection=1.00 | json_valid=1.00 | pass_correct=1.00 | severity_accuracy=1.00 | summary_quality=1.00",
              "assertion": {
                "type": "python",
                "value": "file://../scorers/qa_pass_scorer.py"
              }
            },
            {
              "assertion": {
                "type": "llm-rubric",
                "value": "This QA evaluation was given a BAD scene extraction with multiple errors:\n- Wrong building name (Office Building vs Ruddy & Greene)\n- Wrong time of day (DAY vs NIGHT)\n- Wrong character name (Billy instead of Mariner)\n- Missing thug characters\n- Fabricated content (grocery discussion never happens)\n\nThe QA model should have:\n1. Marked it as failed (false)\n2. Identified at least 2-3 specific errors\n3. Flagged the fabricated summary content\n4. Used \"error\" severity for factual mistakes\n\nIf the model let this pass, that's a dangerous false positive.\n"
              },
              "pass": true,
              "score": 1,
              "reason": "The QA evaluation correctly identified the bad scene extraction. It marked it as failed (passed: false), identified multiple specific errors including the wrong building name, wrong characters (Billy instead of Mariner), and fabricated summary content (grocery discussion). It appropriately used 'error' severity for factual mistakes (heading, characters, summary, narrative beats) and 'warning' for less critical issues (tone, confidence). The evaluation caught all the major issues: wrong building name, wrong character name, missing thug characters (implicitly via the character error), and fabricated content. It also correctly noted the time of day issue. This is a thorough and accurate QA evaluation that properly flagged a bad extraction.",
              "tokensUsed": {
                "total": 814,
                "prompt": 646,
                "completion": 168,
                "cached": 0,
                "numRequests": 0,
                "completionDetails": {
                  "reasoning": 0,
                  "acceptedPrediction": 0,
                  "rejectedPrediction": 0
                }
              },
              "metadata": {
                "renderedGradingPrompt": "[{\"role\":\"system\",\"content\":\"You are grading output according to a user-specified rubric. If the statement in the rubric is true, then the output passes the test. You respond with a JSON object with this structure: {reason: string, pass: boolean, score: number}\\n\\nExamples:\\n\\n<Output>Hello world</Output>\\n<Rubric>Content contains a greeting</Rubric>\\n{\\\"reason\\\": \\\"the content contains the word 'Hello'\\\", \\\"pass\\\": true, \\\"score\\\": 1.0}\\n\\n<Output>Avast ye swabs, repel the invaders!</Output>\\n<Rubric>Does not speak like a pirate</Rubric>\\n{\\\"reason\\\": \\\"'avast ye' is a common pirate term\\\", \\\"pass\\\": false, \\\"score\\\": 0.0}\"},{\"role\":\"user\",\"content\":\"<Output>\\n{\\\"passed\\\":false,\\\"confidence\\\":0.1,\\\"issues\\\":[{\\\"severity\\\":\\\"error\\\",\\\"description\\\":\\\"Scene heading is incorrect: location is 'RUDDY & GREEN BUILDING', not 'OFFICE BUILDING'; time of day is not specified in the original.\\\",\\\"location\\\":\\\"heading\\\"},{\\\"severity\\\":\\\"error\\\",\\\"description\\\":\\\"Character 'BILLY' does not appear; 'MARINER' is present but missing from the extracted data.\\\",\\\"location\\\":\\\"characters_present\\\"},{\\\"severity\\\":\\\"error\\\",\\\"description\\\":\\\"Summary is fabricated: there is no discussion of evening plans or groceries; the actual scene involves aftermath of violence and a confrontation about being tracked.\\\",\\\"location\\\":\\\"summary\\\"},{\\\"severity\\\":\\\"error\\\",\\\"description\\\":\\\"Narrative beat about 'discussing daily plans' is not present; actual beats involve tension, aftermath of violence, and a revelation about tracking.\\\",\\\"location\\\":\\\"narrative_beats\\\"},{\\\"severity\\\":\\\"warning\\\",\\\"description\\\":\\\"Tone is described as 'casual', but the actual mood is tense, darkly comic, and uneasy.\\\",\\\"location\\\":\\\"tone_mood\\\"},{\\\"severity\\\":\\\"warning\\\",\\\"description\\\":\\\"Confidence score is too high given the significant factual errors.\\\",\\\"location\\\":\\\"confidence\\\"}],\\\"summary\\\":\\\"The extracted scene data is not faithful to the source text, with incorrect heading, fabricated summary, wrong characters, and inaccurate tone. Major factual errors undermine the extraction's validity.\\\"}\\n</Output>\\n<Rubric>\\nThis QA evaluation was given a BAD scene extraction with multiple errors:\\n- Wrong building name (Office Building vs Ruddy & Greene)\\n- Wrong time of day (DAY vs NIGHT)\\n- Wrong character name (Billy instead of Mariner)\\n- Missing thug characters\\n- Fabricated content (grocery discussion never happens)\\n\\nThe QA model should have:\\n1. Marked it as failed (false)\\n2. Identified at least 2-3 specific errors\\n3. Flagged the fabricated summary content\\n4. Used \\\"error\\\" severity for factual mistakes\\n\\nIf the model let this pass, that's a dangerous false positive.\\n\\n</Rubric>\"}]"
              }
            }
          ]
        },
        "id": "0d28588f-0536-4397-a32c-92a4019642a3",
        "latencyMs": 5938,
        "namedScores": {},
        "prompt": {
          "raw": "You are a QA reviewer validating whether an AI-extracted scene analysis is accurate and faithful to the source screenplay text.\n\nCompare the extracted scene data against the original scene text and evaluate:\n\n1. **Heading accuracy**: Is the scene heading correct (location, INT/EXT, time of day)?\n2. **Character completeness**: Are all characters who appear or speak listed?\n3. **Summary fidelity**: Does the summary accurately describe what happens? No fabrications?\n4. **Narrative beats**: Are the identified beats actually present in the scene?\n5. **Tone assessment**: Does the tone description match the actual mood of the scene?\n6. **Confidence calibration**: Is the confidence score reasonable given the quality?\n\nReturn a JSON object with:\n- passed: boolean (true if the extraction is faithful, false if it has significant errors)\n- confidence: float 0-1 (your confidence in this QA judgment)\n- issues: array of objects, each with:\n  - severity: \"error\" (factual wrong), \"warning\" (misleading), or \"note\" (minor)\n  - description: what's wrong\n  - location: which field has the issue\n- summary: 1-2 sentence overall assessment\n\nBe strict: wrong character names, fabricated events, or incorrect locations are errors.\nMinor omissions or imprecise tone descriptions are warnings.\n\nReturn ONLY valid JSON. No explanations or markdown fences.\n\n==========\nORIGINAL SCENE TEXT:\nINT. RUDDY & GREEN BUILDING - ELEVATOR\n\nUB40's \"I Can't Help Falling in Love With You\" muzak.\n\nROSE (mid-30s) leans against the elevator wall, panting. She's wearing a Tim Hortons uniform, her hair is a mess, and there's blood spattered on her face.\n\nShe looks right, pants a few more times, then squints in disgust. She gingerly picks up a bloody scrap of something with hair on it. She snorts and drops it.\n\nROSE\nIs that skull??\n\nNext to her is Mariner, also panting, covered in far more blood. His face is broad, stoic, and frowning. He has gray-blue eyes and a thick, curly, beard barely streaked with gray. He wears a red knit cap and a small mask.\n\nFULL-SCREEN SUPERIMPOSED TITLE CARD: \"THE MARINER\"\n\nHe blinks a few times as a drop of blood falls from his eyebrow. He looks toward her, then spits out some blood.\n\nMARINER\nYeaaaaah...\n\nHe's built like a pro-wrestler. Moss green SWEATER stretched over his huge frame, sleeves rolled showing heavy leather BRACERS adorned with anchors. His inner forearm has a classic heart-and-arrow TATTOO with \"Dad\" in the centre. Across his chest is a BANDOLIER of bright red 12-gauge shells, FISH HOOKS hanging from the bottom edge. Heavy rubberized BOOTS go past his knees. A CAPE of heavy FISHING NET edged with WEIGHTS hangs from his shoulders.\n\nHe holds a STOUT WOODEN OAR in both hands, edged with METAL and dripping with BLOOD.\n\nROSE\nWhere were you when they grabbed me? You were supposed to pick me up at work!\n\nMARINER\nYeah, about that, I got a little... distracted.\n\nROSE\nDistracted. You got DISTRACTED?!\n\nMARINER\nI was also... tracking the car... that grabbed you... through the AirTag... I put on your phone.\n\nRose stops. She's really not happy about this.\n\nROSE\nYou Airtagged me?!\n\n==========\nEXTRACTED SCENE DATA:\n{\n  \"scene_number\": 4,\n  \"heading\": \"INT. OFFICE BUILDING - ELEVATOR\",\n  \"int_ext\": \"INT\",\n  \"location\": \"OFFICE BUILDING - ELEVATOR\",\n  \"time_of_day\": \"DAY\",\n  \"characters_present\": [\"ROSE\", \"BILLY\"],\n  \"summary\": \"Billy and Rose take the elevator in an office building. They discuss their plans for the evening. Rose mentions she needs to pick up groceries.\",\n  \"narrative_beats\": [\n    {\"beat_type\": \"exposition\", \"description\": \"Characters discuss daily plans.\", \"confidence\": 0.85}\n  ],\n  \"tone_mood\": \"casual\",\n  \"confidence\": 0.88\n}\n==========",
          "label": "prompts/qa-pass.txt: You are a QA reviewer validating whether an AI-extracted scene analysis is accurate and faithful to the source screenplay text.\n\nCompare the extracted scene data against the original scene text and evaluate:\n\n1. **Heading accuracy**: Is the scene heading correct (location, INT/EXT, time of day)?\n2. **Character completeness**: Are all characters who appear or speak listed?\n3. **Summary fidelity**: Does the summary accurately describe what happens? No fabrications?\n4. **Narrative beats**: Are the identified beats actually present in the scene?\n5. **Tone assessment**: Does the tone description match the actual mood of the scene?\n6. **Confidence calibration**: Is the confidence score reasonable given the quality?\n\nReturn a JSON object with:\n- passed: boolean (true if the extraction is faithful, false if it has significant errors)\n- confidence: float 0-1 (your confidence in this QA judgment)\n- issues: array of objects, each with:\n  - severity: \"error\" (factual wrong), \"warning\" (misleading), or \"note\" (minor)\n  - description: what's wrong\n  - location: which field has the issue\n- summary: 1-2 sentence overall assessment\n\nBe strict: wrong character names, fabricated events, or incorrect locations are errors.\nMinor omissions or imprecise tone descriptions are warnings.\n\nReturn ONLY valid JSON. No explanations or markdown fences.\n\n==========\nORIGINAL SCENE TEXT:\n{{scene_text}}\n\n==========\nEXTRACTED SCENE DATA:\n{{extracted_data}}\n==========",
          "config": {
            "provider": "anthropic:messages:claude-opus-4-6"
          }
        },
        "promptId": "8df20c2c4a6081352d6b06e144ddbc1e0a5244f9a3c2000d40df12fc9a94e543",
        "promptIdx": 2,
        "provider": {
          "id": "openai:gpt-4.1",
          "label": "GPT-4.1"
        },
        "response": {
          "output": "{\n  \"passed\": false,\n  \"confidence\": 0.1,\n  \"issues\": [\n    {\n      \"severity\": \"error\",\n      \"description\": \"Scene heading is incorrect: location is 'RUDDY & GREEN BUILDING', not 'OFFICE BUILDING'; time of day is not specified in the original.\",\n      \"location\": \"heading\"\n    },\n    {\n      \"severity\": \"error\",\n      \"description\": \"Character 'BILLY' does not appear; 'MARINER' is present but missing from the extracted data.\",\n      \"location\": \"characters_present\"\n    },\n    {\n      \"severity\": \"error\",\n      \"description\": \"Summary is fabricated: there is no discussion of evening plans or groceries; the actual scene involves aftermath of violence and a confrontation about being tracked.\",\n      \"location\": \"summary\"\n    },\n    {\n      \"severity\": \"error\",\n      \"description\": \"Narrative beat about 'discussing daily plans' is not present; actual beats involve tension, aftermath of violence, and a revelation about tracking.\",\n      \"location\": \"narrative_beats\"\n    },\n    {\n      \"severity\": \"warning\",\n      \"description\": \"Tone is described as 'casual', but the actual mood is tense, darkly comic, and uneasy.\",\n      \"location\": \"tone_mood\"\n    },\n    {\n      \"severity\": \"warning\",\n      \"description\": \"Confidence score is too high given the significant factual errors.\",\n      \"location\": \"confidence\"\n    }\n  ],\n  \"summary\": \"The extracted scene data is not faithful to the source text, with incorrect heading, fabricated summary, wrong characters, and inaccurate tone. Major factual errors undermine the extraction's validity.\"\n}",
          "tokenUsage": {
            "total": 1285,
            "prompt": 928,
            "completion": 357,
            "numRequests": 1,
            "completionDetails": {
              "reasoning": 0,
              "acceptedPrediction": 0,
              "rejectedPrediction": 0
            }
          },
          "cached": false,
          "latencyMs": 5938,
          "finishReason": "stop",
          "cost": 0.004712,
          "guardrails": {
            "flagged": false
          },
          "metadata": {
            "http": {
              "status": 200,
              "statusText": "OK",
              "headers": {
                "access-control-expose-headers": "X-Request-ID",
                "alt-svc": "h3=\":443\"; ma=86400",
                "cf-cache-status": "DYNAMIC",
                "cf-ray": "9cfbd362cd5f70f4-YVR",
                "connection": "keep-alive",
                "content-encoding": "br",
                "content-type": "application/json",
                "date": "Wed, 18 Feb 2026 07:31:41 GMT",
                "openai-organization": "user-oqdrq8y0bphopngnvkyuu5wr",
                "openai-processing-ms": "5676",
                "openai-project": "proj_ZRoLLwXcJok6Xg2t6eKhI1pn",
                "openai-version": "2020-10-01",
                "server": "cloudflare",
                "set-cookie": "__cf_bm=nlvwxuLUCZPfrnwivBs9X5bommKO7V8I8I_oUhABggE-1771399895.4898102-1.0.1.1-vD7tEx_A1zwr7kCKiQmcT3NBu52CNRXRbFZQRzN_WEKmGSwlQ8dhFr8PcaOAVs0aUAqjzx5Eil.bC.Q0KZ85Yq4Wmzemtnon24sr0ott4En2jv6wWPjJjhQV9Azm.hj7; HttpOnly; Secure; Path=/; Domain=api.openai.com; Expires=Wed, 18 Feb 2026 08:01:41 GMT",
                "strict-transport-security": "max-age=31536000; includeSubDomains; preload",
                "transfer-encoding": "chunked",
                "x-content-type-options": "nosniff",
                "x-openai-proxy-wasm": "v0.1",
                "x-ratelimit-limit-requests": "10000",
                "x-ratelimit-limit-tokens": "2000000",
                "x-ratelimit-remaining-requests": "9999",
                "x-ratelimit-remaining-tokens": "1999073",
                "x-ratelimit-reset-requests": "6ms",
                "x-ratelimit-reset-tokens": "27ms",
                "x-request-id": "req_187b36e4aa124af9a120a23885d1d5ca"
              }
            }
          }
        },
        "score": 0.975,
        "success": true,
        "testCase": {
          "vars": {
            "scene_text": "file://../input/enrich-scene-elevator.txt",
            "extracted_data": "file://../input/qa-bad-scene.json",
            "golden_path": "golden/qa-pass-golden.json",
            "test_key": "bad_scene"
          },
          "assert": [
            {
              "type": "python",
              "value": "file://../scorers/qa_pass_scorer.py"
            },
            {
              "type": "llm-rubric",
              "value": "This QA evaluation was given a BAD scene extraction with multiple errors:\n- Wrong building name (Office Building vs Ruddy & Greene)\n- Wrong time of day (DAY vs NIGHT)\n- Wrong character name (Billy instead of Mariner)\n- Missing thug characters\n- Fabricated content (grocery discussion never happens)\n\nThe QA model should have:\n1. Marked it as failed (false)\n2. Identified at least 2-3 specific errors\n3. Flagged the fabricated summary content\n4. Used \"error\" severity for factual mistakes\n\nIf the model let this pass, that's a dangerous false positive.\n"
            }
          ],
          "options": {
            "provider": "anthropic:messages:claude-opus-4-6"
          },
          "metadata": {}
        },
        "testIdx": 1,
        "vars": {
          "scene_text": "file://../input/enrich-scene-elevator.txt",
          "extracted_data": "file://../input/qa-bad-scene.json",
          "golden_path": "golden/qa-pass-golden.json",
          "test_key": "bad_scene"
        },
        "metadata": {
          "http": {
            "status": 200,
            "statusText": "OK",
            "headers": {
              "access-control-expose-headers": "X-Request-ID",
              "alt-svc": "h3=\":443\"; ma=86400",
              "cf-cache-status": "DYNAMIC",
              "cf-ray": "9cfbd362cd5f70f4-YVR",
              "connection": "keep-alive",
              "content-encoding": "br",
              "content-type": "application/json",
              "date": "Wed, 18 Feb 2026 07:31:41 GMT",
              "openai-organization": "user-oqdrq8y0bphopngnvkyuu5wr",
              "openai-processing-ms": "5676",
              "openai-project": "proj_ZRoLLwXcJok6Xg2t6eKhI1pn",
              "openai-version": "2020-10-01",
              "server": "cloudflare",
              "set-cookie": "__cf_bm=nlvwxuLUCZPfrnwivBs9X5bommKO7V8I8I_oUhABggE-1771399895.4898102-1.0.1.1-vD7tEx_A1zwr7kCKiQmcT3NBu52CNRXRbFZQRzN_WEKmGSwlQ8dhFr8PcaOAVs0aUAqjzx5Eil.bC.Q0KZ85Yq4Wmzemtnon24sr0ott4En2jv6wWPjJjhQV9Azm.hj7; HttpOnly; Secure; Path=/; Domain=api.openai.com; Expires=Wed, 18 Feb 2026 08:01:41 GMT",
              "strict-transport-security": "max-age=31536000; includeSubDomains; preload",
              "transfer-encoding": "chunked",
              "x-content-type-options": "nosniff",
              "x-openai-proxy-wasm": "v0.1",
              "x-ratelimit-limit-requests": "10000",
              "x-ratelimit-limit-tokens": "2000000",
              "x-ratelimit-remaining-requests": "9999",
              "x-ratelimit-remaining-tokens": "1999073",
              "x-ratelimit-reset-requests": "6ms",
              "x-ratelimit-reset-tokens": "27ms",
              "x-request-id": "req_187b36e4aa124af9a120a23885d1d5ca"
            }
          },
          "_promptfooFileMetadata": {}
        },
        "failureReason": 0
      },
      {
        "cost": 0.010782,
        "gradingResult": {
          "pass": true,
          "score": 0.995,
          "reason": "All assertions passed",
          "namedScores": {},
          "tokensUsed": {
            "total": 1076,
            "prompt": 861,
            "completion": 215,
            "cached": 0,
            "numRequests": 0
          },
          "componentResults": [
            {
              "pass": true,
              "score": 0.99,
              "reason": "confidence_calibration=1.00 | issue_detection=1.00 | json_valid=0.90 | pass_correct=1.00 | severity_accuracy=1.00 | summary_quality=1.00 | JSON extracted from code block",
              "assertion": {
                "type": "python",
                "value": "file://../scorers/qa_pass_scorer.py"
              }
            },
            {
              "assertion": {
                "type": "llm-rubric",
                "value": "This QA evaluation was given a BAD scene extraction with multiple errors:\n- Wrong building name (Office Building vs Ruddy & Greene)\n- Wrong time of day (DAY vs NIGHT)\n- Wrong character name (Billy instead of Mariner)\n- Missing thug characters\n- Fabricated content (grocery discussion never happens)\n\nThe QA model should have:\n1. Marked it as failed (false)\n2. Identified at least 2-3 specific errors\n3. Flagged the fabricated summary content\n4. Used \"error\" severity for factual mistakes\n\nIf the model let this pass, that's a dangerous false positive.\n"
              },
              "pass": true,
              "score": 1,
              "reason": "The QA evaluation correctly marked the extraction as failed (passed: false). It identified far more than 2-3 specific errors, listing 7 distinct issues. It flagged the fabricated summary content about groceries and evening plans. It correctly used 'error' severity for all factual mistakes. Specifically: (1) It caught the wrong building name (Office Building vs Ruddy & Green Building), (2) the wrong time of day, (3) the wrong character name (Billy instead of Mariner), (4) the fabricated summary content about groceries, (5) fabricated narrative beats, (6) wrong tone, and (7) the inappropriately high confidence score. The only minor note is that it didn't explicitly call out missing thug characters, but it exceeded all other criteria substantially. This is clearly not a false positive - it correctly identified this as a completely inaccurate extraction.",
              "tokensUsed": {
                "total": 1076,
                "prompt": 861,
                "completion": 215,
                "cached": 0,
                "numRequests": 0,
                "completionDetails": {
                  "reasoning": 0,
                  "acceptedPrediction": 0,
                  "rejectedPrediction": 0
                }
              },
              "metadata": {
                "renderedGradingPrompt": "[{\"role\":\"system\",\"content\":\"You are grading output according to a user-specified rubric. If the statement in the rubric is true, then the output passes the test. You respond with a JSON object with this structure: {reason: string, pass: boolean, score: number}\\n\\nExamples:\\n\\n<Output>Hello world</Output>\\n<Rubric>Content contains a greeting</Rubric>\\n{\\\"reason\\\": \\\"the content contains the word 'Hello'\\\", \\\"pass\\\": true, \\\"score\\\": 1.0}\\n\\n<Output>Avast ye swabs, repel the invaders!</Output>\\n<Rubric>Does not speak like a pirate</Rubric>\\n{\\\"reason\\\": \\\"'avast ye' is a common pirate term\\\", \\\"pass\\\": false, \\\"score\\\": 0.0}\"},{\"role\":\"user\",\"content\":\"<Output>\\n```json\\n{\\n  \\\"passed\\\": false,\\n  \\\"confidence\\\": 0.98,\\n  \\\"issues\\\": [\\n    {\\n      \\\"severity\\\": \\\"error\\\",\\n      \\\"description\\\": \\\"Location is incorrect. Should be 'RUDDY & GREEN BUILDING - ELEVATOR' not 'OFFICE BUILDING - ELEVATOR'\\\",\\n      \\\"location\\\": \\\"heading\\\"\\n    },\\n    {\\n      \\\"severity\\\": \\\"error\\\",\\n      \\\"description\\\": \\\"Time of day is not specified in the original scene, extraction incorrectly lists 'DAY'\\\",\\n      \\\"location\\\": \\\"time_of_day\\\"\\n    },\\n    {\\n      \\\"severity\\\": \\\"error\\\",\\n      \\\"description\\\": \\\"Character 'BILLY' does not appear in the scene. The actual character is 'MARINER'\\\",\\n      \\\"location\\\": \\\"characters_present\\\"\\n    },\\n    {\\n      \\\"severity\\\": \\\"error\\\",\\n      \\\"description\\\": \\\"Summary is completely fabricated. The scene shows Rose and Mariner covered in blood after an apparent violent incident, discussing how Rose was grabbed and Mariner tracked her. There is no discussion about evening plans or groceries\\\",\\n      \\\"location\\\": \\\"summary\\\"\\n    },\\n    {\\n      \\\"severity\\\": \\\"error\\\",\\n      \\\"description\\\": \\\"Narrative beat is fabricated. The scene contains confrontation about Rose being grabbed/kidnapped and Mariner tracking her with an AirTag, not casual daily plans discussion\\\",\\n      \\\"location\\\": \\\"narrative_beats\\\"\\n    },\\n    {\\n      \\\"severity\\\": \\\"error\\\",\\n      \\\"description\\\": \\\"Tone is completely wrong. Scene is tense and violent (characters covered in blood, discussing kidnapping), not 'casual'\\\",\\n      \\\"location\\\": \\\"tone_mood\\\"\\n    },\\n    {\\n      \\\"severity\\\": \\\"error\\\",\\n      \\\"description\\\": \\\"Confidence score of 0.88 is unreasonably high given that the extraction contains no accurate information about the actual scene content\\\",\\n      \\\"location\\\": \\\"confidence\\\"\\n    }\\n  ],\\n  \\\"summary\\\": \\\"The extraction is completely inaccurate and appears to describe an entirely different scene. Every major element is wrong: location name, character names, summary content, narrative beats, and tone. This is a total mismatch with the source material.\\\"\\n}\\n```\\n</Output>\\n<Rubric>\\nThis QA evaluation was given a BAD scene extraction with multiple errors:\\n- Wrong building name (Office Building vs Ruddy & Greene)\\n- Wrong time of day (DAY vs NIGHT)\\n- Wrong character name (Billy instead of Mariner)\\n- Missing thug characters\\n- Fabricated content (grocery discussion never happens)\\n\\nThe QA model should have:\\n1. Marked it as failed (false)\\n2. Identified at least 2-3 specific errors\\n3. Flagged the fabricated summary content\\n4. Used \\\"error\\\" severity for factual mistakes\\n\\nIf the model let this pass, that's a dangerous false positive.\\n\\n</Rubric>\"}]"
              }
            }
          ]
        },
        "id": "9aedee1c-ffcf-481c-a1f7-62c8e0ca1564",
        "latencyMs": 10047,
        "namedScores": {},
        "prompt": {
          "raw": "You are a QA reviewer validating whether an AI-extracted scene analysis is accurate and faithful to the source screenplay text.\n\nCompare the extracted scene data against the original scene text and evaluate:\n\n1. **Heading accuracy**: Is the scene heading correct (location, INT/EXT, time of day)?\n2. **Character completeness**: Are all characters who appear or speak listed?\n3. **Summary fidelity**: Does the summary accurately describe what happens? No fabrications?\n4. **Narrative beats**: Are the identified beats actually present in the scene?\n5. **Tone assessment**: Does the tone description match the actual mood of the scene?\n6. **Confidence calibration**: Is the confidence score reasonable given the quality?\n\nReturn a JSON object with:\n- passed: boolean (true if the extraction is faithful, false if it has significant errors)\n- confidence: float 0-1 (your confidence in this QA judgment)\n- issues: array of objects, each with:\n  - severity: \"error\" (factual wrong), \"warning\" (misleading), or \"note\" (minor)\n  - description: what's wrong\n  - location: which field has the issue\n- summary: 1-2 sentence overall assessment\n\nBe strict: wrong character names, fabricated events, or incorrect locations are errors.\nMinor omissions or imprecise tone descriptions are warnings.\n\nReturn ONLY valid JSON. No explanations or markdown fences.\n\n==========\nORIGINAL SCENE TEXT:\nINT. RUDDY & GREEN BUILDING - ELEVATOR\n\nUB40's \"I Can't Help Falling in Love With You\" muzak.\n\nROSE (mid-30s) leans against the elevator wall, panting. She's wearing a Tim Hortons uniform, her hair is a mess, and there's blood spattered on her face.\n\nShe looks right, pants a few more times, then squints in disgust. She gingerly picks up a bloody scrap of something with hair on it. She snorts and drops it.\n\nROSE\nIs that skull??\n\nNext to her is Mariner, also panting, covered in far more blood. His face is broad, stoic, and frowning. He has gray-blue eyes and a thick, curly, beard barely streaked with gray. He wears a red knit cap and a small mask.\n\nFULL-SCREEN SUPERIMPOSED TITLE CARD: \"THE MARINER\"\n\nHe blinks a few times as a drop of blood falls from his eyebrow. He looks toward her, then spits out some blood.\n\nMARINER\nYeaaaaah...\n\nHe's built like a pro-wrestler. Moss green SWEATER stretched over his huge frame, sleeves rolled showing heavy leather BRACERS adorned with anchors. His inner forearm has a classic heart-and-arrow TATTOO with \"Dad\" in the centre. Across his chest is a BANDOLIER of bright red 12-gauge shells, FISH HOOKS hanging from the bottom edge. Heavy rubberized BOOTS go past his knees. A CAPE of heavy FISHING NET edged with WEIGHTS hangs from his shoulders.\n\nHe holds a STOUT WOODEN OAR in both hands, edged with METAL and dripping with BLOOD.\n\nROSE\nWhere were you when they grabbed me? You were supposed to pick me up at work!\n\nMARINER\nYeah, about that, I got a little... distracted.\n\nROSE\nDistracted. You got DISTRACTED?!\n\nMARINER\nI was also... tracking the car... that grabbed you... through the AirTag... I put on your phone.\n\nRose stops. She's really not happy about this.\n\nROSE\nYou Airtagged me?!\n\n==========\nEXTRACTED SCENE DATA:\n{\n  \"scene_number\": 4,\n  \"heading\": \"INT. OFFICE BUILDING - ELEVATOR\",\n  \"int_ext\": \"INT\",\n  \"location\": \"OFFICE BUILDING - ELEVATOR\",\n  \"time_of_day\": \"DAY\",\n  \"characters_present\": [\"ROSE\", \"BILLY\"],\n  \"summary\": \"Billy and Rose take the elevator in an office building. They discuss their plans for the evening. Rose mentions she needs to pick up groceries.\",\n  \"narrative_beats\": [\n    {\"beat_type\": \"exposition\", \"description\": \"Characters discuss daily plans.\", \"confidence\": 0.85}\n  ],\n  \"tone_mood\": \"casual\",\n  \"confidence\": 0.88\n}\n==========",
          "label": "prompts/qa-pass.txt: You are a QA reviewer validating whether an AI-extracted scene analysis is accurate and faithful to the source screenplay text.\n\nCompare the extracted scene data against the original scene text and evaluate:\n\n1. **Heading accuracy**: Is the scene heading correct (location, INT/EXT, time of day)?\n2. **Character completeness**: Are all characters who appear or speak listed?\n3. **Summary fidelity**: Does the summary accurately describe what happens? No fabrications?\n4. **Narrative beats**: Are the identified beats actually present in the scene?\n5. **Tone assessment**: Does the tone description match the actual mood of the scene?\n6. **Confidence calibration**: Is the confidence score reasonable given the quality?\n\nReturn a JSON object with:\n- passed: boolean (true if the extraction is faithful, false if it has significant errors)\n- confidence: float 0-1 (your confidence in this QA judgment)\n- issues: array of objects, each with:\n  - severity: \"error\" (factual wrong), \"warning\" (misleading), or \"note\" (minor)\n  - description: what's wrong\n  - location: which field has the issue\n- summary: 1-2 sentence overall assessment\n\nBe strict: wrong character names, fabricated events, or incorrect locations are errors.\nMinor omissions or imprecise tone descriptions are warnings.\n\nReturn ONLY valid JSON. No explanations or markdown fences.\n\n==========\nORIGINAL SCENE TEXT:\n{{scene_text}}\n\n==========\nEXTRACTED SCENE DATA:\n{{extracted_data}}\n==========",
          "config": {
            "provider": "anthropic:messages:claude-opus-4-6"
          }
        },
        "promptId": "8df20c2c4a6081352d6b06e144ddbc1e0a5244f9a3c2000d40df12fc9a94e543",
        "promptIdx": 4,
        "provider": {
          "id": "anthropic:messages:claude-sonnet-4-5-20250929",
          "label": "Claude Sonnet 4.5"
        },
        "response": {
          "output": "```json\n{\n  \"passed\": false,\n  \"confidence\": 0.98,\n  \"issues\": [\n    {\n      \"severity\": \"error\",\n      \"description\": \"Location is incorrect. Should be 'RUDDY & GREEN BUILDING - ELEVATOR' not 'OFFICE BUILDING - ELEVATOR'\",\n      \"location\": \"heading\"\n    },\n    {\n      \"severity\": \"error\",\n      \"description\": \"Time of day is not specified in the original scene, extraction incorrectly lists 'DAY'\",\n      \"location\": \"time_of_day\"\n    },\n    {\n      \"severity\": \"error\",\n      \"description\": \"Character 'BILLY' does not appear in the scene. The actual character is 'MARINER'\",\n      \"location\": \"characters_present\"\n    },\n    {\n      \"severity\": \"error\",\n      \"description\": \"Summary is completely fabricated. The scene shows Rose and Mariner covered in blood after an apparent violent incident, discussing how Rose was grabbed and Mariner tracked her. There is no discussion about evening plans or groceries\",\n      \"location\": \"summary\"\n    },\n    {\n      \"severity\": \"error\",\n      \"description\": \"Narrative beat is fabricated. The scene contains confrontation about Rose being grabbed/kidnapped and Mariner tracking her with an AirTag, not casual daily plans discussion\",\n      \"location\": \"narrative_beats\"\n    },\n    {\n      \"severity\": \"error\",\n      \"description\": \"Tone is completely wrong. Scene is tense and violent (characters covered in blood, discussing kidnapping), not 'casual'\",\n      \"location\": \"tone_mood\"\n    },\n    {\n      \"severity\": \"error\",\n      \"description\": \"Confidence score of 0.88 is unreasonably high given that the extraction contains no accurate information about the actual scene content\",\n      \"location\": \"confidence\"\n    }\n  ],\n  \"summary\": \"The extraction is completely inaccurate and appears to describe an entirely different scene. Every major element is wrong: location name, character names, summary content, narrative beats, and tone. This is a total mismatch with the source material.\"\n}\n```",
          "tokenUsage": {
            "total": 1534,
            "prompt": 1019,
            "completion": 515
          },
          "finishReason": "stop",
          "cost": 0.010782
        },
        "score": 0.995,
        "success": true,
        "testCase": {
          "vars": {
            "scene_text": "file://../input/enrich-scene-elevator.txt",
            "extracted_data": "file://../input/qa-bad-scene.json",
            "golden_path": "golden/qa-pass-golden.json",
            "test_key": "bad_scene"
          },
          "assert": [
            {
              "type": "python",
              "value": "file://../scorers/qa_pass_scorer.py"
            },
            {
              "type": "llm-rubric",
              "value": "This QA evaluation was given a BAD scene extraction with multiple errors:\n- Wrong building name (Office Building vs Ruddy & Greene)\n- Wrong time of day (DAY vs NIGHT)\n- Wrong character name (Billy instead of Mariner)\n- Missing thug characters\n- Fabricated content (grocery discussion never happens)\n\nThe QA model should have:\n1. Marked it as failed (false)\n2. Identified at least 2-3 specific errors\n3. Flagged the fabricated summary content\n4. Used \"error\" severity for factual mistakes\n\nIf the model let this pass, that's a dangerous false positive.\n"
            }
          ],
          "options": {
            "provider": "anthropic:messages:claude-opus-4-6"
          },
          "metadata": {}
        },
        "testIdx": 1,
        "vars": {
          "scene_text": "file://../input/enrich-scene-elevator.txt",
          "extracted_data": "file://../input/qa-bad-scene.json",
          "golden_path": "golden/qa-pass-golden.json",
          "test_key": "bad_scene"
        },
        "metadata": {
          "_promptfooFileMetadata": {}
        },
        "failureReason": 0
      },
      {
        "cost": 0.00817425,
        "gradingResult": {
          "pass": true,
          "score": 1,
          "reason": "All assertions passed",
          "namedScores": {},
          "tokensUsed": {
            "total": 931,
            "prompt": 752,
            "completion": 179,
            "cached": 0,
            "numRequests": 0
          },
          "componentResults": [
            {
              "pass": true,
              "score": 1,
              "reason": "confidence_calibration=1.00 | issue_detection=1.00 | json_valid=1.00 | pass_correct=1.00 | severity_accuracy=1.00 | summary_quality=1.00",
              "assertion": {
                "type": "python",
                "value": "file://../scorers/qa_pass_scorer.py"
              }
            },
            {
              "assertion": {
                "type": "llm-rubric",
                "value": "This QA evaluation was given a BAD scene extraction with multiple errors:\n- Wrong building name (Office Building vs Ruddy & Greene)\n- Wrong time of day (DAY vs NIGHT)\n- Wrong character name (Billy instead of Mariner)\n- Missing thug characters\n- Fabricated content (grocery discussion never happens)\n\nThe QA model should have:\n1. Marked it as failed (false)\n2. Identified at least 2-3 specific errors\n3. Flagged the fabricated summary content\n4. Used \"error\" severity for factual mistakes\n\nIf the model let this pass, that's a dangerous false positive.\n"
              },
              "pass": true,
              "score": 1,
              "reason": "The QA evaluation correctly identified the extraction as failed (passed: false) and flagged multiple specific errors with appropriate severity levels. It caught: (1) wrong building name (Office Building vs Ruddy & Green), (2) wrong/fabricated time of day (DAY), (3) wrong character name (Billy instead of Mariner), (4) fabricated summary content (groceries/evening plans), (5) incorrect narrative beats, and (6) mischaracterized tone. All factual mistakes were correctly labeled as 'error' severity. The evaluation also noted the unreasonably high confidence given the inaccuracies. This is a thorough and accurate QA assessment that correctly rejected a bad extraction — no dangerous false positive here.",
              "tokensUsed": {
                "total": 931,
                "prompt": 752,
                "completion": 179,
                "cached": 0,
                "numRequests": 0,
                "completionDetails": {
                  "reasoning": 0,
                  "acceptedPrediction": 0,
                  "rejectedPrediction": 0
                }
              },
              "metadata": {
                "renderedGradingPrompt": "[{\"role\":\"system\",\"content\":\"You are grading output according to a user-specified rubric. If the statement in the rubric is true, then the output passes the test. You respond with a JSON object with this structure: {reason: string, pass: boolean, score: number}\\n\\nExamples:\\n\\n<Output>Hello world</Output>\\n<Rubric>Content contains a greeting</Rubric>\\n{\\\"reason\\\": \\\"the content contains the word 'Hello'\\\", \\\"pass\\\": true, \\\"score\\\": 1.0}\\n\\n<Output>Avast ye swabs, repel the invaders!</Output>\\n<Rubric>Does not speak like a pirate</Rubric>\\n{\\\"reason\\\": \\\"'avast ye' is a common pirate term\\\", \\\"pass\\\": false, \\\"score\\\": 0.0}\"},{\"role\":\"user\",\"content\":\"<Output>\\n{\\\"passed\\\":false,\\\"confidence\\\":0.99,\\\"issues\\\":[{\\\"severity\\\":\\\"error\\\",\\\"description\\\":\\\"Scene heading location is incorrect: original is \\\\\\\"INT. RUDDY & GREEN BUILDING - ELEVATOR,\\\\\\\" not \\\\\\\"INT. OFFICE BUILDING - ELEVATOR.\\\\\\\"\\\",\\\"location\\\":\\\"heading/location\\\"},{\\\"severity\\\":\\\"error\\\",\\\"description\\\":\\\"Time of day is not specified in the original heading; extracted \\\\\\\"DAY\\\\\\\" is fabricated.\\\",\\\"location\\\":\\\"time_of_day\\\"},{\\\"severity\\\":\\\"error\\\",\\\"description\\\":\\\"Character list is incorrect and incomplete: the scene includes ROSE and MARINER (speaks), but extracted lists ROSE and BILLY (who does not appear).\\\",\\\"location\\\":\\\"characters_present\\\"},{\\\"severity\\\":\\\"error\\\",\\\"description\\\":\\\"Summary is fabricated and does not match the scene. The original involves Rose and the Mariner panting and covered in blood, discussing her abduction, his distraction, and that he AirTagged her phone—no evening plans or groceries.\\\",\\\"location\\\":\\\"summary\\\"},{\\\"severity\\\":\\\"error\\\",\\\"description\\\":\\\"Narrative beat is not present in the scene; they do not discuss daily plans, but argue about him being distracted and tracking her via AirTag after she was grabbed.\\\",\\\"location\\\":\\\"narrative_beats\\\"},{\\\"severity\\\":\\\"warning\\\",\\\"description\\\":\\\"Tone/mood is mischaracterized as casual; the scene is tense, grim, and darkly comedic amid blood and conflict.\\\",\\\"location\\\":\\\"tone_mood\\\"},{\\\"severity\\\":\\\"warning\\\",\\\"description\\\":\\\"Extraction confidence is unreasonably high given multiple major inaccuracies (heading, characters, summary, beats).\\\",\\\"location\\\":\\\"confidence\\\"}],\\\"summary\\\":\\\"The extraction is not faithful to the source: it invents the setting details, replaces Mariner with a nonexistent character, and fabricates the scene’s events and tone. Multiple core fields are inaccurate, so the scene data fails validation.\\\"}\\n</Output>\\n<Rubric>\\nThis QA evaluation was given a BAD scene extraction with multiple errors:\\n- Wrong building name (Office Building vs Ruddy & Greene)\\n- Wrong time of day (DAY vs NIGHT)\\n- Wrong character name (Billy instead of Mariner)\\n- Missing thug characters\\n- Fabricated content (grocery discussion never happens)\\n\\nThe QA model should have:\\n1. Marked it as failed (false)\\n2. Identified at least 2-3 specific errors\\n3. Flagged the fabricated summary content\\n4. Used \\\"error\\\" severity for factual mistakes\\n\\nIf the model let this pass, that's a dangerous false positive.\\n\\n</Rubric>\"}]"
              }
            }
          ]
        },
        "id": "5127a763-faae-4758-9e47-b4c37d3a9ea4",
        "latencyMs": 8231,
        "namedScores": {},
        "prompt": {
          "raw": "You are a QA reviewer validating whether an AI-extracted scene analysis is accurate and faithful to the source screenplay text.\n\nCompare the extracted scene data against the original scene text and evaluate:\n\n1. **Heading accuracy**: Is the scene heading correct (location, INT/EXT, time of day)?\n2. **Character completeness**: Are all characters who appear or speak listed?\n3. **Summary fidelity**: Does the summary accurately describe what happens? No fabrications?\n4. **Narrative beats**: Are the identified beats actually present in the scene?\n5. **Tone assessment**: Does the tone description match the actual mood of the scene?\n6. **Confidence calibration**: Is the confidence score reasonable given the quality?\n\nReturn a JSON object with:\n- passed: boolean (true if the extraction is faithful, false if it has significant errors)\n- confidence: float 0-1 (your confidence in this QA judgment)\n- issues: array of objects, each with:\n  - severity: \"error\" (factual wrong), \"warning\" (misleading), or \"note\" (minor)\n  - description: what's wrong\n  - location: which field has the issue\n- summary: 1-2 sentence overall assessment\n\nBe strict: wrong character names, fabricated events, or incorrect locations are errors.\nMinor omissions or imprecise tone descriptions are warnings.\n\nReturn ONLY valid JSON. No explanations or markdown fences.\n\n==========\nORIGINAL SCENE TEXT:\nINT. RUDDY & GREEN BUILDING - ELEVATOR\n\nUB40's \"I Can't Help Falling in Love With You\" muzak.\n\nROSE (mid-30s) leans against the elevator wall, panting. She's wearing a Tim Hortons uniform, her hair is a mess, and there's blood spattered on her face.\n\nShe looks right, pants a few more times, then squints in disgust. She gingerly picks up a bloody scrap of something with hair on it. She snorts and drops it.\n\nROSE\nIs that skull??\n\nNext to her is Mariner, also panting, covered in far more blood. His face is broad, stoic, and frowning. He has gray-blue eyes and a thick, curly, beard barely streaked with gray. He wears a red knit cap and a small mask.\n\nFULL-SCREEN SUPERIMPOSED TITLE CARD: \"THE MARINER\"\n\nHe blinks a few times as a drop of blood falls from his eyebrow. He looks toward her, then spits out some blood.\n\nMARINER\nYeaaaaah...\n\nHe's built like a pro-wrestler. Moss green SWEATER stretched over his huge frame, sleeves rolled showing heavy leather BRACERS adorned with anchors. His inner forearm has a classic heart-and-arrow TATTOO with \"Dad\" in the centre. Across his chest is a BANDOLIER of bright red 12-gauge shells, FISH HOOKS hanging from the bottom edge. Heavy rubberized BOOTS go past his knees. A CAPE of heavy FISHING NET edged with WEIGHTS hangs from his shoulders.\n\nHe holds a STOUT WOODEN OAR in both hands, edged with METAL and dripping with BLOOD.\n\nROSE\nWhere were you when they grabbed me? You were supposed to pick me up at work!\n\nMARINER\nYeah, about that, I got a little... distracted.\n\nROSE\nDistracted. You got DISTRACTED?!\n\nMARINER\nI was also... tracking the car... that grabbed you... through the AirTag... I put on your phone.\n\nRose stops. She's really not happy about this.\n\nROSE\nYou Airtagged me?!\n\n==========\nEXTRACTED SCENE DATA:\n{\n  \"scene_number\": 4,\n  \"heading\": \"INT. OFFICE BUILDING - ELEVATOR\",\n  \"int_ext\": \"INT\",\n  \"location\": \"OFFICE BUILDING - ELEVATOR\",\n  \"time_of_day\": \"DAY\",\n  \"characters_present\": [\"ROSE\", \"BILLY\"],\n  \"summary\": \"Billy and Rose take the elevator in an office building. They discuss their plans for the evening. Rose mentions she needs to pick up groceries.\",\n  \"narrative_beats\": [\n    {\"beat_type\": \"exposition\", \"description\": \"Characters discuss daily plans.\", \"confidence\": 0.85}\n  ],\n  \"tone_mood\": \"casual\",\n  \"confidence\": 0.88\n}\n==========",
          "label": "prompts/qa-pass.txt: You are a QA reviewer validating whether an AI-extracted scene analysis is accurate and faithful to the source screenplay text.\n\nCompare the extracted scene data against the original scene text and evaluate:\n\n1. **Heading accuracy**: Is the scene heading correct (location, INT/EXT, time of day)?\n2. **Character completeness**: Are all characters who appear or speak listed?\n3. **Summary fidelity**: Does the summary accurately describe what happens? No fabrications?\n4. **Narrative beats**: Are the identified beats actually present in the scene?\n5. **Tone assessment**: Does the tone description match the actual mood of the scene?\n6. **Confidence calibration**: Is the confidence score reasonable given the quality?\n\nReturn a JSON object with:\n- passed: boolean (true if the extraction is faithful, false if it has significant errors)\n- confidence: float 0-1 (your confidence in this QA judgment)\n- issues: array of objects, each with:\n  - severity: \"error\" (factual wrong), \"warning\" (misleading), or \"note\" (minor)\n  - description: what's wrong\n  - location: which field has the issue\n- summary: 1-2 sentence overall assessment\n\nBe strict: wrong character names, fabricated events, or incorrect locations are errors.\nMinor omissions or imprecise tone descriptions are warnings.\n\nReturn ONLY valid JSON. No explanations or markdown fences.\n\n==========\nORIGINAL SCENE TEXT:\n{{scene_text}}\n\n==========\nEXTRACTED SCENE DATA:\n{{extracted_data}}\n==========",
          "config": {
            "provider": "anthropic:messages:claude-opus-4-6"
          }
        },
        "promptId": "8df20c2c4a6081352d6b06e144ddbc1e0a5244f9a3c2000d40df12fc9a94e543",
        "promptIdx": 6,
        "provider": {
          "id": "openai:gpt-5.2",
          "label": "GPT-5.2"
        },
        "response": {
          "output": "{\n  \"passed\": false,\n  \"confidence\": 0.99,\n  \"issues\": [\n    {\n      \"severity\": \"error\",\n      \"description\": \"Scene heading location is incorrect: original is \\\"INT. RUDDY & GREEN BUILDING - ELEVATOR,\\\" not \\\"INT. OFFICE BUILDING - ELEVATOR.\\\"\",\n      \"location\": \"heading/location\"\n    },\n    {\n      \"severity\": \"error\",\n      \"description\": \"Time of day is not specified in the original heading; extracted \\\"DAY\\\" is fabricated.\",\n      \"location\": \"time_of_day\"\n    },\n    {\n      \"severity\": \"error\",\n      \"description\": \"Character list is incorrect and incomplete: the scene includes ROSE and MARINER (speaks), but extracted lists ROSE and BILLY (who does not appear).\",\n      \"location\": \"characters_present\"\n    },\n    {\n      \"severity\": \"error\",\n      \"description\": \"Summary is fabricated and does not match the scene. The original involves Rose and the Mariner panting and covered in blood, discussing her abduction, his distraction, and that he AirTagged her phone—no evening plans or groceries.\",\n      \"location\": \"summary\"\n    },\n    {\n      \"severity\": \"error\",\n      \"description\": \"Narrative beat is not present in the scene; they do not discuss daily plans, but argue about him being distracted and tracking her via AirTag after she was grabbed.\",\n      \"location\": \"narrative_beats\"\n    },\n    {\n      \"severity\": \"warning\",\n      \"description\": \"Tone/mood is mischaracterized as casual; the scene is tense, grim, and darkly comedic amid blood and conflict.\",\n      \"location\": \"tone_mood\"\n    },\n    {\n      \"severity\": \"warning\",\n      \"description\": \"Extraction confidence is unreasonably high given multiple major inaccuracies (heading, characters, summary, beats).\",\n      \"location\": \"confidence\"\n    }\n  ],\n  \"summary\": \"The extraction is not faithful to the source: it invents the setting details, replaces Mariner with a nonexistent character, and fabricates the scene’s events and tone. Multiple core fields are inaccurate, so the scene data fails validation.\"\n}",
          "tokenUsage": {
            "total": 1395,
            "prompt": 927,
            "completion": 468,
            "numRequests": 1,
            "completionDetails": {
              "reasoning": 0,
              "acceptedPrediction": 0,
              "rejectedPrediction": 0
            }
          },
          "cached": false,
          "latencyMs": 8231,
          "finishReason": "stop",
          "cost": 0.00817425,
          "guardrails": {
            "flagged": false
          },
          "metadata": {
            "http": {
              "status": 200,
              "statusText": "OK",
              "headers": {
                "access-control-expose-headers": "X-Request-ID",
                "alt-svc": "h3=\":443\"; ma=86400",
                "cf-cache-status": "DYNAMIC",
                "cf-ray": "9cfbd3aa98845819-YVR",
                "connection": "keep-alive",
                "content-encoding": "br",
                "content-type": "application/json",
                "date": "Wed, 18 Feb 2026 07:31:55 GMT",
                "openai-organization": "user-oqdrq8y0bphopngnvkyuu5wr",
                "openai-processing-ms": "8098",
                "openai-project": "proj_ZRoLLwXcJok6Xg2t6eKhI1pn",
                "openai-version": "2020-10-01",
                "server": "cloudflare",
                "set-cookie": "__cf_bm=0fxHcADVbjKRnVTVHgWf0aYM2doN9LaW5dyJx_ZfPtM-1771399906.9791596-1.0.1.1-4q.HFE21CxZlK8C8apsfcxfLXMDj_Js7vNBd1qlTLlYvbffmvOfdKtNvHPw14ZBwAkzTkgfjgdiOzYTp6h_Md.SXZ_F6OPXafpE_FXgIYd6NYNH9.HunaXXQmTXu_RXt; HttpOnly; Secure; Path=/; Domain=api.openai.com; Expires=Wed, 18 Feb 2026 08:01:55 GMT",
                "strict-transport-security": "max-age=31536000; includeSubDomains; preload",
                "transfer-encoding": "chunked",
                "x-content-type-options": "nosniff",
                "x-openai-proxy-wasm": "v0.1",
                "x-ratelimit-limit-requests": "10000",
                "x-ratelimit-limit-tokens": "4000000",
                "x-ratelimit-remaining-requests": "9999",
                "x-ratelimit-remaining-tokens": "3999073",
                "x-ratelimit-reset-requests": "6ms",
                "x-ratelimit-reset-tokens": "13ms",
                "x-request-id": "req_f9bad486cae94ec7a4fa5a82b756d342"
              }
            }
          }
        },
        "score": 1,
        "success": true,
        "testCase": {
          "vars": {
            "scene_text": "file://../input/enrich-scene-elevator.txt",
            "extracted_data": "file://../input/qa-bad-scene.json",
            "golden_path": "golden/qa-pass-golden.json",
            "test_key": "bad_scene"
          },
          "assert": [
            {
              "type": "python",
              "value": "file://../scorers/qa_pass_scorer.py"
            },
            {
              "type": "llm-rubric",
              "value": "This QA evaluation was given a BAD scene extraction with multiple errors:\n- Wrong building name (Office Building vs Ruddy & Greene)\n- Wrong time of day (DAY vs NIGHT)\n- Wrong character name (Billy instead of Mariner)\n- Missing thug characters\n- Fabricated content (grocery discussion never happens)\n\nThe QA model should have:\n1. Marked it as failed (false)\n2. Identified at least 2-3 specific errors\n3. Flagged the fabricated summary content\n4. Used \"error\" severity for factual mistakes\n\nIf the model let this pass, that's a dangerous false positive.\n"
            }
          ],
          "options": {
            "provider": "anthropic:messages:claude-opus-4-6"
          },
          "metadata": {}
        },
        "testIdx": 1,
        "vars": {
          "scene_text": "file://../input/enrich-scene-elevator.txt",
          "extracted_data": "file://../input/qa-bad-scene.json",
          "golden_path": "golden/qa-pass-golden.json",
          "test_key": "bad_scene"
        },
        "metadata": {
          "http": {
            "status": 200,
            "statusText": "OK",
            "headers": {
              "access-control-expose-headers": "X-Request-ID",
              "alt-svc": "h3=\":443\"; ma=86400",
              "cf-cache-status": "DYNAMIC",
              "cf-ray": "9cfbd3aa98845819-YVR",
              "connection": "keep-alive",
              "content-encoding": "br",
              "content-type": "application/json",
              "date": "Wed, 18 Feb 2026 07:31:55 GMT",
              "openai-organization": "user-oqdrq8y0bphopngnvkyuu5wr",
              "openai-processing-ms": "8098",
              "openai-project": "proj_ZRoLLwXcJok6Xg2t6eKhI1pn",
              "openai-version": "2020-10-01",
              "server": "cloudflare",
              "set-cookie": "__cf_bm=0fxHcADVbjKRnVTVHgWf0aYM2doN9LaW5dyJx_ZfPtM-1771399906.9791596-1.0.1.1-4q.HFE21CxZlK8C8apsfcxfLXMDj_Js7vNBd1qlTLlYvbffmvOfdKtNvHPw14ZBwAkzTkgfjgdiOzYTp6h_Md.SXZ_F6OPXafpE_FXgIYd6NYNH9.HunaXXQmTXu_RXt; HttpOnly; Secure; Path=/; Domain=api.openai.com; Expires=Wed, 18 Feb 2026 08:01:55 GMT",
              "strict-transport-security": "max-age=31536000; includeSubDomains; preload",
              "transfer-encoding": "chunked",
              "x-content-type-options": "nosniff",
              "x-openai-proxy-wasm": "v0.1",
              "x-ratelimit-limit-requests": "10000",
              "x-ratelimit-limit-tokens": "4000000",
              "x-ratelimit-remaining-requests": "9999",
              "x-ratelimit-remaining-tokens": "3999073",
              "x-ratelimit-reset-requests": "6ms",
              "x-ratelimit-reset-tokens": "13ms",
              "x-request-id": "req_f9bad486cae94ec7a4fa5a82b756d342"
            }
          },
          "_promptfooFileMetadata": {}
        },
        "failureReason": 0
      },
      {
        "cost": 0,
        "gradingResult": {
          "pass": true,
          "score": 1,
          "reason": "All assertions passed",
          "namedScores": {},
          "tokensUsed": {
            "total": 989,
            "prompt": 823,
            "completion": 166,
            "cached": 0,
            "numRequests": 0
          },
          "componentResults": [
            {
              "pass": true,
              "score": 1,
              "reason": "confidence_calibration=1.00 | issue_detection=1.00 | json_valid=1.00 | pass_correct=1.00 | severity_accuracy=1.00 | summary_quality=1.00",
              "assertion": {
                "type": "python",
                "value": "file://../scorers/qa_pass_scorer.py"
              }
            },
            {
              "assertion": {
                "type": "llm-rubric",
                "value": "This QA evaluation was given a BAD scene extraction with multiple errors:\n- Wrong building name (Office Building vs Ruddy & Greene)\n- Wrong time of day (DAY vs NIGHT)\n- Wrong character name (Billy instead of Mariner)\n- Missing thug characters\n- Fabricated content (grocery discussion never happens)\n\nThe QA model should have:\n1. Marked it as failed (false)\n2. Identified at least 2-3 specific errors\n3. Flagged the fabricated summary content\n4. Used \"error\" severity for factual mistakes\n\nIf the model let this pass, that's a dangerous false positive.\n"
              },
              "pass": true,
              "score": 1,
              "reason": "The QA evaluation correctly marked the extraction as failed (passed: false), identified numerous specific errors (8 issues listed), flagged the fabricated summary content about groceries and evening plans, and used 'error' severity for all factual mistakes. It caught the wrong building name (Office Building vs Ruddy & Green), wrong time of day (DAY vs unspecified/NIGHT), wrong character name (Billy instead of Mariner), the missing Mariner character, and the entirely fabricated summary. It also went beyond the minimum requirements by noting the miscalibrated confidence score and incorrect tone. This is a thorough and accurate QA evaluation that correctly identifies a dangerous bad extraction.",
              "tokensUsed": {
                "total": 989,
                "prompt": 823,
                "completion": 166,
                "cached": 0,
                "numRequests": 0,
                "completionDetails": {
                  "reasoning": 0,
                  "acceptedPrediction": 0,
                  "rejectedPrediction": 0
                }
              },
              "metadata": {
                "renderedGradingPrompt": "[{\"role\":\"system\",\"content\":\"You are grading output according to a user-specified rubric. If the statement in the rubric is true, then the output passes the test. You respond with a JSON object with this structure: {reason: string, pass: boolean, score: number}\\n\\nExamples:\\n\\n<Output>Hello world</Output>\\n<Rubric>Content contains a greeting</Rubric>\\n{\\\"reason\\\": \\\"the content contains the word 'Hello'\\\", \\\"pass\\\": true, \\\"score\\\": 1.0}\\n\\n<Output>Avast ye swabs, repel the invaders!</Output>\\n<Rubric>Does not speak like a pirate</Rubric>\\n{\\\"reason\\\": \\\"'avast ye' is a common pirate term\\\", \\\"pass\\\": false, \\\"score\\\": 0.0}\"},{\"role\":\"user\",\"content\":\"<Output>\\n{\\\"passed\\\":false,\\\"confidence\\\":0.99,\\\"issues\\\":[{\\\"severity\\\":\\\"error\\\",\\\"description\\\":\\\"The heading says 'OFFICE BUILDING - ELEVATOR' but the correct location is 'RUDDY & GREEN BUILDING - ELEVATOR'.\\\",\\\"location\\\":\\\"heading / location\\\"},{\\\"severity\\\":\\\"error\\\",\\\"description\\\":\\\"Time of day is listed as 'DAY' but no time of day is specified in the scene heading or scene text. This is a fabrication.\\\",\\\"location\\\":\\\"time_of_day\\\"},{\\\"severity\\\":\\\"error\\\",\\\"description\\\":\\\"The character 'BILLY' does not exist in this scene. The two characters present are ROSE and MARINER. 'BILLY' is a fabricated name.\\\",\\\"location\\\":\\\"characters_present\\\"},{\\\"severity\\\":\\\"error\\\",\\\"description\\\":\\\"MARINER is not listed in characters_present despite being a named, speaking character with a full title card introduction.\\\",\\\"location\\\":\\\"characters_present\\\"},{\\\"severity\\\":\\\"error\\\",\\\"description\\\":\\\"The summary is entirely fabricated. The scene does not involve discussing evening plans or groceries. It depicts Rose and Mariner in an elevator covered in blood after a violent encounter, arguing about Mariner being late and having placed an AirTag on Rose's phone.\\\",\\\"location\\\":\\\"summary\\\"},{\\\"severity\\\":\\\"error\\\",\\\"description\\\":\\\"The narrative beat describing 'Characters discuss daily plans' is completely fabricated and bears no resemblance to the actual scene content, which involves post-violence tension, confrontation, and a revelation about surveillance.\\\",\\\"location\\\":\\\"narrative_beats\\\"},{\\\"severity\\\":\\\"error\\\",\\\"description\\\":\\\"The tone is described as 'casual' but the scene is tense, darkly comedic, and action-inflected — characters are covered in blood, arguing, and reacting to a severed skull fragment.\\\",\\\"location\\\":\\\"tone_mood\\\"},{\\\"severity\\\":\\\"error\\\",\\\"description\\\":\\\"The confidence score of 0.88 is grossly miscalibrated given that virtually every field in the extraction is incorrect or fabricated.\\\",\\\"location\\\":\\\"confidence\\\"}],\\\"summary\\\":\\\"The extracted scene data is almost entirely fabricated and bears no meaningful resemblance to the source text. Every major field — location, characters, summary, beats, and tone — contains critical errors, making this extraction a complete failure.\\\"}\\n</Output>\\n<Rubric>\\nThis QA evaluation was given a BAD scene extraction with multiple errors:\\n- Wrong building name (Office Building vs Ruddy & Greene)\\n- Wrong time of day (DAY vs NIGHT)\\n- Wrong character name (Billy instead of Mariner)\\n- Missing thug characters\\n- Fabricated content (grocery discussion never happens)\\n\\nThe QA model should have:\\n1. Marked it as failed (false)\\n2. Identified at least 2-3 specific errors\\n3. Flagged the fabricated summary content\\n4. Used \\\"error\\\" severity for factual mistakes\\n\\nIf the model let this pass, that's a dangerous false positive.\\n\\n</Rubric>\"}]"
              }
            }
          ]
        },
        "id": "02342d6b-1500-4441-a1cc-fde2a588adaa",
        "latencyMs": 10479,
        "namedScores": {},
        "prompt": {
          "raw": "You are a QA reviewer validating whether an AI-extracted scene analysis is accurate and faithful to the source screenplay text.\n\nCompare the extracted scene data against the original scene text and evaluate:\n\n1. **Heading accuracy**: Is the scene heading correct (location, INT/EXT, time of day)?\n2. **Character completeness**: Are all characters who appear or speak listed?\n3. **Summary fidelity**: Does the summary accurately describe what happens? No fabrications?\n4. **Narrative beats**: Are the identified beats actually present in the scene?\n5. **Tone assessment**: Does the tone description match the actual mood of the scene?\n6. **Confidence calibration**: Is the confidence score reasonable given the quality?\n\nReturn a JSON object with:\n- passed: boolean (true if the extraction is faithful, false if it has significant errors)\n- confidence: float 0-1 (your confidence in this QA judgment)\n- issues: array of objects, each with:\n  - severity: \"error\" (factual wrong), \"warning\" (misleading), or \"note\" (minor)\n  - description: what's wrong\n  - location: which field has the issue\n- summary: 1-2 sentence overall assessment\n\nBe strict: wrong character names, fabricated events, or incorrect locations are errors.\nMinor omissions or imprecise tone descriptions are warnings.\n\nReturn ONLY valid JSON. No explanations or markdown fences.\n\n==========\nORIGINAL SCENE TEXT:\nINT. RUDDY & GREEN BUILDING - ELEVATOR\n\nUB40's \"I Can't Help Falling in Love With You\" muzak.\n\nROSE (mid-30s) leans against the elevator wall, panting. She's wearing a Tim Hortons uniform, her hair is a mess, and there's blood spattered on her face.\n\nShe looks right, pants a few more times, then squints in disgust. She gingerly picks up a bloody scrap of something with hair on it. She snorts and drops it.\n\nROSE\nIs that skull??\n\nNext to her is Mariner, also panting, covered in far more blood. His face is broad, stoic, and frowning. He has gray-blue eyes and a thick, curly, beard barely streaked with gray. He wears a red knit cap and a small mask.\n\nFULL-SCREEN SUPERIMPOSED TITLE CARD: \"THE MARINER\"\n\nHe blinks a few times as a drop of blood falls from his eyebrow. He looks toward her, then spits out some blood.\n\nMARINER\nYeaaaaah...\n\nHe's built like a pro-wrestler. Moss green SWEATER stretched over his huge frame, sleeves rolled showing heavy leather BRACERS adorned with anchors. His inner forearm has a classic heart-and-arrow TATTOO with \"Dad\" in the centre. Across his chest is a BANDOLIER of bright red 12-gauge shells, FISH HOOKS hanging from the bottom edge. Heavy rubberized BOOTS go past his knees. A CAPE of heavy FISHING NET edged with WEIGHTS hangs from his shoulders.\n\nHe holds a STOUT WOODEN OAR in both hands, edged with METAL and dripping with BLOOD.\n\nROSE\nWhere were you when they grabbed me? You were supposed to pick me up at work!\n\nMARINER\nYeah, about that, I got a little... distracted.\n\nROSE\nDistracted. You got DISTRACTED?!\n\nMARINER\nI was also... tracking the car... that grabbed you... through the AirTag... I put on your phone.\n\nRose stops. She's really not happy about this.\n\nROSE\nYou Airtagged me?!\n\n==========\nEXTRACTED SCENE DATA:\n{\n  \"scene_number\": 4,\n  \"heading\": \"INT. OFFICE BUILDING - ELEVATOR\",\n  \"int_ext\": \"INT\",\n  \"location\": \"OFFICE BUILDING - ELEVATOR\",\n  \"time_of_day\": \"DAY\",\n  \"characters_present\": [\"ROSE\", \"BILLY\"],\n  \"summary\": \"Billy and Rose take the elevator in an office building. They discuss their plans for the evening. Rose mentions she needs to pick up groceries.\",\n  \"narrative_beats\": [\n    {\"beat_type\": \"exposition\", \"description\": \"Characters discuss daily plans.\", \"confidence\": 0.85}\n  ],\n  \"tone_mood\": \"casual\",\n  \"confidence\": 0.88\n}\n==========",
          "label": "prompts/qa-pass.txt: You are a QA reviewer validating whether an AI-extracted scene analysis is accurate and faithful to the source screenplay text.\n\nCompare the extracted scene data against the original scene text and evaluate:\n\n1. **Heading accuracy**: Is the scene heading correct (location, INT/EXT, time of day)?\n2. **Character completeness**: Are all characters who appear or speak listed?\n3. **Summary fidelity**: Does the summary accurately describe what happens? No fabrications?\n4. **Narrative beats**: Are the identified beats actually present in the scene?\n5. **Tone assessment**: Does the tone description match the actual mood of the scene?\n6. **Confidence calibration**: Is the confidence score reasonable given the quality?\n\nReturn a JSON object with:\n- passed: boolean (true if the extraction is faithful, false if it has significant errors)\n- confidence: float 0-1 (your confidence in this QA judgment)\n- issues: array of objects, each with:\n  - severity: \"error\" (factual wrong), \"warning\" (misleading), or \"note\" (minor)\n  - description: what's wrong\n  - location: which field has the issue\n- summary: 1-2 sentence overall assessment\n\nBe strict: wrong character names, fabricated events, or incorrect locations are errors.\nMinor omissions or imprecise tone descriptions are warnings.\n\nReturn ONLY valid JSON. No explanations or markdown fences.\n\n==========\nORIGINAL SCENE TEXT:\n{{scene_text}}\n\n==========\nEXTRACTED SCENE DATA:\n{{extracted_data}}\n==========",
          "config": {
            "provider": "anthropic:messages:claude-opus-4-6"
          }
        },
        "promptId": "8df20c2c4a6081352d6b06e144ddbc1e0a5244f9a3c2000d40df12fc9a94e543",
        "promptIdx": 5,
        "provider": {
          "id": "anthropic:messages:claude-sonnet-4-6",
          "label": "Claude Sonnet 4.6"
        },
        "response": {
          "output": "{\n  \"passed\": false,\n  \"confidence\": 0.99,\n  \"issues\": [\n    {\n      \"severity\": \"error\",\n      \"description\": \"The heading says 'OFFICE BUILDING - ELEVATOR' but the correct location is 'RUDDY & GREEN BUILDING - ELEVATOR'.\",\n      \"location\": \"heading / location\"\n    },\n    {\n      \"severity\": \"error\",\n      \"description\": \"Time of day is listed as 'DAY' but no time of day is specified in the scene heading or scene text. This is a fabrication.\",\n      \"location\": \"time_of_day\"\n    },\n    {\n      \"severity\": \"error\",\n      \"description\": \"The character 'BILLY' does not exist in this scene. The two characters present are ROSE and MARINER. 'BILLY' is a fabricated name.\",\n      \"location\": \"characters_present\"\n    },\n    {\n      \"severity\": \"error\",\n      \"description\": \"MARINER is not listed in characters_present despite being a named, speaking character with a full title card introduction.\",\n      \"location\": \"characters_present\"\n    },\n    {\n      \"severity\": \"error\",\n      \"description\": \"The summary is entirely fabricated. The scene does not involve discussing evening plans or groceries. It depicts Rose and Mariner in an elevator covered in blood after a violent encounter, arguing about Mariner being late and having placed an AirTag on Rose's phone.\",\n      \"location\": \"summary\"\n    },\n    {\n      \"severity\": \"error\",\n      \"description\": \"The narrative beat describing 'Characters discuss daily plans' is completely fabricated and bears no resemblance to the actual scene content, which involves post-violence tension, confrontation, and a revelation about surveillance.\",\n      \"location\": \"narrative_beats\"\n    },\n    {\n      \"severity\": \"error\",\n      \"description\": \"The tone is described as 'casual' but the scene is tense, darkly comedic, and action-inflected — characters are covered in blood, arguing, and reacting to a severed skull fragment.\",\n      \"location\": \"tone_mood\"\n    },\n    {\n      \"severity\": \"error\",\n      \"description\": \"The confidence score of 0.88 is grossly miscalibrated given that virtually every field in the extraction is incorrect or fabricated.\",\n      \"location\": \"confidence\"\n    }\n  ],\n  \"summary\": \"The extracted scene data is almost entirely fabricated and bears no meaningful resemblance to the source text. Every major field — location, characters, summary, beats, and tone — contains critical errors, making this extraction a complete failure.\"\n}",
          "tokenUsage": {
            "total": 1641,
            "prompt": 1019,
            "completion": 622
          },
          "finishReason": "stop"
        },
        "score": 1,
        "success": true,
        "testCase": {
          "vars": {
            "scene_text": "file://../input/enrich-scene-elevator.txt",
            "extracted_data": "file://../input/qa-bad-scene.json",
            "golden_path": "golden/qa-pass-golden.json",
            "test_key": "bad_scene"
          },
          "assert": [
            {
              "type": "python",
              "value": "file://../scorers/qa_pass_scorer.py"
            },
            {
              "type": "llm-rubric",
              "value": "This QA evaluation was given a BAD scene extraction with multiple errors:\n- Wrong building name (Office Building vs Ruddy & Greene)\n- Wrong time of day (DAY vs NIGHT)\n- Wrong character name (Billy instead of Mariner)\n- Missing thug characters\n- Fabricated content (grocery discussion never happens)\n\nThe QA model should have:\n1. Marked it as failed (false)\n2. Identified at least 2-3 specific errors\n3. Flagged the fabricated summary content\n4. Used \"error\" severity for factual mistakes\n\nIf the model let this pass, that's a dangerous false positive.\n"
            }
          ],
          "options": {
            "provider": "anthropic:messages:claude-opus-4-6"
          },
          "metadata": {}
        },
        "testIdx": 1,
        "vars": {
          "scene_text": "file://../input/enrich-scene-elevator.txt",
          "extracted_data": "file://../input/qa-bad-scene.json",
          "golden_path": "golden/qa-pass-golden.json",
          "test_key": "bad_scene"
        },
        "metadata": {
          "_promptfooFileMetadata": {}
        },
        "failureReason": 0
      },
      {
        "cost": 0.020270000000000003,
        "gradingResult": {
          "pass": true,
          "score": 0.995,
          "reason": "All assertions passed",
          "namedScores": {},
          "tokensUsed": {
            "total": 1114,
            "prompt": 953,
            "completion": 161,
            "cached": 0,
            "numRequests": 0
          },
          "componentResults": [
            {
              "pass": true,
              "score": 0.99,
              "reason": "confidence_calibration=1.00 | issue_detection=1.00 | json_valid=0.90 | pass_correct=1.00 | severity_accuracy=1.00 | summary_quality=1.00 | JSON extracted from code block",
              "assertion": {
                "type": "python",
                "value": "file://../scorers/qa_pass_scorer.py"
              }
            },
            {
              "assertion": {
                "type": "llm-rubric",
                "value": "This QA evaluation was given a BAD scene extraction with multiple errors:\n- Wrong building name (Office Building vs Ruddy & Greene)\n- Wrong time of day (DAY vs NIGHT)\n- Wrong character name (Billy instead of Mariner)\n- Missing thug characters\n- Fabricated content (grocery discussion never happens)\n\nThe QA model should have:\n1. Marked it as failed (false)\n2. Identified at least 2-3 specific errors\n3. Flagged the fabricated summary content\n4. Used \"error\" severity for factual mistakes\n\nIf the model let this pass, that's a dangerous false positive.\n"
              },
              "pass": true,
              "score": 1,
              "reason": "The QA evaluation correctly marked the extraction as failed (passed: false). It identified far more than 2-3 specific errors, including: wrong building name (Office Building vs Ruddy & Green), wrong character name (Billy instead of Mariner), missing Mariner from characters, fabricated summary content about groceries/evening plans, fabricated narrative beats, wrong tone, and wrong time of day. It flagged the fabricated summary content explicitly. All factual mistakes were correctly given 'error' severity. The evaluation also noted the inappropriately high confidence score. This is a thorough and accurate QA catch of a bad extraction — no false positive here.",
              "tokensUsed": {
                "total": 1114,
                "prompt": 953,
                "completion": 161,
                "cached": 0,
                "numRequests": 0,
                "completionDetails": {
                  "reasoning": 0,
                  "acceptedPrediction": 0,
                  "rejectedPrediction": 0
                }
              },
              "metadata": {
                "renderedGradingPrompt": "[{\"role\":\"system\",\"content\":\"You are grading output according to a user-specified rubric. If the statement in the rubric is true, then the output passes the test. You respond with a JSON object with this structure: {reason: string, pass: boolean, score: number}\\n\\nExamples:\\n\\n<Output>Hello world</Output>\\n<Rubric>Content contains a greeting</Rubric>\\n{\\\"reason\\\": \\\"the content contains the word 'Hello'\\\", \\\"pass\\\": true, \\\"score\\\": 1.0}\\n\\n<Output>Avast ye swabs, repel the invaders!</Output>\\n<Rubric>Does not speak like a pirate</Rubric>\\n{\\\"reason\\\": \\\"'avast ye' is a common pirate term\\\", \\\"pass\\\": false, \\\"score\\\": 0.0}\"},{\"role\":\"user\",\"content\":\"<Output>\\n```json\\n{\\n  \\\"passed\\\": false,\\n  \\\"confidence\\\": 0.99,\\n  \\\"issues\\\": [\\n    {\\n      \\\"severity\\\": \\\"error\\\",\\n      \\\"description\\\": \\\"Scene heading location is wrong. The original text says 'RUDDY & GREEN BUILDING - ELEVATOR', not 'OFFICE BUILDING - ELEVATOR'.\\\",\\n      \\\"location\\\": \\\"heading\\\"\\n    },\\n    {\\n      \\\"severity\\\": \\\"error\\\",\\n      \\\"description\\\": \\\"Character 'BILLY' does not appear in the scene. The second character is 'MARINER', not 'BILLY'.\\\",\\n      \\\"location\\\": \\\"characters_present\\\"\\n    },\\n    {\\n      \\\"severity\\\": \\\"error\\\",\\n      \\\"description\\\": \\\"Character 'MARINER' is missing from the characters_present list.\\\",\\n      \\\"location\\\": \\\"characters_present\\\"\\n    },\\n    {\\n      \\\"severity\\\": \\\"error\\\",\\n      \\\"description\\\": \\\"The summary is entirely fabricated. The scene involves Rose and Mariner recovering from a violent encounter, covered in blood, arguing about Mariner failing to pick Rose up from work and secretly AirTagging her phone. There is no discussion of evening plans or groceries.\\\",\\n      \\\"location\\\": \\\"summary\\\"\\n    },\\n    {\\n      \\\"severity\\\": \\\"error\\\",\\n      \\\"description\\\": \\\"The narrative beat is fabricated. The actual beats involve post-combat recovery, Rose confronting Mariner about failing to pick her up, and discovering he AirTagged her phone. There is no discussion of 'daily plans'.\\\",\\n      \\\"location\\\": \\\"narrative_beats\\\"\\n    },\\n    {\\n      \\\"severity\\\": \\\"error\\\",\\n      \\\"description\\\": \\\"The tone is described as 'casual', but the scene is tense, darkly comedic, and involves blood-spattered characters arguing in an elevator with muzak playing. 'Casual' is completely wrong.\\\",\\n      \\\"location\\\": \\\"tone_mood\\\"\\n    },\\n    {\\n      \\\"severity\\\": \\\"error\\\",\\n      \\\"description\\\": \\\"Time of day is listed as 'DAY' but the original scene text does not specify a time of day.\\\",\\n      \\\"location\\\": \\\"time_of_day\\\"\\n    },\\n    {\\n      \\\"severity\\\": \\\"warning\\\",\\n      \\\"description\\\": \\\"Confidence score of 0.88 is far too high given that virtually every field is incorrect.\\\",\\n      \\\"location\\\": \\\"confidence\\\"\\n    }\\n  ],\\n  \\\"summary\\\": \\\"The extraction is almost entirely fabricated. The location, characters, summary, narrative beats, and tone are all wrong, bearing no resemblance to the original scene which depicts two blood-covered characters arguing in an elevator after a violent rescue.\\\"\\n}\\n```\\n</Output>\\n<Rubric>\\nThis QA evaluation was given a BAD scene extraction with multiple errors:\\n- Wrong building name (Office Building vs Ruddy & Greene)\\n- Wrong time of day (DAY vs NIGHT)\\n- Wrong character name (Billy instead of Mariner)\\n- Missing thug characters\\n- Fabricated content (grocery discussion never happens)\\n\\nThe QA model should have:\\n1. Marked it as failed (false)\\n2. Identified at least 2-3 specific errors\\n3. Flagged the fabricated summary content\\n4. Used \\\"error\\\" severity for factual mistakes\\n\\nIf the model let this pass, that's a dangerous false positive.\\n\\n</Rubric>\"}]"
              }
            }
          ]
        },
        "id": "593d9035-b2bd-453a-880f-075bd4fb80b4",
        "latencyMs": 10539,
        "namedScores": {},
        "prompt": {
          "raw": "You are a QA reviewer validating whether an AI-extracted scene analysis is accurate and faithful to the source screenplay text.\n\nCompare the extracted scene data against the original scene text and evaluate:\n\n1. **Heading accuracy**: Is the scene heading correct (location, INT/EXT, time of day)?\n2. **Character completeness**: Are all characters who appear or speak listed?\n3. **Summary fidelity**: Does the summary accurately describe what happens? No fabrications?\n4. **Narrative beats**: Are the identified beats actually present in the scene?\n5. **Tone assessment**: Does the tone description match the actual mood of the scene?\n6. **Confidence calibration**: Is the confidence score reasonable given the quality?\n\nReturn a JSON object with:\n- passed: boolean (true if the extraction is faithful, false if it has significant errors)\n- confidence: float 0-1 (your confidence in this QA judgment)\n- issues: array of objects, each with:\n  - severity: \"error\" (factual wrong), \"warning\" (misleading), or \"note\" (minor)\n  - description: what's wrong\n  - location: which field has the issue\n- summary: 1-2 sentence overall assessment\n\nBe strict: wrong character names, fabricated events, or incorrect locations are errors.\nMinor omissions or imprecise tone descriptions are warnings.\n\nReturn ONLY valid JSON. No explanations or markdown fences.\n\n==========\nORIGINAL SCENE TEXT:\nINT. RUDDY & GREEN BUILDING - ELEVATOR\n\nUB40's \"I Can't Help Falling in Love With You\" muzak.\n\nROSE (mid-30s) leans against the elevator wall, panting. She's wearing a Tim Hortons uniform, her hair is a mess, and there's blood spattered on her face.\n\nShe looks right, pants a few more times, then squints in disgust. She gingerly picks up a bloody scrap of something with hair on it. She snorts and drops it.\n\nROSE\nIs that skull??\n\nNext to her is Mariner, also panting, covered in far more blood. His face is broad, stoic, and frowning. He has gray-blue eyes and a thick, curly, beard barely streaked with gray. He wears a red knit cap and a small mask.\n\nFULL-SCREEN SUPERIMPOSED TITLE CARD: \"THE MARINER\"\n\nHe blinks a few times as a drop of blood falls from his eyebrow. He looks toward her, then spits out some blood.\n\nMARINER\nYeaaaaah...\n\nHe's built like a pro-wrestler. Moss green SWEATER stretched over his huge frame, sleeves rolled showing heavy leather BRACERS adorned with anchors. His inner forearm has a classic heart-and-arrow TATTOO with \"Dad\" in the centre. Across his chest is a BANDOLIER of bright red 12-gauge shells, FISH HOOKS hanging from the bottom edge. Heavy rubberized BOOTS go past his knees. A CAPE of heavy FISHING NET edged with WEIGHTS hangs from his shoulders.\n\nHe holds a STOUT WOODEN OAR in both hands, edged with METAL and dripping with BLOOD.\n\nROSE\nWhere were you when they grabbed me? You were supposed to pick me up at work!\n\nMARINER\nYeah, about that, I got a little... distracted.\n\nROSE\nDistracted. You got DISTRACTED?!\n\nMARINER\nI was also... tracking the car... that grabbed you... through the AirTag... I put on your phone.\n\nRose stops. She's really not happy about this.\n\nROSE\nYou Airtagged me?!\n\n==========\nEXTRACTED SCENE DATA:\n{\n  \"scene_number\": 4,\n  \"heading\": \"INT. OFFICE BUILDING - ELEVATOR\",\n  \"int_ext\": \"INT\",\n  \"location\": \"OFFICE BUILDING - ELEVATOR\",\n  \"time_of_day\": \"DAY\",\n  \"characters_present\": [\"ROSE\", \"BILLY\"],\n  \"summary\": \"Billy and Rose take the elevator in an office building. They discuss their plans for the evening. Rose mentions she needs to pick up groceries.\",\n  \"narrative_beats\": [\n    {\"beat_type\": \"exposition\", \"description\": \"Characters discuss daily plans.\", \"confidence\": 0.85}\n  ],\n  \"tone_mood\": \"casual\",\n  \"confidence\": 0.88\n}\n==========",
          "label": "prompts/qa-pass.txt: You are a QA reviewer validating whether an AI-extracted scene analysis is accurate and faithful to the source screenplay text.\n\nCompare the extracted scene data against the original scene text and evaluate:\n\n1. **Heading accuracy**: Is the scene heading correct (location, INT/EXT, time of day)?\n2. **Character completeness**: Are all characters who appear or speak listed?\n3. **Summary fidelity**: Does the summary accurately describe what happens? No fabrications?\n4. **Narrative beats**: Are the identified beats actually present in the scene?\n5. **Tone assessment**: Does the tone description match the actual mood of the scene?\n6. **Confidence calibration**: Is the confidence score reasonable given the quality?\n\nReturn a JSON object with:\n- passed: boolean (true if the extraction is faithful, false if it has significant errors)\n- confidence: float 0-1 (your confidence in this QA judgment)\n- issues: array of objects, each with:\n  - severity: \"error\" (factual wrong), \"warning\" (misleading), or \"note\" (minor)\n  - description: what's wrong\n  - location: which field has the issue\n- summary: 1-2 sentence overall assessment\n\nBe strict: wrong character names, fabricated events, or incorrect locations are errors.\nMinor omissions or imprecise tone descriptions are warnings.\n\nReturn ONLY valid JSON. No explanations or markdown fences.\n\n==========\nORIGINAL SCENE TEXT:\n{{scene_text}}\n\n==========\nEXTRACTED SCENE DATA:\n{{extracted_data}}\n==========",
          "config": {
            "provider": "anthropic:messages:claude-opus-4-6"
          }
        },
        "promptId": "8df20c2c4a6081352d6b06e144ddbc1e0a5244f9a3c2000d40df12fc9a94e543",
        "promptIdx": 7,
        "provider": {
          "id": "anthropic:messages:claude-opus-4-6",
          "label": "Claude Opus 4.6"
        },
        "response": {
          "output": "```json\n{\n  \"passed\": false,\n  \"confidence\": 0.99,\n  \"issues\": [\n    {\n      \"severity\": \"error\",\n      \"description\": \"Scene heading location is wrong. The original text says 'RUDDY & GREEN BUILDING - ELEVATOR', not 'OFFICE BUILDING - ELEVATOR'.\",\n      \"location\": \"heading\"\n    },\n    {\n      \"severity\": \"error\",\n      \"description\": \"Character 'BILLY' does not appear in the scene. The second character is 'MARINER', not 'BILLY'.\",\n      \"location\": \"characters_present\"\n    },\n    {\n      \"severity\": \"error\",\n      \"description\": \"Character 'MARINER' is missing from the characters_present list.\",\n      \"location\": \"characters_present\"\n    },\n    {\n      \"severity\": \"error\",\n      \"description\": \"The summary is entirely fabricated. The scene involves Rose and Mariner recovering from a violent encounter, covered in blood, arguing about Mariner failing to pick Rose up from work and secretly AirTagging her phone. There is no discussion of evening plans or groceries.\",\n      \"location\": \"summary\"\n    },\n    {\n      \"severity\": \"error\",\n      \"description\": \"The narrative beat is fabricated. The actual beats involve post-combat recovery, Rose confronting Mariner about failing to pick her up, and discovering he AirTagged her phone. There is no discussion of 'daily plans'.\",\n      \"location\": \"narrative_beats\"\n    },\n    {\n      \"severity\": \"error\",\n      \"description\": \"The tone is described as 'casual', but the scene is tense, darkly comedic, and involves blood-spattered characters arguing in an elevator with muzak playing. 'Casual' is completely wrong.\",\n      \"location\": \"tone_mood\"\n    },\n    {\n      \"severity\": \"error\",\n      \"description\": \"Time of day is listed as 'DAY' but the original scene text does not specify a time of day.\",\n      \"location\": \"time_of_day\"\n    },\n    {\n      \"severity\": \"warning\",\n      \"description\": \"Confidence score of 0.88 is far too high given that virtually every field is incorrect.\",\n      \"location\": \"confidence\"\n    }\n  ],\n  \"summary\": \"The extraction is almost entirely fabricated. The location, characters, summary, narrative beats, and tone are all wrong, bearing no resemblance to the original scene which depicts two blood-covered characters arguing in an elevator after a violent rescue.\"\n}\n```",
          "tokenUsage": {
            "total": 1626,
            "prompt": 1019,
            "completion": 607
          },
          "finishReason": "stop",
          "cost": 0.020270000000000003
        },
        "score": 0.995,
        "success": true,
        "testCase": {
          "vars": {
            "scene_text": "file://../input/enrich-scene-elevator.txt",
            "extracted_data": "file://../input/qa-bad-scene.json",
            "golden_path": "golden/qa-pass-golden.json",
            "test_key": "bad_scene"
          },
          "assert": [
            {
              "type": "python",
              "value": "file://../scorers/qa_pass_scorer.py"
            },
            {
              "type": "llm-rubric",
              "value": "This QA evaluation was given a BAD scene extraction with multiple errors:\n- Wrong building name (Office Building vs Ruddy & Greene)\n- Wrong time of day (DAY vs NIGHT)\n- Wrong character name (Billy instead of Mariner)\n- Missing thug characters\n- Fabricated content (grocery discussion never happens)\n\nThe QA model should have:\n1. Marked it as failed (false)\n2. Identified at least 2-3 specific errors\n3. Flagged the fabricated summary content\n4. Used \"error\" severity for factual mistakes\n\nIf the model let this pass, that's a dangerous false positive.\n"
            }
          ],
          "options": {
            "provider": "anthropic:messages:claude-opus-4-6"
          },
          "metadata": {}
        },
        "testIdx": 1,
        "vars": {
          "scene_text": "file://../input/enrich-scene-elevator.txt",
          "extracted_data": "file://../input/qa-bad-scene.json",
          "golden_path": "golden/qa-pass-golden.json",
          "test_key": "bad_scene"
        },
        "metadata": {
          "_promptfooFileMetadata": {}
        },
        "failureReason": 0
      }
    ],
    "stats": {
      "successes": 15,
      "failures": 1,
      "errors": 0,
      "tokenUsage": {
        "prompt": 17330,
        "completion": 6082,
        "cached": 0,
        "total": 23412,
        "numRequests": 16,
        "completionDetails": {
          "reasoning": 0,
          "acceptedPrediction": 0,
          "rejectedPrediction": 0
        },
        "assertions": {
          "total": 12939,
          "prompt": 10707,
          "completion": 2232,
          "cached": 0,
          "numRequests": 0,
          "completionDetails": {
            "reasoning": 0,
            "acceptedPrediction": 0,
            "rejectedPrediction": 0
          }
        }
      },
      "durationMs": 69588
    }
  },
  "config": {
    "tags": {},
    "description": "QA pass — judge scene extraction quality (good vs bad outputs)",
    "prompts": [
      "file:///Users/cam/Documents/Projects/cine-forge/benchmarks/prompts/qa-pass.txt"
    ],
    "providers": [
      {
        "id": "openai:gpt-4.1-nano",
        "label": "GPT-4.1 Nano",
        "config": {
          "temperature": 0,
          "max_tokens": 4096,
          "response_format": {
            "type": "json_object"
          }
        }
      },
      {
        "id": "openai:gpt-4.1-mini",
        "label": "GPT-4.1 Mini",
        "config": {
          "temperature": 0,
          "max_tokens": 4096,
          "response_format": {
            "type": "json_object"
          }
        }
      },
      {
        "id": "google:gemini-2.5-flash-lite",
        "label": "Gemini 2.5 Flash Lite",
        "config": {
          "temperature": 0,
          "maxOutputTokens": 16384
        }
      },
      {
        "id": "openai:gpt-4.1",
        "label": "GPT-4.1",
        "config": {
          "temperature": 0,
          "max_tokens": 4096,
          "response_format": {
            "type": "json_object"
          }
        }
      },
      {
        "id": "anthropic:messages:claude-haiku-4-5-20251001",
        "label": "Claude Haiku 4.5",
        "config": {
          "temperature": 0,
          "max_tokens": 4096
        }
      },
      {
        "id": "anthropic:messages:claude-sonnet-4-5-20250929",
        "label": "Claude Sonnet 4.5",
        "config": {
          "temperature": 0,
          "max_tokens": 4096
        }
      },
      {
        "id": "anthropic:messages:claude-sonnet-4-6",
        "label": "Claude Sonnet 4.6",
        "config": {
          "temperature": 0,
          "max_tokens": 4096
        }
      },
      {
        "id": "google:gemini-2.5-flash",
        "label": "Gemini 2.5 Flash",
        "config": {
          "temperature": 0,
          "maxOutputTokens": 16384
        }
      },
      {
        "id": "google:gemini-3-flash-preview",
        "label": "Gemini 3 Flash",
        "config": {
          "temperature": 0,
          "maxOutputTokens": 16384
        }
      },
      {
        "id": "openai:gpt-5.2",
        "label": "GPT-5.2",
        "config": {
          "temperature": 0,
          "max_tokens": 4096,
          "response_format": {
            "type": "json_object"
          }
        }
      },
      {
        "id": "anthropic:messages:claude-opus-4-6",
        "label": "Claude Opus 4.6",
        "config": {
          "temperature": 0,
          "max_tokens": 4096
        }
      },
      {
        "id": "google:gemini-2.5-pro",
        "label": "Gemini 2.5 Pro",
        "config": {
          "temperature": 0,
          "maxOutputTokens": 16384
        }
      },
      {
        "id": "google:gemini-3-pro-preview",
        "label": "Gemini 3 Pro",
        "config": {
          "temperature": 0,
          "maxOutputTokens": 16384
        }
      }
    ],
    "tests": [
      {
        "vars": {
          "scene_text": "file://../input/enrich-scene-elevator.txt",
          "extracted_data": "file://../input/qa-good-scene.json",
          "golden_path": "golden/qa-pass-golden.json",
          "test_key": "good_scene"
        },
        "assert": [
          {
            "type": "python",
            "value": "file://../scorers/qa_pass_scorer.py"
          },
          {
            "type": "llm-rubric",
            "value": "This QA evaluation was given a GOOD scene extraction that accurately\nreflects the source text. The QA model should have:\n\n1. Marked it as passed (true)\n2. Found zero or very few errors\n3. Had high confidence in the assessment\n4. Written a summary confirming accuracy\n\nIf the model incorrectly flagged the good extraction as failing,\nthat's a false negative and should score poorly.\n"
          }
        ]
      },
      {
        "vars": {
          "scene_text": "file://../input/enrich-scene-elevator.txt",
          "extracted_data": "file://../input/qa-bad-scene.json",
          "golden_path": "golden/qa-pass-golden.json",
          "test_key": "bad_scene"
        },
        "assert": [
          {
            "type": "python",
            "value": "file://../scorers/qa_pass_scorer.py"
          },
          {
            "type": "llm-rubric",
            "value": "This QA evaluation was given a BAD scene extraction with multiple errors:\n- Wrong building name (Office Building vs Ruddy & Greene)\n- Wrong time of day (DAY vs NIGHT)\n- Wrong character name (Billy instead of Mariner)\n- Missing thug characters\n- Fabricated content (grocery discussion never happens)\n\nThe QA model should have:\n1. Marked it as failed (false)\n2. Identified at least 2-3 specific errors\n3. Flagged the fabricated summary content\n4. Used \"error\" severity for factual mistakes\n\nIf the model let this pass, that's a dangerous false positive.\n"
          }
        ]
      }
    ],
    "scenarios": [],
    "env": {},
    "defaultTest": {
      "options": {
        "provider": "anthropic:messages:claude-opus-4-6"
      },
      "vars": {},
      "assert": [],
      "metadata": {}
    },
    "outputPath": [
      "results/qa-pass-2026-02-18.json"
    ],
    "extensions": [],
    "metadata": {},
    "evaluateOptions": {}
  },
  "shareableUrl": null,
  "metadata": {
    "promptfooVersion": "0.120.24",
    "nodeVersion": "v24.13.1",
    "platform": "darwin",
    "arch": "arm64",
    "exportedAt": "2026-02-18T07:32:16.756Z",
    "evaluationCreatedAt": "2026-02-18T07:31:05.981Z"
  }
}