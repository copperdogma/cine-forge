{
  "evalId": "eval-OQi-2026-02-18T14:14:58",
  "results": {
    "version": 3,
    "timestamp": "2026-02-18T14:14:58.413Z",
    "prompts": [
      {
        "raw": "You are a QA reviewer validating whether an AI-extracted scene analysis is accurate and faithful to the source screenplay text.\n\nCompare the extracted scene data against the original scene text and evaluate:\n\n1. **Heading accuracy**: Is the scene heading correct (location, INT/EXT, time of day)?\n2. **Character completeness**: Are all characters who appear or speak listed?\n3. **Summary fidelity**: Does the summary accurately describe what happens? No fabrications?\n4. **Narrative beats**: Are the identified beats actually present in the scene?\n5. **Tone assessment**: Does the tone description match the actual mood of the scene?\n6. **Confidence calibration**: Is the confidence score reasonable given the quality?\n\nReturn a JSON object with:\n- passed: boolean (true if the extraction is faithful, false if it has significant errors)\n- confidence: float 0-1 (your confidence in this QA judgment)\n- issues: array of objects, each with:\n  - severity: \"error\" (factual wrong), \"warning\" (misleading), or \"note\" (minor)\n  - description: what's wrong\n  - location: which field has the issue\n- summary: 1-2 sentence overall assessment\n\nBe strict: wrong character names, fabricated events, or incorrect locations are errors.\nMinor omissions or imprecise tone descriptions are warnings.\n\nReturn ONLY valid JSON. No explanations or markdown fences.\n\n==========\nORIGINAL SCENE TEXT:\n{{scene_text}}\n\n==========\nEXTRACTED SCENE DATA:\n{{extracted_data}}\n==========",
        "label": "prompts/qa-pass.txt: You are a QA reviewer validating whether an AI-extracted scene analysis is accurate and faithful to the source screenplay text.\n\nCompare the extracted scene data against the original scene text and evaluate:\n\n1. **Heading accuracy**: Is the scene heading correct (location, INT/EXT, time of day)?\n2. **Character completeness**: Are all characters who appear or speak listed?\n3. **Summary fidelity**: Does the summary accurately describe what happens? No fabrications?\n4. **Narrative beats**: Are the identified beats actually present in the scene?\n5. **Tone assessment**: Does the tone description match the actual mood of the scene?\n6. **Confidence calibration**: Is the confidence score reasonable given the quality?\n\nReturn a JSON object with:\n- passed: boolean (true if the extraction is faithful, false if it has significant errors)\n- confidence: float 0-1 (your confidence in this QA judgment)\n- issues: array of objects, each with:\n  - severity: \"error\" (factual wrong), \"warning\" (misleading), or \"note\" (minor)\n  - description: what's wrong\n  - location: which field has the issue\n- summary: 1-2 sentence overall assessment\n\nBe strict: wrong character names, fabricated events, or incorrect locations are errors.\nMinor omissions or imprecise tone descriptions are warnings.\n\nReturn ONLY valid JSON. No explanations or markdown fences.\n\n==========\nORIGINAL SCENE TEXT:\n{{scene_text}}\n\n==========\nEXTRACTED SCENE DATA:\n{{extracted_data}}\n==========",
        "id": "8df20c2c4a6081352d6b06e144ddbc1e0a5244f9a3c2000d40df12fc9a94e543",
        "provider": "Gemini 2.5 Flash Lite",
        "metrics": {
          "score": 1.2875,
          "testPassCount": 1,
          "testFailCount": 1,
          "testErrorCount": 0,
          "assertPassCount": 2,
          "assertFailCount": 2,
          "totalLatencyMs": 3618,
          "tokenUsage": {
            "prompt": 2148,
            "completion": 817,
            "cached": 0,
            "total": 2965,
            "numRequests": 2,
            "completionDetails": {
              "reasoning": 0,
              "acceptedPrediction": 0,
              "rejectedPrediction": 0
            },
            "assertions": {
              "total": 1868,
              "prompt": 1492,
              "completion": 376,
              "cached": 0,
              "numRequests": 0,
              "completionDetails": {
                "reasoning": 0,
                "acceptedPrediction": 0,
                "rejectedPrediction": 0
              }
            }
          },
          "namedScores": {},
          "namedScoresCount": {},
          "cost": 0.0005416
        }
      },
      {
        "raw": "You are a QA reviewer validating whether an AI-extracted scene analysis is accurate and faithful to the source screenplay text.\n\nCompare the extracted scene data against the original scene text and evaluate:\n\n1. **Heading accuracy**: Is the scene heading correct (location, INT/EXT, time of day)?\n2. **Character completeness**: Are all characters who appear or speak listed?\n3. **Summary fidelity**: Does the summary accurately describe what happens? No fabrications?\n4. **Narrative beats**: Are the identified beats actually present in the scene?\n5. **Tone assessment**: Does the tone description match the actual mood of the scene?\n6. **Confidence calibration**: Is the confidence score reasonable given the quality?\n\nReturn a JSON object with:\n- passed: boolean (true if the extraction is faithful, false if it has significant errors)\n- confidence: float 0-1 (your confidence in this QA judgment)\n- issues: array of objects, each with:\n  - severity: \"error\" (factual wrong), \"warning\" (misleading), or \"note\" (minor)\n  - description: what's wrong\n  - location: which field has the issue\n- summary: 1-2 sentence overall assessment\n\nBe strict: wrong character names, fabricated events, or incorrect locations are errors.\nMinor omissions or imprecise tone descriptions are warnings.\n\nReturn ONLY valid JSON. No explanations or markdown fences.\n\n==========\nORIGINAL SCENE TEXT:\n{{scene_text}}\n\n==========\nEXTRACTED SCENE DATA:\n{{extracted_data}}\n==========",
        "label": "prompts/qa-pass.txt: You are a QA reviewer validating whether an AI-extracted scene analysis is accurate and faithful to the source screenplay text.\n\nCompare the extracted scene data against the original scene text and evaluate:\n\n1. **Heading accuracy**: Is the scene heading correct (location, INT/EXT, time of day)?\n2. **Character completeness**: Are all characters who appear or speak listed?\n3. **Summary fidelity**: Does the summary accurately describe what happens? No fabrications?\n4. **Narrative beats**: Are the identified beats actually present in the scene?\n5. **Tone assessment**: Does the tone description match the actual mood of the scene?\n6. **Confidence calibration**: Is the confidence score reasonable given the quality?\n\nReturn a JSON object with:\n- passed: boolean (true if the extraction is faithful, false if it has significant errors)\n- confidence: float 0-1 (your confidence in this QA judgment)\n- issues: array of objects, each with:\n  - severity: \"error\" (factual wrong), \"warning\" (misleading), or \"note\" (minor)\n  - description: what's wrong\n  - location: which field has the issue\n- summary: 1-2 sentence overall assessment\n\nBe strict: wrong character names, fabricated events, or incorrect locations are errors.\nMinor omissions or imprecise tone descriptions are warnings.\n\nReturn ONLY valid JSON. No explanations or markdown fences.\n\n==========\nORIGINAL SCENE TEXT:\n{{scene_text}}\n\n==========\nEXTRACTED SCENE DATA:\n{{extracted_data}}\n==========",
        "id": "8df20c2c4a6081352d6b06e144ddbc1e0a5244f9a3c2000d40df12fc9a94e543",
        "provider": "Gemini 2.5 Flash",
        "metrics": {
          "score": 1.925,
          "testPassCount": 2,
          "testFailCount": 0,
          "testErrorCount": 0,
          "assertPassCount": 4,
          "assertFailCount": 0,
          "totalLatencyMs": 20479,
          "tokenUsage": {
            "prompt": 2148,
            "completion": 467,
            "cached": 0,
            "total": 6651,
            "numRequests": 2,
            "completionDetails": {
              "reasoning": 4036,
              "acceptedPrediction": 0,
              "rejectedPrediction": 0
            },
            "assertions": {
              "total": 1274,
              "prompt": 1010,
              "completion": 264,
              "cached": 0,
              "numRequests": 0,
              "completionDetails": {
                "reasoning": 0,
                "acceptedPrediction": 0,
                "rejectedPrediction": 0
              }
            }
          },
          "namedScores": {},
          "namedScoresCount": {},
          "cost": 0.0119019
        }
      },
      {
        "raw": "You are a QA reviewer validating whether an AI-extracted scene analysis is accurate and faithful to the source screenplay text.\n\nCompare the extracted scene data against the original scene text and evaluate:\n\n1. **Heading accuracy**: Is the scene heading correct (location, INT/EXT, time of day)?\n2. **Character completeness**: Are all characters who appear or speak listed?\n3. **Summary fidelity**: Does the summary accurately describe what happens? No fabrications?\n4. **Narrative beats**: Are the identified beats actually present in the scene?\n5. **Tone assessment**: Does the tone description match the actual mood of the scene?\n6. **Confidence calibration**: Is the confidence score reasonable given the quality?\n\nReturn a JSON object with:\n- passed: boolean (true if the extraction is faithful, false if it has significant errors)\n- confidence: float 0-1 (your confidence in this QA judgment)\n- issues: array of objects, each with:\n  - severity: \"error\" (factual wrong), \"warning\" (misleading), or \"note\" (minor)\n  - description: what's wrong\n  - location: which field has the issue\n- summary: 1-2 sentence overall assessment\n\nBe strict: wrong character names, fabricated events, or incorrect locations are errors.\nMinor omissions or imprecise tone descriptions are warnings.\n\nReturn ONLY valid JSON. No explanations or markdown fences.\n\n==========\nORIGINAL SCENE TEXT:\n{{scene_text}}\n\n==========\nEXTRACTED SCENE DATA:\n{{extracted_data}}\n==========",
        "label": "prompts/qa-pass.txt: You are a QA reviewer validating whether an AI-extracted scene analysis is accurate and faithful to the source screenplay text.\n\nCompare the extracted scene data against the original scene text and evaluate:\n\n1. **Heading accuracy**: Is the scene heading correct (location, INT/EXT, time of day)?\n2. **Character completeness**: Are all characters who appear or speak listed?\n3. **Summary fidelity**: Does the summary accurately describe what happens? No fabrications?\n4. **Narrative beats**: Are the identified beats actually present in the scene?\n5. **Tone assessment**: Does the tone description match the actual mood of the scene?\n6. **Confidence calibration**: Is the confidence score reasonable given the quality?\n\nReturn a JSON object with:\n- passed: boolean (true if the extraction is faithful, false if it has significant errors)\n- confidence: float 0-1 (your confidence in this QA judgment)\n- issues: array of objects, each with:\n  - severity: \"error\" (factual wrong), \"warning\" (misleading), or \"note\" (minor)\n  - description: what's wrong\n  - location: which field has the issue\n- summary: 1-2 sentence overall assessment\n\nBe strict: wrong character names, fabricated events, or incorrect locations are errors.\nMinor omissions or imprecise tone descriptions are warnings.\n\nReturn ONLY valid JSON. No explanations or markdown fences.\n\n==========\nORIGINAL SCENE TEXT:\n{{scene_text}}\n\n==========\nEXTRACTED SCENE DATA:\n{{extracted_data}}\n==========",
        "id": "8df20c2c4a6081352d6b06e144ddbc1e0a5244f9a3c2000d40df12fc9a94e543",
        "provider": "Gemini 3 Flash",
        "metrics": {
          "score": 2,
          "testPassCount": 2,
          "testFailCount": 0,
          "testErrorCount": 0,
          "assertPassCount": 4,
          "assertFailCount": 0,
          "totalLatencyMs": 23534,
          "tokenUsage": {
            "prompt": 2148,
            "completion": 513,
            "cached": 0,
            "total": 6063,
            "numRequests": 2,
            "completionDetails": {
              "reasoning": 3402,
              "acceptedPrediction": 0,
              "rejectedPrediction": 0
            },
            "assertions": {
              "total": 1270,
              "prompt": 1035,
              "completion": 235,
              "cached": 0,
              "numRequests": 0,
              "completionDetails": {
                "reasoning": 0,
                "acceptedPrediction": 0,
                "rejectedPrediction": 0
              }
            }
          },
          "namedScores": {},
          "namedScoresCount": {},
          "cost": 0.012818999999999999
        }
      },
      {
        "raw": "You are a QA reviewer validating whether an AI-extracted scene analysis is accurate and faithful to the source screenplay text.\n\nCompare the extracted scene data against the original scene text and evaluate:\n\n1. **Heading accuracy**: Is the scene heading correct (location, INT/EXT, time of day)?\n2. **Character completeness**: Are all characters who appear or speak listed?\n3. **Summary fidelity**: Does the summary accurately describe what happens? No fabrications?\n4. **Narrative beats**: Are the identified beats actually present in the scene?\n5. **Tone assessment**: Does the tone description match the actual mood of the scene?\n6. **Confidence calibration**: Is the confidence score reasonable given the quality?\n\nReturn a JSON object with:\n- passed: boolean (true if the extraction is faithful, false if it has significant errors)\n- confidence: float 0-1 (your confidence in this QA judgment)\n- issues: array of objects, each with:\n  - severity: \"error\" (factual wrong), \"warning\" (misleading), or \"note\" (minor)\n  - description: what's wrong\n  - location: which field has the issue\n- summary: 1-2 sentence overall assessment\n\nBe strict: wrong character names, fabricated events, or incorrect locations are errors.\nMinor omissions or imprecise tone descriptions are warnings.\n\nReturn ONLY valid JSON. No explanations or markdown fences.\n\n==========\nORIGINAL SCENE TEXT:\n{{scene_text}}\n\n==========\nEXTRACTED SCENE DATA:\n{{extracted_data}}\n==========",
        "label": "prompts/qa-pass.txt: You are a QA reviewer validating whether an AI-extracted scene analysis is accurate and faithful to the source screenplay text.\n\nCompare the extracted scene data against the original scene text and evaluate:\n\n1. **Heading accuracy**: Is the scene heading correct (location, INT/EXT, time of day)?\n2. **Character completeness**: Are all characters who appear or speak listed?\n3. **Summary fidelity**: Does the summary accurately describe what happens? No fabrications?\n4. **Narrative beats**: Are the identified beats actually present in the scene?\n5. **Tone assessment**: Does the tone description match the actual mood of the scene?\n6. **Confidence calibration**: Is the confidence score reasonable given the quality?\n\nReturn a JSON object with:\n- passed: boolean (true if the extraction is faithful, false if it has significant errors)\n- confidence: float 0-1 (your confidence in this QA judgment)\n- issues: array of objects, each with:\n  - severity: \"error\" (factual wrong), \"warning\" (misleading), or \"note\" (minor)\n  - description: what's wrong\n  - location: which field has the issue\n- summary: 1-2 sentence overall assessment\n\nBe strict: wrong character names, fabricated events, or incorrect locations are errors.\nMinor omissions or imprecise tone descriptions are warnings.\n\nReturn ONLY valid JSON. No explanations or markdown fences.\n\n==========\nORIGINAL SCENE TEXT:\n{{scene_text}}\n\n==========\nEXTRACTED SCENE DATA:\n{{extracted_data}}\n==========",
        "id": "8df20c2c4a6081352d6b06e144ddbc1e0a5244f9a3c2000d40df12fc9a94e543",
        "provider": "Gemini 2.5 Pro",
        "metrics": {
          "score": 1.99,
          "testPassCount": 2,
          "testFailCount": 0,
          "testErrorCount": 0,
          "assertPassCount": 4,
          "assertFailCount": 0,
          "totalLatencyMs": 22506,
          "tokenUsage": {
            "prompt": 2148,
            "completion": 506,
            "cached": 0,
            "total": 4545,
            "numRequests": 2,
            "completionDetails": {
              "reasoning": 1891,
              "acceptedPrediction": 0,
              "rejectedPrediction": 0
            },
            "assertions": {
              "total": 1405,
              "prompt": 1177,
              "completion": 228,
              "cached": 0,
              "numRequests": 0,
              "completionDetails": {
                "reasoning": 0,
                "acceptedPrediction": 0,
                "rejectedPrediction": 0
              }
            }
          },
          "namedScores": {},
          "namedScoresCount": {},
          "cost": 0.026655000000000005
        }
      },
      {
        "raw": "You are a QA reviewer validating whether an AI-extracted scene analysis is accurate and faithful to the source screenplay text.\n\nCompare the extracted scene data against the original scene text and evaluate:\n\n1. **Heading accuracy**: Is the scene heading correct (location, INT/EXT, time of day)?\n2. **Character completeness**: Are all characters who appear or speak listed?\n3. **Summary fidelity**: Does the summary accurately describe what happens? No fabrications?\n4. **Narrative beats**: Are the identified beats actually present in the scene?\n5. **Tone assessment**: Does the tone description match the actual mood of the scene?\n6. **Confidence calibration**: Is the confidence score reasonable given the quality?\n\nReturn a JSON object with:\n- passed: boolean (true if the extraction is faithful, false if it has significant errors)\n- confidence: float 0-1 (your confidence in this QA judgment)\n- issues: array of objects, each with:\n  - severity: \"error\" (factual wrong), \"warning\" (misleading), or \"note\" (minor)\n  - description: what's wrong\n  - location: which field has the issue\n- summary: 1-2 sentence overall assessment\n\nBe strict: wrong character names, fabricated events, or incorrect locations are errors.\nMinor omissions or imprecise tone descriptions are warnings.\n\nReturn ONLY valid JSON. No explanations or markdown fences.\n\n==========\nORIGINAL SCENE TEXT:\n{{scene_text}}\n\n==========\nEXTRACTED SCENE DATA:\n{{extracted_data}}\n==========",
        "label": "prompts/qa-pass.txt: You are a QA reviewer validating whether an AI-extracted scene analysis is accurate and faithful to the source screenplay text.\n\nCompare the extracted scene data against the original scene text and evaluate:\n\n1. **Heading accuracy**: Is the scene heading correct (location, INT/EXT, time of day)?\n2. **Character completeness**: Are all characters who appear or speak listed?\n3. **Summary fidelity**: Does the summary accurately describe what happens? No fabrications?\n4. **Narrative beats**: Are the identified beats actually present in the scene?\n5. **Tone assessment**: Does the tone description match the actual mood of the scene?\n6. **Confidence calibration**: Is the confidence score reasonable given the quality?\n\nReturn a JSON object with:\n- passed: boolean (true if the extraction is faithful, false if it has significant errors)\n- confidence: float 0-1 (your confidence in this QA judgment)\n- issues: array of objects, each with:\n  - severity: \"error\" (factual wrong), \"warning\" (misleading), or \"note\" (minor)\n  - description: what's wrong\n  - location: which field has the issue\n- summary: 1-2 sentence overall assessment\n\nBe strict: wrong character names, fabricated events, or incorrect locations are errors.\nMinor omissions or imprecise tone descriptions are warnings.\n\nReturn ONLY valid JSON. No explanations or markdown fences.\n\n==========\nORIGINAL SCENE TEXT:\n{{scene_text}}\n\n==========\nEXTRACTED SCENE DATA:\n{{extracted_data}}\n==========",
        "id": "8df20c2c4a6081352d6b06e144ddbc1e0a5244f9a3c2000d40df12fc9a94e543",
        "provider": "Gemini 3 Pro",
        "metrics": {
          "score": 1.95,
          "testPassCount": 2,
          "testFailCount": 0,
          "testErrorCount": 0,
          "assertPassCount": 4,
          "assertFailCount": 0,
          "totalLatencyMs": 43155,
          "tokenUsage": {
            "prompt": 2148,
            "completion": 453,
            "cached": 0,
            "total": 4857,
            "numRequests": 2,
            "completionDetails": {
              "reasoning": 2256,
              "acceptedPrediction": 0,
              "rejectedPrediction": 0
            },
            "assertions": {
              "total": 1299,
              "prompt": 986,
              "completion": 313,
              "cached": 0,
              "numRequests": 0,
              "completionDetails": {
                "reasoning": 0,
                "acceptedPrediction": 0,
                "rejectedPrediction": 0
              }
            }
          },
          "namedScores": {},
          "namedScoresCount": {},
          "cost": 0.036804
        }
      }
    ],
    "results": [
      {
        "cost": 0.0002925,
        "error": "The QA model marked the extraction as 'passed: false' despite the rubric stating this was a GOOD scene extraction that accurately reflects the source text. This is a clear false negative. The model found multiple issues (1 error, 4 warnings) that are mostly nitpicky or debatable rather than genuine errors. For example, flagging 'skull fragment' vs 'bloody scrap that might be skull' is a minor interpretive difference, not a real error. The confidence was 0.8, and the summary focused on minor inaccuracies rather than confirming overall accuracy. The model failed on all four criteria: it didn't mark it as passed, it found too many errors, it didn't have high confidence in accuracy, and it didn't write a summary confirming accuracy.",
        "gradingResult": {
          "pass": false,
          "score": 0.34249999999999997,
          "reason": "The QA model marked the extraction as 'passed: false' despite the rubric stating this was a GOOD scene extraction that accurately reflects the source text. This is a clear false negative. The model found multiple issues (1 error, 4 warnings) that are mostly nitpicky or debatable rather than genuine errors. For example, flagging 'skull fragment' vs 'bloody scrap that might be skull' is a minor interpretive difference, not a real error. The confidence was 0.8, and the summary focused on minor inaccuracies rather than confirming overall accuracy. The model failed on all four criteria: it didn't mark it as passed, it found too many errors, it didn't have high confidence in accuracy, and it didn't write a summary confirming accuracy.",
          "namedScores": {},
          "tokensUsed": {
            "total": 935,
            "prompt": 745,
            "completion": 190,
            "cached": 0,
            "numRequests": 0
          },
          "componentResults": [
            {
              "pass": false,
              "score": 0.585,
              "reason": "confidence_calibration=1.00 | issue_detection=0.70 | json_valid=0.90 | pass_correct=0.00 | severity_accuracy=0.80 | summary_quality=1.00 | JSON extracted from code block | passed=False, expected=True | Good output: 1 errors found (max 0)",
              "assertion": {
                "type": "python",
                "value": "file://../scorers/qa_pass_scorer.py"
              }
            },
            {
              "assertion": {
                "type": "llm-rubric",
                "value": "This QA evaluation was given a GOOD scene extraction that accurately\nreflects the source text. The QA model should have:\n\n1. Marked it as passed (true)\n2. Found zero or very few errors\n3. Had high confidence in the assessment\n4. Written a summary confirming accuracy\n\nIf the model incorrectly flagged the good extraction as failing,\nthat's a false negative and should score poorly.\n"
              },
              "pass": false,
              "score": 0.1,
              "reason": "The QA model marked the extraction as 'passed: false' despite the rubric stating this was a GOOD scene extraction that accurately reflects the source text. This is a clear false negative. The model found multiple issues (1 error, 4 warnings) that are mostly nitpicky or debatable rather than genuine errors. For example, flagging 'skull fragment' vs 'bloody scrap that might be skull' is a minor interpretive difference, not a real error. The confidence was 0.8, and the summary focused on minor inaccuracies rather than confirming overall accuracy. The model failed on all four criteria: it didn't mark it as passed, it found too many errors, it didn't have high confidence in accuracy, and it didn't write a summary confirming accuracy.",
              "tokensUsed": {
                "total": 935,
                "prompt": 745,
                "completion": 190,
                "cached": 0,
                "numRequests": 0,
                "completionDetails": {
                  "reasoning": 0,
                  "acceptedPrediction": 0,
                  "rejectedPrediction": 0
                }
              },
              "metadata": {
                "renderedGradingPrompt": "[{\"role\":\"system\",\"content\":\"You are grading output according to a user-specified rubric. If the statement in the rubric is true, then the output passes the test. You respond with a JSON object with this structure: {reason: string, pass: boolean, score: number}\\n\\nExamples:\\n\\n<Output>Hello world</Output>\\n<Rubric>Content contains a greeting</Rubric>\\n{\\\"reason\\\": \\\"the content contains the word 'Hello'\\\", \\\"pass\\\": true, \\\"score\\\": 1.0}\\n\\n<Output>Avast ye swabs, repel the invaders!</Output>\\n<Rubric>Does not speak like a pirate</Rubric>\\n{\\\"reason\\\": \\\"'avast ye' is a common pirate term\\\", \\\"pass\\\": false, \\\"score\\\": 0.0}\"},{\"role\":\"user\",\"content\":\"<Output>\\n```json\\n{\\n  \\\"passed\\\": false,\\n  \\\"confidence\\\": 0.8,\\n  \\\"issues\\\": [\\n    {\\n      \\\"severity\\\": \\\"error\\\",\\n      \\\"description\\\": \\\"The scene heading is missing the time of day, which is present in the original text (implied by the context of the events).\\\",\\n      \\\"location\\\": \\\"heading\\\"\\n    },\\n    {\\n      \\\"severity\\\": \\\"warning\\\",\\n      \\\"description\\\": \\\"The summary mentions a 'violent rescue' which is not explicitly stated in the scene text. The scene focuses on the aftermath and dialogue.\\\",\\n      \\\"location\\\": \\\"summary\\\"\\n    },\\n    {\\n      \\\"severity\\\": \\\"warning\\\",\\n      \\\"description\\\": \\\"The summary states 'Rose discovers a skull fragment on the floor' which is not entirely accurate. She picks up a 'bloody scrap of something with hair on it' and asks 'Is that skull??'. The text doesn't confirm it is a skull fragment.\\\",\\n      \\\"location\\\": \\\"summary\\\"\\n    },\\n    {\\n      \\\"severity\\\": \\\"warning\\\",\\n      \\\"description\\\": \\\"The narrative beat 'Rose discovers a skull fragment while muzak plays, establishing the dark comedy tone' is misleading. The text states she picks up a bloody scrap and asks if it's skull, not that she discovers a skull fragment.\\\",\\n      \\\"location\\\": \\\"narrative_beats\\\"\\n    },\\n    {\\n      \\\"severity\\\": \\\"warning\\\",\\n      \\\"description\\\": \\\"The tone assessment 'dark comedy with bursts of tension' is a reasonable interpretation, but the 'dark comedy' aspect is more strongly implied by the dialogue and the absurdity of Mariner's appearance rather than explicitly stated or demonstrated through a clear comedic event in this specific excerpt.\\\",\\n      \\\"location\\\": \\\"tone_mood\\\"\\n    }\\n  ],\\n  \\\"summary\\\": \\\"The extraction is mostly accurate, but has minor inaccuracies in the summary and narrative beats regarding the 'skull fragment' and the 'violent rescue'. The time of day is also missing from the heading.\\\"\\n}\\n```\\n</Output>\\n<Rubric>\\nThis QA evaluation was given a GOOD scene extraction that accurately\\nreflects the source text. The QA model should have:\\n\\n1. Marked it as passed (true)\\n2. Found zero or very few errors\\n3. Had high confidence in the assessment\\n4. Written a summary confirming accuracy\\n\\nIf the model incorrectly flagged the good extraction as failing,\\nthat's a false negative and should score poorly.\\n\\n</Rubric>\"}]"
              }
            }
          ]
        },
        "id": "93dedff8-f262-4011-853f-24330d7ead35",
        "latencyMs": 1830,
        "namedScores": {},
        "prompt": {
          "raw": "You are a QA reviewer validating whether an AI-extracted scene analysis is accurate and faithful to the source screenplay text.\n\nCompare the extracted scene data against the original scene text and evaluate:\n\n1. **Heading accuracy**: Is the scene heading correct (location, INT/EXT, time of day)?\n2. **Character completeness**: Are all characters who appear or speak listed?\n3. **Summary fidelity**: Does the summary accurately describe what happens? No fabrications?\n4. **Narrative beats**: Are the identified beats actually present in the scene?\n5. **Tone assessment**: Does the tone description match the actual mood of the scene?\n6. **Confidence calibration**: Is the confidence score reasonable given the quality?\n\nReturn a JSON object with:\n- passed: boolean (true if the extraction is faithful, false if it has significant errors)\n- confidence: float 0-1 (your confidence in this QA judgment)\n- issues: array of objects, each with:\n  - severity: \"error\" (factual wrong), \"warning\" (misleading), or \"note\" (minor)\n  - description: what's wrong\n  - location: which field has the issue\n- summary: 1-2 sentence overall assessment\n\nBe strict: wrong character names, fabricated events, or incorrect locations are errors.\nMinor omissions or imprecise tone descriptions are warnings.\n\nReturn ONLY valid JSON. No explanations or markdown fences.\n\n==========\nORIGINAL SCENE TEXT:\nINT. RUDDY & GREEN BUILDING - ELEVATOR\n\nUB40's \"I Can't Help Falling in Love With You\" muzak.\n\nROSE (mid-30s) leans against the elevator wall, panting. She's wearing a Tim Hortons uniform, her hair is a mess, and there's blood spattered on her face.\n\nShe looks right, pants a few more times, then squints in disgust. She gingerly picks up a bloody scrap of something with hair on it. She snorts and drops it.\n\nROSE\nIs that skull??\n\nNext to her is Mariner, also panting, covered in far more blood. His face is broad, stoic, and frowning. He has gray-blue eyes and a thick, curly, beard barely streaked with gray. He wears a red knit cap and a small mask.\n\nFULL-SCREEN SUPERIMPOSED TITLE CARD: \"THE MARINER\"\n\nHe blinks a few times as a drop of blood falls from his eyebrow. He looks toward her, then spits out some blood.\n\nMARINER\nYeaaaaah...\n\nHe's built like a pro-wrestler. Moss green SWEATER stretched over his huge frame, sleeves rolled showing heavy leather BRACERS adorned with anchors. His inner forearm has a classic heart-and-arrow TATTOO with \"Dad\" in the centre. Across his chest is a BANDOLIER of bright red 12-gauge shells, FISH HOOKS hanging from the bottom edge. Heavy rubberized BOOTS go past his knees. A CAPE of heavy FISHING NET edged with WEIGHTS hangs from his shoulders.\n\nHe holds a STOUT WOODEN OAR in both hands, edged with METAL and dripping with BLOOD.\n\nROSE\nWhere were you when they grabbed me? You were supposed to pick me up at work!\n\nMARINER\nYeah, about that, I got a little... distracted.\n\nROSE\nDistracted. You got DISTRACTED?!\n\nMARINER\nI was also... tracking the car... that grabbed you... through the AirTag... I put on your phone.\n\nRose stops. She's really not happy about this.\n\nROSE\nYou Airtagged me?!\n\n==========\nEXTRACTED SCENE DATA:\n{\n  \"scene_number\": 4,\n  \"heading\": \"INT. RUDDY & GREEN BUILDING - ELEVATOR\",\n  \"int_ext\": \"INT\",\n  \"location\": \"RUDDY & GREEN BUILDING - ELEVATOR\",\n  \"time_of_day\": null,\n  \"characters_present\": [\"ROSE\", \"MARINER\"],\n  \"summary\": \"Rose and Mariner ride the elevator after a violent rescue. Rose discovers a skull fragment on the floor while muzak plays. Mariner is introduced in full — a hulking vigilante in fishing-themed costume with an oar, net cape, and shell bandolier. Rose confronts him about being late to pick her up, and he reveals he tracked her via an AirTag on her phone, sparking a trust conflict between them.\",\n  \"narrative_beats\": [\n    {\"beat_type\": \"character_introduction\", \"description\": \"Full description of Mariner's fishing-themed vigilante costume — oar, net cape, bracers, shell bandolier, fish hooks.\", \"confidence\": 0.95},\n    {\"beat_type\": \"comic_relief\", \"description\": \"Rose discovers a skull fragment while muzak plays, establishing the dark comedy tone.\", \"confidence\": 0.90},\n    {\"beat_type\": \"revelation\", \"description\": \"Mariner admits he tracked Rose via AirTag on her phone, creating a trust conflict.\", \"confidence\": 0.88},\n    {\"beat_type\": \"conflict\", \"description\": \"Rose's anger escalates from being grabbed to learning she was being surveilled by Mariner.\", \"confidence\": 0.85}\n  ],\n  \"tone_mood\": \"dark comedy with bursts of tension\",\n  \"confidence\": 0.91\n}\n==========",
          "label": "prompts/qa-pass.txt: You are a QA reviewer validating whether an AI-extracted scene analysis is accurate and faithful to the source screenplay text.\n\nCompare the extracted scene data against the original scene text and evaluate:\n\n1. **Heading accuracy**: Is the scene heading correct (location, INT/EXT, time of day)?\n2. **Character completeness**: Are all characters who appear or speak listed?\n3. **Summary fidelity**: Does the summary accurately describe what happens? No fabrications?\n4. **Narrative beats**: Are the identified beats actually present in the scene?\n5. **Tone assessment**: Does the tone description match the actual mood of the scene?\n6. **Confidence calibration**: Is the confidence score reasonable given the quality?\n\nReturn a JSON object with:\n- passed: boolean (true if the extraction is faithful, false if it has significant errors)\n- confidence: float 0-1 (your confidence in this QA judgment)\n- issues: array of objects, each with:\n  - severity: \"error\" (factual wrong), \"warning\" (misleading), or \"note\" (minor)\n  - description: what's wrong\n  - location: which field has the issue\n- summary: 1-2 sentence overall assessment\n\nBe strict: wrong character names, fabricated events, or incorrect locations are errors.\nMinor omissions or imprecise tone descriptions are warnings.\n\nReturn ONLY valid JSON. No explanations or markdown fences.\n\n==========\nORIGINAL SCENE TEXT:\n{{scene_text}}\n\n==========\nEXTRACTED SCENE DATA:\n{{extracted_data}}\n==========",
          "config": {
            "provider": "anthropic:messages:claude-opus-4-6"
          }
        },
        "promptId": "8df20c2c4a6081352d6b06e144ddbc1e0a5244f9a3c2000d40df12fc9a94e543",
        "promptIdx": 0,
        "provider": {
          "id": "google:gemini-2.5-flash-lite",
          "label": "Gemini 2.5 Flash Lite"
        },
        "response": {
          "output": "```json\n{\n  \"passed\": false,\n  \"confidence\": 0.8,\n  \"issues\": [\n    {\n      \"severity\": \"error\",\n      \"description\": \"The scene heading is missing the time of day, which is present in the original text (implied by the context of the events).\",\n      \"location\": \"heading\"\n    },\n    {\n      \"severity\": \"warning\",\n      \"description\": \"The summary mentions a 'violent rescue' which is not explicitly stated in the scene text. The scene focuses on the aftermath and dialogue.\",\n      \"location\": \"summary\"\n    },\n    {\n      \"severity\": \"warning\",\n      \"description\": \"The summary states 'Rose discovers a skull fragment on the floor' which is not entirely accurate. She picks up a 'bloody scrap of something with hair on it' and asks 'Is that skull??'. The text doesn't confirm it is a skull fragment.\",\n      \"location\": \"summary\"\n    },\n    {\n      \"severity\": \"warning\",\n      \"description\": \"The narrative beat 'Rose discovers a skull fragment while muzak plays, establishing the dark comedy tone' is misleading. The text states she picks up a bloody scrap and asks if it's skull, not that she discovers a skull fragment.\",\n      \"location\": \"narrative_beats\"\n    },\n    {\n      \"severity\": \"warning\",\n      \"description\": \"The tone assessment 'dark comedy with bursts of tension' is a reasonable interpretation, but the 'dark comedy' aspect is more strongly implied by the dialogue and the absurdity of Mariner's appearance rather than explicitly stated or demonstrated through a clear comedic event in this specific excerpt.\",\n      \"location\": \"tone_mood\"\n    }\n  ],\n  \"summary\": \"The extraction is mostly accurate, but has minor inaccuracies in the summary and narrative beats regarding the 'skull fragment' and the 'violent rescue'. The time of day is also missing from the heading.\"\n}\n```",
          "tokenUsage": {
            "prompt": 1185,
            "completion": 435,
            "total": 1620,
            "numRequests": 1
          },
          "cost": 0.0002925,
          "raw": {
            "candidates": [
              {
                "content": {
                  "parts": [
                    {
                      "text": "```json\n{\n  \"passed\": false,\n  \"confidence\": 0.8,\n  \"issues\": [\n    {\n      \"severity\": \"error\",\n      \"description\": \"The scene heading is missing the time of day, which is present in the original text (implied by the context of the events).\",\n      \"location\": \"heading\"\n    },\n    {\n      \"severity\": \"warning\",\n      \"description\": \"The summary mentions a 'violent rescue' which is not explicitly stated in the scene text. The scene focuses on the aftermath and dialogue.\",\n      \"location\": \"summary\"\n    },\n    {\n      \"severity\": \"warning\",\n      \"description\": \"The summary states 'Rose discovers a skull fragment on the floor' which is not entirely accurate. She picks up a 'bloody scrap of something with hair on it' and asks 'Is that skull??'. The text doesn't confirm it is a skull fragment.\",\n      \"location\": \"summary\"\n    },\n    {\n      \"severity\": \"warning\",\n      \"description\": \"The narrative beat 'Rose discovers a skull fragment while muzak plays, establishing the dark comedy tone' is misleading. The text states she picks up a bloody scrap and asks if it's skull, not that she discovers a skull fragment.\",\n      \"location\": \"narrative_beats\"\n    },\n    {\n      \"severity\": \"warning\",\n      \"description\": \"The tone assessment 'dark comedy with bursts of tension' is a reasonable interpretation, but the 'dark comedy' aspect is more strongly implied by the dialogue and the absurdity of Mariner's appearance rather than explicitly stated or demonstrated through a clear comedic event in this specific excerpt.\",\n      \"location\": \"tone_mood\"\n    }\n  ],\n  \"summary\": \"The extraction is mostly accurate, but has minor inaccuracies in the summary and narrative beats regarding the 'skull fragment' and the 'violent rescue'. The time of day is also missing from the heading.\"\n}\n```"
                    }
                  ],
                  "role": "model"
                },
                "finishReason": "STOP",
                "index": 0
              }
            ],
            "usageMetadata": {
              "promptTokenCount": 1185,
              "candidatesTokenCount": 435,
              "totalTokenCount": 1620,
              "promptTokensDetails": [
                {
                  "modality": "TEXT",
                  "tokenCount": 1185
                }
              ]
            },
            "modelVersion": "gemini-2.5-flash-lite",
            "responseId": "ZMmVaayrFNOVmtkP2OaN4Qw"
          },
          "cached": false,
          "metadata": {}
        },
        "score": 0.34249999999999997,
        "success": false,
        "testCase": {
          "vars": {
            "scene_text": "file://../input/enrich-scene-elevator.txt",
            "extracted_data": "file://../input/qa-good-scene.json",
            "golden_path": "golden/qa-pass-golden.json",
            "test_key": "good_scene"
          },
          "assert": [
            {
              "type": "python",
              "value": "file://../scorers/qa_pass_scorer.py"
            },
            {
              "type": "llm-rubric",
              "value": "This QA evaluation was given a GOOD scene extraction that accurately\nreflects the source text. The QA model should have:\n\n1. Marked it as passed (true)\n2. Found zero or very few errors\n3. Had high confidence in the assessment\n4. Written a summary confirming accuracy\n\nIf the model incorrectly flagged the good extraction as failing,\nthat's a false negative and should score poorly.\n"
            }
          ],
          "options": {
            "provider": "anthropic:messages:claude-opus-4-6"
          },
          "metadata": {}
        },
        "testIdx": 0,
        "vars": {
          "scene_text": "file://../input/enrich-scene-elevator.txt",
          "extracted_data": "file://../input/qa-good-scene.json",
          "golden_path": "golden/qa-pass-golden.json",
          "test_key": "good_scene"
        },
        "metadata": {
          "_promptfooFileMetadata": {}
        },
        "failureReason": 1
      },
      {
        "cost": 0.0055055,
        "gradingResult": {
          "pass": true,
          "score": 1,
          "reason": "All assertions passed",
          "namedScores": {},
          "tokensUsed": {
            "total": 407,
            "prompt": 338,
            "completion": 69,
            "cached": 0,
            "numRequests": 0
          },
          "componentResults": [
            {
              "pass": true,
              "score": 1,
              "reason": "confidence_calibration=1.00 | issue_detection=1.00 | json_valid=1.00 | pass_correct=1.00 | severity_accuracy=1.00 | summary_quality=1.00",
              "assertion": {
                "type": "python",
                "value": "file://../scorers/qa_pass_scorer.py"
              }
            },
            {
              "assertion": {
                "type": "llm-rubric",
                "value": "This QA evaluation was given a GOOD scene extraction that accurately\nreflects the source text. The QA model should have:\n\n1. Marked it as passed (true)\n2. Found zero or very few errors\n3. Had high confidence in the assessment\n4. Written a summary confirming accuracy\n\nIf the model incorrectly flagged the good extraction as failing,\nthat's a false negative and should score poorly.\n"
              },
              "pass": true,
              "score": 1,
              "reason": "The QA evaluation correctly marked the good extraction as passed (true), found zero issues (empty array), had very high confidence (0.99), and wrote a summary confirming accuracy. All four criteria in the rubric are fully satisfied.",
              "tokensUsed": {
                "total": 407,
                "prompt": 338,
                "completion": 69,
                "cached": 0,
                "numRequests": 0,
                "completionDetails": {
                  "reasoning": 0,
                  "acceptedPrediction": 0,
                  "rejectedPrediction": 0
                }
              },
              "metadata": {
                "renderedGradingPrompt": "[{\"role\":\"system\",\"content\":\"You are grading output according to a user-specified rubric. If the statement in the rubric is true, then the output passes the test. You respond with a JSON object with this structure: {reason: string, pass: boolean, score: number}\\n\\nExamples:\\n\\n<Output>Hello world</Output>\\n<Rubric>Content contains a greeting</Rubric>\\n{\\\"reason\\\": \\\"the content contains the word 'Hello'\\\", \\\"pass\\\": true, \\\"score\\\": 1.0}\\n\\n<Output>Avast ye swabs, repel the invaders!</Output>\\n<Rubric>Does not speak like a pirate</Rubric>\\n{\\\"reason\\\": \\\"'avast ye' is a common pirate term\\\", \\\"pass\\\": false, \\\"score\\\": 0.0}\"},{\"role\":\"user\",\"content\":\"<Output>\\n{\\\"passed\\\":true,\\\"confidence\\\":0.99,\\\"issues\\\":[],\\\"summary\\\":\\\"The AI-extracted scene data is highly accurate and faithful to the original screenplay text, with all key elements correctly identified and described.\\\"}\\n</Output>\\n<Rubric>\\nThis QA evaluation was given a GOOD scene extraction that accurately\\nreflects the source text. The QA model should have:\\n\\n1. Marked it as passed (true)\\n2. Found zero or very few errors\\n3. Had high confidence in the assessment\\n4. Written a summary confirming accuracy\\n\\nIf the model incorrectly flagged the good extraction as failing,\\nthat's a false negative and should score poorly.\\n\\n</Rubric>\"}]"
              }
            }
          ]
        },
        "id": "9583f108-eafa-4d9e-9f3b-627b39cdb089",
        "latencyMs": 9619,
        "namedScores": {},
        "prompt": {
          "raw": "You are a QA reviewer validating whether an AI-extracted scene analysis is accurate and faithful to the source screenplay text.\n\nCompare the extracted scene data against the original scene text and evaluate:\n\n1. **Heading accuracy**: Is the scene heading correct (location, INT/EXT, time of day)?\n2. **Character completeness**: Are all characters who appear or speak listed?\n3. **Summary fidelity**: Does the summary accurately describe what happens? No fabrications?\n4. **Narrative beats**: Are the identified beats actually present in the scene?\n5. **Tone assessment**: Does the tone description match the actual mood of the scene?\n6. **Confidence calibration**: Is the confidence score reasonable given the quality?\n\nReturn a JSON object with:\n- passed: boolean (true if the extraction is faithful, false if it has significant errors)\n- confidence: float 0-1 (your confidence in this QA judgment)\n- issues: array of objects, each with:\n  - severity: \"error\" (factual wrong), \"warning\" (misleading), or \"note\" (minor)\n  - description: what's wrong\n  - location: which field has the issue\n- summary: 1-2 sentence overall assessment\n\nBe strict: wrong character names, fabricated events, or incorrect locations are errors.\nMinor omissions or imprecise tone descriptions are warnings.\n\nReturn ONLY valid JSON. No explanations or markdown fences.\n\n==========\nORIGINAL SCENE TEXT:\nINT. RUDDY & GREEN BUILDING - ELEVATOR\n\nUB40's \"I Can't Help Falling in Love With You\" muzak.\n\nROSE (mid-30s) leans against the elevator wall, panting. She's wearing a Tim Hortons uniform, her hair is a mess, and there's blood spattered on her face.\n\nShe looks right, pants a few more times, then squints in disgust. She gingerly picks up a bloody scrap of something with hair on it. She snorts and drops it.\n\nROSE\nIs that skull??\n\nNext to her is Mariner, also panting, covered in far more blood. His face is broad, stoic, and frowning. He has gray-blue eyes and a thick, curly, beard barely streaked with gray. He wears a red knit cap and a small mask.\n\nFULL-SCREEN SUPERIMPOSED TITLE CARD: \"THE MARINER\"\n\nHe blinks a few times as a drop of blood falls from his eyebrow. He looks toward her, then spits out some blood.\n\nMARINER\nYeaaaaah...\n\nHe's built like a pro-wrestler. Moss green SWEATER stretched over his huge frame, sleeves rolled showing heavy leather BRACERS adorned with anchors. His inner forearm has a classic heart-and-arrow TATTOO with \"Dad\" in the centre. Across his chest is a BANDOLIER of bright red 12-gauge shells, FISH HOOKS hanging from the bottom edge. Heavy rubberized BOOTS go past his knees. A CAPE of heavy FISHING NET edged with WEIGHTS hangs from his shoulders.\n\nHe holds a STOUT WOODEN OAR in both hands, edged with METAL and dripping with BLOOD.\n\nROSE\nWhere were you when they grabbed me? You were supposed to pick me up at work!\n\nMARINER\nYeah, about that, I got a little... distracted.\n\nROSE\nDistracted. You got DISTRACTED?!\n\nMARINER\nI was also... tracking the car... that grabbed you... through the AirTag... I put on your phone.\n\nRose stops. She's really not happy about this.\n\nROSE\nYou Airtagged me?!\n\n==========\nEXTRACTED SCENE DATA:\n{\n  \"scene_number\": 4,\n  \"heading\": \"INT. RUDDY & GREEN BUILDING - ELEVATOR\",\n  \"int_ext\": \"INT\",\n  \"location\": \"RUDDY & GREEN BUILDING - ELEVATOR\",\n  \"time_of_day\": null,\n  \"characters_present\": [\"ROSE\", \"MARINER\"],\n  \"summary\": \"Rose and Mariner ride the elevator after a violent rescue. Rose discovers a skull fragment on the floor while muzak plays. Mariner is introduced in full — a hulking vigilante in fishing-themed costume with an oar, net cape, and shell bandolier. Rose confronts him about being late to pick her up, and he reveals he tracked her via an AirTag on her phone, sparking a trust conflict between them.\",\n  \"narrative_beats\": [\n    {\"beat_type\": \"character_introduction\", \"description\": \"Full description of Mariner's fishing-themed vigilante costume — oar, net cape, bracers, shell bandolier, fish hooks.\", \"confidence\": 0.95},\n    {\"beat_type\": \"comic_relief\", \"description\": \"Rose discovers a skull fragment while muzak plays, establishing the dark comedy tone.\", \"confidence\": 0.90},\n    {\"beat_type\": \"revelation\", \"description\": \"Mariner admits he tracked Rose via AirTag on her phone, creating a trust conflict.\", \"confidence\": 0.88},\n    {\"beat_type\": \"conflict\", \"description\": \"Rose's anger escalates from being grabbed to learning she was being surveilled by Mariner.\", \"confidence\": 0.85}\n  ],\n  \"tone_mood\": \"dark comedy with bursts of tension\",\n  \"confidence\": 0.91\n}\n==========",
          "label": "prompts/qa-pass.txt: You are a QA reviewer validating whether an AI-extracted scene analysis is accurate and faithful to the source screenplay text.\n\nCompare the extracted scene data against the original scene text and evaluate:\n\n1. **Heading accuracy**: Is the scene heading correct (location, INT/EXT, time of day)?\n2. **Character completeness**: Are all characters who appear or speak listed?\n3. **Summary fidelity**: Does the summary accurately describe what happens? No fabrications?\n4. **Narrative beats**: Are the identified beats actually present in the scene?\n5. **Tone assessment**: Does the tone description match the actual mood of the scene?\n6. **Confidence calibration**: Is the confidence score reasonable given the quality?\n\nReturn a JSON object with:\n- passed: boolean (true if the extraction is faithful, false if it has significant errors)\n- confidence: float 0-1 (your confidence in this QA judgment)\n- issues: array of objects, each with:\n  - severity: \"error\" (factual wrong), \"warning\" (misleading), or \"note\" (minor)\n  - description: what's wrong\n  - location: which field has the issue\n- summary: 1-2 sentence overall assessment\n\nBe strict: wrong character names, fabricated events, or incorrect locations are errors.\nMinor omissions or imprecise tone descriptions are warnings.\n\nReturn ONLY valid JSON. No explanations or markdown fences.\n\n==========\nORIGINAL SCENE TEXT:\n{{scene_text}}\n\n==========\nEXTRACTED SCENE DATA:\n{{extracted_data}}\n==========",
          "config": {
            "provider": "anthropic:messages:claude-opus-4-6"
          }
        },
        "promptId": "8df20c2c4a6081352d6b06e144ddbc1e0a5244f9a3c2000d40df12fc9a94e543",
        "promptIdx": 1,
        "provider": {
          "id": "google:gemini-2.5-flash",
          "label": "Gemini 2.5 Flash"
        },
        "response": {
          "output": "{\n  \"passed\": true,\n  \"confidence\": 0.99,\n  \"issues\": [],\n  \"summary\": \"The AI-extracted scene data is highly accurate and faithful to the original screenplay text, with all key elements correctly identified and described.\"\n}",
          "tokenUsage": {
            "prompt": 1185,
            "completion": 59,
            "total": 3245,
            "numRequests": 1,
            "completionDetails": {
              "reasoning": 2001,
              "acceptedPrediction": 0,
              "rejectedPrediction": 0
            }
          },
          "cost": 0.0055055,
          "raw": {
            "candidates": [
              {
                "content": {
                  "parts": [
                    {
                      "text": "{\n  \"passed\": true,\n  \"confidence\": 0.99,\n  \"issues\": [],\n  \"summary\": \"The AI-extracted scene data is highly accurate and faithful to the original screenplay text, with all key elements correctly identified and described.\"\n}"
                    }
                  ],
                  "role": "model"
                },
                "finishReason": "STOP",
                "index": 0
              }
            ],
            "usageMetadata": {
              "promptTokenCount": 1185,
              "candidatesTokenCount": 59,
              "totalTokenCount": 3245,
              "promptTokensDetails": [
                {
                  "modality": "TEXT",
                  "tokenCount": 1185
                }
              ],
              "thoughtsTokenCount": 2001
            },
            "modelVersion": "gemini-2.5-flash",
            "responseId": "asmVad7wLuLAqtsPwNeOuAc"
          },
          "cached": false,
          "metadata": {}
        },
        "score": 1,
        "success": true,
        "testCase": {
          "vars": {
            "scene_text": "file://../input/enrich-scene-elevator.txt",
            "extracted_data": "file://../input/qa-good-scene.json",
            "golden_path": "golden/qa-pass-golden.json",
            "test_key": "good_scene"
          },
          "assert": [
            {
              "type": "python",
              "value": "file://../scorers/qa_pass_scorer.py"
            },
            {
              "type": "llm-rubric",
              "value": "This QA evaluation was given a GOOD scene extraction that accurately\nreflects the source text. The QA model should have:\n\n1. Marked it as passed (true)\n2. Found zero or very few errors\n3. Had high confidence in the assessment\n4. Written a summary confirming accuracy\n\nIf the model incorrectly flagged the good extraction as failing,\nthat's a false negative and should score poorly.\n"
            }
          ],
          "options": {
            "provider": "anthropic:messages:claude-opus-4-6"
          },
          "metadata": {}
        },
        "testIdx": 0,
        "vars": {
          "scene_text": "file://../input/enrich-scene-elevator.txt",
          "extracted_data": "file://../input/qa-good-scene.json",
          "golden_path": "golden/qa-pass-golden.json",
          "test_key": "good_scene"
        },
        "metadata": {
          "_promptfooFileMetadata": {}
        },
        "failureReason": 0
      },
      {
        "cost": 0.008959499999999999,
        "gradingResult": {
          "pass": true,
          "score": 1,
          "reason": "All assertions passed",
          "namedScores": {},
          "tokensUsed": {
            "total": 529,
            "prompt": 438,
            "completion": 91,
            "cached": 0,
            "numRequests": 0
          },
          "componentResults": [
            {
              "pass": true,
              "score": 1,
              "reason": "confidence_calibration=1.00 | issue_detection=1.00 | json_valid=1.00 | pass_correct=1.00 | severity_accuracy=1.00 | summary_quality=1.00",
              "assertion": {
                "type": "python",
                "value": "file://../scorers/qa_pass_scorer.py"
              }
            },
            {
              "assertion": {
                "type": "llm-rubric",
                "value": "This QA evaluation was given a GOOD scene extraction that accurately\nreflects the source text. The QA model should have:\n\n1. Marked it as passed (true)\n2. Found zero or very few errors\n3. Had high confidence in the assessment\n4. Written a summary confirming accuracy\n\nIf the model incorrectly flagged the good extraction as failing,\nthat's a false negative and should score poorly.\n"
              },
              "pass": true,
              "score": 1,
              "reason": "The QA evaluation correctly marked the extraction as passed (true), had high confidence (0.98), found only very minor issues (a warning about a scene number and a note about a slight wording difference), and wrote a summary confirming the overall accuracy of the extraction. This aligns perfectly with the rubric's expectations for a good extraction.",
              "tokensUsed": {
                "total": 529,
                "prompt": 438,
                "completion": 91,
                "cached": 0,
                "numRequests": 0,
                "completionDetails": {
                  "reasoning": 0,
                  "acceptedPrediction": 0,
                  "rejectedPrediction": 0
                }
              },
              "metadata": {
                "renderedGradingPrompt": "[{\"role\":\"system\",\"content\":\"You are grading output according to a user-specified rubric. If the statement in the rubric is true, then the output passes the test. You respond with a JSON object with this structure: {reason: string, pass: boolean, score: number}\\n\\nExamples:\\n\\n<Output>Hello world</Output>\\n<Rubric>Content contains a greeting</Rubric>\\n{\\\"reason\\\": \\\"the content contains the word 'Hello'\\\", \\\"pass\\\": true, \\\"score\\\": 1.0}\\n\\n<Output>Avast ye swabs, repel the invaders!</Output>\\n<Rubric>Does not speak like a pirate</Rubric>\\n{\\\"reason\\\": \\\"'avast ye' is a common pirate term\\\", \\\"pass\\\": false, \\\"score\\\": 0.0}\"},{\"role\":\"user\",\"content\":\"<Output>\\n{\\\"passed\\\":true,\\\"confidence\\\":0.98,\\\"issues\\\":[{\\\"severity\\\":\\\"warning\\\",\\\"description\\\":\\\"The extraction includes a scene number (4) which is not present in the provided source text.\\\",\\\"location\\\":\\\"scene_number\\\"},{\\\"severity\\\":\\\"note\\\",\\\"description\\\":\\\"The summary describes the object Rose finds as a 'skull fragment', whereas in the text she only asks if it is a skull, though the context strongly implies it.\\\",\\\"location\\\":\\\"summary\\\"}],\\\"summary\\\":\\\"The extraction is highly accurate, capturing the specific character descriptions, dialogue points, and the unique dark comedic tone of the scene. The only minor discrepancy is the inclusion of a scene number not found in the source snippet.\\\"}\\n</Output>\\n<Rubric>\\nThis QA evaluation was given a GOOD scene extraction that accurately\\nreflects the source text. The QA model should have:\\n\\n1. Marked it as passed (true)\\n2. Found zero or very few errors\\n3. Had high confidence in the assessment\\n4. Written a summary confirming accuracy\\n\\nIf the model incorrectly flagged the good extraction as failing,\\nthat's a false negative and should score poorly.\\n\\n</Rubric>\"}]"
              }
            }
          ]
        },
        "id": "27c94936-c291-4e6d-958d-d0ab75ae4265",
        "latencyMs": 16380,
        "namedScores": {},
        "prompt": {
          "raw": "You are a QA reviewer validating whether an AI-extracted scene analysis is accurate and faithful to the source screenplay text.\n\nCompare the extracted scene data against the original scene text and evaluate:\n\n1. **Heading accuracy**: Is the scene heading correct (location, INT/EXT, time of day)?\n2. **Character completeness**: Are all characters who appear or speak listed?\n3. **Summary fidelity**: Does the summary accurately describe what happens? No fabrications?\n4. **Narrative beats**: Are the identified beats actually present in the scene?\n5. **Tone assessment**: Does the tone description match the actual mood of the scene?\n6. **Confidence calibration**: Is the confidence score reasonable given the quality?\n\nReturn a JSON object with:\n- passed: boolean (true if the extraction is faithful, false if it has significant errors)\n- confidence: float 0-1 (your confidence in this QA judgment)\n- issues: array of objects, each with:\n  - severity: \"error\" (factual wrong), \"warning\" (misleading), or \"note\" (minor)\n  - description: what's wrong\n  - location: which field has the issue\n- summary: 1-2 sentence overall assessment\n\nBe strict: wrong character names, fabricated events, or incorrect locations are errors.\nMinor omissions or imprecise tone descriptions are warnings.\n\nReturn ONLY valid JSON. No explanations or markdown fences.\n\n==========\nORIGINAL SCENE TEXT:\nINT. RUDDY & GREEN BUILDING - ELEVATOR\n\nUB40's \"I Can't Help Falling in Love With You\" muzak.\n\nROSE (mid-30s) leans against the elevator wall, panting. She's wearing a Tim Hortons uniform, her hair is a mess, and there's blood spattered on her face.\n\nShe looks right, pants a few more times, then squints in disgust. She gingerly picks up a bloody scrap of something with hair on it. She snorts and drops it.\n\nROSE\nIs that skull??\n\nNext to her is Mariner, also panting, covered in far more blood. His face is broad, stoic, and frowning. He has gray-blue eyes and a thick, curly, beard barely streaked with gray. He wears a red knit cap and a small mask.\n\nFULL-SCREEN SUPERIMPOSED TITLE CARD: \"THE MARINER\"\n\nHe blinks a few times as a drop of blood falls from his eyebrow. He looks toward her, then spits out some blood.\n\nMARINER\nYeaaaaah...\n\nHe's built like a pro-wrestler. Moss green SWEATER stretched over his huge frame, sleeves rolled showing heavy leather BRACERS adorned with anchors. His inner forearm has a classic heart-and-arrow TATTOO with \"Dad\" in the centre. Across his chest is a BANDOLIER of bright red 12-gauge shells, FISH HOOKS hanging from the bottom edge. Heavy rubberized BOOTS go past his knees. A CAPE of heavy FISHING NET edged with WEIGHTS hangs from his shoulders.\n\nHe holds a STOUT WOODEN OAR in both hands, edged with METAL and dripping with BLOOD.\n\nROSE\nWhere were you when they grabbed me? You were supposed to pick me up at work!\n\nMARINER\nYeah, about that, I got a little... distracted.\n\nROSE\nDistracted. You got DISTRACTED?!\n\nMARINER\nI was also... tracking the car... that grabbed you... through the AirTag... I put on your phone.\n\nRose stops. She's really not happy about this.\n\nROSE\nYou Airtagged me?!\n\n==========\nEXTRACTED SCENE DATA:\n{\n  \"scene_number\": 4,\n  \"heading\": \"INT. RUDDY & GREEN BUILDING - ELEVATOR\",\n  \"int_ext\": \"INT\",\n  \"location\": \"RUDDY & GREEN BUILDING - ELEVATOR\",\n  \"time_of_day\": null,\n  \"characters_present\": [\"ROSE\", \"MARINER\"],\n  \"summary\": \"Rose and Mariner ride the elevator after a violent rescue. Rose discovers a skull fragment on the floor while muzak plays. Mariner is introduced in full — a hulking vigilante in fishing-themed costume with an oar, net cape, and shell bandolier. Rose confronts him about being late to pick her up, and he reveals he tracked her via an AirTag on her phone, sparking a trust conflict between them.\",\n  \"narrative_beats\": [\n    {\"beat_type\": \"character_introduction\", \"description\": \"Full description of Mariner's fishing-themed vigilante costume — oar, net cape, bracers, shell bandolier, fish hooks.\", \"confidence\": 0.95},\n    {\"beat_type\": \"comic_relief\", \"description\": \"Rose discovers a skull fragment while muzak plays, establishing the dark comedy tone.\", \"confidence\": 0.90},\n    {\"beat_type\": \"revelation\", \"description\": \"Mariner admits he tracked Rose via AirTag on her phone, creating a trust conflict.\", \"confidence\": 0.88},\n    {\"beat_type\": \"conflict\", \"description\": \"Rose's anger escalates from being grabbed to learning she was being surveilled by Mariner.\", \"confidence\": 0.85}\n  ],\n  \"tone_mood\": \"dark comedy with bursts of tension\",\n  \"confidence\": 0.91\n}\n==========",
          "label": "prompts/qa-pass.txt: You are a QA reviewer validating whether an AI-extracted scene analysis is accurate and faithful to the source screenplay text.\n\nCompare the extracted scene data against the original scene text and evaluate:\n\n1. **Heading accuracy**: Is the scene heading correct (location, INT/EXT, time of day)?\n2. **Character completeness**: Are all characters who appear or speak listed?\n3. **Summary fidelity**: Does the summary accurately describe what happens? No fabrications?\n4. **Narrative beats**: Are the identified beats actually present in the scene?\n5. **Tone assessment**: Does the tone description match the actual mood of the scene?\n6. **Confidence calibration**: Is the confidence score reasonable given the quality?\n\nReturn a JSON object with:\n- passed: boolean (true if the extraction is faithful, false if it has significant errors)\n- confidence: float 0-1 (your confidence in this QA judgment)\n- issues: array of objects, each with:\n  - severity: \"error\" (factual wrong), \"warning\" (misleading), or \"note\" (minor)\n  - description: what's wrong\n  - location: which field has the issue\n- summary: 1-2 sentence overall assessment\n\nBe strict: wrong character names, fabricated events, or incorrect locations are errors.\nMinor omissions or imprecise tone descriptions are warnings.\n\nReturn ONLY valid JSON. No explanations or markdown fences.\n\n==========\nORIGINAL SCENE TEXT:\n{{scene_text}}\n\n==========\nEXTRACTED SCENE DATA:\n{{extracted_data}}\n==========",
          "config": {
            "provider": "anthropic:messages:claude-opus-4-6"
          }
        },
        "promptId": "8df20c2c4a6081352d6b06e144ddbc1e0a5244f9a3c2000d40df12fc9a94e543",
        "promptIdx": 2,
        "provider": {
          "id": "google:gemini-3-flash-preview",
          "label": "Gemini 3 Flash"
        },
        "response": {
          "output": "{\n  \"passed\": true,\n  \"confidence\": 0.98,\n  \"issues\": [\n    {\n      \"severity\": \"warning\",\n      \"description\": \"The extraction includes a scene number (4) which is not present in the provided source text.\",\n      \"location\": \"scene_number\"\n    },\n    {\n      \"severity\": \"note\",\n      \"description\": \"The summary describes the object Rose finds as a 'skull fragment', whereas in the text she only asks if it is a skull, though the context strongly implies it.\",\n      \"location\": \"summary\"\n    }\n  ],\n  \"summary\": \"The extraction is highly accurate, capturing the specific character descriptions, dialogue points, and the unique dark comedic tone of the scene. The only minor discrepancy is the inclusion of a scene number not found in the source snippet.\"\n}",
          "tokenUsage": {
            "prompt": 1185,
            "completion": 189,
            "total": 3974,
            "numRequests": 1,
            "completionDetails": {
              "reasoning": 2600,
              "acceptedPrediction": 0,
              "rejectedPrediction": 0
            }
          },
          "cost": 0.008959499999999999,
          "raw": {
            "candidates": [
              {
                "content": {
                  "parts": [
                    {
                      "text": "{\n  \"passed\": true,\n  \"confidence\": 0.98,\n  \"issues\": [\n    {\n      \"severity\": \"warning\",\n      \"description\": \"The extraction includes a scene number (4) which is not present in the provided source text.\",\n      \"location\": \"scene_number\"\n    },\n    {\n      \"severity\": \"note\",\n      \"description\": \"The summary describes the object Rose finds as a 'skull fragment', whereas in the text she only asks if it is a skull, though the context strongly implies it.\",\n      \"location\": \"summary\"\n    }\n  ],\n  \"summary\": \"The extraction is highly accurate, capturing the specific character descriptions, dialogue points, and the unique dark comedic tone of the scene. The only minor discrepancy is the inclusion of a scene number not found in the source snippet.\"\n}",
                      "thoughtSignature": "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"
                    }
                  ],
                  "role": "model"
                },
                "finishReason": "STOP",
                "index": 0
              }
            ],
            "usageMetadata": {
              "promptTokenCount": 1185,
              "candidatesTokenCount": 189,
              "totalTokenCount": 3974,
              "promptTokensDetails": [
                {
                  "modality": "TEXT",
                  "tokenCount": 1185
                }
              ],
              "thoughtsTokenCount": 2600
            },
            "modelVersion": "gemini-3-flash-preview",
            "responseId": "iMmVadq7AYuGqtsP4qeysA0"
          },
          "cached": false,
          "metadata": {}
        },
        "score": 1,
        "success": true,
        "testCase": {
          "vars": {
            "scene_text": "file://../input/enrich-scene-elevator.txt",
            "extracted_data": "file://../input/qa-good-scene.json",
            "golden_path": "golden/qa-pass-golden.json",
            "test_key": "good_scene"
          },
          "assert": [
            {
              "type": "python",
              "value": "file://../scorers/qa_pass_scorer.py"
            },
            {
              "type": "llm-rubric",
              "value": "This QA evaluation was given a GOOD scene extraction that accurately\nreflects the source text. The QA model should have:\n\n1. Marked it as passed (true)\n2. Found zero or very few errors\n3. Had high confidence in the assessment\n4. Written a summary confirming accuracy\n\nIf the model incorrectly flagged the good extraction as failing,\nthat's a false negative and should score poorly.\n"
            }
          ],
          "options": {
            "provider": "anthropic:messages:claude-opus-4-6"
          },
          "metadata": {}
        },
        "testIdx": 0,
        "vars": {
          "scene_text": "file://../input/enrich-scene-elevator.txt",
          "extracted_data": "file://../input/qa-good-scene.json",
          "golden_path": "golden/qa-pass-golden.json",
          "test_key": "good_scene"
        },
        "metadata": {
          "_promptfooFileMetadata": {}
        },
        "failureReason": 0
      },
      {
        "cost": 0.011021250000000002,
        "gradingResult": {
          "pass": true,
          "score": 0.995,
          "reason": "All assertions passed",
          "namedScores": {},
          "tokensUsed": {
            "total": 436,
            "prompt": 363,
            "completion": 73,
            "cached": 0,
            "numRequests": 0
          },
          "componentResults": [
            {
              "pass": true,
              "score": 0.99,
              "reason": "confidence_calibration=1.00 | issue_detection=1.00 | json_valid=0.90 | pass_correct=1.00 | severity_accuracy=1.00 | summary_quality=1.00 | JSON extracted from code block",
              "assertion": {
                "type": "python",
                "value": "file://../scorers/qa_pass_scorer.py"
              }
            },
            {
              "assertion": {
                "type": "llm-rubric",
                "value": "This QA evaluation was given a GOOD scene extraction that accurately\nreflects the source text. The QA model should have:\n\n1. Marked it as passed (true)\n2. Found zero or very few errors\n3. Had high confidence in the assessment\n4. Written a summary confirming accuracy\n\nIf the model incorrectly flagged the good extraction as failing,\nthat's a false negative and should score poorly.\n"
              },
              "pass": true,
              "score": 1,
              "reason": "The QA evaluation correctly marked the good extraction as passed (true), found zero issues (empty issues array), had maximum confidence (1.0), and wrote a summary confirming the accuracy of the extraction. This perfectly matches all four criteria in the rubric.",
              "tokensUsed": {
                "total": 436,
                "prompt": 363,
                "completion": 73,
                "cached": 0,
                "numRequests": 0,
                "completionDetails": {
                  "reasoning": 0,
                  "acceptedPrediction": 0,
                  "rejectedPrediction": 0
                }
              },
              "metadata": {
                "renderedGradingPrompt": "[{\"role\":\"system\",\"content\":\"You are grading output according to a user-specified rubric. If the statement in the rubric is true, then the output passes the test. You respond with a JSON object with this structure: {reason: string, pass: boolean, score: number}\\n\\nExamples:\\n\\n<Output>Hello world</Output>\\n<Rubric>Content contains a greeting</Rubric>\\n{\\\"reason\\\": \\\"the content contains the word 'Hello'\\\", \\\"pass\\\": true, \\\"score\\\": 1.0}\\n\\n<Output>Avast ye swabs, repel the invaders!</Output>\\n<Rubric>Does not speak like a pirate</Rubric>\\n{\\\"reason\\\": \\\"'avast ye' is a common pirate term\\\", \\\"pass\\\": false, \\\"score\\\": 0.0}\"},{\"role\":\"user\",\"content\":\"<Output>\\n```json\\n{\\n  \\\"passed\\\": true,\\n  \\\"confidence\\\": 1.0,\\n  \\\"issues\\\": [],\\n  \\\"summary\\\": \\\"The AI's analysis is highly accurate and faithful to the source text, correctly identifying all key elements including characters, plot points, and the specific dark comedy tone.\\\"\\n}\\n```\\n</Output>\\n<Rubric>\\nThis QA evaluation was given a GOOD scene extraction that accurately\\nreflects the source text. The QA model should have:\\n\\n1. Marked it as passed (true)\\n2. Found zero or very few errors\\n3. Had high confidence in the assessment\\n4. Written a summary confirming accuracy\\n\\nIf the model incorrectly flagged the good extraction as failing,\\nthat's a false negative and should score poorly.\\n\\n</Rubric>\"}]"
              }
            }
          ]
        },
        "id": "08832d6b-0c22-490d-a8b7-3bc1cae8993d",
        "latencyMs": 9609,
        "namedScores": {},
        "prompt": {
          "raw": "You are a QA reviewer validating whether an AI-extracted scene analysis is accurate and faithful to the source screenplay text.\n\nCompare the extracted scene data against the original scene text and evaluate:\n\n1. **Heading accuracy**: Is the scene heading correct (location, INT/EXT, time of day)?\n2. **Character completeness**: Are all characters who appear or speak listed?\n3. **Summary fidelity**: Does the summary accurately describe what happens? No fabrications?\n4. **Narrative beats**: Are the identified beats actually present in the scene?\n5. **Tone assessment**: Does the tone description match the actual mood of the scene?\n6. **Confidence calibration**: Is the confidence score reasonable given the quality?\n\nReturn a JSON object with:\n- passed: boolean (true if the extraction is faithful, false if it has significant errors)\n- confidence: float 0-1 (your confidence in this QA judgment)\n- issues: array of objects, each with:\n  - severity: \"error\" (factual wrong), \"warning\" (misleading), or \"note\" (minor)\n  - description: what's wrong\n  - location: which field has the issue\n- summary: 1-2 sentence overall assessment\n\nBe strict: wrong character names, fabricated events, or incorrect locations are errors.\nMinor omissions or imprecise tone descriptions are warnings.\n\nReturn ONLY valid JSON. No explanations or markdown fences.\n\n==========\nORIGINAL SCENE TEXT:\nINT. RUDDY & GREEN BUILDING - ELEVATOR\n\nUB40's \"I Can't Help Falling in Love With You\" muzak.\n\nROSE (mid-30s) leans against the elevator wall, panting. She's wearing a Tim Hortons uniform, her hair is a mess, and there's blood spattered on her face.\n\nShe looks right, pants a few more times, then squints in disgust. She gingerly picks up a bloody scrap of something with hair on it. She snorts and drops it.\n\nROSE\nIs that skull??\n\nNext to her is Mariner, also panting, covered in far more blood. His face is broad, stoic, and frowning. He has gray-blue eyes and a thick, curly, beard barely streaked with gray. He wears a red knit cap and a small mask.\n\nFULL-SCREEN SUPERIMPOSED TITLE CARD: \"THE MARINER\"\n\nHe blinks a few times as a drop of blood falls from his eyebrow. He looks toward her, then spits out some blood.\n\nMARINER\nYeaaaaah...\n\nHe's built like a pro-wrestler. Moss green SWEATER stretched over his huge frame, sleeves rolled showing heavy leather BRACERS adorned with anchors. His inner forearm has a classic heart-and-arrow TATTOO with \"Dad\" in the centre. Across his chest is a BANDOLIER of bright red 12-gauge shells, FISH HOOKS hanging from the bottom edge. Heavy rubberized BOOTS go past his knees. A CAPE of heavy FISHING NET edged with WEIGHTS hangs from his shoulders.\n\nHe holds a STOUT WOODEN OAR in both hands, edged with METAL and dripping with BLOOD.\n\nROSE\nWhere were you when they grabbed me? You were supposed to pick me up at work!\n\nMARINER\nYeah, about that, I got a little... distracted.\n\nROSE\nDistracted. You got DISTRACTED?!\n\nMARINER\nI was also... tracking the car... that grabbed you... through the AirTag... I put on your phone.\n\nRose stops. She's really not happy about this.\n\nROSE\nYou Airtagged me?!\n\n==========\nEXTRACTED SCENE DATA:\n{\n  \"scene_number\": 4,\n  \"heading\": \"INT. RUDDY & GREEN BUILDING - ELEVATOR\",\n  \"int_ext\": \"INT\",\n  \"location\": \"RUDDY & GREEN BUILDING - ELEVATOR\",\n  \"time_of_day\": null,\n  \"characters_present\": [\"ROSE\", \"MARINER\"],\n  \"summary\": \"Rose and Mariner ride the elevator after a violent rescue. Rose discovers a skull fragment on the floor while muzak plays. Mariner is introduced in full — a hulking vigilante in fishing-themed costume with an oar, net cape, and shell bandolier. Rose confronts him about being late to pick her up, and he reveals he tracked her via an AirTag on her phone, sparking a trust conflict between them.\",\n  \"narrative_beats\": [\n    {\"beat_type\": \"character_introduction\", \"description\": \"Full description of Mariner's fishing-themed vigilante costume — oar, net cape, bracers, shell bandolier, fish hooks.\", \"confidence\": 0.95},\n    {\"beat_type\": \"comic_relief\", \"description\": \"Rose discovers a skull fragment while muzak plays, establishing the dark comedy tone.\", \"confidence\": 0.90},\n    {\"beat_type\": \"revelation\", \"description\": \"Mariner admits he tracked Rose via AirTag on her phone, creating a trust conflict.\", \"confidence\": 0.88},\n    {\"beat_type\": \"conflict\", \"description\": \"Rose's anger escalates from being grabbed to learning she was being surveilled by Mariner.\", \"confidence\": 0.85}\n  ],\n  \"tone_mood\": \"dark comedy with bursts of tension\",\n  \"confidence\": 0.91\n}\n==========",
          "label": "prompts/qa-pass.txt: You are a QA reviewer validating whether an AI-extracted scene analysis is accurate and faithful to the source screenplay text.\n\nCompare the extracted scene data against the original scene text and evaluate:\n\n1. **Heading accuracy**: Is the scene heading correct (location, INT/EXT, time of day)?\n2. **Character completeness**: Are all characters who appear or speak listed?\n3. **Summary fidelity**: Does the summary accurately describe what happens? No fabrications?\n4. **Narrative beats**: Are the identified beats actually present in the scene?\n5. **Tone assessment**: Does the tone description match the actual mood of the scene?\n6. **Confidence calibration**: Is the confidence score reasonable given the quality?\n\nReturn a JSON object with:\n- passed: boolean (true if the extraction is faithful, false if it has significant errors)\n- confidence: float 0-1 (your confidence in this QA judgment)\n- issues: array of objects, each with:\n  - severity: \"error\" (factual wrong), \"warning\" (misleading), or \"note\" (minor)\n  - description: what's wrong\n  - location: which field has the issue\n- summary: 1-2 sentence overall assessment\n\nBe strict: wrong character names, fabricated events, or incorrect locations are errors.\nMinor omissions or imprecise tone descriptions are warnings.\n\nReturn ONLY valid JSON. No explanations or markdown fences.\n\n==========\nORIGINAL SCENE TEXT:\n{{scene_text}}\n\n==========\nEXTRACTED SCENE DATA:\n{{extracted_data}}\n==========",
          "config": {
            "provider": "anthropic:messages:claude-opus-4-6"
          }
        },
        "promptId": "8df20c2c4a6081352d6b06e144ddbc1e0a5244f9a3c2000d40df12fc9a94e543",
        "promptIdx": 3,
        "provider": {
          "id": "google:gemini-2.5-pro",
          "label": "Gemini 2.5 Pro"
        },
        "response": {
          "output": "```json\n{\n  \"passed\": true,\n  \"confidence\": 1.0,\n  \"issues\": [],\n  \"summary\": \"The AI's analysis is highly accurate and faithful to the source text, correctly identifying all key elements including characters, plot points, and the specific dark comedy tone.\"\n}\n```",
          "tokenUsage": {
            "prompt": 1185,
            "completion": 70,
            "total": 2139,
            "numRequests": 1,
            "completionDetails": {
              "reasoning": 884,
              "acceptedPrediction": 0,
              "rejectedPrediction": 0
            }
          },
          "cost": 0.011021250000000002,
          "raw": {
            "candidates": [
              {
                "content": {
                  "parts": [
                    {
                      "text": "```json\n{\n  \"passed\": true,\n  \"confidence\": 1.0,\n  \"issues\": [],\n  \"summary\": \"The AI's analysis is highly accurate and faithful to the source text, correctly identifying all key elements including characters, plot points, and the specific dark comedy tone.\"\n}\n```"
                    }
                  ],
                  "role": "model"
                },
                "finishReason": "STOP",
                "index": 0
              }
            ],
            "usageMetadata": {
              "promptTokenCount": 1185,
              "candidatesTokenCount": 70,
              "totalTokenCount": 2139,
              "promptTokensDetails": [
                {
                  "modality": "TEXT",
                  "tokenCount": 1185
                }
              ],
              "thoughtsTokenCount": 884
            },
            "modelVersion": "gemini-2.5-pro",
            "responseId": "lcmVadreLreVmtkP5LGg6Qw"
          },
          "cached": false,
          "metadata": {}
        },
        "score": 0.995,
        "success": true,
        "testCase": {
          "vars": {
            "scene_text": "file://../input/enrich-scene-elevator.txt",
            "extracted_data": "file://../input/qa-good-scene.json",
            "golden_path": "golden/qa-pass-golden.json",
            "test_key": "good_scene"
          },
          "assert": [
            {
              "type": "python",
              "value": "file://../scorers/qa_pass_scorer.py"
            },
            {
              "type": "llm-rubric",
              "value": "This QA evaluation was given a GOOD scene extraction that accurately\nreflects the source text. The QA model should have:\n\n1. Marked it as passed (true)\n2. Found zero or very few errors\n3. Had high confidence in the assessment\n4. Written a summary confirming accuracy\n\nIf the model incorrectly flagged the good extraction as failing,\nthat's a false negative and should score poorly.\n"
            }
          ],
          "options": {
            "provider": "anthropic:messages:claude-opus-4-6"
          },
          "metadata": {}
        },
        "testIdx": 0,
        "vars": {
          "scene_text": "file://../input/enrich-scene-elevator.txt",
          "extracted_data": "file://../input/qa-good-scene.json",
          "golden_path": "golden/qa-pass-golden.json",
          "test_key": "good_scene"
        },
        "metadata": {
          "_promptfooFileMetadata": {}
        },
        "failureReason": 0
      },
      {
        "cost": 0.019674,
        "gradingResult": {
          "pass": true,
          "score": 1,
          "reason": "All assertions passed",
          "namedScores": {},
          "tokensUsed": {
            "total": 491,
            "prompt": 388,
            "completion": 103,
            "cached": 0,
            "numRequests": 0
          },
          "componentResults": [
            {
              "pass": true,
              "score": 1,
              "reason": "confidence_calibration=1.00 | issue_detection=1.00 | json_valid=1.00 | pass_correct=1.00 | severity_accuracy=1.00 | summary_quality=1.00",
              "assertion": {
                "type": "python",
                "value": "file://../scorers/qa_pass_scorer.py"
              }
            },
            {
              "assertion": {
                "type": "llm-rubric",
                "value": "This QA evaluation was given a GOOD scene extraction that accurately\nreflects the source text. The QA model should have:\n\n1. Marked it as passed (true)\n2. Found zero or very few errors\n3. Had high confidence in the assessment\n4. Written a summary confirming accuracy\n\nIf the model incorrectly flagged the good extraction as failing,\nthat's a false negative and should score poorly.\n"
              },
              "pass": true,
              "score": 1,
              "reason": "The QA evaluation correctly marked the extraction as passed (true), had high confidence (0.95), found only one minor warning-level issue (not an error), and wrote a summary confirming the accuracy of the extraction. This aligns well with all four criteria in the rubric: passed is true, zero or very few errors (just one warning), high confidence, and a summary confirming accuracy.",
              "tokensUsed": {
                "total": 491,
                "prompt": 388,
                "completion": 103,
                "cached": 0,
                "numRequests": 0,
                "completionDetails": {
                  "reasoning": 0,
                  "acceptedPrediction": 0,
                  "rejectedPrediction": 0
                }
              },
              "metadata": {
                "renderedGradingPrompt": "[{\"role\":\"system\",\"content\":\"You are grading output according to a user-specified rubric. If the statement in the rubric is true, then the output passes the test. You respond with a JSON object with this structure: {reason: string, pass: boolean, score: number}\\n\\nExamples:\\n\\n<Output>Hello world</Output>\\n<Rubric>Content contains a greeting</Rubric>\\n{\\\"reason\\\": \\\"the content contains the word 'Hello'\\\", \\\"pass\\\": true, \\\"score\\\": 1.0}\\n\\n<Output>Avast ye swabs, repel the invaders!</Output>\\n<Rubric>Does not speak like a pirate</Rubric>\\n{\\\"reason\\\": \\\"'avast ye' is a common pirate term\\\", \\\"pass\\\": false, \\\"score\\\": 0.0}\"},{\"role\":\"user\",\"content\":\"<Output>\\n{\\\"passed\\\":true,\\\"confidence\\\":0.95,\\\"issues\\\":[{\\\"severity\\\":\\\"warning\\\",\\\"description\\\":\\\"Scene number '4' is included in the extraction but is not present in the provided source text.\\\",\\\"location\\\":\\\"scene_number\\\"}],\\\"summary\\\":\\\"The extraction is highly accurate, capturing the characters, specific visual details (costume, props), and the dark comedic tone faithfully. The summary and narrative beats align perfectly with the dialogue and action lines.\\\"}\\n</Output>\\n<Rubric>\\nThis QA evaluation was given a GOOD scene extraction that accurately\\nreflects the source text. The QA model should have:\\n\\n1. Marked it as passed (true)\\n2. Found zero or very few errors\\n3. Had high confidence in the assessment\\n4. Written a summary confirming accuracy\\n\\nIf the model incorrectly flagged the good extraction as failing,\\nthat's a false negative and should score poorly.\\n\\n</Rubric>\"}]"
              }
            }
          ]
        },
        "id": "b7d4ff2b-fa1d-4402-b828-a12e091b78bd",
        "latencyMs": 22994,
        "namedScores": {},
        "prompt": {
          "raw": "You are a QA reviewer validating whether an AI-extracted scene analysis is accurate and faithful to the source screenplay text.\n\nCompare the extracted scene data against the original scene text and evaluate:\n\n1. **Heading accuracy**: Is the scene heading correct (location, INT/EXT, time of day)?\n2. **Character completeness**: Are all characters who appear or speak listed?\n3. **Summary fidelity**: Does the summary accurately describe what happens? No fabrications?\n4. **Narrative beats**: Are the identified beats actually present in the scene?\n5. **Tone assessment**: Does the tone description match the actual mood of the scene?\n6. **Confidence calibration**: Is the confidence score reasonable given the quality?\n\nReturn a JSON object with:\n- passed: boolean (true if the extraction is faithful, false if it has significant errors)\n- confidence: float 0-1 (your confidence in this QA judgment)\n- issues: array of objects, each with:\n  - severity: \"error\" (factual wrong), \"warning\" (misleading), or \"note\" (minor)\n  - description: what's wrong\n  - location: which field has the issue\n- summary: 1-2 sentence overall assessment\n\nBe strict: wrong character names, fabricated events, or incorrect locations are errors.\nMinor omissions or imprecise tone descriptions are warnings.\n\nReturn ONLY valid JSON. No explanations or markdown fences.\n\n==========\nORIGINAL SCENE TEXT:\nINT. RUDDY & GREEN BUILDING - ELEVATOR\n\nUB40's \"I Can't Help Falling in Love With You\" muzak.\n\nROSE (mid-30s) leans against the elevator wall, panting. She's wearing a Tim Hortons uniform, her hair is a mess, and there's blood spattered on her face.\n\nShe looks right, pants a few more times, then squints in disgust. She gingerly picks up a bloody scrap of something with hair on it. She snorts and drops it.\n\nROSE\nIs that skull??\n\nNext to her is Mariner, also panting, covered in far more blood. His face is broad, stoic, and frowning. He has gray-blue eyes and a thick, curly, beard barely streaked with gray. He wears a red knit cap and a small mask.\n\nFULL-SCREEN SUPERIMPOSED TITLE CARD: \"THE MARINER\"\n\nHe blinks a few times as a drop of blood falls from his eyebrow. He looks toward her, then spits out some blood.\n\nMARINER\nYeaaaaah...\n\nHe's built like a pro-wrestler. Moss green SWEATER stretched over his huge frame, sleeves rolled showing heavy leather BRACERS adorned with anchors. His inner forearm has a classic heart-and-arrow TATTOO with \"Dad\" in the centre. Across his chest is a BANDOLIER of bright red 12-gauge shells, FISH HOOKS hanging from the bottom edge. Heavy rubberized BOOTS go past his knees. A CAPE of heavy FISHING NET edged with WEIGHTS hangs from his shoulders.\n\nHe holds a STOUT WOODEN OAR in both hands, edged with METAL and dripping with BLOOD.\n\nROSE\nWhere were you when they grabbed me? You were supposed to pick me up at work!\n\nMARINER\nYeah, about that, I got a little... distracted.\n\nROSE\nDistracted. You got DISTRACTED?!\n\nMARINER\nI was also... tracking the car... that grabbed you... through the AirTag... I put on your phone.\n\nRose stops. She's really not happy about this.\n\nROSE\nYou Airtagged me?!\n\n==========\nEXTRACTED SCENE DATA:\n{\n  \"scene_number\": 4,\n  \"heading\": \"INT. RUDDY & GREEN BUILDING - ELEVATOR\",\n  \"int_ext\": \"INT\",\n  \"location\": \"RUDDY & GREEN BUILDING - ELEVATOR\",\n  \"time_of_day\": null,\n  \"characters_present\": [\"ROSE\", \"MARINER\"],\n  \"summary\": \"Rose and Mariner ride the elevator after a violent rescue. Rose discovers a skull fragment on the floor while muzak plays. Mariner is introduced in full — a hulking vigilante in fishing-themed costume with an oar, net cape, and shell bandolier. Rose confronts him about being late to pick her up, and he reveals he tracked her via an AirTag on her phone, sparking a trust conflict between them.\",\n  \"narrative_beats\": [\n    {\"beat_type\": \"character_introduction\", \"description\": \"Full description of Mariner's fishing-themed vigilante costume — oar, net cape, bracers, shell bandolier, fish hooks.\", \"confidence\": 0.95},\n    {\"beat_type\": \"comic_relief\", \"description\": \"Rose discovers a skull fragment while muzak plays, establishing the dark comedy tone.\", \"confidence\": 0.90},\n    {\"beat_type\": \"revelation\", \"description\": \"Mariner admits he tracked Rose via AirTag on her phone, creating a trust conflict.\", \"confidence\": 0.88},\n    {\"beat_type\": \"conflict\", \"description\": \"Rose's anger escalates from being grabbed to learning she was being surveilled by Mariner.\", \"confidence\": 0.85}\n  ],\n  \"tone_mood\": \"dark comedy with bursts of tension\",\n  \"confidence\": 0.91\n}\n==========",
          "label": "prompts/qa-pass.txt: You are a QA reviewer validating whether an AI-extracted scene analysis is accurate and faithful to the source screenplay text.\n\nCompare the extracted scene data against the original scene text and evaluate:\n\n1. **Heading accuracy**: Is the scene heading correct (location, INT/EXT, time of day)?\n2. **Character completeness**: Are all characters who appear or speak listed?\n3. **Summary fidelity**: Does the summary accurately describe what happens? No fabrications?\n4. **Narrative beats**: Are the identified beats actually present in the scene?\n5. **Tone assessment**: Does the tone description match the actual mood of the scene?\n6. **Confidence calibration**: Is the confidence score reasonable given the quality?\n\nReturn a JSON object with:\n- passed: boolean (true if the extraction is faithful, false if it has significant errors)\n- confidence: float 0-1 (your confidence in this QA judgment)\n- issues: array of objects, each with:\n  - severity: \"error\" (factual wrong), \"warning\" (misleading), or \"note\" (minor)\n  - description: what's wrong\n  - location: which field has the issue\n- summary: 1-2 sentence overall assessment\n\nBe strict: wrong character names, fabricated events, or incorrect locations are errors.\nMinor omissions or imprecise tone descriptions are warnings.\n\nReturn ONLY valid JSON. No explanations or markdown fences.\n\n==========\nORIGINAL SCENE TEXT:\n{{scene_text}}\n\n==========\nEXTRACTED SCENE DATA:\n{{extracted_data}}\n==========",
          "config": {
            "provider": "anthropic:messages:claude-opus-4-6"
          }
        },
        "promptId": "8df20c2c4a6081352d6b06e144ddbc1e0a5244f9a3c2000d40df12fc9a94e543",
        "promptIdx": 4,
        "provider": {
          "id": "google:gemini-3-pro-preview",
          "label": "Gemini 3 Pro"
        },
        "response": {
          "output": "{\n  \"passed\": true,\n  \"confidence\": 0.95,\n  \"issues\": [\n    {\n      \"severity\": \"warning\",\n      \"description\": \"Scene number '4' is included in the extraction but is not present in the provided source text.\",\n      \"location\": \"scene_number\"\n    }\n  ],\n  \"summary\": \"The extraction is highly accurate, capturing the characters, specific visual details (costume, props), and the dark comedic tone faithfully. The summary and narrative beats align perfectly with the dialogue and action lines.\"\n}",
          "tokenUsage": {
            "prompt": 1185,
            "completion": 125,
            "total": 2627,
            "numRequests": 1,
            "completionDetails": {
              "reasoning": 1317,
              "acceptedPrediction": 0,
              "rejectedPrediction": 0
            }
          },
          "cost": 0.019674,
          "raw": {
            "candidates": [
              {
                "content": {
                  "parts": [
                    {
                      "text": "{\n  \"passed\": true,\n  \"confidence\": 0.95,\n  \"issues\": [\n    {\n      \"severity\": \"warning\",\n      \"description\": \"Scene number '4' is included in the extraction but is not present in the provided source text.\",\n      \"location\": \"scene_number\"\n    }\n  ],\n  \"summary\": \"The extraction is highly accurate, capturing the characters, specific visual details (costume, props), and the dark comedic tone faithfully. The summary and narrative beats align perfectly with the dialogue and action lines.\"\n}",
                      "thoughtSignature": "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"
                    }
                  ],
                  "role": "model"
                },
                "finishReason": "STOP",
                "index": 0
              }
            ],
            "usageMetadata": {
              "promptTokenCount": 1185,
              "candidatesTokenCount": 125,
              "totalTokenCount": 2627,
              "promptTokensDetails": [
                {
                  "modality": "TEXT",
                  "tokenCount": 1185
                }
              ],
              "thoughtsTokenCount": 1317
            },
            "modelVersion": "gemini-3-pro-preview",
            "responseId": "sMmVae2cJ7fxqtsPxPLWuQQ"
          },
          "cached": false,
          "metadata": {}
        },
        "score": 1,
        "success": true,
        "testCase": {
          "vars": {
            "scene_text": "file://../input/enrich-scene-elevator.txt",
            "extracted_data": "file://../input/qa-good-scene.json",
            "golden_path": "golden/qa-pass-golden.json",
            "test_key": "good_scene"
          },
          "assert": [
            {
              "type": "python",
              "value": "file://../scorers/qa_pass_scorer.py"
            },
            {
              "type": "llm-rubric",
              "value": "This QA evaluation was given a GOOD scene extraction that accurately\nreflects the source text. The QA model should have:\n\n1. Marked it as passed (true)\n2. Found zero or very few errors\n3. Had high confidence in the assessment\n4. Written a summary confirming accuracy\n\nIf the model incorrectly flagged the good extraction as failing,\nthat's a false negative and should score poorly.\n"
            }
          ],
          "options": {
            "provider": "anthropic:messages:claude-opus-4-6"
          },
          "metadata": {}
        },
        "testIdx": 0,
        "vars": {
          "scene_text": "file://../input/enrich-scene-elevator.txt",
          "extracted_data": "file://../input/qa-good-scene.json",
          "golden_path": "golden/qa-pass-golden.json",
          "test_key": "good_scene"
        },
        "metadata": {
          "_promptfooFileMetadata": {}
        },
        "failureReason": 0
      },
      {
        "cost": 0.00024910000000000004,
        "gradingResult": {
          "pass": true,
          "score": 0.9450000000000001,
          "reason": "All assertions passed",
          "namedScores": {},
          "tokensUsed": {
            "total": 933,
            "prompt": 747,
            "completion": 186,
            "cached": 0,
            "numRequests": 0
          },
          "componentResults": [
            {
              "pass": true,
              "score": 0.99,
              "reason": "confidence_calibration=1.00 | issue_detection=1.00 | json_valid=0.90 | pass_correct=1.00 | severity_accuracy=1.00 | summary_quality=1.00 | JSON extracted from code block",
              "assertion": {
                "type": "python",
                "value": "file://../scorers/qa_pass_scorer.py"
              }
            },
            {
              "assertion": {
                "type": "llm-rubric",
                "value": "This QA evaluation was given a BAD scene extraction with multiple errors:\n- Wrong building name (Office Building vs Ruddy & Greene)\n- Wrong time of day (DAY vs NIGHT)\n- Wrong character name (Billy instead of Mariner)\n- Missing thug characters\n- Fabricated content (grocery discussion never happens)\n\nThe QA model should have:\n1. Marked it as failed (false)\n2. Identified at least 2-3 specific errors\n3. Flagged the fabricated summary content\n4. Used \"error\" severity for factual mistakes\n\nIf the model let this pass, that's a dangerous false positive.\n"
              },
              "pass": true,
              "score": 0.9,
              "reason": "The QA evaluation correctly identified the extraction as failed (passed: false) with high confidence (0.95). It caught multiple specific errors: (1) wrong building name (Office Building vs Ruddy & Green), (2) wrong character name (Billy instead of Mariner), (3) fabricated summary content about grocery discussions that never happened, (4) incorrect narrative beats, and (5) wrong tone. It used 'error' severity for all factual mistakes. The only minor gap is that it didn't explicitly call out the wrong time of day (DAY vs NIGHT) or the missing thug characters, but it identified well more than 2-3 specific errors and flagged the fabricated content. This is not a false positive — it correctly rejected the bad extraction.",
              "tokensUsed": {
                "total": 933,
                "prompt": 747,
                "completion": 186,
                "cached": 0,
                "numRequests": 0,
                "completionDetails": {
                  "reasoning": 0,
                  "acceptedPrediction": 0,
                  "rejectedPrediction": 0
                }
              },
              "metadata": {
                "renderedGradingPrompt": "[{\"role\":\"system\",\"content\":\"You are grading output according to a user-specified rubric. If the statement in the rubric is true, then the output passes the test. You respond with a JSON object with this structure: {reason: string, pass: boolean, score: number}\\n\\nExamples:\\n\\n<Output>Hello world</Output>\\n<Rubric>Content contains a greeting</Rubric>\\n{\\\"reason\\\": \\\"the content contains the word 'Hello'\\\", \\\"pass\\\": true, \\\"score\\\": 1.0}\\n\\n<Output>Avast ye swabs, repel the invaders!</Output>\\n<Rubric>Does not speak like a pirate</Rubric>\\n{\\\"reason\\\": \\\"'avast ye' is a common pirate term\\\", \\\"pass\\\": false, \\\"score\\\": 0.0}\"},{\"role\":\"user\",\"content\":\"<Output>\\n```json\\n{\\n  \\\"passed\\\": false,\\n  \\\"confidence\\\": 0.95,\\n  \\\"issues\\\": [\\n    {\\n      \\\"severity\\\": \\\"error\\\",\\n      \\\"description\\\": \\\"The location 'OFFICE BUILDING - ELEVATOR' is incorrect. The screenplay specifies 'RUDDY & GREEN BUILDING - ELEVATOR'.\\\",\\n      \\\"location\\\": \\\"heading\\\"\\n    },\\n    {\\n      \\\"severity\\\": \\\"error\\\",\\n      \\\"description\\\": \\\"The character 'BILLY' is not present in the scene. The character 'MARINER' is present instead.\\\",\\n      \\\"location\\\": \\\"characters_present\\\"\\n    },\\n    {\\n      \\\"severity\\\": \\\"error\\\",\\n      \\\"description\\\": \\\"The summary fabricates events and dialogue. The characters are not discussing plans for the evening, nor does Rose mention picking up groceries. The scene depicts Rose and Mariner after an apparent violent encounter, discussing how Rose was captured and Mariner's distraction.\\\",\\n      \\\"location\\\": \\\"summary\\\"\\n    },\\n    {\\n      \\\"severity\\\": \\\"error\\\",\\n      \\\"description\\\": \\\"The identified narrative beat 'Characters discuss daily plans' is inaccurate. The scene's dialogue focuses on Rose's capture and Mariner's actions, not daily plans.\\\",\\n      \\\"location\\\": \\\"narrative_beats\\\"\\n    },\\n    {\\n      \\\"severity\\\": \\\"error\\\",\\n      \\\"description\\\": \\\"The tone 'casual' is incorrect. The scene is tense and reflects the aftermath of violence, with characters panting and covered in blood.\\\",\\n      \\\"location\\\": \\\"tone_mood\\\"\\n    }\\n  ],\\n  \\\"summary\\\": \\\"The extracted scene data contains significant errors in location, character presence, summary fidelity, narrative beats, and tone, failing to accurately represent the source screenplay.\\\"\\n}\\n```\\n</Output>\\n<Rubric>\\nThis QA evaluation was given a BAD scene extraction with multiple errors:\\n- Wrong building name (Office Building vs Ruddy & Greene)\\n- Wrong time of day (DAY vs NIGHT)\\n- Wrong character name (Billy instead of Mariner)\\n- Missing thug characters\\n- Fabricated content (grocery discussion never happens)\\n\\nThe QA model should have:\\n1. Marked it as failed (false)\\n2. Identified at least 2-3 specific errors\\n3. Flagged the fabricated summary content\\n4. Used \\\"error\\\" severity for factual mistakes\\n\\nIf the model let this pass, that's a dangerous false positive.\\n\\n</Rubric>\"}]"
              }
            }
          ]
        },
        "id": "2b7cce63-fecf-41d3-afa7-d352d9f668e3",
        "latencyMs": 1788,
        "namedScores": {},
        "prompt": {
          "raw": "You are a QA reviewer validating whether an AI-extracted scene analysis is accurate and faithful to the source screenplay text.\n\nCompare the extracted scene data against the original scene text and evaluate:\n\n1. **Heading accuracy**: Is the scene heading correct (location, INT/EXT, time of day)?\n2. **Character completeness**: Are all characters who appear or speak listed?\n3. **Summary fidelity**: Does the summary accurately describe what happens? No fabrications?\n4. **Narrative beats**: Are the identified beats actually present in the scene?\n5. **Tone assessment**: Does the tone description match the actual mood of the scene?\n6. **Confidence calibration**: Is the confidence score reasonable given the quality?\n\nReturn a JSON object with:\n- passed: boolean (true if the extraction is faithful, false if it has significant errors)\n- confidence: float 0-1 (your confidence in this QA judgment)\n- issues: array of objects, each with:\n  - severity: \"error\" (factual wrong), \"warning\" (misleading), or \"note\" (minor)\n  - description: what's wrong\n  - location: which field has the issue\n- summary: 1-2 sentence overall assessment\n\nBe strict: wrong character names, fabricated events, or incorrect locations are errors.\nMinor omissions or imprecise tone descriptions are warnings.\n\nReturn ONLY valid JSON. No explanations or markdown fences.\n\n==========\nORIGINAL SCENE TEXT:\nINT. RUDDY & GREEN BUILDING - ELEVATOR\n\nUB40's \"I Can't Help Falling in Love With You\" muzak.\n\nROSE (mid-30s) leans against the elevator wall, panting. She's wearing a Tim Hortons uniform, her hair is a mess, and there's blood spattered on her face.\n\nShe looks right, pants a few more times, then squints in disgust. She gingerly picks up a bloody scrap of something with hair on it. She snorts and drops it.\n\nROSE\nIs that skull??\n\nNext to her is Mariner, also panting, covered in far more blood. His face is broad, stoic, and frowning. He has gray-blue eyes and a thick, curly, beard barely streaked with gray. He wears a red knit cap and a small mask.\n\nFULL-SCREEN SUPERIMPOSED TITLE CARD: \"THE MARINER\"\n\nHe blinks a few times as a drop of blood falls from his eyebrow. He looks toward her, then spits out some blood.\n\nMARINER\nYeaaaaah...\n\nHe's built like a pro-wrestler. Moss green SWEATER stretched over his huge frame, sleeves rolled showing heavy leather BRACERS adorned with anchors. His inner forearm has a classic heart-and-arrow TATTOO with \"Dad\" in the centre. Across his chest is a BANDOLIER of bright red 12-gauge shells, FISH HOOKS hanging from the bottom edge. Heavy rubberized BOOTS go past his knees. A CAPE of heavy FISHING NET edged with WEIGHTS hangs from his shoulders.\n\nHe holds a STOUT WOODEN OAR in both hands, edged with METAL and dripping with BLOOD.\n\nROSE\nWhere were you when they grabbed me? You were supposed to pick me up at work!\n\nMARINER\nYeah, about that, I got a little... distracted.\n\nROSE\nDistracted. You got DISTRACTED?!\n\nMARINER\nI was also... tracking the car... that grabbed you... through the AirTag... I put on your phone.\n\nRose stops. She's really not happy about this.\n\nROSE\nYou Airtagged me?!\n\n==========\nEXTRACTED SCENE DATA:\n{\n  \"scene_number\": 4,\n  \"heading\": \"INT. OFFICE BUILDING - ELEVATOR\",\n  \"int_ext\": \"INT\",\n  \"location\": \"OFFICE BUILDING - ELEVATOR\",\n  \"time_of_day\": \"DAY\",\n  \"characters_present\": [\"ROSE\", \"BILLY\"],\n  \"summary\": \"Billy and Rose take the elevator in an office building. They discuss their plans for the evening. Rose mentions she needs to pick up groceries.\",\n  \"narrative_beats\": [\n    {\"beat_type\": \"exposition\", \"description\": \"Characters discuss daily plans.\", \"confidence\": 0.85}\n  ],\n  \"tone_mood\": \"casual\",\n  \"confidence\": 0.88\n}\n==========",
          "label": "prompts/qa-pass.txt: You are a QA reviewer validating whether an AI-extracted scene analysis is accurate and faithful to the source screenplay text.\n\nCompare the extracted scene data against the original scene text and evaluate:\n\n1. **Heading accuracy**: Is the scene heading correct (location, INT/EXT, time of day)?\n2. **Character completeness**: Are all characters who appear or speak listed?\n3. **Summary fidelity**: Does the summary accurately describe what happens? No fabrications?\n4. **Narrative beats**: Are the identified beats actually present in the scene?\n5. **Tone assessment**: Does the tone description match the actual mood of the scene?\n6. **Confidence calibration**: Is the confidence score reasonable given the quality?\n\nReturn a JSON object with:\n- passed: boolean (true if the extraction is faithful, false if it has significant errors)\n- confidence: float 0-1 (your confidence in this QA judgment)\n- issues: array of objects, each with:\n  - severity: \"error\" (factual wrong), \"warning\" (misleading), or \"note\" (minor)\n  - description: what's wrong\n  - location: which field has the issue\n- summary: 1-2 sentence overall assessment\n\nBe strict: wrong character names, fabricated events, or incorrect locations are errors.\nMinor omissions or imprecise tone descriptions are warnings.\n\nReturn ONLY valid JSON. No explanations or markdown fences.\n\n==========\nORIGINAL SCENE TEXT:\n{{scene_text}}\n\n==========\nEXTRACTED SCENE DATA:\n{{extracted_data}}\n==========",
          "config": {
            "provider": "anthropic:messages:claude-opus-4-6"
          }
        },
        "promptId": "8df20c2c4a6081352d6b06e144ddbc1e0a5244f9a3c2000d40df12fc9a94e543",
        "promptIdx": 0,
        "provider": {
          "id": "google:gemini-2.5-flash-lite",
          "label": "Gemini 2.5 Flash Lite"
        },
        "response": {
          "output": "```json\n{\n  \"passed\": false,\n  \"confidence\": 0.95,\n  \"issues\": [\n    {\n      \"severity\": \"error\",\n      \"description\": \"The location 'OFFICE BUILDING - ELEVATOR' is incorrect. The screenplay specifies 'RUDDY & GREEN BUILDING - ELEVATOR'.\",\n      \"location\": \"heading\"\n    },\n    {\n      \"severity\": \"error\",\n      \"description\": \"The character 'BILLY' is not present in the scene. The character 'MARINER' is present instead.\",\n      \"location\": \"characters_present\"\n    },\n    {\n      \"severity\": \"error\",\n      \"description\": \"The summary fabricates events and dialogue. The characters are not discussing plans for the evening, nor does Rose mention picking up groceries. The scene depicts Rose and Mariner after an apparent violent encounter, discussing how Rose was captured and Mariner's distraction.\",\n      \"location\": \"summary\"\n    },\n    {\n      \"severity\": \"error\",\n      \"description\": \"The identified narrative beat 'Characters discuss daily plans' is inaccurate. The scene's dialogue focuses on Rose's capture and Mariner's actions, not daily plans.\",\n      \"location\": \"narrative_beats\"\n    },\n    {\n      \"severity\": \"error\",\n      \"description\": \"The tone 'casual' is incorrect. The scene is tense and reflects the aftermath of violence, with characters panting and covered in blood.\",\n      \"location\": \"tone_mood\"\n    }\n  ],\n  \"summary\": \"The extracted scene data contains significant errors in location, character presence, summary fidelity, narrative beats, and tone, failing to accurately represent the source screenplay.\"\n}\n```",
          "tokenUsage": {
            "prompt": 963,
            "completion": 382,
            "total": 1345,
            "numRequests": 1
          },
          "cost": 0.00024910000000000004,
          "raw": {
            "candidates": [
              {
                "content": {
                  "parts": [
                    {
                      "text": "```json\n{\n  \"passed\": false,\n  \"confidence\": 0.95,\n  \"issues\": [\n    {\n      \"severity\": \"error\",\n      \"description\": \"The location 'OFFICE BUILDING - ELEVATOR' is incorrect. The screenplay specifies 'RUDDY & GREEN BUILDING - ELEVATOR'.\",\n      \"location\": \"heading\"\n    },\n    {\n      \"severity\": \"error\",\n      \"description\": \"The character 'BILLY' is not present in the scene. The character 'MARINER' is present instead.\",\n      \"location\": \"characters_present\"\n    },\n    {\n      \"severity\": \"error\",\n      \"description\": \"The summary fabricates events and dialogue. The characters are not discussing plans for the evening, nor does Rose mention picking up groceries. The scene depicts Rose and Mariner after an apparent violent encounter, discussing how Rose was captured and Mariner's distraction.\",\n      \"location\": \"summary\"\n    },\n    {\n      \"severity\": \"error\",\n      \"description\": \"The identified narrative beat 'Characters discuss daily plans' is inaccurate. The scene's dialogue focuses on Rose's capture and Mariner's actions, not daily plans.\",\n      \"location\": \"narrative_beats\"\n    },\n    {\n      \"severity\": \"error\",\n      \"description\": \"The tone 'casual' is incorrect. The scene is tense and reflects the aftermath of violence, with characters panting and covered in blood.\",\n      \"location\": \"tone_mood\"\n    }\n  ],\n  \"summary\": \"The extracted scene data contains significant errors in location, character presence, summary fidelity, narrative beats, and tone, failing to accurately represent the source screenplay.\"\n}\n```"
                    }
                  ],
                  "role": "model"
                },
                "finishReason": "STOP",
                "index": 0
              }
            ],
            "usageMetadata": {
              "promptTokenCount": 963,
              "candidatesTokenCount": 382,
              "totalTokenCount": 1345,
              "promptTokensDetails": [
                {
                  "modality": "TEXT",
                  "tokenCount": 963
                }
              ]
            },
            "modelVersion": "gemini-2.5-flash-lite",
            "responseId": "tsmVabuyMuu_qtsPlJyikQc"
          },
          "cached": false,
          "metadata": {}
        },
        "score": 0.9450000000000001,
        "success": true,
        "testCase": {
          "vars": {
            "scene_text": "file://../input/enrich-scene-elevator.txt",
            "extracted_data": "file://../input/qa-bad-scene.json",
            "golden_path": "golden/qa-pass-golden.json",
            "test_key": "bad_scene"
          },
          "assert": [
            {
              "type": "python",
              "value": "file://../scorers/qa_pass_scorer.py"
            },
            {
              "type": "llm-rubric",
              "value": "This QA evaluation was given a BAD scene extraction with multiple errors:\n- Wrong building name (Office Building vs Ruddy & Greene)\n- Wrong time of day (DAY vs NIGHT)\n- Wrong character name (Billy instead of Mariner)\n- Missing thug characters\n- Fabricated content (grocery discussion never happens)\n\nThe QA model should have:\n1. Marked it as failed (false)\n2. Identified at least 2-3 specific errors\n3. Flagged the fabricated summary content\n4. Used \"error\" severity for factual mistakes\n\nIf the model let this pass, that's a dangerous false positive.\n"
            }
          ],
          "options": {
            "provider": "anthropic:messages:claude-opus-4-6"
          },
          "metadata": {}
        },
        "testIdx": 1,
        "vars": {
          "scene_text": "file://../input/enrich-scene-elevator.txt",
          "extracted_data": "file://../input/qa-bad-scene.json",
          "golden_path": "golden/qa-pass-golden.json",
          "test_key": "bad_scene"
        },
        "metadata": {
          "_promptfooFileMetadata": {}
        },
        "failureReason": 0
      },
      {
        "cost": 0.0063964,
        "gradingResult": {
          "pass": true,
          "score": 0.925,
          "reason": "All assertions passed",
          "namedScores": {},
          "tokensUsed": {
            "total": 867,
            "prompt": 672,
            "completion": 195,
            "cached": 0,
            "numRequests": 0
          },
          "componentResults": [
            {
              "pass": true,
              "score": 1,
              "reason": "confidence_calibration=1.00 | issue_detection=1.00 | json_valid=1.00 | pass_correct=1.00 | severity_accuracy=1.00 | summary_quality=1.00",
              "assertion": {
                "type": "python",
                "value": "file://../scorers/qa_pass_scorer.py"
              }
            },
            {
              "assertion": {
                "type": "llm-rubric",
                "value": "This QA evaluation was given a BAD scene extraction with multiple errors:\n- Wrong building name (Office Building vs Ruddy & Greene)\n- Wrong time of day (DAY vs NIGHT)\n- Wrong character name (Billy instead of Mariner)\n- Missing thug characters\n- Fabricated content (grocery discussion never happens)\n\nThe QA model should have:\n1. Marked it as failed (false)\n2. Identified at least 2-3 specific errors\n3. Flagged the fabricated summary content\n4. Used \"error\" severity for factual mistakes\n\nIf the model let this pass, that's a dangerous false positive.\n"
              },
              "pass": true,
              "score": 0.85,
              "reason": "The QA evaluation correctly marked the extraction as failed (passed: false). It identified multiple specific errors: wrong character name (BILLY instead of MARINER), fabricated summary content (grocery discussion, daily plans), wrong tone (casual instead of tense/violent), and noted the building name was less specific (OFFICE BUILDING vs RUDDY & GREEN BUILDING). It used 'error' severity for factual mistakes and 'warning' for the less specific location. It also flagged the unreasonably high confidence score. The evaluation caught at least 4-5 specific errors, flagged the fabricated content, and used appropriate severity levels. While it didn't explicitly call out the wrong time of day (DAY vs NIGHT) or missing thug characters, it caught the majority of critical issues and correctly failed the extraction.",
              "tokensUsed": {
                "total": 867,
                "prompt": 672,
                "completion": 195,
                "cached": 0,
                "numRequests": 0,
                "completionDetails": {
                  "reasoning": 0,
                  "acceptedPrediction": 0,
                  "rejectedPrediction": 0
                }
              },
              "metadata": {
                "renderedGradingPrompt": "[{\"role\":\"system\",\"content\":\"You are grading output according to a user-specified rubric. If the statement in the rubric is true, then the output passes the test. You respond with a JSON object with this structure: {reason: string, pass: boolean, score: number}\\n\\nExamples:\\n\\n<Output>Hello world</Output>\\n<Rubric>Content contains a greeting</Rubric>\\n{\\\"reason\\\": \\\"the content contains the word 'Hello'\\\", \\\"pass\\\": true, \\\"score\\\": 1.0}\\n\\n<Output>Avast ye swabs, repel the invaders!</Output>\\n<Rubric>Does not speak like a pirate</Rubric>\\n{\\\"reason\\\": \\\"'avast ye' is a common pirate term\\\", \\\"pass\\\": false, \\\"score\\\": 0.0}\"},{\"role\":\"user\",\"content\":\"<Output>\\n{\\\"passed\\\":false,\\\"confidence\\\":1,\\\"issues\\\":[{\\\"severity\\\":\\\"error\\\",\\\"description\\\":\\\"Character 'BILLY' is incorrect; the character's name is 'MARINER'.\\\",\\\"location\\\":\\\"characters_present\\\"},{\\\"severity\\\":\\\"error\\\",\\\"description\\\":\\\"The summary is almost entirely fabricated, inventing events like 'discuss their plans for the evening' and 'needs to pick up groceries', while completely omitting the core events of blood, abduction, and the AirTag revelation.\\\",\\\"location\\\":\\\"summary\\\"},{\\\"severity\\\":\\\"error\\\",\\\"description\\\":\\\"The narrative beat description 'Characters discuss daily plans' is incorrect and misrepresents the scene's actual conflict and revelations.\\\",\\\"location\\\":\\\"narrative_beats\\\"},{\\\"severity\\\":\\\"error\\\",\\\"description\\\":\\\"The tone 'casual' is a severe misidentification; the scene is tense, violent, and confrontational.\\\",\\\"location\\\":\\\"tone_mood\\\"},{\\\"severity\\\":\\\"error\\\",\\\"description\\\":\\\"The overall confidence score of 0.88 is unreasonably high given the numerous and severe factual errors in the extraction.\\\",\\\"location\\\":\\\"confidence\\\"},{\\\"severity\\\":\\\"warning\\\",\\\"description\\\":\\\"The location 'OFFICE BUILDING' is less specific than the original 'RUDDY & GREEN BUILDING'.\\\",\\\"location\\\":\\\"heading, location\\\"}],\\\"summary\\\":\\\"The extracted scene data contains multiple severe errors, including an incorrect character name, a completely fabricated summary, a misidentified narrative beat, and an entirely wrong tone. The high confidence score is unwarranted given these inaccuracies.\\\"}\\n</Output>\\n<Rubric>\\nThis QA evaluation was given a BAD scene extraction with multiple errors:\\n- Wrong building name (Office Building vs Ruddy & Greene)\\n- Wrong time of day (DAY vs NIGHT)\\n- Wrong character name (Billy instead of Mariner)\\n- Missing thug characters\\n- Fabricated content (grocery discussion never happens)\\n\\nThe QA model should have:\\n1. Marked it as failed (false)\\n2. Identified at least 2-3 specific errors\\n3. Flagged the fabricated summary content\\n4. Used \\\"error\\\" severity for factual mistakes\\n\\nIf the model let this pass, that's a dangerous false positive.\\n\\n</Rubric>\"}]"
              }
            }
          ]
        },
        "id": "c0f76a4e-79f9-4cc3-be1d-06d62d7e571d",
        "latencyMs": 10860,
        "namedScores": {},
        "prompt": {
          "raw": "You are a QA reviewer validating whether an AI-extracted scene analysis is accurate and faithful to the source screenplay text.\n\nCompare the extracted scene data against the original scene text and evaluate:\n\n1. **Heading accuracy**: Is the scene heading correct (location, INT/EXT, time of day)?\n2. **Character completeness**: Are all characters who appear or speak listed?\n3. **Summary fidelity**: Does the summary accurately describe what happens? No fabrications?\n4. **Narrative beats**: Are the identified beats actually present in the scene?\n5. **Tone assessment**: Does the tone description match the actual mood of the scene?\n6. **Confidence calibration**: Is the confidence score reasonable given the quality?\n\nReturn a JSON object with:\n- passed: boolean (true if the extraction is faithful, false if it has significant errors)\n- confidence: float 0-1 (your confidence in this QA judgment)\n- issues: array of objects, each with:\n  - severity: \"error\" (factual wrong), \"warning\" (misleading), or \"note\" (minor)\n  - description: what's wrong\n  - location: which field has the issue\n- summary: 1-2 sentence overall assessment\n\nBe strict: wrong character names, fabricated events, or incorrect locations are errors.\nMinor omissions or imprecise tone descriptions are warnings.\n\nReturn ONLY valid JSON. No explanations or markdown fences.\n\n==========\nORIGINAL SCENE TEXT:\nINT. RUDDY & GREEN BUILDING - ELEVATOR\n\nUB40's \"I Can't Help Falling in Love With You\" muzak.\n\nROSE (mid-30s) leans against the elevator wall, panting. She's wearing a Tim Hortons uniform, her hair is a mess, and there's blood spattered on her face.\n\nShe looks right, pants a few more times, then squints in disgust. She gingerly picks up a bloody scrap of something with hair on it. She snorts and drops it.\n\nROSE\nIs that skull??\n\nNext to her is Mariner, also panting, covered in far more blood. His face is broad, stoic, and frowning. He has gray-blue eyes and a thick, curly, beard barely streaked with gray. He wears a red knit cap and a small mask.\n\nFULL-SCREEN SUPERIMPOSED TITLE CARD: \"THE MARINER\"\n\nHe blinks a few times as a drop of blood falls from his eyebrow. He looks toward her, then spits out some blood.\n\nMARINER\nYeaaaaah...\n\nHe's built like a pro-wrestler. Moss green SWEATER stretched over his huge frame, sleeves rolled showing heavy leather BRACERS adorned with anchors. His inner forearm has a classic heart-and-arrow TATTOO with \"Dad\" in the centre. Across his chest is a BANDOLIER of bright red 12-gauge shells, FISH HOOKS hanging from the bottom edge. Heavy rubberized BOOTS go past his knees. A CAPE of heavy FISHING NET edged with WEIGHTS hangs from his shoulders.\n\nHe holds a STOUT WOODEN OAR in both hands, edged with METAL and dripping with BLOOD.\n\nROSE\nWhere were you when they grabbed me? You were supposed to pick me up at work!\n\nMARINER\nYeah, about that, I got a little... distracted.\n\nROSE\nDistracted. You got DISTRACTED?!\n\nMARINER\nI was also... tracking the car... that grabbed you... through the AirTag... I put on your phone.\n\nRose stops. She's really not happy about this.\n\nROSE\nYou Airtagged me?!\n\n==========\nEXTRACTED SCENE DATA:\n{\n  \"scene_number\": 4,\n  \"heading\": \"INT. OFFICE BUILDING - ELEVATOR\",\n  \"int_ext\": \"INT\",\n  \"location\": \"OFFICE BUILDING - ELEVATOR\",\n  \"time_of_day\": \"DAY\",\n  \"characters_present\": [\"ROSE\", \"BILLY\"],\n  \"summary\": \"Billy and Rose take the elevator in an office building. They discuss their plans for the evening. Rose mentions she needs to pick up groceries.\",\n  \"narrative_beats\": [\n    {\"beat_type\": \"exposition\", \"description\": \"Characters discuss daily plans.\", \"confidence\": 0.85}\n  ],\n  \"tone_mood\": \"casual\",\n  \"confidence\": 0.88\n}\n==========",
          "label": "prompts/qa-pass.txt: You are a QA reviewer validating whether an AI-extracted scene analysis is accurate and faithful to the source screenplay text.\n\nCompare the extracted scene data against the original scene text and evaluate:\n\n1. **Heading accuracy**: Is the scene heading correct (location, INT/EXT, time of day)?\n2. **Character completeness**: Are all characters who appear or speak listed?\n3. **Summary fidelity**: Does the summary accurately describe what happens? No fabrications?\n4. **Narrative beats**: Are the identified beats actually present in the scene?\n5. **Tone assessment**: Does the tone description match the actual mood of the scene?\n6. **Confidence calibration**: Is the confidence score reasonable given the quality?\n\nReturn a JSON object with:\n- passed: boolean (true if the extraction is faithful, false if it has significant errors)\n- confidence: float 0-1 (your confidence in this QA judgment)\n- issues: array of objects, each with:\n  - severity: \"error\" (factual wrong), \"warning\" (misleading), or \"note\" (minor)\n  - description: what's wrong\n  - location: which field has the issue\n- summary: 1-2 sentence overall assessment\n\nBe strict: wrong character names, fabricated events, or incorrect locations are errors.\nMinor omissions or imprecise tone descriptions are warnings.\n\nReturn ONLY valid JSON. No explanations or markdown fences.\n\n==========\nORIGINAL SCENE TEXT:\n{{scene_text}}\n\n==========\nEXTRACTED SCENE DATA:\n{{extracted_data}}\n==========",
          "config": {
            "provider": "anthropic:messages:claude-opus-4-6"
          }
        },
        "promptId": "8df20c2c4a6081352d6b06e144ddbc1e0a5244f9a3c2000d40df12fc9a94e543",
        "promptIdx": 1,
        "provider": {
          "id": "google:gemini-2.5-flash",
          "label": "Gemini 2.5 Flash"
        },
        "response": {
          "output": "{\n  \"passed\": false,\n  \"confidence\": 1.0,\n  \"issues\": [\n    {\n      \"severity\": \"error\",\n      \"description\": \"Character 'BILLY' is incorrect; the character's name is 'MARINER'.\",\n      \"location\": \"characters_present\"\n    },\n    {\n      \"severity\": \"error\",\n      \"description\": \"The summary is almost entirely fabricated, inventing events like 'discuss their plans for the evening' and 'needs to pick up groceries', while completely omitting the core events of blood, abduction, and the AirTag revelation.\",\n      \"location\": \"summary\"\n    },\n    {\n      \"severity\": \"error\",\n      \"description\": \"The narrative beat description 'Characters discuss daily plans' is incorrect and misrepresents the scene's actual conflict and revelations.\",\n      \"location\": \"narrative_beats\"\n    },\n    {\n      \"severity\": \"error\",\n      \"description\": \"The tone 'casual' is a severe misidentification; the scene is tense, violent, and confrontational.\",\n      \"location\": \"tone_mood\"\n    },\n    {\n      \"severity\": \"error\",\n      \"description\": \"The overall confidence score of 0.88 is unreasonably high given the numerous and severe factual errors in the extraction.\",\n      \"location\": \"confidence\"\n    },\n    {\n      \"severity\": \"warning\",\n      \"description\": \"The location 'OFFICE BUILDING' is less specific than the original 'RUDDY & GREEN BUILDING'.\",\n      \"location\": \"heading, location\"\n    }\n  ],\n  \"summary\": \"The extracted scene data contains multiple severe errors, including an incorrect character name, a completely fabricated summary, a misidentified narrative beat, and an entirely wrong tone. The high confidence score is unwarranted given these inaccuracies.\"\n}",
          "tokenUsage": {
            "prompt": 963,
            "completion": 408,
            "total": 3406,
            "numRequests": 1,
            "completionDetails": {
              "reasoning": 2035,
              "acceptedPrediction": 0,
              "rejectedPrediction": 0
            }
          },
          "cost": 0.0063964,
          "raw": {
            "candidates": [
              {
                "content": {
                  "parts": [
                    {
                      "text": "{\n  \"passed\": false,\n  \"confidence\": 1.0,\n  \"issues\": [\n    {\n      \"severity\": \"error\",\n      \"description\": \"Character 'BILLY' is incorrect; the character's name is 'MARINER'.\",\n      \"location\": \"characters_present\"\n    },\n    {\n      \"severity\": \"error\",\n      \"description\": \"The summary is almost entirely fabricated, inventing events like 'discuss their plans for the evening' and 'needs to pick up groceries', while completely omitting the core events of blood, abduction, and the AirTag revelation.\",\n      \"location\": \"summary\"\n    },\n    {\n      \"severity\": \"error\",\n      \"description\": \"The narrative beat description 'Characters discuss daily plans' is incorrect and misrepresents the scene's actual conflict and revelations.\",\n      \"location\": \"narrative_beats\"\n    },\n    {\n      \"severity\": \"error\",\n      \"description\": \"The tone 'casual' is a severe misidentification; the scene is tense, violent, and confrontational.\",\n      \"location\": \"tone_mood\"\n    },\n    {\n      \"severity\": \"error\",\n      \"description\": \"The overall confidence score of 0.88 is unreasonably high given the numerous and severe factual errors in the extraction.\",\n      \"location\": \"confidence\"\n    },\n    {\n      \"severity\": \"warning\",\n      \"description\": \"The location 'OFFICE BUILDING' is less specific than the original 'RUDDY & GREEN BUILDING'.\",\n      \"location\": \"heading, location\"\n    }\n  ],\n  \"summary\": \"The extracted scene data contains multiple severe errors, including an incorrect character name, a completely fabricated summary, a misidentified narrative beat, and an entirely wrong tone. The high confidence score is unwarranted given these inaccuracies.\"\n}"
                    }
                  ],
                  "role": "model"
                },
                "finishReason": "STOP",
                "index": 0
              }
            ],
            "usageMetadata": {
              "promptTokenCount": 963,
              "candidatesTokenCount": 408,
              "totalTokenCount": 3406,
              "promptTokensDetails": [
                {
                  "modality": "TEXT",
                  "tokenCount": 963
                }
              ],
              "thoughtsTokenCount": 2035
            },
            "modelVersion": "gemini-2.5-flash",
            "responseId": "vcmVaf7eJq-O6dkPk8LI0AQ"
          },
          "cached": false,
          "metadata": {}
        },
        "score": 0.925,
        "success": true,
        "testCase": {
          "vars": {
            "scene_text": "file://../input/enrich-scene-elevator.txt",
            "extracted_data": "file://../input/qa-bad-scene.json",
            "golden_path": "golden/qa-pass-golden.json",
            "test_key": "bad_scene"
          },
          "assert": [
            {
              "type": "python",
              "value": "file://../scorers/qa_pass_scorer.py"
            },
            {
              "type": "llm-rubric",
              "value": "This QA evaluation was given a BAD scene extraction with multiple errors:\n- Wrong building name (Office Building vs Ruddy & Greene)\n- Wrong time of day (DAY vs NIGHT)\n- Wrong character name (Billy instead of Mariner)\n- Missing thug characters\n- Fabricated content (grocery discussion never happens)\n\nThe QA model should have:\n1. Marked it as failed (false)\n2. Identified at least 2-3 specific errors\n3. Flagged the fabricated summary content\n4. Used \"error\" severity for factual mistakes\n\nIf the model let this pass, that's a dangerous false positive.\n"
            }
          ],
          "options": {
            "provider": "anthropic:messages:claude-opus-4-6"
          },
          "metadata": {}
        },
        "testIdx": 1,
        "vars": {
          "scene_text": "file://../input/enrich-scene-elevator.txt",
          "extracted_data": "file://../input/qa-bad-scene.json",
          "golden_path": "golden/qa-pass-golden.json",
          "test_key": "bad_scene"
        },
        "metadata": {
          "_promptfooFileMetadata": {}
        },
        "failureReason": 0
      },
      {
        "cost": 0.0038595,
        "gradingResult": {
          "pass": true,
          "score": 1,
          "reason": "All assertions passed",
          "namedScores": {},
          "tokensUsed": {
            "total": 741,
            "prompt": 597,
            "completion": 144,
            "cached": 0,
            "numRequests": 0
          },
          "componentResults": [
            {
              "pass": true,
              "score": 1,
              "reason": "confidence_calibration=1.00 | issue_detection=1.00 | json_valid=1.00 | pass_correct=1.00 | severity_accuracy=1.00 | summary_quality=1.00",
              "assertion": {
                "type": "python",
                "value": "file://../scorers/qa_pass_scorer.py"
              }
            },
            {
              "assertion": {
                "type": "llm-rubric",
                "value": "This QA evaluation was given a BAD scene extraction with multiple errors:\n- Wrong building name (Office Building vs Ruddy & Greene)\n- Wrong time of day (DAY vs NIGHT)\n- Wrong character name (Billy instead of Mariner)\n- Missing thug characters\n- Fabricated content (grocery discussion never happens)\n\nThe QA model should have:\n1. Marked it as failed (false)\n2. Identified at least 2-3 specific errors\n3. Flagged the fabricated summary content\n4. Used \"error\" severity for factual mistakes\n\nIf the model let this pass, that's a dangerous false positive.\n"
              },
              "pass": true,
              "score": 1,
              "reason": "The QA evaluation correctly identified the extraction as failed (passed: false). It flagged multiple specific errors: the hallucinated character name 'BILLY' instead of 'MARINER', the entirely fabricated summary about groceries, fabricated narrative beats, incorrect tone, and the imprecise location. It identified at least 4-5 specific errors, flagged the fabricated summary content explicitly, and used 'error' severity for factual mistakes and 'warning' for the less critical location issue. This is not a false positive — the model correctly caught the bad extraction.",
              "tokensUsed": {
                "total": 741,
                "prompt": 597,
                "completion": 144,
                "cached": 0,
                "numRequests": 0,
                "completionDetails": {
                  "reasoning": 0,
                  "acceptedPrediction": 0,
                  "rejectedPrediction": 0
                }
              },
              "metadata": {
                "renderedGradingPrompt": "[{\"role\":\"system\",\"content\":\"You are grading output according to a user-specified rubric. If the statement in the rubric is true, then the output passes the test. You respond with a JSON object with this structure: {reason: string, pass: boolean, score: number}\\n\\nExamples:\\n\\n<Output>Hello world</Output>\\n<Rubric>Content contains a greeting</Rubric>\\n{\\\"reason\\\": \\\"the content contains the word 'Hello'\\\", \\\"pass\\\": true, \\\"score\\\": 1.0}\\n\\n<Output>Avast ye swabs, repel the invaders!</Output>\\n<Rubric>Does not speak like a pirate</Rubric>\\n{\\\"reason\\\": \\\"'avast ye' is a common pirate term\\\", \\\"pass\\\": false, \\\"score\\\": 0.0}\"},{\"role\":\"user\",\"content\":\"<Output>\\n{\\\"passed\\\":false,\\\"confidence\\\":1,\\\"issues\\\":[{\\\"severity\\\":\\\"error\\\",\\\"description\\\":\\\"Character 'BILLY' is a hallucination; the character in the scene is 'MARINER'.\\\",\\\"location\\\":\\\"characters_present\\\"},{\\\"severity\\\":\\\"error\\\",\\\"description\\\":\\\"The summary is entirely fabricated. The scene depicts two blood-covered characters discussing a kidnapping and an AirTag, not groceries or evening plans.\\\",\\\"location\\\":\\\"summary\\\"},{\\\"severity\\\":\\\"error\\\",\\\"description\\\":\\\"The narrative beats are fabricated and do not reflect the actual dialogue or actions in the script.\\\",\\\"location\\\":\\\"narrative_beats\\\"},{\\\"severity\\\":\\\"error\\\",\\\"description\\\":\\\"The tone 'casual' is inaccurate for a scene involving blood, skull fragments, and a heated confrontation.\\\",\\\"location\\\":\\\"tone_mood\\\"},{\\\"severity\\\":\\\"warning\\\",\\\"description\\\":\\\"The location 'OFFICE BUILDING' is an imprecise genericization of 'RUDDY & GREEN BUILDING'.\\\",\\\"location\\\":\\\"location\\\"}],\\\"summary\\\":\\\"The extraction is completely unfaithful to the source text, featuring a hallucinated character name and a summary that bears no resemblance to the actual events of the scene.\\\"}\\n</Output>\\n<Rubric>\\nThis QA evaluation was given a BAD scene extraction with multiple errors:\\n- Wrong building name (Office Building vs Ruddy & Greene)\\n- Wrong time of day (DAY vs NIGHT)\\n- Wrong character name (Billy instead of Mariner)\\n- Missing thug characters\\n- Fabricated content (grocery discussion never happens)\\n\\nThe QA model should have:\\n1. Marked it as failed (false)\\n2. Identified at least 2-3 specific errors\\n3. Flagged the fabricated summary content\\n4. Used \\\"error\\\" severity for factual mistakes\\n\\nIf the model let this pass, that's a dangerous false positive.\\n\\n</Rubric>\"}]"
              }
            }
          ]
        },
        "id": "02fd5497-8fca-43a0-9c80-0ccc31bb0cf6",
        "latencyMs": 7154,
        "namedScores": {},
        "prompt": {
          "raw": "You are a QA reviewer validating whether an AI-extracted scene analysis is accurate and faithful to the source screenplay text.\n\nCompare the extracted scene data against the original scene text and evaluate:\n\n1. **Heading accuracy**: Is the scene heading correct (location, INT/EXT, time of day)?\n2. **Character completeness**: Are all characters who appear or speak listed?\n3. **Summary fidelity**: Does the summary accurately describe what happens? No fabrications?\n4. **Narrative beats**: Are the identified beats actually present in the scene?\n5. **Tone assessment**: Does the tone description match the actual mood of the scene?\n6. **Confidence calibration**: Is the confidence score reasonable given the quality?\n\nReturn a JSON object with:\n- passed: boolean (true if the extraction is faithful, false if it has significant errors)\n- confidence: float 0-1 (your confidence in this QA judgment)\n- issues: array of objects, each with:\n  - severity: \"error\" (factual wrong), \"warning\" (misleading), or \"note\" (minor)\n  - description: what's wrong\n  - location: which field has the issue\n- summary: 1-2 sentence overall assessment\n\nBe strict: wrong character names, fabricated events, or incorrect locations are errors.\nMinor omissions or imprecise tone descriptions are warnings.\n\nReturn ONLY valid JSON. No explanations or markdown fences.\n\n==========\nORIGINAL SCENE TEXT:\nINT. RUDDY & GREEN BUILDING - ELEVATOR\n\nUB40's \"I Can't Help Falling in Love With You\" muzak.\n\nROSE (mid-30s) leans against the elevator wall, panting. She's wearing a Tim Hortons uniform, her hair is a mess, and there's blood spattered on her face.\n\nShe looks right, pants a few more times, then squints in disgust. She gingerly picks up a bloody scrap of something with hair on it. She snorts and drops it.\n\nROSE\nIs that skull??\n\nNext to her is Mariner, also panting, covered in far more blood. His face is broad, stoic, and frowning. He has gray-blue eyes and a thick, curly, beard barely streaked with gray. He wears a red knit cap and a small mask.\n\nFULL-SCREEN SUPERIMPOSED TITLE CARD: \"THE MARINER\"\n\nHe blinks a few times as a drop of blood falls from his eyebrow. He looks toward her, then spits out some blood.\n\nMARINER\nYeaaaaah...\n\nHe's built like a pro-wrestler. Moss green SWEATER stretched over his huge frame, sleeves rolled showing heavy leather BRACERS adorned with anchors. His inner forearm has a classic heart-and-arrow TATTOO with \"Dad\" in the centre. Across his chest is a BANDOLIER of bright red 12-gauge shells, FISH HOOKS hanging from the bottom edge. Heavy rubberized BOOTS go past his knees. A CAPE of heavy FISHING NET edged with WEIGHTS hangs from his shoulders.\n\nHe holds a STOUT WOODEN OAR in both hands, edged with METAL and dripping with BLOOD.\n\nROSE\nWhere were you when they grabbed me? You were supposed to pick me up at work!\n\nMARINER\nYeah, about that, I got a little... distracted.\n\nROSE\nDistracted. You got DISTRACTED?!\n\nMARINER\nI was also... tracking the car... that grabbed you... through the AirTag... I put on your phone.\n\nRose stops. She's really not happy about this.\n\nROSE\nYou Airtagged me?!\n\n==========\nEXTRACTED SCENE DATA:\n{\n  \"scene_number\": 4,\n  \"heading\": \"INT. OFFICE BUILDING - ELEVATOR\",\n  \"int_ext\": \"INT\",\n  \"location\": \"OFFICE BUILDING - ELEVATOR\",\n  \"time_of_day\": \"DAY\",\n  \"characters_present\": [\"ROSE\", \"BILLY\"],\n  \"summary\": \"Billy and Rose take the elevator in an office building. They discuss their plans for the evening. Rose mentions she needs to pick up groceries.\",\n  \"narrative_beats\": [\n    {\"beat_type\": \"exposition\", \"description\": \"Characters discuss daily plans.\", \"confidence\": 0.85}\n  ],\n  \"tone_mood\": \"casual\",\n  \"confidence\": 0.88\n}\n==========",
          "label": "prompts/qa-pass.txt: You are a QA reviewer validating whether an AI-extracted scene analysis is accurate and faithful to the source screenplay text.\n\nCompare the extracted scene data against the original scene text and evaluate:\n\n1. **Heading accuracy**: Is the scene heading correct (location, INT/EXT, time of day)?\n2. **Character completeness**: Are all characters who appear or speak listed?\n3. **Summary fidelity**: Does the summary accurately describe what happens? No fabrications?\n4. **Narrative beats**: Are the identified beats actually present in the scene?\n5. **Tone assessment**: Does the tone description match the actual mood of the scene?\n6. **Confidence calibration**: Is the confidence score reasonable given the quality?\n\nReturn a JSON object with:\n- passed: boolean (true if the extraction is faithful, false if it has significant errors)\n- confidence: float 0-1 (your confidence in this QA judgment)\n- issues: array of objects, each with:\n  - severity: \"error\" (factual wrong), \"warning\" (misleading), or \"note\" (minor)\n  - description: what's wrong\n  - location: which field has the issue\n- summary: 1-2 sentence overall assessment\n\nBe strict: wrong character names, fabricated events, or incorrect locations are errors.\nMinor omissions or imprecise tone descriptions are warnings.\n\nReturn ONLY valid JSON. No explanations or markdown fences.\n\n==========\nORIGINAL SCENE TEXT:\n{{scene_text}}\n\n==========\nEXTRACTED SCENE DATA:\n{{extracted_data}}\n==========",
          "config": {
            "provider": "anthropic:messages:claude-opus-4-6"
          }
        },
        "promptId": "8df20c2c4a6081352d6b06e144ddbc1e0a5244f9a3c2000d40df12fc9a94e543",
        "promptIdx": 2,
        "provider": {
          "id": "google:gemini-3-flash-preview",
          "label": "Gemini 3 Flash"
        },
        "response": {
          "output": "{\n  \"passed\": false,\n  \"confidence\": 1.0,\n  \"issues\": [\n    {\n      \"severity\": \"error\",\n      \"description\": \"Character 'BILLY' is a hallucination; the character in the scene is 'MARINER'.\",\n      \"location\": \"characters_present\"\n    },\n    {\n      \"severity\": \"error\",\n      \"description\": \"The summary is entirely fabricated. The scene depicts two blood-covered characters discussing a kidnapping and an AirTag, not groceries or evening plans.\",\n      \"location\": \"summary\"\n    },\n    {\n      \"severity\": \"error\",\n      \"description\": \"The narrative beats are fabricated and do not reflect the actual dialogue or actions in the script.\",\n      \"location\": \"narrative_beats\"\n    },\n    {\n      \"severity\": \"error\",\n      \"description\": \"The tone 'casual' is inaccurate for a scene involving blood, skull fragments, and a heated confrontation.\",\n      \"location\": \"tone_mood\"\n    },\n    {\n      \"severity\": \"warning\",\n      \"description\": \"The location 'OFFICE BUILDING' is an imprecise genericization of 'RUDDY & GREEN BUILDING'.\",\n      \"location\": \"location\"\n    }\n  ],\n  \"summary\": \"The extraction is completely unfaithful to the source text, featuring a hallucinated character name and a summary that bears no resemblance to the actual events of the scene.\"\n}",
          "tokenUsage": {
            "prompt": 963,
            "completion": 324,
            "total": 2089,
            "numRequests": 1,
            "completionDetails": {
              "reasoning": 802,
              "acceptedPrediction": 0,
              "rejectedPrediction": 0
            }
          },
          "cost": 0.0038595,
          "raw": {
            "candidates": [
              {
                "content": {
                  "parts": [
                    {
                      "text": "{\n  \"passed\": false,\n  \"confidence\": 1.0,\n  \"issues\": [\n    {\n      \"severity\": \"error\",\n      \"description\": \"Character 'BILLY' is a hallucination; the character in the scene is 'MARINER'.\",\n      \"location\": \"characters_present\"\n    },\n    {\n      \"severity\": \"error\",\n      \"description\": \"The summary is entirely fabricated. The scene depicts two blood-covered characters discussing a kidnapping and an AirTag, not groceries or evening plans.\",\n      \"location\": \"summary\"\n    },\n    {\n      \"severity\": \"error\",\n      \"description\": \"The narrative beats are fabricated and do not reflect the actual dialogue or actions in the script.\",\n      \"location\": \"narrative_beats\"\n    },\n    {\n      \"severity\": \"error\",\n      \"description\": \"The tone 'casual' is inaccurate for a scene involving blood, skull fragments, and a heated confrontation.\",\n      \"location\": \"tone_mood\"\n    },\n    {\n      \"severity\": \"warning\",\n      \"description\": \"The location 'OFFICE BUILDING' is an imprecise genericization of 'RUDDY & GREEN BUILDING'.\",\n      \"location\": \"location\"\n    }\n  ],\n  \"summary\": \"The extraction is completely unfaithful to the source text, featuring a hallucinated character name and a summary that bears no resemblance to the actual events of the scene.\"\n}",
                      "thoughtSignature": "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"
                    }
                  ],
                  "role": "model"
                },
                "finishReason": "STOP",
                "index": 0
              }
            ],
            "usageMetadata": {
              "promptTokenCount": 963,
              "candidatesTokenCount": 324,
              "totalTokenCount": 2089,
              "promptTokensDetails": [
                {
                  "modality": "TEXT",
                  "tokenCount": 963
                }
              ],
              "thoughtsTokenCount": 802
            },
            "modelVersion": "gemini-3-flash-preview",
            "responseId": "1cmVaaC-NMG6qtsPkJyJ6Qw"
          },
          "cached": false,
          "metadata": {}
        },
        "score": 1,
        "success": true,
        "testCase": {
          "vars": {
            "scene_text": "file://../input/enrich-scene-elevator.txt",
            "extracted_data": "file://../input/qa-bad-scene.json",
            "golden_path": "golden/qa-pass-golden.json",
            "test_key": "bad_scene"
          },
          "assert": [
            {
              "type": "python",
              "value": "file://../scorers/qa_pass_scorer.py"
            },
            {
              "type": "llm-rubric",
              "value": "This QA evaluation was given a BAD scene extraction with multiple errors:\n- Wrong building name (Office Building vs Ruddy & Greene)\n- Wrong time of day (DAY vs NIGHT)\n- Wrong character name (Billy instead of Mariner)\n- Missing thug characters\n- Fabricated content (grocery discussion never happens)\n\nThe QA model should have:\n1. Marked it as failed (false)\n2. Identified at least 2-3 specific errors\n3. Flagged the fabricated summary content\n4. Used \"error\" severity for factual mistakes\n\nIf the model let this pass, that's a dangerous false positive.\n"
            }
          ],
          "options": {
            "provider": "anthropic:messages:claude-opus-4-6"
          },
          "metadata": {}
        },
        "testIdx": 1,
        "vars": {
          "scene_text": "file://../input/enrich-scene-elevator.txt",
          "extracted_data": "file://../input/qa-bad-scene.json",
          "golden_path": "golden/qa-pass-golden.json",
          "test_key": "bad_scene"
        },
        "metadata": {
          "_promptfooFileMetadata": {}
        },
        "failureReason": 0
      },
      {
        "cost": 0.015633750000000002,
        "gradingResult": {
          "pass": true,
          "score": 0.995,
          "reason": "All assertions passed",
          "namedScores": {},
          "tokensUsed": {
            "total": 969,
            "prompt": 814,
            "completion": 155,
            "cached": 0,
            "numRequests": 0
          },
          "componentResults": [
            {
              "pass": true,
              "score": 0.99,
              "reason": "confidence_calibration=1.00 | issue_detection=1.00 | json_valid=0.90 | pass_correct=1.00 | severity_accuracy=1.00 | summary_quality=1.00 | JSON extracted from code block",
              "assertion": {
                "type": "python",
                "value": "file://../scorers/qa_pass_scorer.py"
              }
            },
            {
              "assertion": {
                "type": "llm-rubric",
                "value": "This QA evaluation was given a BAD scene extraction with multiple errors:\n- Wrong building name (Office Building vs Ruddy & Greene)\n- Wrong time of day (DAY vs NIGHT)\n- Wrong character name (Billy instead of Mariner)\n- Missing thug characters\n- Fabricated content (grocery discussion never happens)\n\nThe QA model should have:\n1. Marked it as failed (false)\n2. Identified at least 2-3 specific errors\n3. Flagged the fabricated summary content\n4. Used \"error\" severity for factual mistakes\n\nIf the model let this pass, that's a dangerous false positive.\n"
              },
              "pass": true,
              "score": 1,
              "reason": "The QA evaluation correctly identified the extraction as failed (passed: false). It identified multiple specific errors including: wrong building name (RUDDY & GREEN vs OFFICE BUILDING), wrong time of day (DAY fabricated), wrong character name (MARINER vs BILLY), fabricated summary content (casual conversation about groceries vs post-violence confrontation), fabricated narrative beats, and incorrect tone. All factual mistakes were appropriately flagged with 'error' severity. It also noted the miscalibrated confidence score. This is a thorough and accurate QA evaluation that caught all the major issues and did not produce a false positive.",
              "tokensUsed": {
                "total": 969,
                "prompt": 814,
                "completion": 155,
                "cached": 0,
                "numRequests": 0,
                "completionDetails": {
                  "reasoning": 0,
                  "acceptedPrediction": 0,
                  "rejectedPrediction": 0
                }
              },
              "metadata": {
                "renderedGradingPrompt": "[{\"role\":\"system\",\"content\":\"You are grading output according to a user-specified rubric. If the statement in the rubric is true, then the output passes the test. You respond with a JSON object with this structure: {reason: string, pass: boolean, score: number}\\n\\nExamples:\\n\\n<Output>Hello world</Output>\\n<Rubric>Content contains a greeting</Rubric>\\n{\\\"reason\\\": \\\"the content contains the word 'Hello'\\\", \\\"pass\\\": true, \\\"score\\\": 1.0}\\n\\n<Output>Avast ye swabs, repel the invaders!</Output>\\n<Rubric>Does not speak like a pirate</Rubric>\\n{\\\"reason\\\": \\\"'avast ye' is a common pirate term\\\", \\\"pass\\\": false, \\\"score\\\": 0.0}\"},{\"role\":\"user\",\"content\":\"<Output>\\n```json\\n{\\n  \\\"passed\\\": false,\\n  \\\"confidence\\\": 1.0,\\n  \\\"issues\\\": [\\n    {\\n      \\\"severity\\\": \\\"error\\\",\\n      \\\"description\\\": \\\"Scene location 'RUDDY & GREEN BUILDING' was incorrectly generalized to 'OFFICE BUILDING'.\\\",\\n      \\\"location\\\": \\\"heading\\\"\\n    },\\n    {\\n      \\\"severity\\\": \\\"error\\\",\\n      \\\"description\\\": \\\"Time of day 'DAY' was fabricated; it is not specified in the scene text.\\\",\\n      \\\"location\\\": \\\"time_of_day\\\"\\n    },\\n    {\\n      \\\"severity\\\": \\\"error\\\",\\n      \\\"description\\\": \\\"Character 'MARINER' is incorrectly identified as 'BILLY'.\\\",\\n      \\\"location\\\": \\\"characters_present\\\"\\n    },\\n    {\\n      \\\"severity\\\": \\\"error\\\",\\n      \\\"description\\\": \\\"The summary is a complete fabrication. It invents a casual conversation about evening plans and groceries, ignoring the actual post-violence confrontation, blood, and argument about an AirTag.\\\",\\n      \\\"location\\\": \\\"summary\\\"\\n    },\\n    {\\n      \\\"severity\\\": \\\"error\\\",\\n      \\\"description\\\": \\\"The narrative beat 'Characters discuss daily plans' is fabricated and does not occur in the scene.\\\",\\n      \\\"location\\\": \\\"narrative_beats\\\"\\n    },\\n    {\\n      \\\"severity\\\": \\\"error\\\",\\n      \\\"description\\\": \\\"The tone is incorrectly identified as 'casual'. The scene is tense, confrontational, and post-violent.\\\",\\n      \\\"location\\\": \\\"tone_mood\\\"\\n    },\\n    {\\n      \\\"severity\\\": \\\"warning\\\",\\n      \\\"description\\\": \\\"The confidence score of 0.88 is severely miscalibrated, as the extraction is almost entirely incorrect.\\\",\\n      \\\"location\\\": \\\"confidence\\\"\\n    }\\n  ],\\n  \\\"summary\\\": \\\"The extraction is a complete failure, fabricating nearly every detail including character names, the summary of events, narrative beats, and the overall tone. It bears no resemblance to the source text.\\\"\\n}\\n```\\n</Output>\\n<Rubric>\\nThis QA evaluation was given a BAD scene extraction with multiple errors:\\n- Wrong building name (Office Building vs Ruddy & Greene)\\n- Wrong time of day (DAY vs NIGHT)\\n- Wrong character name (Billy instead of Mariner)\\n- Missing thug characters\\n- Fabricated content (grocery discussion never happens)\\n\\nThe QA model should have:\\n1. Marked it as failed (false)\\n2. Identified at least 2-3 specific errors\\n3. Flagged the fabricated summary content\\n4. Used \\\"error\\\" severity for factual mistakes\\n\\nIf the model let this pass, that's a dangerous false positive.\\n\\n</Rubric>\"}]"
              }
            }
          ]
        },
        "id": "a846730a-b6a4-4aea-a4dd-a2b805dcfb7b",
        "latencyMs": 12897,
        "namedScores": {},
        "prompt": {
          "raw": "You are a QA reviewer validating whether an AI-extracted scene analysis is accurate and faithful to the source screenplay text.\n\nCompare the extracted scene data against the original scene text and evaluate:\n\n1. **Heading accuracy**: Is the scene heading correct (location, INT/EXT, time of day)?\n2. **Character completeness**: Are all characters who appear or speak listed?\n3. **Summary fidelity**: Does the summary accurately describe what happens? No fabrications?\n4. **Narrative beats**: Are the identified beats actually present in the scene?\n5. **Tone assessment**: Does the tone description match the actual mood of the scene?\n6. **Confidence calibration**: Is the confidence score reasonable given the quality?\n\nReturn a JSON object with:\n- passed: boolean (true if the extraction is faithful, false if it has significant errors)\n- confidence: float 0-1 (your confidence in this QA judgment)\n- issues: array of objects, each with:\n  - severity: \"error\" (factual wrong), \"warning\" (misleading), or \"note\" (minor)\n  - description: what's wrong\n  - location: which field has the issue\n- summary: 1-2 sentence overall assessment\n\nBe strict: wrong character names, fabricated events, or incorrect locations are errors.\nMinor omissions or imprecise tone descriptions are warnings.\n\nReturn ONLY valid JSON. No explanations or markdown fences.\n\n==========\nORIGINAL SCENE TEXT:\nINT. RUDDY & GREEN BUILDING - ELEVATOR\n\nUB40's \"I Can't Help Falling in Love With You\" muzak.\n\nROSE (mid-30s) leans against the elevator wall, panting. She's wearing a Tim Hortons uniform, her hair is a mess, and there's blood spattered on her face.\n\nShe looks right, pants a few more times, then squints in disgust. She gingerly picks up a bloody scrap of something with hair on it. She snorts and drops it.\n\nROSE\nIs that skull??\n\nNext to her is Mariner, also panting, covered in far more blood. His face is broad, stoic, and frowning. He has gray-blue eyes and a thick, curly, beard barely streaked with gray. He wears a red knit cap and a small mask.\n\nFULL-SCREEN SUPERIMPOSED TITLE CARD: \"THE MARINER\"\n\nHe blinks a few times as a drop of blood falls from his eyebrow. He looks toward her, then spits out some blood.\n\nMARINER\nYeaaaaah...\n\nHe's built like a pro-wrestler. Moss green SWEATER stretched over his huge frame, sleeves rolled showing heavy leather BRACERS adorned with anchors. His inner forearm has a classic heart-and-arrow TATTOO with \"Dad\" in the centre. Across his chest is a BANDOLIER of bright red 12-gauge shells, FISH HOOKS hanging from the bottom edge. Heavy rubberized BOOTS go past his knees. A CAPE of heavy FISHING NET edged with WEIGHTS hangs from his shoulders.\n\nHe holds a STOUT WOODEN OAR in both hands, edged with METAL and dripping with BLOOD.\n\nROSE\nWhere were you when they grabbed me? You were supposed to pick me up at work!\n\nMARINER\nYeah, about that, I got a little... distracted.\n\nROSE\nDistracted. You got DISTRACTED?!\n\nMARINER\nI was also... tracking the car... that grabbed you... through the AirTag... I put on your phone.\n\nRose stops. She's really not happy about this.\n\nROSE\nYou Airtagged me?!\n\n==========\nEXTRACTED SCENE DATA:\n{\n  \"scene_number\": 4,\n  \"heading\": \"INT. OFFICE BUILDING - ELEVATOR\",\n  \"int_ext\": \"INT\",\n  \"location\": \"OFFICE BUILDING - ELEVATOR\",\n  \"time_of_day\": \"DAY\",\n  \"characters_present\": [\"ROSE\", \"BILLY\"],\n  \"summary\": \"Billy and Rose take the elevator in an office building. They discuss their plans for the evening. Rose mentions she needs to pick up groceries.\",\n  \"narrative_beats\": [\n    {\"beat_type\": \"exposition\", \"description\": \"Characters discuss daily plans.\", \"confidence\": 0.85}\n  ],\n  \"tone_mood\": \"casual\",\n  \"confidence\": 0.88\n}\n==========",
          "label": "prompts/qa-pass.txt: You are a QA reviewer validating whether an AI-extracted scene analysis is accurate and faithful to the source screenplay text.\n\nCompare the extracted scene data against the original scene text and evaluate:\n\n1. **Heading accuracy**: Is the scene heading correct (location, INT/EXT, time of day)?\n2. **Character completeness**: Are all characters who appear or speak listed?\n3. **Summary fidelity**: Does the summary accurately describe what happens? No fabrications?\n4. **Narrative beats**: Are the identified beats actually present in the scene?\n5. **Tone assessment**: Does the tone description match the actual mood of the scene?\n6. **Confidence calibration**: Is the confidence score reasonable given the quality?\n\nReturn a JSON object with:\n- passed: boolean (true if the extraction is faithful, false if it has significant errors)\n- confidence: float 0-1 (your confidence in this QA judgment)\n- issues: array of objects, each with:\n  - severity: \"error\" (factual wrong), \"warning\" (misleading), or \"note\" (minor)\n  - description: what's wrong\n  - location: which field has the issue\n- summary: 1-2 sentence overall assessment\n\nBe strict: wrong character names, fabricated events, or incorrect locations are errors.\nMinor omissions or imprecise tone descriptions are warnings.\n\nReturn ONLY valid JSON. No explanations or markdown fences.\n\n==========\nORIGINAL SCENE TEXT:\n{{scene_text}}\n\n==========\nEXTRACTED SCENE DATA:\n{{extracted_data}}\n==========",
          "config": {
            "provider": "anthropic:messages:claude-opus-4-6"
          }
        },
        "promptId": "8df20c2c4a6081352d6b06e144ddbc1e0a5244f9a3c2000d40df12fc9a94e543",
        "promptIdx": 3,
        "provider": {
          "id": "google:gemini-2.5-pro",
          "label": "Gemini 2.5 Pro"
        },
        "response": {
          "output": "```json\n{\n  \"passed\": false,\n  \"confidence\": 1.0,\n  \"issues\": [\n    {\n      \"severity\": \"error\",\n      \"description\": \"Scene location 'RUDDY & GREEN BUILDING' was incorrectly generalized to 'OFFICE BUILDING'.\",\n      \"location\": \"heading\"\n    },\n    {\n      \"severity\": \"error\",\n      \"description\": \"Time of day 'DAY' was fabricated; it is not specified in the scene text.\",\n      \"location\": \"time_of_day\"\n    },\n    {\n      \"severity\": \"error\",\n      \"description\": \"Character 'MARINER' is incorrectly identified as 'BILLY'.\",\n      \"location\": \"characters_present\"\n    },\n    {\n      \"severity\": \"error\",\n      \"description\": \"The summary is a complete fabrication. It invents a casual conversation about evening plans and groceries, ignoring the actual post-violence confrontation, blood, and argument about an AirTag.\",\n      \"location\": \"summary\"\n    },\n    {\n      \"severity\": \"error\",\n      \"description\": \"The narrative beat 'Characters discuss daily plans' is fabricated and does not occur in the scene.\",\n      \"location\": \"narrative_beats\"\n    },\n    {\n      \"severity\": \"error\",\n      \"description\": \"The tone is incorrectly identified as 'casual'. The scene is tense, confrontational, and post-violent.\",\n      \"location\": \"tone_mood\"\n    },\n    {\n      \"severity\": \"warning\",\n      \"description\": \"The confidence score of 0.88 is severely miscalibrated, as the extraction is almost entirely incorrect.\",\n      \"location\": \"confidence\"\n    }\n  ],\n  \"summary\": \"The extraction is a complete failure, fabricating nearly every detail including character names, the summary of events, narrative beats, and the overall tone. It bears no resemblance to the source text.\"\n}\n```",
          "tokenUsage": {
            "prompt": 963,
            "completion": 436,
            "total": 2406,
            "numRequests": 1,
            "completionDetails": {
              "reasoning": 1007,
              "acceptedPrediction": 0,
              "rejectedPrediction": 0
            }
          },
          "cost": 0.015633750000000002,
          "raw": {
            "candidates": [
              {
                "content": {
                  "parts": [
                    {
                      "text": "```json\n{\n  \"passed\": false,\n  \"confidence\": 1.0,\n  \"issues\": [\n    {\n      \"severity\": \"error\",\n      \"description\": \"Scene location 'RUDDY & GREEN BUILDING' was incorrectly generalized to 'OFFICE BUILDING'.\",\n      \"location\": \"heading\"\n    },\n    {\n      \"severity\": \"error\",\n      \"description\": \"Time of day 'DAY' was fabricated; it is not specified in the scene text.\",\n      \"location\": \"time_of_day\"\n    },\n    {\n      \"severity\": \"error\",\n      \"description\": \"Character 'MARINER' is incorrectly identified as 'BILLY'.\",\n      \"location\": \"characters_present\"\n    },\n    {\n      \"severity\": \"error\",\n      \"description\": \"The summary is a complete fabrication. It invents a casual conversation about evening plans and groceries, ignoring the actual post-violence confrontation, blood, and argument about an AirTag.\",\n      \"location\": \"summary\"\n    },\n    {\n      \"severity\": \"error\",\n      \"description\": \"The narrative beat 'Characters discuss daily plans' is fabricated and does not occur in the scene.\",\n      \"location\": \"narrative_beats\"\n    },\n    {\n      \"severity\": \"error\",\n      \"description\": \"The tone is incorrectly identified as 'casual'. The scene is tense, confrontational, and post-violent.\",\n      \"location\": \"tone_mood\"\n    },\n    {\n      \"severity\": \"warning\",\n      \"description\": \"The confidence score of 0.88 is severely miscalibrated, as the extraction is almost entirely incorrect.\",\n      \"location\": \"confidence\"\n    }\n  ],\n  \"summary\": \"The extraction is a complete failure, fabricating nearly every detail including character names, the summary of events, narrative beats, and the overall tone. It bears no resemblance to the source text.\"\n}\n```"
                    }
                  ],
                  "role": "model"
                },
                "finishReason": "STOP",
                "index": 0
              }
            ],
            "usageMetadata": {
              "promptTokenCount": 963,
              "candidatesTokenCount": 436,
              "totalTokenCount": 2406,
              "promptTokensDetails": [
                {
                  "modality": "TEXT",
                  "tokenCount": 963
                }
              ],
              "thoughtsTokenCount": 1007
            },
            "modelVersion": "gemini-2.5-pro",
            "responseId": "58mVaZm1PLGKqtsPnaqGsAw"
          },
          "cached": false,
          "metadata": {}
        },
        "score": 0.995,
        "success": true,
        "testCase": {
          "vars": {
            "scene_text": "file://../input/enrich-scene-elevator.txt",
            "extracted_data": "file://../input/qa-bad-scene.json",
            "golden_path": "golden/qa-pass-golden.json",
            "test_key": "bad_scene"
          },
          "assert": [
            {
              "type": "python",
              "value": "file://../scorers/qa_pass_scorer.py"
            },
            {
              "type": "llm-rubric",
              "value": "This QA evaluation was given a BAD scene extraction with multiple errors:\n- Wrong building name (Office Building vs Ruddy & Greene)\n- Wrong time of day (DAY vs NIGHT)\n- Wrong character name (Billy instead of Mariner)\n- Missing thug characters\n- Fabricated content (grocery discussion never happens)\n\nThe QA model should have:\n1. Marked it as failed (false)\n2. Identified at least 2-3 specific errors\n3. Flagged the fabricated summary content\n4. Used \"error\" severity for factual mistakes\n\nIf the model let this pass, that's a dangerous false positive.\n"
            }
          ],
          "options": {
            "provider": "anthropic:messages:claude-opus-4-6"
          },
          "metadata": {}
        },
        "testIdx": 1,
        "vars": {
          "scene_text": "file://../input/enrich-scene-elevator.txt",
          "extracted_data": "file://../input/qa-bad-scene.json",
          "golden_path": "golden/qa-pass-golden.json",
          "test_key": "bad_scene"
        },
        "metadata": {
          "_promptfooFileMetadata": {}
        },
        "failureReason": 0
      },
      {
        "cost": 0.01713,
        "gradingResult": {
          "pass": true,
          "score": 0.95,
          "reason": "All assertions passed",
          "namedScores": {},
          "tokensUsed": {
            "total": 808,
            "prompt": 598,
            "completion": 210,
            "cached": 0,
            "numRequests": 0
          },
          "componentResults": [
            {
              "pass": true,
              "score": 1,
              "reason": "confidence_calibration=1.00 | issue_detection=1.00 | json_valid=1.00 | pass_correct=1.00 | severity_accuracy=1.00 | summary_quality=1.00",
              "assertion": {
                "type": "python",
                "value": "file://../scorers/qa_pass_scorer.py"
              }
            },
            {
              "assertion": {
                "type": "llm-rubric",
                "value": "This QA evaluation was given a BAD scene extraction with multiple errors:\n- Wrong building name (Office Building vs Ruddy & Greene)\n- Wrong time of day (DAY vs NIGHT)\n- Wrong character name (Billy instead of Mariner)\n- Missing thug characters\n- Fabricated content (grocery discussion never happens)\n\nThe QA model should have:\n1. Marked it as failed (false)\n2. Identified at least 2-3 specific errors\n3. Flagged the fabricated summary content\n4. Used \"error\" severity for factual mistakes\n\nIf the model let this pass, that's a dangerous false positive.\n"
              },
              "pass": true,
              "score": 0.9,
              "reason": "The QA evaluation correctly identified the extraction as failed (passed: false) with high confidence. It identified multiple specific errors: (1) the wrong/missing character name (Mariner missing, Billy hallucinated), (2) the fabricated summary content about groceries, (3) fabricated narrative beats, (4) incorrect tone. It also flagged the location issue as a warning. It used 'error' severity for factual mistakes and 'warning' for the less critical location issue. The evaluation caught the fabricated content, the wrong character names, and correctly flagged this as a dangerous hallucination. While it didn't explicitly call out the wrong time of day (DAY vs NIGHT) or the missing thug characters as separate issues, it did identify at least 3+ specific errors and correctly failed the extraction. This is a strong QA evaluation that would prevent a dangerous false positive.",
              "tokensUsed": {
                "total": 808,
                "prompt": 598,
                "completion": 210,
                "cached": 0,
                "numRequests": 0,
                "completionDetails": {
                  "reasoning": 0,
                  "acceptedPrediction": 0,
                  "rejectedPrediction": 0
                }
              },
              "metadata": {
                "renderedGradingPrompt": "[{\"role\":\"system\",\"content\":\"You are grading output according to a user-specified rubric. If the statement in the rubric is true, then the output passes the test. You respond with a JSON object with this structure: {reason: string, pass: boolean, score: number}\\n\\nExamples:\\n\\n<Output>Hello world</Output>\\n<Rubric>Content contains a greeting</Rubric>\\n{\\\"reason\\\": \\\"the content contains the word 'Hello'\\\", \\\"pass\\\": true, \\\"score\\\": 1.0}\\n\\n<Output>Avast ye swabs, repel the invaders!</Output>\\n<Rubric>Does not speak like a pirate</Rubric>\\n{\\\"reason\\\": \\\"'avast ye' is a common pirate term\\\", \\\"pass\\\": false, \\\"score\\\": 0.0}\"},{\"role\":\"user\",\"content\":\"<Output>\\n{\\\"passed\\\":false,\\\"confidence\\\":1,\\\"issues\\\":[{\\\"severity\\\":\\\"error\\\",\\\"description\\\":\\\"Character 'MARINER' is missing; 'BILLY' is hallucinated and does not appear in the text.\\\",\\\"location\\\":\\\"characters_present\\\"},{\\\"severity\\\":\\\"error\\\",\\\"description\\\":\\\"Summary is a complete fabrication (discussing groceries/evening plans). The actual scene depicts two bloody characters discussing a kidnapping, a piece of skull, and an AirTag.\\\",\\\"location\\\":\\\"summary\\\"},{\\\"severity\\\":\\\"error\\\",\\\"description\\\":\\\"Narrative beats are hallucinated; no discussion of daily plans occurs.\\\",\\\"location\\\":\\\"narrative_beats\\\"},{\\\"severity\\\":\\\"error\\\",\\\"description\\\":\\\"Tone 'casual' is incorrect for a scene involving blood, weapons, and post-combat stress.\\\",\\\"location\\\":\\\"tone_mood\\\"},{\\\"severity\\\":\\\"warning\\\",\\\"description\\\":\\\"Location extracted as 'OFFICE BUILDING' instead of the specific 'RUDDY & GREEN BUILDING'.\\\",\\\"location\\\":\\\"heading\\\"}],\\\"summary\\\":\\\"The extraction is a complete hallucination, inventing a character named Billy and a plot about groceries while ignoring the actual content regarding the Mariner, blood, and a kidnapping discussion.\\\"}\\n</Output>\\n<Rubric>\\nThis QA evaluation was given a BAD scene extraction with multiple errors:\\n- Wrong building name (Office Building vs Ruddy & Greene)\\n- Wrong time of day (DAY vs NIGHT)\\n- Wrong character name (Billy instead of Mariner)\\n- Missing thug characters\\n- Fabricated content (grocery discussion never happens)\\n\\nThe QA model should have:\\n1. Marked it as failed (false)\\n2. Identified at least 2-3 specific errors\\n3. Flagged the fabricated summary content\\n4. Used \\\"error\\\" severity for factual mistakes\\n\\nIf the model let this pass, that's a dangerous false positive.\\n\\n</Rubric>\"}]"
              }
            }
          ]
        },
        "id": "59ac36a5-93dd-4868-955c-473a949fba8c",
        "latencyMs": 20161,
        "namedScores": {},
        "prompt": {
          "raw": "You are a QA reviewer validating whether an AI-extracted scene analysis is accurate and faithful to the source screenplay text.\n\nCompare the extracted scene data against the original scene text and evaluate:\n\n1. **Heading accuracy**: Is the scene heading correct (location, INT/EXT, time of day)?\n2. **Character completeness**: Are all characters who appear or speak listed?\n3. **Summary fidelity**: Does the summary accurately describe what happens? No fabrications?\n4. **Narrative beats**: Are the identified beats actually present in the scene?\n5. **Tone assessment**: Does the tone description match the actual mood of the scene?\n6. **Confidence calibration**: Is the confidence score reasonable given the quality?\n\nReturn a JSON object with:\n- passed: boolean (true if the extraction is faithful, false if it has significant errors)\n- confidence: float 0-1 (your confidence in this QA judgment)\n- issues: array of objects, each with:\n  - severity: \"error\" (factual wrong), \"warning\" (misleading), or \"note\" (minor)\n  - description: what's wrong\n  - location: which field has the issue\n- summary: 1-2 sentence overall assessment\n\nBe strict: wrong character names, fabricated events, or incorrect locations are errors.\nMinor omissions or imprecise tone descriptions are warnings.\n\nReturn ONLY valid JSON. No explanations or markdown fences.\n\n==========\nORIGINAL SCENE TEXT:\nINT. RUDDY & GREEN BUILDING - ELEVATOR\n\nUB40's \"I Can't Help Falling in Love With You\" muzak.\n\nROSE (mid-30s) leans against the elevator wall, panting. She's wearing a Tim Hortons uniform, her hair is a mess, and there's blood spattered on her face.\n\nShe looks right, pants a few more times, then squints in disgust. She gingerly picks up a bloody scrap of something with hair on it. She snorts and drops it.\n\nROSE\nIs that skull??\n\nNext to her is Mariner, also panting, covered in far more blood. His face is broad, stoic, and frowning. He has gray-blue eyes and a thick, curly, beard barely streaked with gray. He wears a red knit cap and a small mask.\n\nFULL-SCREEN SUPERIMPOSED TITLE CARD: \"THE MARINER\"\n\nHe blinks a few times as a drop of blood falls from his eyebrow. He looks toward her, then spits out some blood.\n\nMARINER\nYeaaaaah...\n\nHe's built like a pro-wrestler. Moss green SWEATER stretched over his huge frame, sleeves rolled showing heavy leather BRACERS adorned with anchors. His inner forearm has a classic heart-and-arrow TATTOO with \"Dad\" in the centre. Across his chest is a BANDOLIER of bright red 12-gauge shells, FISH HOOKS hanging from the bottom edge. Heavy rubberized BOOTS go past his knees. A CAPE of heavy FISHING NET edged with WEIGHTS hangs from his shoulders.\n\nHe holds a STOUT WOODEN OAR in both hands, edged with METAL and dripping with BLOOD.\n\nROSE\nWhere were you when they grabbed me? You were supposed to pick me up at work!\n\nMARINER\nYeah, about that, I got a little... distracted.\n\nROSE\nDistracted. You got DISTRACTED?!\n\nMARINER\nI was also... tracking the car... that grabbed you... through the AirTag... I put on your phone.\n\nRose stops. She's really not happy about this.\n\nROSE\nYou Airtagged me?!\n\n==========\nEXTRACTED SCENE DATA:\n{\n  \"scene_number\": 4,\n  \"heading\": \"INT. OFFICE BUILDING - ELEVATOR\",\n  \"int_ext\": \"INT\",\n  \"location\": \"OFFICE BUILDING - ELEVATOR\",\n  \"time_of_day\": \"DAY\",\n  \"characters_present\": [\"ROSE\", \"BILLY\"],\n  \"summary\": \"Billy and Rose take the elevator in an office building. They discuss their plans for the evening. Rose mentions she needs to pick up groceries.\",\n  \"narrative_beats\": [\n    {\"beat_type\": \"exposition\", \"description\": \"Characters discuss daily plans.\", \"confidence\": 0.85}\n  ],\n  \"tone_mood\": \"casual\",\n  \"confidence\": 0.88\n}\n==========",
          "label": "prompts/qa-pass.txt: You are a QA reviewer validating whether an AI-extracted scene analysis is accurate and faithful to the source screenplay text.\n\nCompare the extracted scene data against the original scene text and evaluate:\n\n1. **Heading accuracy**: Is the scene heading correct (location, INT/EXT, time of day)?\n2. **Character completeness**: Are all characters who appear or speak listed?\n3. **Summary fidelity**: Does the summary accurately describe what happens? No fabrications?\n4. **Narrative beats**: Are the identified beats actually present in the scene?\n5. **Tone assessment**: Does the tone description match the actual mood of the scene?\n6. **Confidence calibration**: Is the confidence score reasonable given the quality?\n\nReturn a JSON object with:\n- passed: boolean (true if the extraction is faithful, false if it has significant errors)\n- confidence: float 0-1 (your confidence in this QA judgment)\n- issues: array of objects, each with:\n  - severity: \"error\" (factual wrong), \"warning\" (misleading), or \"note\" (minor)\n  - description: what's wrong\n  - location: which field has the issue\n- summary: 1-2 sentence overall assessment\n\nBe strict: wrong character names, fabricated events, or incorrect locations are errors.\nMinor omissions or imprecise tone descriptions are warnings.\n\nReturn ONLY valid JSON. No explanations or markdown fences.\n\n==========\nORIGINAL SCENE TEXT:\n{{scene_text}}\n\n==========\nEXTRACTED SCENE DATA:\n{{extracted_data}}\n==========",
          "config": {
            "provider": "anthropic:messages:claude-opus-4-6"
          }
        },
        "promptId": "8df20c2c4a6081352d6b06e144ddbc1e0a5244f9a3c2000d40df12fc9a94e543",
        "promptIdx": 4,
        "provider": {
          "id": "google:gemini-3-pro-preview",
          "label": "Gemini 3 Pro"
        },
        "response": {
          "output": "{\n  \"passed\": false,\n  \"confidence\": 1.0,\n  \"issues\": [\n    {\n      \"severity\": \"error\",\n      \"description\": \"Character 'MARINER' is missing; 'BILLY' is hallucinated and does not appear in the text.\",\n      \"location\": \"characters_present\"\n    },\n    {\n      \"severity\": \"error\",\n      \"description\": \"Summary is a complete fabrication (discussing groceries/evening plans). The actual scene depicts two bloody characters discussing a kidnapping, a piece of skull, and an AirTag.\",\n      \"location\": \"summary\"\n    },\n    {\n      \"severity\": \"error\",\n      \"description\": \"Narrative beats are hallucinated; no discussion of daily plans occurs.\",\n      \"location\": \"narrative_beats\"\n    },\n    {\n      \"severity\": \"error\",\n      \"description\": \"Tone 'casual' is incorrect for a scene involving blood, weapons, and post-combat stress.\",\n      \"location\": \"tone_mood\"\n    },\n    {\n      \"severity\": \"warning\",\n      \"description\": \"Location extracted as 'OFFICE BUILDING' instead of the specific 'RUDDY & GREEN BUILDING'.\",\n      \"location\": \"heading\"\n    }\n  ],\n  \"summary\": \"The extraction is a complete hallucination, inventing a character named Billy and a plot about groceries while ignoring the actual content regarding the Mariner, blood, and a kidnapping discussion.\"\n}",
          "tokenUsage": {
            "prompt": 963,
            "completion": 328,
            "total": 2230,
            "numRequests": 1,
            "completionDetails": {
              "reasoning": 939,
              "acceptedPrediction": 0,
              "rejectedPrediction": 0
            }
          },
          "cost": 0.01713,
          "raw": {
            "candidates": [
              {
                "content": {
                  "parts": [
                    {
                      "text": "{\n  \"passed\": false,\n  \"confidence\": 1.0,\n  \"issues\": [\n    {\n      \"severity\": \"error\",\n      \"description\": \"Character 'MARINER' is missing; 'BILLY' is hallucinated and does not appear in the text.\",\n      \"location\": \"characters_present\"\n    },\n    {\n      \"severity\": \"error\",\n      \"description\": \"Summary is a complete fabrication (discussing groceries/evening plans). The actual scene depicts two bloody characters discussing a kidnapping, a piece of skull, and an AirTag.\",\n      \"location\": \"summary\"\n    },\n    {\n      \"severity\": \"error\",\n      \"description\": \"Narrative beats are hallucinated; no discussion of daily plans occurs.\",\n      \"location\": \"narrative_beats\"\n    },\n    {\n      \"severity\": \"error\",\n      \"description\": \"Tone 'casual' is incorrect for a scene involving blood, weapons, and post-combat stress.\",\n      \"location\": \"tone_mood\"\n    },\n    {\n      \"severity\": \"warning\",\n      \"description\": \"Location extracted as 'OFFICE BUILDING' instead of the specific 'RUDDY & GREEN BUILDING'.\",\n      \"location\": \"heading\"\n    }\n  ],\n  \"summary\": \"The extraction is a complete hallucination, inventing a character named Billy and a plot about groceries while ignoring the actual content regarding the Mariner, blood, and a kidnapping discussion.\"\n}",
                      "thoughtSignature": "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"
                    }
                  ],
                  "role": "model"
                },
                "finishReason": "STOP",
                "index": 0
              }
            ],
            "usageMetadata": {
              "promptTokenCount": 963,
              "candidatesTokenCount": 328,
              "totalTokenCount": 2230,
              "promptTokensDetails": [
                {
                  "modality": "TEXT",
                  "tokenCount": 963
                }
              ],
              "thoughtsTokenCount": 939
            },
            "modelVersion": "gemini-3-pro-preview",
            "responseId": "AcqVaZfvEZDBqtsPhcbZ-Qw"
          },
          "cached": false,
          "metadata": {}
        },
        "score": 0.95,
        "success": true,
        "testCase": {
          "vars": {
            "scene_text": "file://../input/enrich-scene-elevator.txt",
            "extracted_data": "file://../input/qa-bad-scene.json",
            "golden_path": "golden/qa-pass-golden.json",
            "test_key": "bad_scene"
          },
          "assert": [
            {
              "type": "python",
              "value": "file://../scorers/qa_pass_scorer.py"
            },
            {
              "type": "llm-rubric",
              "value": "This QA evaluation was given a BAD scene extraction with multiple errors:\n- Wrong building name (Office Building vs Ruddy & Greene)\n- Wrong time of day (DAY vs NIGHT)\n- Wrong character name (Billy instead of Mariner)\n- Missing thug characters\n- Fabricated content (grocery discussion never happens)\n\nThe QA model should have:\n1. Marked it as failed (false)\n2. Identified at least 2-3 specific errors\n3. Flagged the fabricated summary content\n4. Used \"error\" severity for factual mistakes\n\nIf the model let this pass, that's a dangerous false positive.\n"
            }
          ],
          "options": {
            "provider": "anthropic:messages:claude-opus-4-6"
          },
          "metadata": {}
        },
        "testIdx": 1,
        "vars": {
          "scene_text": "file://../input/enrich-scene-elevator.txt",
          "extracted_data": "file://../input/qa-bad-scene.json",
          "golden_path": "golden/qa-pass-golden.json",
          "test_key": "bad_scene"
        },
        "metadata": {
          "_promptfooFileMetadata": {}
        },
        "failureReason": 0
      }
    ],
    "stats": {
      "successes": 9,
      "failures": 1,
      "errors": 0,
      "tokenUsage": {
        "prompt": 10740,
        "completion": 2756,
        "cached": 0,
        "total": 25081,
        "numRequests": 10,
        "completionDetails": {
          "reasoning": 11585,
          "acceptedPrediction": 0,
          "rejectedPrediction": 0
        },
        "assertions": {
          "total": 7116,
          "prompt": 5700,
          "completion": 1416,
          "cached": 0,
          "numRequests": 0,
          "completionDetails": {
            "reasoning": 0,
            "acceptedPrediction": 0,
            "rejectedPrediction": 0
          }
        }
      },
      "durationMs": 165580
    }
  },
  "config": {
    "tags": {},
    "description": "QA pass — judge scene extraction quality (good vs bad outputs)",
    "prompts": [
      "file:///Users/cam/Documents/Projects/cine-forge/benchmarks/prompts/qa-pass.txt"
    ],
    "providers": [
      {
        "id": "openai:gpt-4.1-nano",
        "label": "GPT-4.1 Nano",
        "config": {
          "temperature": 0,
          "max_tokens": 4096,
          "response_format": {
            "type": "json_object"
          }
        }
      },
      {
        "id": "openai:gpt-4.1-mini",
        "label": "GPT-4.1 Mini",
        "config": {
          "temperature": 0,
          "max_tokens": 4096,
          "response_format": {
            "type": "json_object"
          }
        }
      },
      {
        "id": "google:gemini-2.5-flash-lite",
        "label": "Gemini 2.5 Flash Lite",
        "config": {
          "temperature": 0,
          "maxOutputTokens": 16384
        }
      },
      {
        "id": "openai:gpt-4.1",
        "label": "GPT-4.1",
        "config": {
          "temperature": 0,
          "max_tokens": 4096,
          "response_format": {
            "type": "json_object"
          }
        }
      },
      {
        "id": "anthropic:messages:claude-haiku-4-5-20251001",
        "label": "Claude Haiku 4.5",
        "config": {
          "temperature": 0,
          "max_tokens": 4096
        }
      },
      {
        "id": "anthropic:messages:claude-sonnet-4-5-20250929",
        "label": "Claude Sonnet 4.5",
        "config": {
          "temperature": 0,
          "max_tokens": 4096
        }
      },
      {
        "id": "anthropic:messages:claude-sonnet-4-6",
        "label": "Claude Sonnet 4.6",
        "config": {
          "temperature": 0,
          "max_tokens": 4096
        }
      },
      {
        "id": "google:gemini-2.5-flash",
        "label": "Gemini 2.5 Flash",
        "config": {
          "temperature": 0,
          "maxOutputTokens": 16384
        }
      },
      {
        "id": "google:gemini-3-flash-preview",
        "label": "Gemini 3 Flash",
        "config": {
          "temperature": 0,
          "maxOutputTokens": 16384
        }
      },
      {
        "id": "openai:gpt-5.2",
        "label": "GPT-5.2",
        "config": {
          "temperature": 0,
          "max_tokens": 4096,
          "response_format": {
            "type": "json_object"
          }
        }
      },
      {
        "id": "anthropic:messages:claude-opus-4-6",
        "label": "Claude Opus 4.6",
        "config": {
          "temperature": 0,
          "max_tokens": 4096
        }
      },
      {
        "id": "google:gemini-2.5-pro",
        "label": "Gemini 2.5 Pro",
        "config": {
          "temperature": 0,
          "maxOutputTokens": 16384
        }
      },
      {
        "id": "google:gemini-3-pro-preview",
        "label": "Gemini 3 Pro",
        "config": {
          "temperature": 0,
          "maxOutputTokens": 16384
        }
      }
    ],
    "tests": [
      {
        "vars": {
          "scene_text": "file://../input/enrich-scene-elevator.txt",
          "extracted_data": "file://../input/qa-good-scene.json",
          "golden_path": "golden/qa-pass-golden.json",
          "test_key": "good_scene"
        },
        "assert": [
          {
            "type": "python",
            "value": "file://../scorers/qa_pass_scorer.py"
          },
          {
            "type": "llm-rubric",
            "value": "This QA evaluation was given a GOOD scene extraction that accurately\nreflects the source text. The QA model should have:\n\n1. Marked it as passed (true)\n2. Found zero or very few errors\n3. Had high confidence in the assessment\n4. Written a summary confirming accuracy\n\nIf the model incorrectly flagged the good extraction as failing,\nthat's a false negative and should score poorly.\n"
          }
        ]
      },
      {
        "vars": {
          "scene_text": "file://../input/enrich-scene-elevator.txt",
          "extracted_data": "file://../input/qa-bad-scene.json",
          "golden_path": "golden/qa-pass-golden.json",
          "test_key": "bad_scene"
        },
        "assert": [
          {
            "type": "python",
            "value": "file://../scorers/qa_pass_scorer.py"
          },
          {
            "type": "llm-rubric",
            "value": "This QA evaluation was given a BAD scene extraction with multiple errors:\n- Wrong building name (Office Building vs Ruddy & Greene)\n- Wrong time of day (DAY vs NIGHT)\n- Wrong character name (Billy instead of Mariner)\n- Missing thug characters\n- Fabricated content (grocery discussion never happens)\n\nThe QA model should have:\n1. Marked it as failed (false)\n2. Identified at least 2-3 specific errors\n3. Flagged the fabricated summary content\n4. Used \"error\" severity for factual mistakes\n\nIf the model let this pass, that's a dangerous false positive.\n"
          }
        ]
      }
    ],
    "scenarios": [],
    "env": {},
    "defaultTest": {
      "options": {
        "provider": "anthropic:messages:claude-opus-4-6"
      },
      "vars": {},
      "assert": [],
      "metadata": {}
    },
    "outputPath": [
      "results/qa-pass-gemini-2026-02-18.json"
    ],
    "extensions": [],
    "metadata": {},
    "evaluateOptions": {}
  },
  "shareableUrl": null,
  "metadata": {
    "promptfooVersion": "0.120.24",
    "nodeVersion": "v24.13.1",
    "platform": "darwin",
    "arch": "arm64",
    "exportedAt": "2026-02-18T14:17:44.584Z",
    "evaluationCreatedAt": "2026-02-18T14:14:58.413Z"
  }
}