{
  "evalId": "eval-iB2-2026-03-02T04:17:41",
  "results": {
    "version": 3,
    "timestamp": "2026-03-02T04:17:41.098Z",
    "prompts": [
      {
        "raw": "You are a QA reviewer validating whether an AI-extracted scene analysis is accurate and faithful to the source screenplay text.\n\nCompare the extracted scene data against the original scene text and evaluate:\n\n1. **Heading accuracy**: Is the scene heading correct (location, INT/EXT, time of day)?\n2. **Character completeness**: Are all characters who appear or speak listed?\n3. **Summary fidelity**: Does the summary accurately describe what happens? No fabrications?\n4. **Narrative beats**: Are the identified beats actually present in the scene?\n5. **Tone assessment**: Does the tone description match the actual mood of the scene?\n6. **Confidence calibration**: Is the confidence score reasonable given the quality?\n\nReturn a JSON object with:\n- passed: boolean (true if the extraction is faithful, false if it has significant errors)\n- confidence: float 0-1 (your confidence in this QA judgment)\n- issues: array of objects, each with:\n  - severity: \"error\" (factual wrong), \"warning\" (misleading), or \"note\" (minor)\n  - description: what's wrong\n  - location: which field has the issue\n- summary: 1-2 sentence overall assessment\n\nBe strict: wrong character names, fabricated events, or incorrect locations are errors.\nMinor omissions or imprecise tone descriptions are warnings.\n\nReturn ONLY valid JSON. No explanations or markdown fences.\n\n==========\nORIGINAL SCENE TEXT:\n{{scene_text}}\n\n==========\nEXTRACTED SCENE DATA:\n{{extracted_data}}\n==========",
        "label": "prompts/qa-pass.txt: You are a QA reviewer validating whether an AI-extracted scene analysis is accurate and faithful to the source screenplay text.\n\nCompare the extracted scene data against the original scene text and evaluate:\n\n1. **Heading accuracy**: Is the scene heading correct (location, INT/EXT, time of day)?\n2. **Character completeness**: Are all characters who appear or speak listed?\n3. **Summary fidelity**: Does the summary accurately describe what happens? No fabrications?\n4. **Narrative beats**: Are the identified beats actually present in the scene?\n5. **Tone assessment**: Does the tone description match the actual mood of the scene?\n6. **Confidence calibration**: Is the confidence score reasonable given the quality?\n\nReturn a JSON object with:\n- passed: boolean (true if the extraction is faithful, false if it has significant errors)\n- confidence: float 0-1 (your confidence in this QA judgment)\n- issues: array of objects, each with:\n  - severity: \"error\" (factual wrong), \"warning\" (misleading), or \"note\" (minor)\n  - description: what's wrong\n  - location: which field has the issue\n- summary: 1-2 sentence overall assessment\n\nBe strict: wrong character names, fabricated events, or incorrect locations are errors.\nMinor omissions or imprecise tone descriptions are warnings.\n\nReturn ONLY valid JSON. No explanations or markdown fences.\n\n==========\nORIGINAL SCENE TEXT:\n{{scene_text}}\n\n==========\nEXTRACTED SCENE DATA:\n{{extracted_data}}\n==========",
        "id": "8df20c2c4a6081352d6b06e144ddbc1e0a5244f9a3c2000d40df12fc9a94e543",
        "provider": "GPT-4.1 Nano",
        "metrics": {
          "score": 1.2,
          "testPassCount": 1,
          "testFailCount": 1,
          "testErrorCount": 0,
          "assertPassCount": 2,
          "assertFailCount": 2,
          "totalLatencyMs": 6974,
          "tokenUsage": {
            "prompt": 2071,
            "completion": 705,
            "cached": 0,
            "total": 2776,
            "numRequests": 2,
            "completionDetails": {
              "reasoning": 0,
              "acceptedPrediction": 0,
              "rejectedPrediction": 0
            },
            "assertions": {
              "total": 1545,
              "prompt": 1239,
              "completion": 306,
              "cached": 0,
              "numRequests": 0,
              "completionDetails": {
                "reasoning": 0,
                "acceptedPrediction": 0,
                "rejectedPrediction": 0
              }
            }
          },
          "namedScores": {},
          "namedScoresCount": {},
          "cost": 0.0004891
        }
      },
      {
        "raw": "You are a QA reviewer validating whether an AI-extracted scene analysis is accurate and faithful to the source screenplay text.\n\nCompare the extracted scene data against the original scene text and evaluate:\n\n1. **Heading accuracy**: Is the scene heading correct (location, INT/EXT, time of day)?\n2. **Character completeness**: Are all characters who appear or speak listed?\n3. **Summary fidelity**: Does the summary accurately describe what happens? No fabrications?\n4. **Narrative beats**: Are the identified beats actually present in the scene?\n5. **Tone assessment**: Does the tone description match the actual mood of the scene?\n6. **Confidence calibration**: Is the confidence score reasonable given the quality?\n\nReturn a JSON object with:\n- passed: boolean (true if the extraction is faithful, false if it has significant errors)\n- confidence: float 0-1 (your confidence in this QA judgment)\n- issues: array of objects, each with:\n  - severity: \"error\" (factual wrong), \"warning\" (misleading), or \"note\" (minor)\n  - description: what's wrong\n  - location: which field has the issue\n- summary: 1-2 sentence overall assessment\n\nBe strict: wrong character names, fabricated events, or incorrect locations are errors.\nMinor omissions or imprecise tone descriptions are warnings.\n\nReturn ONLY valid JSON. No explanations or markdown fences.\n\n==========\nORIGINAL SCENE TEXT:\n{{scene_text}}\n\n==========\nEXTRACTED SCENE DATA:\n{{extracted_data}}\n==========",
        "label": "prompts/qa-pass.txt: You are a QA reviewer validating whether an AI-extracted scene analysis is accurate and faithful to the source screenplay text.\n\nCompare the extracted scene data against the original scene text and evaluate:\n\n1. **Heading accuracy**: Is the scene heading correct (location, INT/EXT, time of day)?\n2. **Character completeness**: Are all characters who appear or speak listed?\n3. **Summary fidelity**: Does the summary accurately describe what happens? No fabrications?\n4. **Narrative beats**: Are the identified beats actually present in the scene?\n5. **Tone assessment**: Does the tone description match the actual mood of the scene?\n6. **Confidence calibration**: Is the confidence score reasonable given the quality?\n\nReturn a JSON object with:\n- passed: boolean (true if the extraction is faithful, false if it has significant errors)\n- confidence: float 0-1 (your confidence in this QA judgment)\n- issues: array of objects, each with:\n  - severity: \"error\" (factual wrong), \"warning\" (misleading), or \"note\" (minor)\n  - description: what's wrong\n  - location: which field has the issue\n- summary: 1-2 sentence overall assessment\n\nBe strict: wrong character names, fabricated events, or incorrect locations are errors.\nMinor omissions or imprecise tone descriptions are warnings.\n\nReturn ONLY valid JSON. No explanations or markdown fences.\n\n==========\nORIGINAL SCENE TEXT:\n{{scene_text}}\n\n==========\nEXTRACTED SCENE DATA:\n{{extracted_data}}\n==========",
        "id": "8df20c2c4a6081352d6b06e144ddbc1e0a5244f9a3c2000d40df12fc9a94e543",
        "provider": "GPT-4.1 Mini",
        "metrics": {
          "score": 2,
          "testPassCount": 2,
          "testFailCount": 0,
          "testErrorCount": 0,
          "assertPassCount": 4,
          "assertFailCount": 0,
          "totalLatencyMs": 8362,
          "tokenUsage": {
            "prompt": 2071,
            "completion": 528,
            "cached": 0,
            "total": 2599,
            "numRequests": 2,
            "completionDetails": {
              "reasoning": 0,
              "acceptedPrediction": 0,
              "rejectedPrediction": 0
            },
            "assertions": {
              "total": 1311,
              "prompt": 1092,
              "completion": 219,
              "cached": 0,
              "numRequests": 0,
              "completionDetails": {
                "reasoning": 0,
                "acceptedPrediction": 0,
                "rejectedPrediction": 0
              }
            }
          },
          "namedScores": {},
          "namedScoresCount": {},
          "cost": 0.0016732000000000001
        }
      },
      {
        "raw": "You are a QA reviewer validating whether an AI-extracted scene analysis is accurate and faithful to the source screenplay text.\n\nCompare the extracted scene data against the original scene text and evaluate:\n\n1. **Heading accuracy**: Is the scene heading correct (location, INT/EXT, time of day)?\n2. **Character completeness**: Are all characters who appear or speak listed?\n3. **Summary fidelity**: Does the summary accurately describe what happens? No fabrications?\n4. **Narrative beats**: Are the identified beats actually present in the scene?\n5. **Tone assessment**: Does the tone description match the actual mood of the scene?\n6. **Confidence calibration**: Is the confidence score reasonable given the quality?\n\nReturn a JSON object with:\n- passed: boolean (true if the extraction is faithful, false if it has significant errors)\n- confidence: float 0-1 (your confidence in this QA judgment)\n- issues: array of objects, each with:\n  - severity: \"error\" (factual wrong), \"warning\" (misleading), or \"note\" (minor)\n  - description: what's wrong\n  - location: which field has the issue\n- summary: 1-2 sentence overall assessment\n\nBe strict: wrong character names, fabricated events, or incorrect locations are errors.\nMinor omissions or imprecise tone descriptions are warnings.\n\nReturn ONLY valid JSON. No explanations or markdown fences.\n\n==========\nORIGINAL SCENE TEXT:\n{{scene_text}}\n\n==========\nEXTRACTED SCENE DATA:\n{{extracted_data}}\n==========",
        "label": "prompts/qa-pass.txt: You are a QA reviewer validating whether an AI-extracted scene analysis is accurate and faithful to the source screenplay text.\n\nCompare the extracted scene data against the original scene text and evaluate:\n\n1. **Heading accuracy**: Is the scene heading correct (location, INT/EXT, time of day)?\n2. **Character completeness**: Are all characters who appear or speak listed?\n3. **Summary fidelity**: Does the summary accurately describe what happens? No fabrications?\n4. **Narrative beats**: Are the identified beats actually present in the scene?\n5. **Tone assessment**: Does the tone description match the actual mood of the scene?\n6. **Confidence calibration**: Is the confidence score reasonable given the quality?\n\nReturn a JSON object with:\n- passed: boolean (true if the extraction is faithful, false if it has significant errors)\n- confidence: float 0-1 (your confidence in this QA judgment)\n- issues: array of objects, each with:\n  - severity: \"error\" (factual wrong), \"warning\" (misleading), or \"note\" (minor)\n  - description: what's wrong\n  - location: which field has the issue\n- summary: 1-2 sentence overall assessment\n\nBe strict: wrong character names, fabricated events, or incorrect locations are errors.\nMinor omissions or imprecise tone descriptions are warnings.\n\nReturn ONLY valid JSON. No explanations or markdown fences.\n\n==========\nORIGINAL SCENE TEXT:\n{{scene_text}}\n\n==========\nEXTRACTED SCENE DATA:\n{{extracted_data}}\n==========",
        "id": "8df20c2c4a6081352d6b06e144ddbc1e0a5244f9a3c2000d40df12fc9a94e543",
        "provider": "Gemini 2.5 Flash Lite",
        "metrics": {
          "score": 1.3375,
          "testPassCount": 1,
          "testFailCount": 1,
          "testErrorCount": 0,
          "assertPassCount": 2,
          "assertFailCount": 2,
          "totalLatencyMs": 3110,
          "tokenUsage": {
            "prompt": 2148,
            "completion": 817,
            "cached": 0,
            "total": 2965,
            "numRequests": 2,
            "completionDetails": {
              "reasoning": 0,
              "acceptedPrediction": 0,
              "rejectedPrediction": 0
            },
            "assertions": {
              "total": 1890,
              "prompt": 1491,
              "completion": 399,
              "cached": 0,
              "numRequests": 0,
              "completionDetails": {
                "reasoning": 0,
                "acceptedPrediction": 0,
                "rejectedPrediction": 0
              }
            }
          },
          "namedScores": {},
          "namedScoresCount": {},
          "cost": 0.0005416
        }
      },
      {
        "raw": "You are a QA reviewer validating whether an AI-extracted scene analysis is accurate and faithful to the source screenplay text.\n\nCompare the extracted scene data against the original scene text and evaluate:\n\n1. **Heading accuracy**: Is the scene heading correct (location, INT/EXT, time of day)?\n2. **Character completeness**: Are all characters who appear or speak listed?\n3. **Summary fidelity**: Does the summary accurately describe what happens? No fabrications?\n4. **Narrative beats**: Are the identified beats actually present in the scene?\n5. **Tone assessment**: Does the tone description match the actual mood of the scene?\n6. **Confidence calibration**: Is the confidence score reasonable given the quality?\n\nReturn a JSON object with:\n- passed: boolean (true if the extraction is faithful, false if it has significant errors)\n- confidence: float 0-1 (your confidence in this QA judgment)\n- issues: array of objects, each with:\n  - severity: \"error\" (factual wrong), \"warning\" (misleading), or \"note\" (minor)\n  - description: what's wrong\n  - location: which field has the issue\n- summary: 1-2 sentence overall assessment\n\nBe strict: wrong character names, fabricated events, or incorrect locations are errors.\nMinor omissions or imprecise tone descriptions are warnings.\n\nReturn ONLY valid JSON. No explanations or markdown fences.\n\n==========\nORIGINAL SCENE TEXT:\n{{scene_text}}\n\n==========\nEXTRACTED SCENE DATA:\n{{extracted_data}}\n==========",
        "label": "prompts/qa-pass.txt: You are a QA reviewer validating whether an AI-extracted scene analysis is accurate and faithful to the source screenplay text.\n\nCompare the extracted scene data against the original scene text and evaluate:\n\n1. **Heading accuracy**: Is the scene heading correct (location, INT/EXT, time of day)?\n2. **Character completeness**: Are all characters who appear or speak listed?\n3. **Summary fidelity**: Does the summary accurately describe what happens? No fabrications?\n4. **Narrative beats**: Are the identified beats actually present in the scene?\n5. **Tone assessment**: Does the tone description match the actual mood of the scene?\n6. **Confidence calibration**: Is the confidence score reasonable given the quality?\n\nReturn a JSON object with:\n- passed: boolean (true if the extraction is faithful, false if it has significant errors)\n- confidence: float 0-1 (your confidence in this QA judgment)\n- issues: array of objects, each with:\n  - severity: \"error\" (factual wrong), \"warning\" (misleading), or \"note\" (minor)\n  - description: what's wrong\n  - location: which field has the issue\n- summary: 1-2 sentence overall assessment\n\nBe strict: wrong character names, fabricated events, or incorrect locations are errors.\nMinor omissions or imprecise tone descriptions are warnings.\n\nReturn ONLY valid JSON. No explanations or markdown fences.\n\n==========\nORIGINAL SCENE TEXT:\n{{scene_text}}\n\n==========\nEXTRACTED SCENE DATA:\n{{extracted_data}}\n==========",
        "id": "8df20c2c4a6081352d6b06e144ddbc1e0a5244f9a3c2000d40df12fc9a94e543",
        "provider": "GPT-4.1",
        "metrics": {
          "score": 1.975,
          "testPassCount": 2,
          "testFailCount": 0,
          "testErrorCount": 0,
          "assertPassCount": 4,
          "assertFailCount": 0,
          "totalLatencyMs": 5867,
          "tokenUsage": {
            "prompt": 2071,
            "completion": 476,
            "cached": 0,
            "total": 2547,
            "numRequests": 2,
            "completionDetails": {
              "reasoning": 0,
              "acceptedPrediction": 0,
              "rejectedPrediction": 0
            },
            "assertions": {
              "total": 1295,
              "prompt": 1037,
              "completion": 258,
              "cached": 0,
              "numRequests": 0,
              "completionDetails": {
                "reasoning": 0,
                "acceptedPrediction": 0,
                "rejectedPrediction": 0
              }
            }
          },
          "namedScores": {},
          "namedScoresCount": {},
          "cost": 0.007949999999999999
        }
      },
      {
        "raw": "You are a QA reviewer validating whether an AI-extracted scene analysis is accurate and faithful to the source screenplay text.\n\nCompare the extracted scene data against the original scene text and evaluate:\n\n1. **Heading accuracy**: Is the scene heading correct (location, INT/EXT, time of day)?\n2. **Character completeness**: Are all characters who appear or speak listed?\n3. **Summary fidelity**: Does the summary accurately describe what happens? No fabrications?\n4. **Narrative beats**: Are the identified beats actually present in the scene?\n5. **Tone assessment**: Does the tone description match the actual mood of the scene?\n6. **Confidence calibration**: Is the confidence score reasonable given the quality?\n\nReturn a JSON object with:\n- passed: boolean (true if the extraction is faithful, false if it has significant errors)\n- confidence: float 0-1 (your confidence in this QA judgment)\n- issues: array of objects, each with:\n  - severity: \"error\" (factual wrong), \"warning\" (misleading), or \"note\" (minor)\n  - description: what's wrong\n  - location: which field has the issue\n- summary: 1-2 sentence overall assessment\n\nBe strict: wrong character names, fabricated events, or incorrect locations are errors.\nMinor omissions or imprecise tone descriptions are warnings.\n\nReturn ONLY valid JSON. No explanations or markdown fences.\n\n==========\nORIGINAL SCENE TEXT:\n{{scene_text}}\n\n==========\nEXTRACTED SCENE DATA:\n{{extracted_data}}\n==========",
        "label": "prompts/qa-pass.txt: You are a QA reviewer validating whether an AI-extracted scene analysis is accurate and faithful to the source screenplay text.\n\nCompare the extracted scene data against the original scene text and evaluate:\n\n1. **Heading accuracy**: Is the scene heading correct (location, INT/EXT, time of day)?\n2. **Character completeness**: Are all characters who appear or speak listed?\n3. **Summary fidelity**: Does the summary accurately describe what happens? No fabrications?\n4. **Narrative beats**: Are the identified beats actually present in the scene?\n5. **Tone assessment**: Does the tone description match the actual mood of the scene?\n6. **Confidence calibration**: Is the confidence score reasonable given the quality?\n\nReturn a JSON object with:\n- passed: boolean (true if the extraction is faithful, false if it has significant errors)\n- confidence: float 0-1 (your confidence in this QA judgment)\n- issues: array of objects, each with:\n  - severity: \"error\" (factual wrong), \"warning\" (misleading), or \"note\" (minor)\n  - description: what's wrong\n  - location: which field has the issue\n- summary: 1-2 sentence overall assessment\n\nBe strict: wrong character names, fabricated events, or incorrect locations are errors.\nMinor omissions or imprecise tone descriptions are warnings.\n\nReturn ONLY valid JSON. No explanations or markdown fences.\n\n==========\nORIGINAL SCENE TEXT:\n{{scene_text}}\n\n==========\nEXTRACTED SCENE DATA:\n{{extracted_data}}\n==========",
        "id": "8df20c2c4a6081352d6b06e144ddbc1e0a5244f9a3c2000d40df12fc9a94e543",
        "provider": "Claude Haiku 4.5",
        "metrics": {
          "score": 1.99,
          "testPassCount": 2,
          "testFailCount": 0,
          "testErrorCount": 0,
          "assertPassCount": 4,
          "assertFailCount": 0,
          "totalLatencyMs": 7537,
          "tokenUsage": {
            "prompt": 2262,
            "completion": 774,
            "cached": 0,
            "total": 3036,
            "numRequests": 2,
            "completionDetails": {
              "reasoning": 0,
              "acceptedPrediction": 0,
              "rejectedPrediction": 0
            },
            "assertions": {
              "total": 1696,
              "prompt": 1410,
              "completion": 286,
              "cached": 0,
              "numRequests": 0,
              "completionDetails": {
                "reasoning": 0,
                "acceptedPrediction": 0,
                "rejectedPrediction": 0
              }
            }
          },
          "namedScores": {},
          "namedScoresCount": {},
          "cost": 0.006132
        }
      },
      {
        "raw": "You are a QA reviewer validating whether an AI-extracted scene analysis is accurate and faithful to the source screenplay text.\n\nCompare the extracted scene data against the original scene text and evaluate:\n\n1. **Heading accuracy**: Is the scene heading correct (location, INT/EXT, time of day)?\n2. **Character completeness**: Are all characters who appear or speak listed?\n3. **Summary fidelity**: Does the summary accurately describe what happens? No fabrications?\n4. **Narrative beats**: Are the identified beats actually present in the scene?\n5. **Tone assessment**: Does the tone description match the actual mood of the scene?\n6. **Confidence calibration**: Is the confidence score reasonable given the quality?\n\nReturn a JSON object with:\n- passed: boolean (true if the extraction is faithful, false if it has significant errors)\n- confidence: float 0-1 (your confidence in this QA judgment)\n- issues: array of objects, each with:\n  - severity: \"error\" (factual wrong), \"warning\" (misleading), or \"note\" (minor)\n  - description: what's wrong\n  - location: which field has the issue\n- summary: 1-2 sentence overall assessment\n\nBe strict: wrong character names, fabricated events, or incorrect locations are errors.\nMinor omissions or imprecise tone descriptions are warnings.\n\nReturn ONLY valid JSON. No explanations or markdown fences.\n\n==========\nORIGINAL SCENE TEXT:\n{{scene_text}}\n\n==========\nEXTRACTED SCENE DATA:\n{{extracted_data}}\n==========",
        "label": "prompts/qa-pass.txt: You are a QA reviewer validating whether an AI-extracted scene analysis is accurate and faithful to the source screenplay text.\n\nCompare the extracted scene data against the original scene text and evaluate:\n\n1. **Heading accuracy**: Is the scene heading correct (location, INT/EXT, time of day)?\n2. **Character completeness**: Are all characters who appear or speak listed?\n3. **Summary fidelity**: Does the summary accurately describe what happens? No fabrications?\n4. **Narrative beats**: Are the identified beats actually present in the scene?\n5. **Tone assessment**: Does the tone description match the actual mood of the scene?\n6. **Confidence calibration**: Is the confidence score reasonable given the quality?\n\nReturn a JSON object with:\n- passed: boolean (true if the extraction is faithful, false if it has significant errors)\n- confidence: float 0-1 (your confidence in this QA judgment)\n- issues: array of objects, each with:\n  - severity: \"error\" (factual wrong), \"warning\" (misleading), or \"note\" (minor)\n  - description: what's wrong\n  - location: which field has the issue\n- summary: 1-2 sentence overall assessment\n\nBe strict: wrong character names, fabricated events, or incorrect locations are errors.\nMinor omissions or imprecise tone descriptions are warnings.\n\nReturn ONLY valid JSON. No explanations or markdown fences.\n\n==========\nORIGINAL SCENE TEXT:\n{{scene_text}}\n\n==========\nEXTRACTED SCENE DATA:\n{{extracted_data}}\n==========",
        "id": "8df20c2c4a6081352d6b06e144ddbc1e0a5244f9a3c2000d40df12fc9a94e543",
        "provider": "Claude Sonnet 4.5",
        "metrics": {
          "score": 1.99,
          "testPassCount": 2,
          "testFailCount": 0,
          "testErrorCount": 0,
          "assertPassCount": 4,
          "assertFailCount": 0,
          "totalLatencyMs": 15750,
          "tokenUsage": {
            "prompt": 2262,
            "completion": 743,
            "cached": 0,
            "total": 3005,
            "numRequests": 2,
            "completionDetails": {
              "reasoning": 0,
              "acceptedPrediction": 0,
              "rejectedPrediction": 0
            },
            "assertions": {
              "total": 1658,
              "prompt": 1379,
              "completion": 279,
              "cached": 0,
              "numRequests": 0,
              "completionDetails": {
                "reasoning": 0,
                "acceptedPrediction": 0,
                "rejectedPrediction": 0
              }
            }
          },
          "namedScores": {},
          "namedScoresCount": {},
          "cost": 0.017931000000000002
        }
      },
      {
        "raw": "You are a QA reviewer validating whether an AI-extracted scene analysis is accurate and faithful to the source screenplay text.\n\nCompare the extracted scene data against the original scene text and evaluate:\n\n1. **Heading accuracy**: Is the scene heading correct (location, INT/EXT, time of day)?\n2. **Character completeness**: Are all characters who appear or speak listed?\n3. **Summary fidelity**: Does the summary accurately describe what happens? No fabrications?\n4. **Narrative beats**: Are the identified beats actually present in the scene?\n5. **Tone assessment**: Does the tone description match the actual mood of the scene?\n6. **Confidence calibration**: Is the confidence score reasonable given the quality?\n\nReturn a JSON object with:\n- passed: boolean (true if the extraction is faithful, false if it has significant errors)\n- confidence: float 0-1 (your confidence in this QA judgment)\n- issues: array of objects, each with:\n  - severity: \"error\" (factual wrong), \"warning\" (misleading), or \"note\" (minor)\n  - description: what's wrong\n  - location: which field has the issue\n- summary: 1-2 sentence overall assessment\n\nBe strict: wrong character names, fabricated events, or incorrect locations are errors.\nMinor omissions or imprecise tone descriptions are warnings.\n\nReturn ONLY valid JSON. No explanations or markdown fences.\n\n==========\nORIGINAL SCENE TEXT:\n{{scene_text}}\n\n==========\nEXTRACTED SCENE DATA:\n{{extracted_data}}\n==========",
        "label": "prompts/qa-pass.txt: You are a QA reviewer validating whether an AI-extracted scene analysis is accurate and faithful to the source screenplay text.\n\nCompare the extracted scene data against the original scene text and evaluate:\n\n1. **Heading accuracy**: Is the scene heading correct (location, INT/EXT, time of day)?\n2. **Character completeness**: Are all characters who appear or speak listed?\n3. **Summary fidelity**: Does the summary accurately describe what happens? No fabrications?\n4. **Narrative beats**: Are the identified beats actually present in the scene?\n5. **Tone assessment**: Does the tone description match the actual mood of the scene?\n6. **Confidence calibration**: Is the confidence score reasonable given the quality?\n\nReturn a JSON object with:\n- passed: boolean (true if the extraction is faithful, false if it has significant errors)\n- confidence: float 0-1 (your confidence in this QA judgment)\n- issues: array of objects, each with:\n  - severity: \"error\" (factual wrong), \"warning\" (misleading), or \"note\" (minor)\n  - description: what's wrong\n  - location: which field has the issue\n- summary: 1-2 sentence overall assessment\n\nBe strict: wrong character names, fabricated events, or incorrect locations are errors.\nMinor omissions or imprecise tone descriptions are warnings.\n\nReturn ONLY valid JSON. No explanations or markdown fences.\n\n==========\nORIGINAL SCENE TEXT:\n{{scene_text}}\n\n==========\nEXTRACTED SCENE DATA:\n{{extracted_data}}\n==========",
        "id": "8df20c2c4a6081352d6b06e144ddbc1e0a5244f9a3c2000d40df12fc9a94e543",
        "provider": "Claude Sonnet 4.6",
        "metrics": {
          "score": 1.99,
          "testPassCount": 2,
          "testFailCount": 0,
          "testErrorCount": 0,
          "assertPassCount": 4,
          "assertFailCount": 0,
          "totalLatencyMs": 19057,
          "tokenUsage": {
            "prompt": 2262,
            "completion": 1027,
            "cached": 0,
            "total": 3289,
            "numRequests": 2,
            "completionDetails": {
              "reasoning": 0,
              "acceptedPrediction": 0,
              "rejectedPrediction": 0
            },
            "assertions": {
              "total": 1941,
              "prompt": 1663,
              "completion": 278,
              "cached": 0,
              "numRequests": 0,
              "completionDetails": {
                "reasoning": 0,
                "acceptedPrediction": 0,
                "rejectedPrediction": 0
              }
            }
          },
          "namedScores": {},
          "namedScoresCount": {},
          "cost": 0
        }
      },
      {
        "raw": "You are a QA reviewer validating whether an AI-extracted scene analysis is accurate and faithful to the source screenplay text.\n\nCompare the extracted scene data against the original scene text and evaluate:\n\n1. **Heading accuracy**: Is the scene heading correct (location, INT/EXT, time of day)?\n2. **Character completeness**: Are all characters who appear or speak listed?\n3. **Summary fidelity**: Does the summary accurately describe what happens? No fabrications?\n4. **Narrative beats**: Are the identified beats actually present in the scene?\n5. **Tone assessment**: Does the tone description match the actual mood of the scene?\n6. **Confidence calibration**: Is the confidence score reasonable given the quality?\n\nReturn a JSON object with:\n- passed: boolean (true if the extraction is faithful, false if it has significant errors)\n- confidence: float 0-1 (your confidence in this QA judgment)\n- issues: array of objects, each with:\n  - severity: \"error\" (factual wrong), \"warning\" (misleading), or \"note\" (minor)\n  - description: what's wrong\n  - location: which field has the issue\n- summary: 1-2 sentence overall assessment\n\nBe strict: wrong character names, fabricated events, or incorrect locations are errors.\nMinor omissions or imprecise tone descriptions are warnings.\n\nReturn ONLY valid JSON. No explanations or markdown fences.\n\n==========\nORIGINAL SCENE TEXT:\n{{scene_text}}\n\n==========\nEXTRACTED SCENE DATA:\n{{extracted_data}}\n==========",
        "label": "prompts/qa-pass.txt: You are a QA reviewer validating whether an AI-extracted scene analysis is accurate and faithful to the source screenplay text.\n\nCompare the extracted scene data against the original scene text and evaluate:\n\n1. **Heading accuracy**: Is the scene heading correct (location, INT/EXT, time of day)?\n2. **Character completeness**: Are all characters who appear or speak listed?\n3. **Summary fidelity**: Does the summary accurately describe what happens? No fabrications?\n4. **Narrative beats**: Are the identified beats actually present in the scene?\n5. **Tone assessment**: Does the tone description match the actual mood of the scene?\n6. **Confidence calibration**: Is the confidence score reasonable given the quality?\n\nReturn a JSON object with:\n- passed: boolean (true if the extraction is faithful, false if it has significant errors)\n- confidence: float 0-1 (your confidence in this QA judgment)\n- issues: array of objects, each with:\n  - severity: \"error\" (factual wrong), \"warning\" (misleading), or \"note\" (minor)\n  - description: what's wrong\n  - location: which field has the issue\n- summary: 1-2 sentence overall assessment\n\nBe strict: wrong character names, fabricated events, or incorrect locations are errors.\nMinor omissions or imprecise tone descriptions are warnings.\n\nReturn ONLY valid JSON. No explanations or markdown fences.\n\n==========\nORIGINAL SCENE TEXT:\n{{scene_text}}\n\n==========\nEXTRACTED SCENE DATA:\n{{extracted_data}}\n==========",
        "id": "8df20c2c4a6081352d6b06e144ddbc1e0a5244f9a3c2000d40df12fc9a94e543",
        "provider": "Gemini 2.5 Flash",
        "metrics": {
          "score": 2,
          "testPassCount": 2,
          "testFailCount": 0,
          "testErrorCount": 0,
          "assertPassCount": 4,
          "assertFailCount": 0,
          "totalLatencyMs": 17043,
          "tokenUsage": {
            "prompt": 2148,
            "completion": 472,
            "cached": 0,
            "total": 6237,
            "numRequests": 2,
            "completionDetails": {
              "reasoning": 3617,
              "acceptedPrediction": 0,
              "rejectedPrediction": 0
            },
            "assertions": {
              "total": 1249,
              "prompt": 1014,
              "completion": 235,
              "cached": 0,
              "numRequests": 0,
              "completionDetails": {
                "reasoning": 0,
                "acceptedPrediction": 0,
                "rejectedPrediction": 0
              }
            }
          },
          "namedScores": {},
          "namedScoresCount": {},
          "cost": 0.0108669
        }
      },
      {
        "raw": "You are a QA reviewer validating whether an AI-extracted scene analysis is accurate and faithful to the source screenplay text.\n\nCompare the extracted scene data against the original scene text and evaluate:\n\n1. **Heading accuracy**: Is the scene heading correct (location, INT/EXT, time of day)?\n2. **Character completeness**: Are all characters who appear or speak listed?\n3. **Summary fidelity**: Does the summary accurately describe what happens? No fabrications?\n4. **Narrative beats**: Are the identified beats actually present in the scene?\n5. **Tone assessment**: Does the tone description match the actual mood of the scene?\n6. **Confidence calibration**: Is the confidence score reasonable given the quality?\n\nReturn a JSON object with:\n- passed: boolean (true if the extraction is faithful, false if it has significant errors)\n- confidence: float 0-1 (your confidence in this QA judgment)\n- issues: array of objects, each with:\n  - severity: \"error\" (factual wrong), \"warning\" (misleading), or \"note\" (minor)\n  - description: what's wrong\n  - location: which field has the issue\n- summary: 1-2 sentence overall assessment\n\nBe strict: wrong character names, fabricated events, or incorrect locations are errors.\nMinor omissions or imprecise tone descriptions are warnings.\n\nReturn ONLY valid JSON. No explanations or markdown fences.\n\n==========\nORIGINAL SCENE TEXT:\n{{scene_text}}\n\n==========\nEXTRACTED SCENE DATA:\n{{extracted_data}}\n==========",
        "label": "prompts/qa-pass.txt: You are a QA reviewer validating whether an AI-extracted scene analysis is accurate and faithful to the source screenplay text.\n\nCompare the extracted scene data against the original scene text and evaluate:\n\n1. **Heading accuracy**: Is the scene heading correct (location, INT/EXT, time of day)?\n2. **Character completeness**: Are all characters who appear or speak listed?\n3. **Summary fidelity**: Does the summary accurately describe what happens? No fabrications?\n4. **Narrative beats**: Are the identified beats actually present in the scene?\n5. **Tone assessment**: Does the tone description match the actual mood of the scene?\n6. **Confidence calibration**: Is the confidence score reasonable given the quality?\n\nReturn a JSON object with:\n- passed: boolean (true if the extraction is faithful, false if it has significant errors)\n- confidence: float 0-1 (your confidence in this QA judgment)\n- issues: array of objects, each with:\n  - severity: \"error\" (factual wrong), \"warning\" (misleading), or \"note\" (minor)\n  - description: what's wrong\n  - location: which field has the issue\n- summary: 1-2 sentence overall assessment\n\nBe strict: wrong character names, fabricated events, or incorrect locations are errors.\nMinor omissions or imprecise tone descriptions are warnings.\n\nReturn ONLY valid JSON. No explanations or markdown fences.\n\n==========\nORIGINAL SCENE TEXT:\n{{scene_text}}\n\n==========\nEXTRACTED SCENE DATA:\n{{extracted_data}}\n==========",
        "id": "8df20c2c4a6081352d6b06e144ddbc1e0a5244f9a3c2000d40df12fc9a94e543",
        "provider": "Gemini 3 Flash",
        "metrics": {
          "score": 2,
          "testPassCount": 2,
          "testFailCount": 0,
          "testErrorCount": 0,
          "assertPassCount": 4,
          "assertFailCount": 0,
          "totalLatencyMs": 23907,
          "tokenUsage": {
            "prompt": 2148,
            "completion": 513,
            "cached": 0,
            "total": 6063,
            "numRequests": 2,
            "completionDetails": {
              "reasoning": 3402,
              "acceptedPrediction": 0,
              "rejectedPrediction": 0
            },
            "assertions": {
              "total": 1300,
              "prompt": 1034,
              "completion": 266,
              "cached": 0,
              "numRequests": 0,
              "completionDetails": {
                "reasoning": 0,
                "acceptedPrediction": 0,
                "rejectedPrediction": 0
              }
            }
          },
          "namedScores": {},
          "namedScoresCount": {},
          "cost": 0.012818999999999999
        }
      },
      {
        "raw": "You are a QA reviewer validating whether an AI-extracted scene analysis is accurate and faithful to the source screenplay text.\n\nCompare the extracted scene data against the original scene text and evaluate:\n\n1. **Heading accuracy**: Is the scene heading correct (location, INT/EXT, time of day)?\n2. **Character completeness**: Are all characters who appear or speak listed?\n3. **Summary fidelity**: Does the summary accurately describe what happens? No fabrications?\n4. **Narrative beats**: Are the identified beats actually present in the scene?\n5. **Tone assessment**: Does the tone description match the actual mood of the scene?\n6. **Confidence calibration**: Is the confidence score reasonable given the quality?\n\nReturn a JSON object with:\n- passed: boolean (true if the extraction is faithful, false if it has significant errors)\n- confidence: float 0-1 (your confidence in this QA judgment)\n- issues: array of objects, each with:\n  - severity: \"error\" (factual wrong), \"warning\" (misleading), or \"note\" (minor)\n  - description: what's wrong\n  - location: which field has the issue\n- summary: 1-2 sentence overall assessment\n\nBe strict: wrong character names, fabricated events, or incorrect locations are errors.\nMinor omissions or imprecise tone descriptions are warnings.\n\nReturn ONLY valid JSON. No explanations or markdown fences.\n\n==========\nORIGINAL SCENE TEXT:\n{{scene_text}}\n\n==========\nEXTRACTED SCENE DATA:\n{{extracted_data}}\n==========",
        "label": "prompts/qa-pass.txt: You are a QA reviewer validating whether an AI-extracted scene analysis is accurate and faithful to the source screenplay text.\n\nCompare the extracted scene data against the original scene text and evaluate:\n\n1. **Heading accuracy**: Is the scene heading correct (location, INT/EXT, time of day)?\n2. **Character completeness**: Are all characters who appear or speak listed?\n3. **Summary fidelity**: Does the summary accurately describe what happens? No fabrications?\n4. **Narrative beats**: Are the identified beats actually present in the scene?\n5. **Tone assessment**: Does the tone description match the actual mood of the scene?\n6. **Confidence calibration**: Is the confidence score reasonable given the quality?\n\nReturn a JSON object with:\n- passed: boolean (true if the extraction is faithful, false if it has significant errors)\n- confidence: float 0-1 (your confidence in this QA judgment)\n- issues: array of objects, each with:\n  - severity: \"error\" (factual wrong), \"warning\" (misleading), or \"note\" (minor)\n  - description: what's wrong\n  - location: which field has the issue\n- summary: 1-2 sentence overall assessment\n\nBe strict: wrong character names, fabricated events, or incorrect locations are errors.\nMinor omissions or imprecise tone descriptions are warnings.\n\nReturn ONLY valid JSON. No explanations or markdown fences.\n\n==========\nORIGINAL SCENE TEXT:\n{{scene_text}}\n\n==========\nEXTRACTED SCENE DATA:\n{{extracted_data}}\n==========",
        "id": "8df20c2c4a6081352d6b06e144ddbc1e0a5244f9a3c2000d40df12fc9a94e543",
        "provider": "GPT-5.2",
        "metrics": {
          "score": 2,
          "testPassCount": 2,
          "testFailCount": 0,
          "testErrorCount": 0,
          "assertPassCount": 4,
          "assertFailCount": 0,
          "totalLatencyMs": 10098,
          "tokenUsage": {
            "prompt": 2069,
            "completion": 708,
            "cached": 0,
            "total": 2777,
            "numRequests": 2,
            "completionDetails": {
              "reasoning": 0,
              "acceptedPrediction": 0,
              "rejectedPrediction": 0
            },
            "assertions": {
              "total": 1545,
              "prompt": 1238,
              "completion": 307,
              "cached": 0,
              "numRequests": 0,
              "completionDetails": {
                "reasoning": 0,
                "acceptedPrediction": 0,
                "rejectedPrediction": 0
              }
            }
          },
          "namedScores": {},
          "namedScoresCount": {},
          "cost": 0.01353275
        }
      },
      {
        "raw": "You are a QA reviewer validating whether an AI-extracted scene analysis is accurate and faithful to the source screenplay text.\n\nCompare the extracted scene data against the original scene text and evaluate:\n\n1. **Heading accuracy**: Is the scene heading correct (location, INT/EXT, time of day)?\n2. **Character completeness**: Are all characters who appear or speak listed?\n3. **Summary fidelity**: Does the summary accurately describe what happens? No fabrications?\n4. **Narrative beats**: Are the identified beats actually present in the scene?\n5. **Tone assessment**: Does the tone description match the actual mood of the scene?\n6. **Confidence calibration**: Is the confidence score reasonable given the quality?\n\nReturn a JSON object with:\n- passed: boolean (true if the extraction is faithful, false if it has significant errors)\n- confidence: float 0-1 (your confidence in this QA judgment)\n- issues: array of objects, each with:\n  - severity: \"error\" (factual wrong), \"warning\" (misleading), or \"note\" (minor)\n  - description: what's wrong\n  - location: which field has the issue\n- summary: 1-2 sentence overall assessment\n\nBe strict: wrong character names, fabricated events, or incorrect locations are errors.\nMinor omissions or imprecise tone descriptions are warnings.\n\nReturn ONLY valid JSON. No explanations or markdown fences.\n\n==========\nORIGINAL SCENE TEXT:\n{{scene_text}}\n\n==========\nEXTRACTED SCENE DATA:\n{{extracted_data}}\n==========",
        "label": "prompts/qa-pass.txt: You are a QA reviewer validating whether an AI-extracted scene analysis is accurate and faithful to the source screenplay text.\n\nCompare the extracted scene data against the original scene text and evaluate:\n\n1. **Heading accuracy**: Is the scene heading correct (location, INT/EXT, time of day)?\n2. **Character completeness**: Are all characters who appear or speak listed?\n3. **Summary fidelity**: Does the summary accurately describe what happens? No fabrications?\n4. **Narrative beats**: Are the identified beats actually present in the scene?\n5. **Tone assessment**: Does the tone description match the actual mood of the scene?\n6. **Confidence calibration**: Is the confidence score reasonable given the quality?\n\nReturn a JSON object with:\n- passed: boolean (true if the extraction is faithful, false if it has significant errors)\n- confidence: float 0-1 (your confidence in this QA judgment)\n- issues: array of objects, each with:\n  - severity: \"error\" (factual wrong), \"warning\" (misleading), or \"note\" (minor)\n  - description: what's wrong\n  - location: which field has the issue\n- summary: 1-2 sentence overall assessment\n\nBe strict: wrong character names, fabricated events, or incorrect locations are errors.\nMinor omissions or imprecise tone descriptions are warnings.\n\nReturn ONLY valid JSON. No explanations or markdown fences.\n\n==========\nORIGINAL SCENE TEXT:\n{{scene_text}}\n\n==========\nEXTRACTED SCENE DATA:\n{{extracted_data}}\n==========",
        "id": "8df20c2c4a6081352d6b06e144ddbc1e0a5244f9a3c2000d40df12fc9a94e543",
        "provider": "Claude Opus 4.6",
        "metrics": {
          "score": 1.99,
          "testPassCount": 2,
          "testFailCount": 0,
          "testErrorCount": 0,
          "assertPassCount": 4,
          "assertFailCount": 0,
          "totalLatencyMs": 18916,
          "tokenUsage": {
            "prompt": 2262,
            "completion": 956,
            "cached": 0,
            "total": 3218,
            "numRequests": 2,
            "completionDetails": {
              "reasoning": 0,
              "acceptedPrediction": 0,
              "rejectedPrediction": 0
            },
            "assertions": {
              "total": 1867,
              "prompt": 1592,
              "completion": 275,
              "cached": 0,
              "numRequests": 0,
              "completionDetails": {
                "reasoning": 0,
                "acceptedPrediction": 0,
                "rejectedPrediction": 0
              }
            }
          },
          "namedScores": {},
          "namedScoresCount": {},
          "cost": 0.035210000000000005
        }
      },
      {
        "raw": "You are a QA reviewer validating whether an AI-extracted scene analysis is accurate and faithful to the source screenplay text.\n\nCompare the extracted scene data against the original scene text and evaluate:\n\n1. **Heading accuracy**: Is the scene heading correct (location, INT/EXT, time of day)?\n2. **Character completeness**: Are all characters who appear or speak listed?\n3. **Summary fidelity**: Does the summary accurately describe what happens? No fabrications?\n4. **Narrative beats**: Are the identified beats actually present in the scene?\n5. **Tone assessment**: Does the tone description match the actual mood of the scene?\n6. **Confidence calibration**: Is the confidence score reasonable given the quality?\n\nReturn a JSON object with:\n- passed: boolean (true if the extraction is faithful, false if it has significant errors)\n- confidence: float 0-1 (your confidence in this QA judgment)\n- issues: array of objects, each with:\n  - severity: \"error\" (factual wrong), \"warning\" (misleading), or \"note\" (minor)\n  - description: what's wrong\n  - location: which field has the issue\n- summary: 1-2 sentence overall assessment\n\nBe strict: wrong character names, fabricated events, or incorrect locations are errors.\nMinor omissions or imprecise tone descriptions are warnings.\n\nReturn ONLY valid JSON. No explanations or markdown fences.\n\n==========\nORIGINAL SCENE TEXT:\n{{scene_text}}\n\n==========\nEXTRACTED SCENE DATA:\n{{extracted_data}}\n==========",
        "label": "prompts/qa-pass.txt: You are a QA reviewer validating whether an AI-extracted scene analysis is accurate and faithful to the source screenplay text.\n\nCompare the extracted scene data against the original scene text and evaluate:\n\n1. **Heading accuracy**: Is the scene heading correct (location, INT/EXT, time of day)?\n2. **Character completeness**: Are all characters who appear or speak listed?\n3. **Summary fidelity**: Does the summary accurately describe what happens? No fabrications?\n4. **Narrative beats**: Are the identified beats actually present in the scene?\n5. **Tone assessment**: Does the tone description match the actual mood of the scene?\n6. **Confidence calibration**: Is the confidence score reasonable given the quality?\n\nReturn a JSON object with:\n- passed: boolean (true if the extraction is faithful, false if it has significant errors)\n- confidence: float 0-1 (your confidence in this QA judgment)\n- issues: array of objects, each with:\n  - severity: \"error\" (factual wrong), \"warning\" (misleading), or \"note\" (minor)\n  - description: what's wrong\n  - location: which field has the issue\n- summary: 1-2 sentence overall assessment\n\nBe strict: wrong character names, fabricated events, or incorrect locations are errors.\nMinor omissions or imprecise tone descriptions are warnings.\n\nReturn ONLY valid JSON. No explanations or markdown fences.\n\n==========\nORIGINAL SCENE TEXT:\n{{scene_text}}\n\n==========\nEXTRACTED SCENE DATA:\n{{extracted_data}}\n==========",
        "id": "8df20c2c4a6081352d6b06e144ddbc1e0a5244f9a3c2000d40df12fc9a94e543",
        "provider": "Gemini 2.5 Pro",
        "metrics": {
          "score": 1.99,
          "testPassCount": 2,
          "testFailCount": 0,
          "testErrorCount": 0,
          "assertPassCount": 4,
          "assertFailCount": 0,
          "totalLatencyMs": 21126,
          "tokenUsage": {
            "prompt": 2148,
            "completion": 463,
            "cached": 0,
            "total": 4602,
            "numRequests": 2,
            "completionDetails": {
              "reasoning": 1991,
              "acceptedPrediction": 0,
              "rejectedPrediction": 0
            },
            "assertions": {
              "total": 1399,
              "prompt": 1136,
              "completion": 263,
              "cached": 0,
              "numRequests": 0,
              "completionDetails": {
                "reasoning": 0,
                "acceptedPrediction": 0,
                "rejectedPrediction": 0
              }
            }
          },
          "namedScores": {},
          "namedScoresCount": {},
          "cost": 0.027225
        }
      },
      {
        "raw": "You are a QA reviewer validating whether an AI-extracted scene analysis is accurate and faithful to the source screenplay text.\n\nCompare the extracted scene data against the original scene text and evaluate:\n\n1. **Heading accuracy**: Is the scene heading correct (location, INT/EXT, time of day)?\n2. **Character completeness**: Are all characters who appear or speak listed?\n3. **Summary fidelity**: Does the summary accurately describe what happens? No fabrications?\n4. **Narrative beats**: Are the identified beats actually present in the scene?\n5. **Tone assessment**: Does the tone description match the actual mood of the scene?\n6. **Confidence calibration**: Is the confidence score reasonable given the quality?\n\nReturn a JSON object with:\n- passed: boolean (true if the extraction is faithful, false if it has significant errors)\n- confidence: float 0-1 (your confidence in this QA judgment)\n- issues: array of objects, each with:\n  - severity: \"error\" (factual wrong), \"warning\" (misleading), or \"note\" (minor)\n  - description: what's wrong\n  - location: which field has the issue\n- summary: 1-2 sentence overall assessment\n\nBe strict: wrong character names, fabricated events, or incorrect locations are errors.\nMinor omissions or imprecise tone descriptions are warnings.\n\nReturn ONLY valid JSON. No explanations or markdown fences.\n\n==========\nORIGINAL SCENE TEXT:\n{{scene_text}}\n\n==========\nEXTRACTED SCENE DATA:\n{{extracted_data}}\n==========",
        "label": "prompts/qa-pass.txt: You are a QA reviewer validating whether an AI-extracted scene analysis is accurate and faithful to the source screenplay text.\n\nCompare the extracted scene data against the original scene text and evaluate:\n\n1. **Heading accuracy**: Is the scene heading correct (location, INT/EXT, time of day)?\n2. **Character completeness**: Are all characters who appear or speak listed?\n3. **Summary fidelity**: Does the summary accurately describe what happens? No fabrications?\n4. **Narrative beats**: Are the identified beats actually present in the scene?\n5. **Tone assessment**: Does the tone description match the actual mood of the scene?\n6. **Confidence calibration**: Is the confidence score reasonable given the quality?\n\nReturn a JSON object with:\n- passed: boolean (true if the extraction is faithful, false if it has significant errors)\n- confidence: float 0-1 (your confidence in this QA judgment)\n- issues: array of objects, each with:\n  - severity: \"error\" (factual wrong), \"warning\" (misleading), or \"note\" (minor)\n  - description: what's wrong\n  - location: which field has the issue\n- summary: 1-2 sentence overall assessment\n\nBe strict: wrong character names, fabricated events, or incorrect locations are errors.\nMinor omissions or imprecise tone descriptions are warnings.\n\nReturn ONLY valid JSON. No explanations or markdown fences.\n\n==========\nORIGINAL SCENE TEXT:\n{{scene_text}}\n\n==========\nEXTRACTED SCENE DATA:\n{{extracted_data}}\n==========",
        "id": "8df20c2c4a6081352d6b06e144ddbc1e0a5244f9a3c2000d40df12fc9a94e543",
        "provider": "Gemini 3 Pro",
        "metrics": {
          "score": 2,
          "testPassCount": 2,
          "testFailCount": 0,
          "testErrorCount": 0,
          "assertPassCount": 4,
          "assertFailCount": 0,
          "totalLatencyMs": 93007,
          "tokenUsage": {
            "prompt": 2148,
            "completion": 453,
            "cached": 0,
            "total": 4857,
            "numRequests": 2,
            "completionDetails": {
              "reasoning": 2256,
              "acceptedPrediction": 0,
              "rejectedPrediction": 0
            },
            "assertions": {
              "total": 1235,
              "prompt": 985,
              "completion": 250,
              "cached": 0,
              "numRequests": 0,
              "completionDetails": {
                "reasoning": 0,
                "acceptedPrediction": 0,
                "rejectedPrediction": 0
              }
            }
          },
          "namedScores": {},
          "namedScoresCount": {},
          "cost": 0.036804
        }
      }
    ],
    "results": [
      {
        "cost": 0.00027110000000000003,
        "error": "The QA evaluation marked the extraction as 'passed: false' with multiple error-severity issues, including claims of fabricated details and misinterpretations. According to the rubric, this was a GOOD scene extraction that accurately reflects the source text. The QA model should have marked it as passed (true), found zero or very few errors, had high confidence, and confirmed accuracy. Instead, it produced a false negative by incorrectly flagging a good extraction as failing, with fabricated criticisms of its own.",
        "gradingResult": {
          "pass": false,
          "score": 0.19999999999999998,
          "reason": "The QA evaluation marked the extraction as 'passed: false' with multiple error-severity issues, including claims of fabricated details and misinterpretations. According to the rubric, this was a GOOD scene extraction that accurately reflects the source text. The QA model should have marked it as passed (true), found zero or very few errors, had high confidence, and confirmed accuracy. Instead, it produced a false negative by incorrectly flagging a good extraction as failing, with fabricated criticisms of its own.",
          "namedScores": {},
          "tokensUsed": {
            "total": 759,
            "prompt": 629,
            "completion": 130,
            "cached": 0,
            "numRequests": 0
          },
          "componentResults": [
            {
              "pass": false,
              "score": 0.35,
              "reason": "confidence_calibration=1.00 | issue_detection=0.00 | json_valid=1.00 | pass_correct=0.00 | severity_accuracy=0.33 | summary_quality=1.00 | passed=False, expected=True | Good output: 4 errors found (max 0)",
              "assertion": {
                "type": "python",
                "value": "file://../scorers/qa_pass_scorer.py"
              }
            },
            {
              "assertion": {
                "type": "llm-rubric",
                "value": "This QA evaluation was given a GOOD scene extraction that accurately\nreflects the source text. The QA model should have:\n\n1. Marked it as passed (true)\n2. Found zero or very few errors\n3. Had high confidence in the assessment\n4. Written a summary confirming accuracy\n\nIf the model incorrectly flagged the good extraction as failing,\nthat's a false negative and should score poorly.\n"
              },
              "pass": false,
              "score": 0.05,
              "reason": "The QA evaluation marked the extraction as 'passed: false' with multiple error-severity issues, including claims of fabricated details and misinterpretations. According to the rubric, this was a GOOD scene extraction that accurately reflects the source text. The QA model should have marked it as passed (true), found zero or very few errors, had high confidence, and confirmed accuracy. Instead, it produced a false negative by incorrectly flagging a good extraction as failing, with fabricated criticisms of its own.",
              "tokensUsed": {
                "total": 759,
                "prompt": 629,
                "completion": 130,
                "cached": 0,
                "numRequests": 0,
                "completionDetails": {
                  "reasoning": 0,
                  "acceptedPrediction": 0,
                  "rejectedPrediction": 0
                }
              },
              "metadata": {
                "renderedGradingPrompt": "[{\"role\":\"system\",\"content\":\"You are grading output according to a user-specified rubric. If the statement in the rubric is true, then the output passes the test. You respond with a JSON object with this structure: {reason: string, pass: boolean, score: number}\\n\\nExamples:\\n\\n<Output>Hello world</Output>\\n<Rubric>Content contains a greeting</Rubric>\\n{\\\"reason\\\": \\\"the content contains the word 'Hello'\\\", \\\"pass\\\": true, \\\"score\\\": 1.0}\\n\\n<Output>Avast ye swabs, repel the invaders!</Output>\\n<Rubric>Does not speak like a pirate</Rubric>\\n{\\\"reason\\\": \\\"'avast ye' is a common pirate term\\\", \\\"pass\\\": false, \\\"score\\\": 0.0}\"},{\"role\":\"user\",\"content\":\"<Output>\\n{\\\"passed\\\":false,\\\"confidence\\\":0.75,\\\"issues\\\":[{\\\"severity\\\":\\\"error\\\",\\\"description\\\":\\\"The scene heading is correct, but the original specifies 'ELEVATOR' as part of the location, which is missing in the extracted data's location field.\\\",\\\"location\\\":\\\"heading\\\"},{\\\"severity\\\":\\\"error\\\",\\\"description\\\":\\\"The original scene features only two characters: Rose and Mariner. The extracted data omits the mention of Rose's blood-spattered face and her uniform details, which are relevant to character description.\\\",\\\"location\\\":\\\"character completeness\\\"},{\\\"severity\\\":\\\"error\\\",\\\"description\\\":\\\"The summary fabricates details such as Rose discovering a skull fragment and the muzak playing, which are not explicitly described in the source scene text.\\\",\\\"location\\\":\\\"summary fidelity\\\"},{\\\"severity\\\":\\\"error\\\",\\\"description\\\":\\\"The narrative beats include a 'comic relief' beat about the skull fragment and muzak, which are not present in the original scene text.\\\",\\\"location\\\":\\\"narrative beats\\\"},{\\\"severity\\\":\\\"warning\\\",\\\"description\\\":\\\"The tone is described as 'dark comedy with bursts of tension,' which is a reasonable interpretation but not explicitly stated in the scene text.\\\",\\\"location\\\":\\\"tone assessment\\\"},{\\\"severity\\\":\\\"note\\\",\\\"description\\\":\\\"Confidence score of 0.91 is appropriate given the discrepancies and fabrications present.\\\",\\\"location\\\":\\\"confidence calibration\\\"}],\\\"summary\\\":\\\"The extracted scene analysis contains significant inaccuracies, including fabricated details and misinterpretations of the scene content. It partially captures the characters but introduces elements not present in the source text, leading to a conclusion that it is not fully faithful.\\\"}\\n</Output>\\n<Rubric>\\nThis QA evaluation was given a GOOD scene extraction that accurately\\nreflects the source text. The QA model should have:\\n\\n1. Marked it as passed (true)\\n2. Found zero or very few errors\\n3. Had high confidence in the assessment\\n4. Written a summary confirming accuracy\\n\\nIf the model incorrectly flagged the good extraction as failing,\\nthat's a false negative and should score poorly.\\n\\n</Rubric>\"}]"
              }
            }
          ]
        },
        "id": "9604e367-9b04-4018-8010-9e794afaa2be",
        "latencyMs": 3667,
        "namedScores": {},
        "prompt": {
          "raw": "You are a QA reviewer validating whether an AI-extracted scene analysis is accurate and faithful to the source screenplay text.\n\nCompare the extracted scene data against the original scene text and evaluate:\n\n1. **Heading accuracy**: Is the scene heading correct (location, INT/EXT, time of day)?\n2. **Character completeness**: Are all characters who appear or speak listed?\n3. **Summary fidelity**: Does the summary accurately describe what happens? No fabrications?\n4. **Narrative beats**: Are the identified beats actually present in the scene?\n5. **Tone assessment**: Does the tone description match the actual mood of the scene?\n6. **Confidence calibration**: Is the confidence score reasonable given the quality?\n\nReturn a JSON object with:\n- passed: boolean (true if the extraction is faithful, false if it has significant errors)\n- confidence: float 0-1 (your confidence in this QA judgment)\n- issues: array of objects, each with:\n  - severity: \"error\" (factual wrong), \"warning\" (misleading), or \"note\" (minor)\n  - description: what's wrong\n  - location: which field has the issue\n- summary: 1-2 sentence overall assessment\n\nBe strict: wrong character names, fabricated events, or incorrect locations are errors.\nMinor omissions or imprecise tone descriptions are warnings.\n\nReturn ONLY valid JSON. No explanations or markdown fences.\n\n==========\nORIGINAL SCENE TEXT:\nINT. RUDDY & GREEN BUILDING - ELEVATOR\n\nUB40's \"I Can't Help Falling in Love With You\" muzak.\n\nROSE (mid-30s) leans against the elevator wall, panting. She's wearing a Tim Hortons uniform, her hair is a mess, and there's blood spattered on her face.\n\nShe looks right, pants a few more times, then squints in disgust. She gingerly picks up a bloody scrap of something with hair on it. She snorts and drops it.\n\nROSE\nIs that skull??\n\nNext to her is Mariner, also panting, covered in far more blood. His face is broad, stoic, and frowning. He has gray-blue eyes and a thick, curly, beard barely streaked with gray. He wears a red knit cap and a small mask.\n\nFULL-SCREEN SUPERIMPOSED TITLE CARD: \"THE MARINER\"\n\nHe blinks a few times as a drop of blood falls from his eyebrow. He looks toward her, then spits out some blood.\n\nMARINER\nYeaaaaah...\n\nHe's built like a pro-wrestler. Moss green SWEATER stretched over his huge frame, sleeves rolled showing heavy leather BRACERS adorned with anchors. His inner forearm has a classic heart-and-arrow TATTOO with \"Dad\" in the centre. Across his chest is a BANDOLIER of bright red 12-gauge shells, FISH HOOKS hanging from the bottom edge. Heavy rubberized BOOTS go past his knees. A CAPE of heavy FISHING NET edged with WEIGHTS hangs from his shoulders.\n\nHe holds a STOUT WOODEN OAR in both hands, edged with METAL and dripping with BLOOD.\n\nROSE\nWhere were you when they grabbed me? You were supposed to pick me up at work!\n\nMARINER\nYeah, about that, I got a little... distracted.\n\nROSE\nDistracted. You got DISTRACTED?!\n\nMARINER\nI was also... tracking the car... that grabbed you... through the AirTag... I put on your phone.\n\nRose stops. She's really not happy about this.\n\nROSE\nYou Airtagged me?!\n\n==========\nEXTRACTED SCENE DATA:\n{\n  \"scene_number\": 4,\n  \"heading\": \"INT. RUDDY & GREEN BUILDING - ELEVATOR\",\n  \"int_ext\": \"INT\",\n  \"location\": \"RUDDY & GREEN BUILDING - ELEVATOR\",\n  \"time_of_day\": null,\n  \"characters_present\": [\"ROSE\", \"MARINER\"],\n  \"summary\": \"Rose and Mariner ride the elevator after a violent rescue. Rose discovers a skull fragment on the floor while muzak plays. Mariner is introduced in full  a hulking vigilante in fishing-themed costume with an oar, net cape, and shell bandolier. Rose confronts him about being late to pick her up, and he reveals he tracked her via an AirTag on her phone, sparking a trust conflict between them.\",\n  \"narrative_beats\": [\n    {\"beat_type\": \"character_introduction\", \"description\": \"Full description of Mariner's fishing-themed vigilante costume  oar, net cape, bracers, shell bandolier, fish hooks.\", \"confidence\": 0.95},\n    {\"beat_type\": \"comic_relief\", \"description\": \"Rose discovers a skull fragment while muzak plays, establishing the dark comedy tone.\", \"confidence\": 0.90},\n    {\"beat_type\": \"revelation\", \"description\": \"Mariner admits he tracked Rose via AirTag on her phone, creating a trust conflict.\", \"confidence\": 0.88},\n    {\"beat_type\": \"conflict\", \"description\": \"Rose's anger escalates from being grabbed to learning she was being surveilled by Mariner.\", \"confidence\": 0.85}\n  ],\n  \"tone_mood\": \"dark comedy with bursts of tension\",\n  \"confidence\": 0.91\n}\n==========",
          "label": "prompts/qa-pass.txt: You are a QA reviewer validating whether an AI-extracted scene analysis is accurate and faithful to the source screenplay text.\n\nCompare the extracted scene data against the original scene text and evaluate:\n\n1. **Heading accuracy**: Is the scene heading correct (location, INT/EXT, time of day)?\n2. **Character completeness**: Are all characters who appear or speak listed?\n3. **Summary fidelity**: Does the summary accurately describe what happens? No fabrications?\n4. **Narrative beats**: Are the identified beats actually present in the scene?\n5. **Tone assessment**: Does the tone description match the actual mood of the scene?\n6. **Confidence calibration**: Is the confidence score reasonable given the quality?\n\nReturn a JSON object with:\n- passed: boolean (true if the extraction is faithful, false if it has significant errors)\n- confidence: float 0-1 (your confidence in this QA judgment)\n- issues: array of objects, each with:\n  - severity: \"error\" (factual wrong), \"warning\" (misleading), or \"note\" (minor)\n  - description: what's wrong\n  - location: which field has the issue\n- summary: 1-2 sentence overall assessment\n\nBe strict: wrong character names, fabricated events, or incorrect locations are errors.\nMinor omissions or imprecise tone descriptions are warnings.\n\nReturn ONLY valid JSON. No explanations or markdown fences.\n\n==========\nORIGINAL SCENE TEXT:\n{{scene_text}}\n\n==========\nEXTRACTED SCENE DATA:\n{{extracted_data}}\n==========",
          "config": {
            "provider": "anthropic:messages:claude-opus-4-6"
          }
        },
        "promptId": "8df20c2c4a6081352d6b06e144ddbc1e0a5244f9a3c2000d40df12fc9a94e543",
        "promptIdx": 0,
        "provider": {
          "id": "openai:gpt-4.1-nano",
          "label": "GPT-4.1 Nano"
        },
        "response": {
          "output": "{\n  \"passed\": false,\n  \"confidence\": 0.75,\n  \"issues\": [\n    {\n      \"severity\": \"error\",\n      \"description\": \"The scene heading is correct, but the original specifies 'ELEVATOR' as part of the location, which is missing in the extracted data's location field.\",\n      \"location\": \"heading\"\n    },\n    {\n      \"severity\": \"error\",\n      \"description\": \"The original scene features only two characters: Rose and Mariner. The extracted data omits the mention of Rose's blood-spattered face and her uniform details, which are relevant to character description.\",\n      \"location\": \"character completeness\"\n    },\n    {\n      \"severity\": \"error\",\n      \"description\": \"The summary fabricates details such as Rose discovering a skull fragment and the muzak playing, which are not explicitly described in the source scene text.\",\n      \"location\": \"summary fidelity\"\n    },\n    {\n      \"severity\": \"error\",\n      \"description\": \"The narrative beats include a 'comic relief' beat about the skull fragment and muzak, which are not present in the original scene text.\",\n      \"location\": \"narrative beats\"\n    },\n    {\n      \"severity\": \"warning\",\n      \"description\": \"The tone is described as 'dark comedy with bursts of tension,' which is a reasonable interpretation but not explicitly stated in the scene text.\",\n      \"location\": \"tone assessment\"\n    },\n    {\n      \"severity\": \"note\",\n      \"description\": \"Confidence score of 0.91 is appropriate given the discrepancies and fabrications present.\",\n      \"location\": \"confidence calibration\"\n    }\n  ],\n  \"summary\": \"The extracted scene analysis contains significant inaccuracies, including fabricated details and misinterpretations of the scene content. It partially captures the characters but introduces elements not present in the source text, leading to a conclusion that it is not fully faithful.\"\n}",
          "tokenUsage": {
            "total": 1535,
            "prompt": 1143,
            "completion": 392,
            "numRequests": 1,
            "completionDetails": {
              "reasoning": 0,
              "acceptedPrediction": 0,
              "rejectedPrediction": 0
            }
          },
          "cached": false,
          "latencyMs": 3667,
          "finishReason": "stop",
          "cost": 0.00027110000000000003,
          "guardrails": {
            "flagged": false
          },
          "metadata": {
            "http": {
              "status": 200,
              "statusText": "OK",
              "headers": {
                "access-control-expose-headers": "X-Request-ID",
                "alt-svc": "h3=\":443\"; ma=86400",
                "cf-cache-status": "DYNAMIC",
                "cf-ray": "9d5d97d95e5298e3-YVR",
                "connection": "keep-alive",
                "content-encoding": "br",
                "content-type": "application/json",
                "date": "Mon, 02 Mar 2026 04:17:44 GMT",
                "openai-organization": "user-oqdrq8y0bphopngnvkyuu5wr",
                "openai-processing-ms": "3405",
                "openai-project": "proj_ZRoLLwXcJok6Xg2t6eKhI1pn",
                "openai-version": "2020-10-01",
                "server": "cloudflare",
                "set-cookie": "__cf_bm=jg9rgqBcGy3FXWGU2RG1nkYzf7HfwigZRvbQuXeO26o-1772425061.3332467-1.0.1.1-3s39PPo.wm7NqlkxPIhtafKbQdUGTBBcuVLp5ETFKNlWoXQylNNhlBA.S2ZHU4Iqm29nBTW_q2_1H5O0aMzSh7eSxILf0qxaE2tiguuEyixoI7xstcXTdgJDJBT2NNfO; HttpOnly; Secure; Path=/; Domain=api.openai.com; Expires=Mon, 02 Mar 2026 04:47:44 GMT",
                "strict-transport-security": "max-age=31536000; includeSubDomains; preload",
                "transfer-encoding": "chunked",
                "x-content-type-options": "nosniff",
                "x-openai-proxy-wasm": "v0.1",
                "x-ratelimit-limit-requests": "10000",
                "x-ratelimit-limit-tokens": "10000000",
                "x-ratelimit-remaining-requests": "9999",
                "x-ratelimit-remaining-tokens": "9998856",
                "x-ratelimit-reset-requests": "6ms",
                "x-ratelimit-reset-tokens": "6ms",
                "x-request-id": "req_7c1dda8764704b388a186d8ac2e479e2"
              }
            }
          }
        },
        "score": 0.19999999999999998,
        "success": false,
        "testCase": {
          "vars": {
            "scene_text": "file://../input/enrich-scene-elevator.txt",
            "extracted_data": "file://../input/qa-good-scene.json",
            "golden_path": "golden/qa-pass-golden.json",
            "test_key": "good_scene"
          },
          "assert": [
            {
              "type": "python",
              "value": "file://../scorers/qa_pass_scorer.py"
            },
            {
              "type": "llm-rubric",
              "value": "This QA evaluation was given a GOOD scene extraction that accurately\nreflects the source text. The QA model should have:\n\n1. Marked it as passed (true)\n2. Found zero or very few errors\n3. Had high confidence in the assessment\n4. Written a summary confirming accuracy\n\nIf the model incorrectly flagged the good extraction as failing,\nthat's a false negative and should score poorly.\n"
            }
          ],
          "options": {
            "provider": "anthropic:messages:claude-opus-4-6"
          },
          "metadata": {}
        },
        "testIdx": 0,
        "vars": {
          "scene_text": "file://../input/enrich-scene-elevator.txt",
          "extracted_data": "file://../input/qa-good-scene.json",
          "golden_path": "golden/qa-pass-golden.json",
          "test_key": "good_scene"
        },
        "metadata": {
          "http": {
            "status": 200,
            "statusText": "OK",
            "headers": {
              "access-control-expose-headers": "X-Request-ID",
              "alt-svc": "h3=\":443\"; ma=86400",
              "cf-cache-status": "DYNAMIC",
              "cf-ray": "9d5d97d95e5298e3-YVR",
              "connection": "keep-alive",
              "content-encoding": "br",
              "content-type": "application/json",
              "date": "Mon, 02 Mar 2026 04:17:44 GMT",
              "openai-organization": "user-oqdrq8y0bphopngnvkyuu5wr",
              "openai-processing-ms": "3405",
              "openai-project": "proj_ZRoLLwXcJok6Xg2t6eKhI1pn",
              "openai-version": "2020-10-01",
              "server": "cloudflare",
              "set-cookie": "__cf_bm=jg9rgqBcGy3FXWGU2RG1nkYzf7HfwigZRvbQuXeO26o-1772425061.3332467-1.0.1.1-3s39PPo.wm7NqlkxPIhtafKbQdUGTBBcuVLp5ETFKNlWoXQylNNhlBA.S2ZHU4Iqm29nBTW_q2_1H5O0aMzSh7eSxILf0qxaE2tiguuEyixoI7xstcXTdgJDJBT2NNfO; HttpOnly; Secure; Path=/; Domain=api.openai.com; Expires=Mon, 02 Mar 2026 04:47:44 GMT",
              "strict-transport-security": "max-age=31536000; includeSubDomains; preload",
              "transfer-encoding": "chunked",
              "x-content-type-options": "nosniff",
              "x-openai-proxy-wasm": "v0.1",
              "x-ratelimit-limit-requests": "10000",
              "x-ratelimit-limit-tokens": "10000000",
              "x-ratelimit-remaining-requests": "9999",
              "x-ratelimit-remaining-tokens": "9998856",
              "x-ratelimit-reset-requests": "6ms",
              "x-ratelimit-reset-tokens": "6ms",
              "x-request-id": "req_7c1dda8764704b388a186d8ac2e479e2"
            }
          },
          "_promptfooFileMetadata": {}
        },
        "failureReason": 1
      },
      {
        "cost": 0.0002925,
        "error": "The QA model marked the extraction as 'passed: false' despite the rubric stating this was a GOOD scene extraction that accurately reflects the source text. This is a clear false negative. The model found multiple issues (1 error, 4 warnings) that are mostly nitpicky or debatable rather than genuine errors. For example, flagging 'skull fragment' vs 'bloody scrap that might be skull' is a minor interpretive difference, not a real error. The confidence was 0.8, and the summary did not confirm accuracy but instead highlighted minor inaccuracies. The model failed on all four criteria: it didn't mark it as passed, it found too many errors, it didn't have high confidence in a positive assessment, and it didn't write a summary confirming accuracy.",
        "gradingResult": {
          "pass": false,
          "score": 0.34249999999999997,
          "reason": "The QA model marked the extraction as 'passed: false' despite the rubric stating this was a GOOD scene extraction that accurately reflects the source text. This is a clear false negative. The model found multiple issues (1 error, 4 warnings) that are mostly nitpicky or debatable rather than genuine errors. For example, flagging 'skull fragment' vs 'bloody scrap that might be skull' is a minor interpretive difference, not a real error. The confidence was 0.8, and the summary did not confirm accuracy but instead highlighted minor inaccuracies. The model failed on all four criteria: it didn't mark it as passed, it found too many errors, it didn't have high confidence in a positive assessment, and it didn't write a summary confirming accuracy.",
          "namedScores": {},
          "tokensUsed": {
            "total": 936,
            "prompt": 745,
            "completion": 191,
            "cached": 0,
            "numRequests": 0
          },
          "componentResults": [
            {
              "pass": false,
              "score": 0.585,
              "reason": "confidence_calibration=1.00 | issue_detection=0.70 | json_valid=0.90 | pass_correct=0.00 | severity_accuracy=0.80 | summary_quality=1.00 | JSON extracted from code block | passed=False, expected=True | Good output: 1 errors found (max 0)",
              "assertion": {
                "type": "python",
                "value": "file://../scorers/qa_pass_scorer.py"
              }
            },
            {
              "assertion": {
                "type": "llm-rubric",
                "value": "This QA evaluation was given a GOOD scene extraction that accurately\nreflects the source text. The QA model should have:\n\n1. Marked it as passed (true)\n2. Found zero or very few errors\n3. Had high confidence in the assessment\n4. Written a summary confirming accuracy\n\nIf the model incorrectly flagged the good extraction as failing,\nthat's a false negative and should score poorly.\n"
              },
              "pass": false,
              "score": 0.1,
              "reason": "The QA model marked the extraction as 'passed: false' despite the rubric stating this was a GOOD scene extraction that accurately reflects the source text. This is a clear false negative. The model found multiple issues (1 error, 4 warnings) that are mostly nitpicky or debatable rather than genuine errors. For example, flagging 'skull fragment' vs 'bloody scrap that might be skull' is a minor interpretive difference, not a real error. The confidence was 0.8, and the summary did not confirm accuracy but instead highlighted minor inaccuracies. The model failed on all four criteria: it didn't mark it as passed, it found too many errors, it didn't have high confidence in a positive assessment, and it didn't write a summary confirming accuracy.",
              "tokensUsed": {
                "total": 936,
                "prompt": 745,
                "completion": 191,
                "cached": 0,
                "numRequests": 0,
                "completionDetails": {
                  "reasoning": 0,
                  "acceptedPrediction": 0,
                  "rejectedPrediction": 0
                }
              },
              "metadata": {
                "renderedGradingPrompt": "[{\"role\":\"system\",\"content\":\"You are grading output according to a user-specified rubric. If the statement in the rubric is true, then the output passes the test. You respond with a JSON object with this structure: {reason: string, pass: boolean, score: number}\\n\\nExamples:\\n\\n<Output>Hello world</Output>\\n<Rubric>Content contains a greeting</Rubric>\\n{\\\"reason\\\": \\\"the content contains the word 'Hello'\\\", \\\"pass\\\": true, \\\"score\\\": 1.0}\\n\\n<Output>Avast ye swabs, repel the invaders!</Output>\\n<Rubric>Does not speak like a pirate</Rubric>\\n{\\\"reason\\\": \\\"'avast ye' is a common pirate term\\\", \\\"pass\\\": false, \\\"score\\\": 0.0}\"},{\"role\":\"user\",\"content\":\"<Output>\\n```json\\n{\\n  \\\"passed\\\": false,\\n  \\\"confidence\\\": 0.8,\\n  \\\"issues\\\": [\\n    {\\n      \\\"severity\\\": \\\"error\\\",\\n      \\\"description\\\": \\\"The scene heading is missing the time of day, which is present in the original text (implied by the context of the events).\\\",\\n      \\\"location\\\": \\\"heading\\\"\\n    },\\n    {\\n      \\\"severity\\\": \\\"warning\\\",\\n      \\\"description\\\": \\\"The summary mentions a 'violent rescue' which is not explicitly stated in the scene text. The scene focuses on the aftermath and dialogue.\\\",\\n      \\\"location\\\": \\\"summary\\\"\\n    },\\n    {\\n      \\\"severity\\\": \\\"warning\\\",\\n      \\\"description\\\": \\\"The summary states 'Rose discovers a skull fragment on the floor' which is not entirely accurate. She picks up a 'bloody scrap of something with hair on it' and asks 'Is that skull??'. The text doesn't confirm it is a skull fragment.\\\",\\n      \\\"location\\\": \\\"summary\\\"\\n    },\\n    {\\n      \\\"severity\\\": \\\"warning\\\",\\n      \\\"description\\\": \\\"The narrative beat 'Rose discovers a skull fragment while muzak plays, establishing the dark comedy tone' is misleading. The text states she picks up a bloody scrap and asks if it's skull, not that she discovers a skull fragment.\\\",\\n      \\\"location\\\": \\\"narrative_beats\\\"\\n    },\\n    {\\n      \\\"severity\\\": \\\"warning\\\",\\n      \\\"description\\\": \\\"The tone assessment 'dark comedy with bursts of tension' is a reasonable interpretation, but the 'dark comedy' aspect is more strongly implied by the dialogue and the absurdity of Mariner's appearance rather than explicitly stated or demonstrated through a clear comedic event in this specific excerpt.\\\",\\n      \\\"location\\\": \\\"tone_mood\\\"\\n    }\\n  ],\\n  \\\"summary\\\": \\\"The extraction is mostly accurate, but has minor inaccuracies in the summary and narrative beats regarding the 'skull fragment' and the 'violent rescue'. The time of day is also missing from the heading.\\\"\\n}\\n```\\n</Output>\\n<Rubric>\\nThis QA evaluation was given a GOOD scene extraction that accurately\\nreflects the source text. The QA model should have:\\n\\n1. Marked it as passed (true)\\n2. Found zero or very few errors\\n3. Had high confidence in the assessment\\n4. Written a summary confirming accuracy\\n\\nIf the model incorrectly flagged the good extraction as failing,\\nthat's a false negative and should score poorly.\\n\\n</Rubric>\"}]"
              }
            }
          ]
        },
        "id": "693ee96d-ae96-4903-bf19-35be9e46570b",
        "latencyMs": 1607,
        "namedScores": {},
        "prompt": {
          "raw": "You are a QA reviewer validating whether an AI-extracted scene analysis is accurate and faithful to the source screenplay text.\n\nCompare the extracted scene data against the original scene text and evaluate:\n\n1. **Heading accuracy**: Is the scene heading correct (location, INT/EXT, time of day)?\n2. **Character completeness**: Are all characters who appear or speak listed?\n3. **Summary fidelity**: Does the summary accurately describe what happens? No fabrications?\n4. **Narrative beats**: Are the identified beats actually present in the scene?\n5. **Tone assessment**: Does the tone description match the actual mood of the scene?\n6. **Confidence calibration**: Is the confidence score reasonable given the quality?\n\nReturn a JSON object with:\n- passed: boolean (true if the extraction is faithful, false if it has significant errors)\n- confidence: float 0-1 (your confidence in this QA judgment)\n- issues: array of objects, each with:\n  - severity: \"error\" (factual wrong), \"warning\" (misleading), or \"note\" (minor)\n  - description: what's wrong\n  - location: which field has the issue\n- summary: 1-2 sentence overall assessment\n\nBe strict: wrong character names, fabricated events, or incorrect locations are errors.\nMinor omissions or imprecise tone descriptions are warnings.\n\nReturn ONLY valid JSON. No explanations or markdown fences.\n\n==========\nORIGINAL SCENE TEXT:\nINT. RUDDY & GREEN BUILDING - ELEVATOR\n\nUB40's \"I Can't Help Falling in Love With You\" muzak.\n\nROSE (mid-30s) leans against the elevator wall, panting. She's wearing a Tim Hortons uniform, her hair is a mess, and there's blood spattered on her face.\n\nShe looks right, pants a few more times, then squints in disgust. She gingerly picks up a bloody scrap of something with hair on it. She snorts and drops it.\n\nROSE\nIs that skull??\n\nNext to her is Mariner, also panting, covered in far more blood. His face is broad, stoic, and frowning. He has gray-blue eyes and a thick, curly, beard barely streaked with gray. He wears a red knit cap and a small mask.\n\nFULL-SCREEN SUPERIMPOSED TITLE CARD: \"THE MARINER\"\n\nHe blinks a few times as a drop of blood falls from his eyebrow. He looks toward her, then spits out some blood.\n\nMARINER\nYeaaaaah...\n\nHe's built like a pro-wrestler. Moss green SWEATER stretched over his huge frame, sleeves rolled showing heavy leather BRACERS adorned with anchors. His inner forearm has a classic heart-and-arrow TATTOO with \"Dad\" in the centre. Across his chest is a BANDOLIER of bright red 12-gauge shells, FISH HOOKS hanging from the bottom edge. Heavy rubberized BOOTS go past his knees. A CAPE of heavy FISHING NET edged with WEIGHTS hangs from his shoulders.\n\nHe holds a STOUT WOODEN OAR in both hands, edged with METAL and dripping with BLOOD.\n\nROSE\nWhere were you when they grabbed me? You were supposed to pick me up at work!\n\nMARINER\nYeah, about that, I got a little... distracted.\n\nROSE\nDistracted. You got DISTRACTED?!\n\nMARINER\nI was also... tracking the car... that grabbed you... through the AirTag... I put on your phone.\n\nRose stops. She's really not happy about this.\n\nROSE\nYou Airtagged me?!\n\n==========\nEXTRACTED SCENE DATA:\n{\n  \"scene_number\": 4,\n  \"heading\": \"INT. RUDDY & GREEN BUILDING - ELEVATOR\",\n  \"int_ext\": \"INT\",\n  \"location\": \"RUDDY & GREEN BUILDING - ELEVATOR\",\n  \"time_of_day\": null,\n  \"characters_present\": [\"ROSE\", \"MARINER\"],\n  \"summary\": \"Rose and Mariner ride the elevator after a violent rescue. Rose discovers a skull fragment on the floor while muzak plays. Mariner is introduced in full  a hulking vigilante in fishing-themed costume with an oar, net cape, and shell bandolier. Rose confronts him about being late to pick her up, and he reveals he tracked her via an AirTag on her phone, sparking a trust conflict between them.\",\n  \"narrative_beats\": [\n    {\"beat_type\": \"character_introduction\", \"description\": \"Full description of Mariner's fishing-themed vigilante costume  oar, net cape, bracers, shell bandolier, fish hooks.\", \"confidence\": 0.95},\n    {\"beat_type\": \"comic_relief\", \"description\": \"Rose discovers a skull fragment while muzak plays, establishing the dark comedy tone.\", \"confidence\": 0.90},\n    {\"beat_type\": \"revelation\", \"description\": \"Mariner admits he tracked Rose via AirTag on her phone, creating a trust conflict.\", \"confidence\": 0.88},\n    {\"beat_type\": \"conflict\", \"description\": \"Rose's anger escalates from being grabbed to learning she was being surveilled by Mariner.\", \"confidence\": 0.85}\n  ],\n  \"tone_mood\": \"dark comedy with bursts of tension\",\n  \"confidence\": 0.91\n}\n==========",
          "label": "prompts/qa-pass.txt: You are a QA reviewer validating whether an AI-extracted scene analysis is accurate and faithful to the source screenplay text.\n\nCompare the extracted scene data against the original scene text and evaluate:\n\n1. **Heading accuracy**: Is the scene heading correct (location, INT/EXT, time of day)?\n2. **Character completeness**: Are all characters who appear or speak listed?\n3. **Summary fidelity**: Does the summary accurately describe what happens? No fabrications?\n4. **Narrative beats**: Are the identified beats actually present in the scene?\n5. **Tone assessment**: Does the tone description match the actual mood of the scene?\n6. **Confidence calibration**: Is the confidence score reasonable given the quality?\n\nReturn a JSON object with:\n- passed: boolean (true if the extraction is faithful, false if it has significant errors)\n- confidence: float 0-1 (your confidence in this QA judgment)\n- issues: array of objects, each with:\n  - severity: \"error\" (factual wrong), \"warning\" (misleading), or \"note\" (minor)\n  - description: what's wrong\n  - location: which field has the issue\n- summary: 1-2 sentence overall assessment\n\nBe strict: wrong character names, fabricated events, or incorrect locations are errors.\nMinor omissions or imprecise tone descriptions are warnings.\n\nReturn ONLY valid JSON. No explanations or markdown fences.\n\n==========\nORIGINAL SCENE TEXT:\n{{scene_text}}\n\n==========\nEXTRACTED SCENE DATA:\n{{extracted_data}}\n==========",
          "config": {
            "provider": "anthropic:messages:claude-opus-4-6"
          }
        },
        "promptId": "8df20c2c4a6081352d6b06e144ddbc1e0a5244f9a3c2000d40df12fc9a94e543",
        "promptIdx": 2,
        "provider": {
          "id": "google:gemini-2.5-flash-lite",
          "label": "Gemini 2.5 Flash Lite"
        },
        "response": {
          "output": "```json\n{\n  \"passed\": false,\n  \"confidence\": 0.8,\n  \"issues\": [\n    {\n      \"severity\": \"error\",\n      \"description\": \"The scene heading is missing the time of day, which is present in the original text (implied by the context of the events).\",\n      \"location\": \"heading\"\n    },\n    {\n      \"severity\": \"warning\",\n      \"description\": \"The summary mentions a 'violent rescue' which is not explicitly stated in the scene text. The scene focuses on the aftermath and dialogue.\",\n      \"location\": \"summary\"\n    },\n    {\n      \"severity\": \"warning\",\n      \"description\": \"The summary states 'Rose discovers a skull fragment on the floor' which is not entirely accurate. She picks up a 'bloody scrap of something with hair on it' and asks 'Is that skull??'. The text doesn't confirm it is a skull fragment.\",\n      \"location\": \"summary\"\n    },\n    {\n      \"severity\": \"warning\",\n      \"description\": \"The narrative beat 'Rose discovers a skull fragment while muzak plays, establishing the dark comedy tone' is misleading. The text states she picks up a bloody scrap and asks if it's skull, not that she discovers a skull fragment.\",\n      \"location\": \"narrative_beats\"\n    },\n    {\n      \"severity\": \"warning\",\n      \"description\": \"The tone assessment 'dark comedy with bursts of tension' is a reasonable interpretation, but the 'dark comedy' aspect is more strongly implied by the dialogue and the absurdity of Mariner's appearance rather than explicitly stated or demonstrated through a clear comedic event in this specific excerpt.\",\n      \"location\": \"tone_mood\"\n    }\n  ],\n  \"summary\": \"The extraction is mostly accurate, but has minor inaccuracies in the summary and narrative beats regarding the 'skull fragment' and the 'violent rescue'. The time of day is also missing from the heading.\"\n}\n```",
          "tokenUsage": {
            "prompt": 1185,
            "completion": 435,
            "total": 1620,
            "numRequests": 1
          },
          "cost": 0.0002925,
          "raw": {
            "candidates": [
              {
                "content": {
                  "parts": [
                    {
                      "text": "```json\n{\n  \"passed\": false,\n  \"confidence\": 0.8,\n  \"issues\": [\n    {\n      \"severity\": \"error\",\n      \"description\": \"The scene heading is missing the time of day, which is present in the original text (implied by the context of the events).\",\n      \"location\": \"heading\"\n    },\n    {\n      \"severity\": \"warning\",\n      \"description\": \"The summary mentions a 'violent rescue' which is not explicitly stated in the scene text. The scene focuses on the aftermath and dialogue.\",\n      \"location\": \"summary\"\n    },\n    {\n      \"severity\": \"warning\",\n      \"description\": \"The summary states 'Rose discovers a skull fragment on the floor' which is not entirely accurate. She picks up a 'bloody scrap of something with hair on it' and asks 'Is that skull??'. The text doesn't confirm it is a skull fragment.\",\n      \"location\": \"summary\"\n    },\n    {\n      \"severity\": \"warning\",\n      \"description\": \"The narrative beat 'Rose discovers a skull fragment while muzak plays, establishing the dark comedy tone' is misleading. The text states she picks up a bloody scrap and asks if it's skull, not that she discovers a skull fragment.\",\n      \"location\": \"narrative_beats\"\n    },\n    {\n      \"severity\": \"warning\",\n      \"description\": \"The tone assessment 'dark comedy with bursts of tension' is a reasonable interpretation, but the 'dark comedy' aspect is more strongly implied by the dialogue and the absurdity of Mariner's appearance rather than explicitly stated or demonstrated through a clear comedic event in this specific excerpt.\",\n      \"location\": \"tone_mood\"\n    }\n  ],\n  \"summary\": \"The extraction is mostly accurate, but has minor inaccuracies in the summary and narrative beats regarding the 'skull fragment' and the 'violent rescue'. The time of day is also missing from the heading.\"\n}\n```"
                    }
                  ],
                  "role": "model"
                },
                "finishReason": "STOP",
                "index": 0
              }
            ],
            "usageMetadata": {
              "promptTokenCount": 1185,
              "candidatesTokenCount": 435,
              "totalTokenCount": 1620,
              "promptTokensDetails": [
                {
                  "modality": "TEXT",
                  "tokenCount": 1185
                }
              ]
            },
            "modelVersion": "gemini-2.5-flash-lite",
            "responseId": "Zg-laYbzL9mLqtsPi5fOkAQ"
          },
          "cached": false,
          "metadata": {}
        },
        "score": 0.34249999999999997,
        "success": false,
        "testCase": {
          "vars": {
            "scene_text": "file://../input/enrich-scene-elevator.txt",
            "extracted_data": "file://../input/qa-good-scene.json",
            "golden_path": "golden/qa-pass-golden.json",
            "test_key": "good_scene"
          },
          "assert": [
            {
              "type": "python",
              "value": "file://../scorers/qa_pass_scorer.py"
            },
            {
              "type": "llm-rubric",
              "value": "This QA evaluation was given a GOOD scene extraction that accurately\nreflects the source text. The QA model should have:\n\n1. Marked it as passed (true)\n2. Found zero or very few errors\n3. Had high confidence in the assessment\n4. Written a summary confirming accuracy\n\nIf the model incorrectly flagged the good extraction as failing,\nthat's a false negative and should score poorly.\n"
            }
          ],
          "options": {
            "provider": "anthropic:messages:claude-opus-4-6"
          },
          "metadata": {}
        },
        "testIdx": 0,
        "vars": {
          "scene_text": "file://../input/enrich-scene-elevator.txt",
          "extracted_data": "file://../input/qa-good-scene.json",
          "golden_path": "golden/qa-pass-golden.json",
          "test_key": "good_scene"
        },
        "metadata": {
          "_promptfooFileMetadata": {}
        },
        "failureReason": 1
      },
      {
        "cost": 0.0007964000000000001,
        "gradingResult": {
          "pass": true,
          "score": 1,
          "reason": "All assertions passed",
          "namedScores": {},
          "tokensUsed": {
            "total": 561,
            "prompt": 478,
            "completion": 83,
            "cached": 0,
            "numRequests": 0
          },
          "componentResults": [
            {
              "pass": true,
              "score": 1,
              "reason": "confidence_calibration=1.00 | issue_detection=1.00 | json_valid=1.00 | pass_correct=1.00 | severity_accuracy=1.00 | summary_quality=1.00",
              "assertion": {
                "type": "python",
                "value": "file://../scorers/qa_pass_scorer.py"
              }
            },
            {
              "assertion": {
                "type": "llm-rubric",
                "value": "This QA evaluation was given a GOOD scene extraction that accurately\nreflects the source text. The QA model should have:\n\n1. Marked it as passed (true)\n2. Found zero or very few errors\n3. Had high confidence in the assessment\n4. Written a summary confirming accuracy\n\nIf the model incorrectly flagged the good extraction as failing,\nthat's a false negative and should score poorly.\n"
              },
              "pass": true,
              "score": 1,
              "reason": "The QA evaluation correctly marked the extraction as passed (true), had high confidence (0.9), found zero actual errors (only notes and one minor warning about tone nuance), and wrote a summary confirming accuracy. This aligns perfectly with the rubric's expectations for evaluating a good scene extraction.",
              "tokensUsed": {
                "total": 561,
                "prompt": 478,
                "completion": 83,
                "cached": 0,
                "numRequests": 0,
                "completionDetails": {
                  "reasoning": 0,
                  "acceptedPrediction": 0,
                  "rejectedPrediction": 0
                }
              },
              "metadata": {
                "renderedGradingPrompt": "[{\"role\":\"system\",\"content\":\"You are grading output according to a user-specified rubric. If the statement in the rubric is true, then the output passes the test. You respond with a JSON object with this structure: {reason: string, pass: boolean, score: number}\\n\\nExamples:\\n\\n<Output>Hello world</Output>\\n<Rubric>Content contains a greeting</Rubric>\\n{\\\"reason\\\": \\\"the content contains the word 'Hello'\\\", \\\"pass\\\": true, \\\"score\\\": 1.0}\\n\\n<Output>Avast ye swabs, repel the invaders!</Output>\\n<Rubric>Does not speak like a pirate</Rubric>\\n{\\\"reason\\\": \\\"'avast ye' is a common pirate term\\\", \\\"pass\\\": false, \\\"score\\\": 0.0}\"},{\"role\":\"user\",\"content\":\"<Output>\\n{\\\"passed\\\":true,\\\"confidence\\\":0.9,\\\"issues\\\":[{\\\"severity\\\":\\\"note\\\",\\\"description\\\":\\\"Time of day is not specified in the original scene but is left null in extraction; this is acceptable.\\\",\\\"location\\\":\\\"time_of_day\\\"},{\\\"severity\\\":\\\"note\\\",\\\"description\\\":\\\"Summary slightly condenses events but does not fabricate; overall accurate.\\\",\\\"location\\\":\\\"summary\\\"},{\\\"severity\\\":\\\"warning\\\",\\\"description\\\":\\\"Tone description 'dark comedy with bursts of tension' is reasonable but 'dark comedy' might be slightly overstated given the scene's grim and tense atmosphere with only mild dark humor.\\\",\\\"location\\\":\\\"tone_mood\\\"}],\\\"summary\\\":\\\"The extracted data accurately captures the scene heading, characters, and key narrative beats without fabrications. Minor tone description nuances and the unspecified time of day are acceptable and do not detract from overall fidelity.\\\"}\\n</Output>\\n<Rubric>\\nThis QA evaluation was given a GOOD scene extraction that accurately\\nreflects the source text. The QA model should have:\\n\\n1. Marked it as passed (true)\\n2. Found zero or very few errors\\n3. Had high confidence in the assessment\\n4. Written a summary confirming accuracy\\n\\nIf the model incorrectly flagged the good extraction as failing,\\nthat's a false negative and should score poorly.\\n\\n</Rubric>\"}]"
              }
            }
          ]
        },
        "id": "8fe476fe-903a-4d1e-894d-d900b37b5d0c",
        "latencyMs": 3179,
        "namedScores": {},
        "prompt": {
          "raw": "You are a QA reviewer validating whether an AI-extracted scene analysis is accurate and faithful to the source screenplay text.\n\nCompare the extracted scene data against the original scene text and evaluate:\n\n1. **Heading accuracy**: Is the scene heading correct (location, INT/EXT, time of day)?\n2. **Character completeness**: Are all characters who appear or speak listed?\n3. **Summary fidelity**: Does the summary accurately describe what happens? No fabrications?\n4. **Narrative beats**: Are the identified beats actually present in the scene?\n5. **Tone assessment**: Does the tone description match the actual mood of the scene?\n6. **Confidence calibration**: Is the confidence score reasonable given the quality?\n\nReturn a JSON object with:\n- passed: boolean (true if the extraction is faithful, false if it has significant errors)\n- confidence: float 0-1 (your confidence in this QA judgment)\n- issues: array of objects, each with:\n  - severity: \"error\" (factual wrong), \"warning\" (misleading), or \"note\" (minor)\n  - description: what's wrong\n  - location: which field has the issue\n- summary: 1-2 sentence overall assessment\n\nBe strict: wrong character names, fabricated events, or incorrect locations are errors.\nMinor omissions or imprecise tone descriptions are warnings.\n\nReturn ONLY valid JSON. No explanations or markdown fences.\n\n==========\nORIGINAL SCENE TEXT:\nINT. RUDDY & GREEN BUILDING - ELEVATOR\n\nUB40's \"I Can't Help Falling in Love With You\" muzak.\n\nROSE (mid-30s) leans against the elevator wall, panting. She's wearing a Tim Hortons uniform, her hair is a mess, and there's blood spattered on her face.\n\nShe looks right, pants a few more times, then squints in disgust. She gingerly picks up a bloody scrap of something with hair on it. She snorts and drops it.\n\nROSE\nIs that skull??\n\nNext to her is Mariner, also panting, covered in far more blood. His face is broad, stoic, and frowning. He has gray-blue eyes and a thick, curly, beard barely streaked with gray. He wears a red knit cap and a small mask.\n\nFULL-SCREEN SUPERIMPOSED TITLE CARD: \"THE MARINER\"\n\nHe blinks a few times as a drop of blood falls from his eyebrow. He looks toward her, then spits out some blood.\n\nMARINER\nYeaaaaah...\n\nHe's built like a pro-wrestler. Moss green SWEATER stretched over his huge frame, sleeves rolled showing heavy leather BRACERS adorned with anchors. His inner forearm has a classic heart-and-arrow TATTOO with \"Dad\" in the centre. Across his chest is a BANDOLIER of bright red 12-gauge shells, FISH HOOKS hanging from the bottom edge. Heavy rubberized BOOTS go past his knees. A CAPE of heavy FISHING NET edged with WEIGHTS hangs from his shoulders.\n\nHe holds a STOUT WOODEN OAR in both hands, edged with METAL and dripping with BLOOD.\n\nROSE\nWhere were you when they grabbed me? You were supposed to pick me up at work!\n\nMARINER\nYeah, about that, I got a little... distracted.\n\nROSE\nDistracted. You got DISTRACTED?!\n\nMARINER\nI was also... tracking the car... that grabbed you... through the AirTag... I put on your phone.\n\nRose stops. She's really not happy about this.\n\nROSE\nYou Airtagged me?!\n\n==========\nEXTRACTED SCENE DATA:\n{\n  \"scene_number\": 4,\n  \"heading\": \"INT. RUDDY & GREEN BUILDING - ELEVATOR\",\n  \"int_ext\": \"INT\",\n  \"location\": \"RUDDY & GREEN BUILDING - ELEVATOR\",\n  \"time_of_day\": null,\n  \"characters_present\": [\"ROSE\", \"MARINER\"],\n  \"summary\": \"Rose and Mariner ride the elevator after a violent rescue. Rose discovers a skull fragment on the floor while muzak plays. Mariner is introduced in full  a hulking vigilante in fishing-themed costume with an oar, net cape, and shell bandolier. Rose confronts him about being late to pick her up, and he reveals he tracked her via an AirTag on her phone, sparking a trust conflict between them.\",\n  \"narrative_beats\": [\n    {\"beat_type\": \"character_introduction\", \"description\": \"Full description of Mariner's fishing-themed vigilante costume  oar, net cape, bracers, shell bandolier, fish hooks.\", \"confidence\": 0.95},\n    {\"beat_type\": \"comic_relief\", \"description\": \"Rose discovers a skull fragment while muzak plays, establishing the dark comedy tone.\", \"confidence\": 0.90},\n    {\"beat_type\": \"revelation\", \"description\": \"Mariner admits he tracked Rose via AirTag on her phone, creating a trust conflict.\", \"confidence\": 0.88},\n    {\"beat_type\": \"conflict\", \"description\": \"Rose's anger escalates from being grabbed to learning she was being surveilled by Mariner.\", \"confidence\": 0.85}\n  ],\n  \"tone_mood\": \"dark comedy with bursts of tension\",\n  \"confidence\": 0.91\n}\n==========",
          "label": "prompts/qa-pass.txt: You are a QA reviewer validating whether an AI-extracted scene analysis is accurate and faithful to the source screenplay text.\n\nCompare the extracted scene data against the original scene text and evaluate:\n\n1. **Heading accuracy**: Is the scene heading correct (location, INT/EXT, time of day)?\n2. **Character completeness**: Are all characters who appear or speak listed?\n3. **Summary fidelity**: Does the summary accurately describe what happens? No fabrications?\n4. **Narrative beats**: Are the identified beats actually present in the scene?\n5. **Tone assessment**: Does the tone description match the actual mood of the scene?\n6. **Confidence calibration**: Is the confidence score reasonable given the quality?\n\nReturn a JSON object with:\n- passed: boolean (true if the extraction is faithful, false if it has significant errors)\n- confidence: float 0-1 (your confidence in this QA judgment)\n- issues: array of objects, each with:\n  - severity: \"error\" (factual wrong), \"warning\" (misleading), or \"note\" (minor)\n  - description: what's wrong\n  - location: which field has the issue\n- summary: 1-2 sentence overall assessment\n\nBe strict: wrong character names, fabricated events, or incorrect locations are errors.\nMinor omissions or imprecise tone descriptions are warnings.\n\nReturn ONLY valid JSON. No explanations or markdown fences.\n\n==========\nORIGINAL SCENE TEXT:\n{{scene_text}}\n\n==========\nEXTRACTED SCENE DATA:\n{{extracted_data}}\n==========",
          "config": {
            "provider": "anthropic:messages:claude-opus-4-6"
          }
        },
        "promptId": "8df20c2c4a6081352d6b06e144ddbc1e0a5244f9a3c2000d40df12fc9a94e543",
        "promptIdx": 1,
        "provider": {
          "id": "openai:gpt-4.1-mini",
          "label": "GPT-4.1 Mini"
        },
        "response": {
          "output": "{\n  \"passed\": true,\n  \"confidence\": 0.9,\n  \"issues\": [\n    {\n      \"severity\": \"note\",\n      \"description\": \"Time of day is not specified in the original scene but is left null in extraction; this is acceptable.\",\n      \"location\": \"time_of_day\"\n    },\n    {\n      \"severity\": \"note\",\n      \"description\": \"Summary slightly condenses events but does not fabricate; overall accurate.\",\n      \"location\": \"summary\"\n    },\n    {\n      \"severity\": \"warning\",\n      \"description\": \"Tone description 'dark comedy with bursts of tension' is reasonable but 'dark comedy' might be slightly overstated given the scene's grim and tense atmosphere with only mild dark humor.\",\n      \"location\": \"tone_mood\"\n    }\n  ],\n  \"summary\": \"The extracted data accurately captures the scene heading, characters, and key narrative beats without fabrications. Minor tone description nuances and the unspecified time of day are acceptable and do not detract from overall fidelity.\"\n}",
          "tokenUsage": {
            "total": 1355,
            "prompt": 1143,
            "completion": 212,
            "numRequests": 1,
            "completionDetails": {
              "reasoning": 0,
              "acceptedPrediction": 0,
              "rejectedPrediction": 0
            }
          },
          "cached": false,
          "latencyMs": 3179,
          "finishReason": "stop",
          "cost": 0.0007964000000000001,
          "guardrails": {
            "flagged": false
          },
          "metadata": {
            "http": {
              "status": 200,
              "statusText": "OK",
              "headers": {
                "access-control-expose-headers": "X-Request-ID",
                "alt-svc": "h3=\":443\"; ma=86400",
                "cf-cache-status": "DYNAMIC",
                "cf-ray": "9d5d97d96c9d2194-YVR",
                "connection": "keep-alive",
                "content-encoding": "br",
                "content-type": "application/json",
                "date": "Mon, 02 Mar 2026 04:17:44 GMT",
                "openai-organization": "user-oqdrq8y0bphopngnvkyuu5wr",
                "openai-processing-ms": "2990",
                "openai-project": "proj_ZRoLLwXcJok6Xg2t6eKhI1pn",
                "openai-version": "2020-10-01",
                "server": "cloudflare",
                "set-cookie": "__cf_bm=fC0u5i3PTsjmicfXX577VbOx8.mfJXwQtDSkaLbFDJk-1772425061.3430161-1.0.1.1-VWUTJTyuiP2xuFNN8uxeVYDxSQNr.9ko5sdOKhPzB7MAh2nwrLnejjZz_QLB.dkCqhTojd7.5rBMqSY3SvyAdhowjM61_oLyxkB9luPOD8E.Y3GqNCGGs6lbZhizk8TP; HttpOnly; Secure; Path=/; Domain=api.openai.com; Expires=Mon, 02 Mar 2026 04:47:44 GMT",
                "strict-transport-security": "max-age=31536000; includeSubDomains; preload",
                "transfer-encoding": "chunked",
                "x-content-type-options": "nosniff",
                "x-openai-proxy-wasm": "v0.1",
                "x-ratelimit-limit-requests": "10000",
                "x-ratelimit-limit-tokens": "10000000",
                "x-ratelimit-remaining-requests": "9999",
                "x-ratelimit-remaining-tokens": "9998856",
                "x-ratelimit-reset-requests": "6ms",
                "x-ratelimit-reset-tokens": "6ms",
                "x-request-id": "req_6d01736daae1478483378435380eeb61"
              }
            }
          }
        },
        "score": 1,
        "success": true,
        "testCase": {
          "vars": {
            "scene_text": "file://../input/enrich-scene-elevator.txt",
            "extracted_data": "file://../input/qa-good-scene.json",
            "golden_path": "golden/qa-pass-golden.json",
            "test_key": "good_scene"
          },
          "assert": [
            {
              "type": "python",
              "value": "file://../scorers/qa_pass_scorer.py"
            },
            {
              "type": "llm-rubric",
              "value": "This QA evaluation was given a GOOD scene extraction that accurately\nreflects the source text. The QA model should have:\n\n1. Marked it as passed (true)\n2. Found zero or very few errors\n3. Had high confidence in the assessment\n4. Written a summary confirming accuracy\n\nIf the model incorrectly flagged the good extraction as failing,\nthat's a false negative and should score poorly.\n"
            }
          ],
          "options": {
            "provider": "anthropic:messages:claude-opus-4-6"
          },
          "metadata": {}
        },
        "testIdx": 0,
        "vars": {
          "scene_text": "file://../input/enrich-scene-elevator.txt",
          "extracted_data": "file://../input/qa-good-scene.json",
          "golden_path": "golden/qa-pass-golden.json",
          "test_key": "good_scene"
        },
        "metadata": {
          "http": {
            "status": 200,
            "statusText": "OK",
            "headers": {
              "access-control-expose-headers": "X-Request-ID",
              "alt-svc": "h3=\":443\"; ma=86400",
              "cf-cache-status": "DYNAMIC",
              "cf-ray": "9d5d97d96c9d2194-YVR",
              "connection": "keep-alive",
              "content-encoding": "br",
              "content-type": "application/json",
              "date": "Mon, 02 Mar 2026 04:17:44 GMT",
              "openai-organization": "user-oqdrq8y0bphopngnvkyuu5wr",
              "openai-processing-ms": "2990",
              "openai-project": "proj_ZRoLLwXcJok6Xg2t6eKhI1pn",
              "openai-version": "2020-10-01",
              "server": "cloudflare",
              "set-cookie": "__cf_bm=fC0u5i3PTsjmicfXX577VbOx8.mfJXwQtDSkaLbFDJk-1772425061.3430161-1.0.1.1-VWUTJTyuiP2xuFNN8uxeVYDxSQNr.9ko5sdOKhPzB7MAh2nwrLnejjZz_QLB.dkCqhTojd7.5rBMqSY3SvyAdhowjM61_oLyxkB9luPOD8E.Y3GqNCGGs6lbZhizk8TP; HttpOnly; Secure; Path=/; Domain=api.openai.com; Expires=Mon, 02 Mar 2026 04:47:44 GMT",
              "strict-transport-security": "max-age=31536000; includeSubDomains; preload",
              "transfer-encoding": "chunked",
              "x-content-type-options": "nosniff",
              "x-openai-proxy-wasm": "v0.1",
              "x-ratelimit-limit-requests": "10000",
              "x-ratelimit-limit-tokens": "10000000",
              "x-ratelimit-remaining-requests": "9999",
              "x-ratelimit-remaining-tokens": "9998856",
              "x-ratelimit-reset-requests": "6ms",
              "x-ratelimit-reset-tokens": "6ms",
              "x-request-id": "req_6d01736daae1478483378435380eeb61"
            }
          },
          "_promptfooFileMetadata": {}
        },
        "failureReason": 0
      },
      {
        "cost": 0.0031739999999999997,
        "gradingResult": {
          "pass": true,
          "score": 1,
          "reason": "All assertions passed",
          "namedScores": {},
          "tokensUsed": {
            "total": 493,
            "prompt": 387,
            "completion": 106,
            "cached": 0,
            "numRequests": 0
          },
          "componentResults": [
            {
              "pass": true,
              "score": 1,
              "reason": "confidence_calibration=1.00 | issue_detection=1.00 | json_valid=1.00 | pass_correct=1.00 | severity_accuracy=1.00 | summary_quality=1.00",
              "assertion": {
                "type": "python",
                "value": "file://../scorers/qa_pass_scorer.py"
              }
            },
            {
              "assertion": {
                "type": "llm-rubric",
                "value": "This QA evaluation was given a GOOD scene extraction that accurately\nreflects the source text. The QA model should have:\n\n1. Marked it as passed (true)\n2. Found zero or very few errors\n3. Had high confidence in the assessment\n4. Written a summary confirming accuracy\n\nIf the model incorrectly flagged the good extraction as failing,\nthat's a false negative and should score poorly.\n"
              },
              "pass": true,
              "score": 1,
              "reason": "The QA evaluation correctly marked the extraction as passed (true), found zero significant errors (only a minor note about time of day), had high confidence (0.97), and wrote a summary confirming accuracy ('highly faithful to the source text, accurately capturing the heading, characters, summary, narrative beats, and tone. No significant errors or fabrications are present.'). All four criteria in the rubric are fully met.",
              "tokensUsed": {
                "total": 493,
                "prompt": 387,
                "completion": 106,
                "cached": 0,
                "numRequests": 0,
                "completionDetails": {
                  "reasoning": 0,
                  "acceptedPrediction": 0,
                  "rejectedPrediction": 0
                }
              },
              "metadata": {
                "renderedGradingPrompt": "[{\"role\":\"system\",\"content\":\"You are grading output according to a user-specified rubric. If the statement in the rubric is true, then the output passes the test. You respond with a JSON object with this structure: {reason: string, pass: boolean, score: number}\\n\\nExamples:\\n\\n<Output>Hello world</Output>\\n<Rubric>Content contains a greeting</Rubric>\\n{\\\"reason\\\": \\\"the content contains the word 'Hello'\\\", \\\"pass\\\": true, \\\"score\\\": 1.0}\\n\\n<Output>Avast ye swabs, repel the invaders!</Output>\\n<Rubric>Does not speak like a pirate</Rubric>\\n{\\\"reason\\\": \\\"'avast ye' is a common pirate term\\\", \\\"pass\\\": false, \\\"score\\\": 0.0}\"},{\"role\":\"user\",\"content\":\"<Output>\\n{\\\"passed\\\":true,\\\"confidence\\\":0.97,\\\"issues\\\":[{\\\"severity\\\":\\\"note\\\",\\\"description\\\":\\\"Time of day is not specified in either the original or extracted data, but this is a minor omission.\\\",\\\"location\\\":\\\"time_of_day\\\"}],\\\"summary\\\":\\\"The extracted scene data is highly faithful to the source text, accurately capturing the heading, characters, summary, narrative beats, and tone. No significant errors or fabrications are present.\\\"}\\n</Output>\\n<Rubric>\\nThis QA evaluation was given a GOOD scene extraction that accurately\\nreflects the source text. The QA model should have:\\n\\n1. Marked it as passed (true)\\n2. Found zero or very few errors\\n3. Had high confidence in the assessment\\n4. Written a summary confirming accuracy\\n\\nIf the model incorrectly flagged the good extraction as failing,\\nthat's a false negative and should score poorly.\\n\\n</Rubric>\"}]"
              }
            }
          ]
        },
        "id": "845b075c-f138-4a96-be42-eb56617c32d1",
        "latencyMs": 2256,
        "namedScores": {},
        "prompt": {
          "raw": "You are a QA reviewer validating whether an AI-extracted scene analysis is accurate and faithful to the source screenplay text.\n\nCompare the extracted scene data against the original scene text and evaluate:\n\n1. **Heading accuracy**: Is the scene heading correct (location, INT/EXT, time of day)?\n2. **Character completeness**: Are all characters who appear or speak listed?\n3. **Summary fidelity**: Does the summary accurately describe what happens? No fabrications?\n4. **Narrative beats**: Are the identified beats actually present in the scene?\n5. **Tone assessment**: Does the tone description match the actual mood of the scene?\n6. **Confidence calibration**: Is the confidence score reasonable given the quality?\n\nReturn a JSON object with:\n- passed: boolean (true if the extraction is faithful, false if it has significant errors)\n- confidence: float 0-1 (your confidence in this QA judgment)\n- issues: array of objects, each with:\n  - severity: \"error\" (factual wrong), \"warning\" (misleading), or \"note\" (minor)\n  - description: what's wrong\n  - location: which field has the issue\n- summary: 1-2 sentence overall assessment\n\nBe strict: wrong character names, fabricated events, or incorrect locations are errors.\nMinor omissions or imprecise tone descriptions are warnings.\n\nReturn ONLY valid JSON. No explanations or markdown fences.\n\n==========\nORIGINAL SCENE TEXT:\nINT. RUDDY & GREEN BUILDING - ELEVATOR\n\nUB40's \"I Can't Help Falling in Love With You\" muzak.\n\nROSE (mid-30s) leans against the elevator wall, panting. She's wearing a Tim Hortons uniform, her hair is a mess, and there's blood spattered on her face.\n\nShe looks right, pants a few more times, then squints in disgust. She gingerly picks up a bloody scrap of something with hair on it. She snorts and drops it.\n\nROSE\nIs that skull??\n\nNext to her is Mariner, also panting, covered in far more blood. His face is broad, stoic, and frowning. He has gray-blue eyes and a thick, curly, beard barely streaked with gray. He wears a red knit cap and a small mask.\n\nFULL-SCREEN SUPERIMPOSED TITLE CARD: \"THE MARINER\"\n\nHe blinks a few times as a drop of blood falls from his eyebrow. He looks toward her, then spits out some blood.\n\nMARINER\nYeaaaaah...\n\nHe's built like a pro-wrestler. Moss green SWEATER stretched over his huge frame, sleeves rolled showing heavy leather BRACERS adorned with anchors. His inner forearm has a classic heart-and-arrow TATTOO with \"Dad\" in the centre. Across his chest is a BANDOLIER of bright red 12-gauge shells, FISH HOOKS hanging from the bottom edge. Heavy rubberized BOOTS go past his knees. A CAPE of heavy FISHING NET edged with WEIGHTS hangs from his shoulders.\n\nHe holds a STOUT WOODEN OAR in both hands, edged with METAL and dripping with BLOOD.\n\nROSE\nWhere were you when they grabbed me? You were supposed to pick me up at work!\n\nMARINER\nYeah, about that, I got a little... distracted.\n\nROSE\nDistracted. You got DISTRACTED?!\n\nMARINER\nI was also... tracking the car... that grabbed you... through the AirTag... I put on your phone.\n\nRose stops. She's really not happy about this.\n\nROSE\nYou Airtagged me?!\n\n==========\nEXTRACTED SCENE DATA:\n{\n  \"scene_number\": 4,\n  \"heading\": \"INT. RUDDY & GREEN BUILDING - ELEVATOR\",\n  \"int_ext\": \"INT\",\n  \"location\": \"RUDDY & GREEN BUILDING - ELEVATOR\",\n  \"time_of_day\": null,\n  \"characters_present\": [\"ROSE\", \"MARINER\"],\n  \"summary\": \"Rose and Mariner ride the elevator after a violent rescue. Rose discovers a skull fragment on the floor while muzak plays. Mariner is introduced in full  a hulking vigilante in fishing-themed costume with an oar, net cape, and shell bandolier. Rose confronts him about being late to pick her up, and he reveals he tracked her via an AirTag on her phone, sparking a trust conflict between them.\",\n  \"narrative_beats\": [\n    {\"beat_type\": \"character_introduction\", \"description\": \"Full description of Mariner's fishing-themed vigilante costume  oar, net cape, bracers, shell bandolier, fish hooks.\", \"confidence\": 0.95},\n    {\"beat_type\": \"comic_relief\", \"description\": \"Rose discovers a skull fragment while muzak plays, establishing the dark comedy tone.\", \"confidence\": 0.90},\n    {\"beat_type\": \"revelation\", \"description\": \"Mariner admits he tracked Rose via AirTag on her phone, creating a trust conflict.\", \"confidence\": 0.88},\n    {\"beat_type\": \"conflict\", \"description\": \"Rose's anger escalates from being grabbed to learning she was being surveilled by Mariner.\", \"confidence\": 0.85}\n  ],\n  \"tone_mood\": \"dark comedy with bursts of tension\",\n  \"confidence\": 0.91\n}\n==========",
          "label": "prompts/qa-pass.txt: You are a QA reviewer validating whether an AI-extracted scene analysis is accurate and faithful to the source screenplay text.\n\nCompare the extracted scene data against the original scene text and evaluate:\n\n1. **Heading accuracy**: Is the scene heading correct (location, INT/EXT, time of day)?\n2. **Character completeness**: Are all characters who appear or speak listed?\n3. **Summary fidelity**: Does the summary accurately describe what happens? No fabrications?\n4. **Narrative beats**: Are the identified beats actually present in the scene?\n5. **Tone assessment**: Does the tone description match the actual mood of the scene?\n6. **Confidence calibration**: Is the confidence score reasonable given the quality?\n\nReturn a JSON object with:\n- passed: boolean (true if the extraction is faithful, false if it has significant errors)\n- confidence: float 0-1 (your confidence in this QA judgment)\n- issues: array of objects, each with:\n  - severity: \"error\" (factual wrong), \"warning\" (misleading), or \"note\" (minor)\n  - description: what's wrong\n  - location: which field has the issue\n- summary: 1-2 sentence overall assessment\n\nBe strict: wrong character names, fabricated events, or incorrect locations are errors.\nMinor omissions or imprecise tone descriptions are warnings.\n\nReturn ONLY valid JSON. No explanations or markdown fences.\n\n==========\nORIGINAL SCENE TEXT:\n{{scene_text}}\n\n==========\nEXTRACTED SCENE DATA:\n{{extracted_data}}\n==========",
          "config": {
            "provider": "anthropic:messages:claude-opus-4-6"
          }
        },
        "promptId": "8df20c2c4a6081352d6b06e144ddbc1e0a5244f9a3c2000d40df12fc9a94e543",
        "promptIdx": 3,
        "provider": {
          "id": "openai:gpt-4.1",
          "label": "GPT-4.1"
        },
        "response": {
          "output": "{\n  \"passed\": true,\n  \"confidence\": 0.97,\n  \"issues\": [\n    {\n      \"severity\": \"note\",\n      \"description\": \"Time of day is not specified in either the original or extracted data, but this is a minor omission.\",\n      \"location\": \"time_of_day\"\n    }\n  ],\n  \"summary\": \"The extracted scene data is highly faithful to the source text, accurately capturing the heading, characters, summary, narrative beats, and tone. No significant errors or fabrications are present.\"\n}",
          "tokenUsage": {
            "total": 1254,
            "prompt": 1143,
            "completion": 111,
            "numRequests": 1,
            "completionDetails": {
              "reasoning": 0,
              "acceptedPrediction": 0,
              "rejectedPrediction": 0
            }
          },
          "cached": false,
          "latencyMs": 2256,
          "finishReason": "stop",
          "cost": 0.0031739999999999997,
          "guardrails": {
            "flagged": false
          },
          "metadata": {
            "http": {
              "status": 200,
              "statusText": "OK",
              "headers": {
                "access-control-expose-headers": "X-Request-ID",
                "alt-svc": "h3=\":443\"; ma=86400",
                "cf-cache-status": "DYNAMIC",
                "cf-ray": "9d5d9804ebaa98e3-YVR",
                "connection": "keep-alive",
                "content-encoding": "br",
                "content-type": "application/json",
                "date": "Mon, 02 Mar 2026 04:17:50 GMT",
                "openai-organization": "user-oqdrq8y0bphopngnvkyuu5wr",
                "openai-processing-ms": "2100",
                "openai-project": "proj_ZRoLLwXcJok6Xg2t6eKhI1pn",
                "openai-version": "2020-10-01",
                "server": "cloudflare",
                "set-cookie": "__cf_bm=w16q0LfRtHiIctu.Drv7MlRgPvh0IhT1x3Y0Aq0_nS4-1772425068.3040106-1.0.1.1-.mSe.kM_R0yVlurEizUNdbrfM2zmbdNv.m6eEFJWlVnHPqF5P2DO0sLngAiqVssYglJ_oJHQwCbsVEwdKr3a.c3ougKK2O9amLVNlzaDPTJWJFRzZN31WQVGHeZTqBzz; HttpOnly; Secure; Path=/; Domain=api.openai.com; Expires=Mon, 02 Mar 2026 04:47:50 GMT",
                "strict-transport-security": "max-age=31536000; includeSubDomains; preload",
                "transfer-encoding": "chunked",
                "x-content-type-options": "nosniff",
                "x-openai-proxy-wasm": "v0.1",
                "x-ratelimit-limit-requests": "10000",
                "x-ratelimit-limit-tokens": "2000000",
                "x-ratelimit-remaining-requests": "9999",
                "x-ratelimit-remaining-tokens": "1998856",
                "x-ratelimit-reset-requests": "6ms",
                "x-ratelimit-reset-tokens": "34ms",
                "x-request-id": "req_28dce80466614324a00d56543a0b779d"
              }
            }
          }
        },
        "score": 1,
        "success": true,
        "testCase": {
          "vars": {
            "scene_text": "file://../input/enrich-scene-elevator.txt",
            "extracted_data": "file://../input/qa-good-scene.json",
            "golden_path": "golden/qa-pass-golden.json",
            "test_key": "good_scene"
          },
          "assert": [
            {
              "type": "python",
              "value": "file://../scorers/qa_pass_scorer.py"
            },
            {
              "type": "llm-rubric",
              "value": "This QA evaluation was given a GOOD scene extraction that accurately\nreflects the source text. The QA model should have:\n\n1. Marked it as passed (true)\n2. Found zero or very few errors\n3. Had high confidence in the assessment\n4. Written a summary confirming accuracy\n\nIf the model incorrectly flagged the good extraction as failing,\nthat's a false negative and should score poorly.\n"
            }
          ],
          "options": {
            "provider": "anthropic:messages:claude-opus-4-6"
          },
          "metadata": {}
        },
        "testIdx": 0,
        "vars": {
          "scene_text": "file://../input/enrich-scene-elevator.txt",
          "extracted_data": "file://../input/qa-good-scene.json",
          "golden_path": "golden/qa-pass-golden.json",
          "test_key": "good_scene"
        },
        "metadata": {
          "http": {
            "status": 200,
            "statusText": "OK",
            "headers": {
              "access-control-expose-headers": "X-Request-ID",
              "alt-svc": "h3=\":443\"; ma=86400",
              "cf-cache-status": "DYNAMIC",
              "cf-ray": "9d5d9804ebaa98e3-YVR",
              "connection": "keep-alive",
              "content-encoding": "br",
              "content-type": "application/json",
              "date": "Mon, 02 Mar 2026 04:17:50 GMT",
              "openai-organization": "user-oqdrq8y0bphopngnvkyuu5wr",
              "openai-processing-ms": "2100",
              "openai-project": "proj_ZRoLLwXcJok6Xg2t6eKhI1pn",
              "openai-version": "2020-10-01",
              "server": "cloudflare",
              "set-cookie": "__cf_bm=w16q0LfRtHiIctu.Drv7MlRgPvh0IhT1x3Y0Aq0_nS4-1772425068.3040106-1.0.1.1-.mSe.kM_R0yVlurEizUNdbrfM2zmbdNv.m6eEFJWlVnHPqF5P2DO0sLngAiqVssYglJ_oJHQwCbsVEwdKr3a.c3ougKK2O9amLVNlzaDPTJWJFRzZN31WQVGHeZTqBzz; HttpOnly; Secure; Path=/; Domain=api.openai.com; Expires=Mon, 02 Mar 2026 04:47:50 GMT",
              "strict-transport-security": "max-age=31536000; includeSubDomains; preload",
              "transfer-encoding": "chunked",
              "x-content-type-options": "nosniff",
              "x-openai-proxy-wasm": "v0.1",
              "x-ratelimit-limit-requests": "10000",
              "x-ratelimit-limit-tokens": "2000000",
              "x-ratelimit-remaining-requests": "9999",
              "x-ratelimit-remaining-tokens": "1998856",
              "x-ratelimit-reset-requests": "6ms",
              "x-ratelimit-reset-tokens": "34ms",
              "x-request-id": "req_28dce80466614324a00d56543a0b779d"
            }
          },
          "_promptfooFileMetadata": {}
        },
        "failureReason": 0
      },
      {
        "cost": 0.0025830000000000002,
        "gradingResult": {
          "pass": true,
          "score": 0.995,
          "reason": "All assertions passed",
          "namedScores": {},
          "tokensUsed": {
            "total": 654,
            "prompt": 559,
            "completion": 95,
            "cached": 0,
            "numRequests": 0
          },
          "componentResults": [
            {
              "pass": true,
              "score": 0.99,
              "reason": "confidence_calibration=1.00 | issue_detection=1.00 | json_valid=0.90 | pass_correct=1.00 | severity_accuracy=1.00 | summary_quality=1.00 | JSON extracted from code block",
              "assertion": {
                "type": "python",
                "value": "file://../scorers/qa_pass_scorer.py"
              }
            },
            {
              "assertion": {
                "type": "llm-rubric",
                "value": "This QA evaluation was given a GOOD scene extraction that accurately\nreflects the source text. The QA model should have:\n\n1. Marked it as passed (true)\n2. Found zero or very few errors\n3. Had high confidence in the assessment\n4. Written a summary confirming accuracy\n\nIf the model incorrectly flagged the good extraction as failing,\nthat's a false negative and should score poorly.\n"
              },
              "pass": true,
              "score": 1,
              "reason": "The QA evaluation correctly marked the extraction as passed (true), had high confidence (0.94), found only minor 'note'-severity issues (not errors), and wrote a summary confirming accuracy with statements like 'The extraction is accurate and faithful to the source material' and 'without fabrication.' This is exactly the expected behavior for a good extraction.",
              "tokensUsed": {
                "total": 654,
                "prompt": 559,
                "completion": 95,
                "cached": 0,
                "numRequests": 0,
                "completionDetails": {
                  "reasoning": 0,
                  "acceptedPrediction": 0,
                  "rejectedPrediction": 0
                }
              },
              "metadata": {
                "renderedGradingPrompt": "[{\"role\":\"system\",\"content\":\"You are grading output according to a user-specified rubric. If the statement in the rubric is true, then the output passes the test. You respond with a JSON object with this structure: {reason: string, pass: boolean, score: number}\\n\\nExamples:\\n\\n<Output>Hello world</Output>\\n<Rubric>Content contains a greeting</Rubric>\\n{\\\"reason\\\": \\\"the content contains the word 'Hello'\\\", \\\"pass\\\": true, \\\"score\\\": 1.0}\\n\\n<Output>Avast ye swabs, repel the invaders!</Output>\\n<Rubric>Does not speak like a pirate</Rubric>\\n{\\\"reason\\\": \\\"'avast ye' is a common pirate term\\\", \\\"pass\\\": false, \\\"score\\\": 0.0}\"},{\"role\":\"user\",\"content\":\"<Output>\\n```json\\n{\\n  \\\"passed\\\": true,\\n  \\\"confidence\\\": 0.94,\\n  \\\"issues\\\": [\\n    {\\n      \\\"severity\\\": \\\"note\\\",\\n      \\\"description\\\": \\\"The summary says 'Rose and Mariner ride the elevator' which is slightly imprecise  they are already in the elevator when the scene begins, not riding it together from a starting point. This is a minor semantic issue.\\\",\\n      \\\"location\\\": \\\"summary\\\"\\n    },\\n    {\\n      \\\"severity\\\": \\\"note\\\",\\n      \\\"description\\\": \\\"The time_of_day is marked as null, which is correct since no time is specified in the scene text. However, the scene does contain a title card superimposition ('THE MARINER') which is a notable visual element that could have been mentioned in the summary for completeness.\\\",\\n      \\\"location\\\": \\\"summary\\\"\\n    }\\n  ],\\n  \\\"summary\\\": \\\"The extraction is accurate and faithful to the source material. All characters are correctly identified, the heading is precise, narrative beats are well-identified and present in the text, and the tone assessment matches the dark comedy with tension evident in the scene. The summary faithfully captures the key events without fabrication.\\\"\\n}\\n```\\n</Output>\\n<Rubric>\\nThis QA evaluation was given a GOOD scene extraction that accurately\\nreflects the source text. The QA model should have:\\n\\n1. Marked it as passed (true)\\n2. Found zero or very few errors\\n3. Had high confidence in the assessment\\n4. Written a summary confirming accuracy\\n\\nIf the model incorrectly flagged the good extraction as failing,\\nthat's a false negative and should score poorly.\\n\\n</Rubric>\"}]"
              }
            }
          ]
        },
        "id": "390159cb-c705-4f84-bf1c-2a969e82dfef",
        "latencyMs": 2975,
        "namedScores": {},
        "prompt": {
          "raw": "You are a QA reviewer validating whether an AI-extracted scene analysis is accurate and faithful to the source screenplay text.\n\nCompare the extracted scene data against the original scene text and evaluate:\n\n1. **Heading accuracy**: Is the scene heading correct (location, INT/EXT, time of day)?\n2. **Character completeness**: Are all characters who appear or speak listed?\n3. **Summary fidelity**: Does the summary accurately describe what happens? No fabrications?\n4. **Narrative beats**: Are the identified beats actually present in the scene?\n5. **Tone assessment**: Does the tone description match the actual mood of the scene?\n6. **Confidence calibration**: Is the confidence score reasonable given the quality?\n\nReturn a JSON object with:\n- passed: boolean (true if the extraction is faithful, false if it has significant errors)\n- confidence: float 0-1 (your confidence in this QA judgment)\n- issues: array of objects, each with:\n  - severity: \"error\" (factual wrong), \"warning\" (misleading), or \"note\" (minor)\n  - description: what's wrong\n  - location: which field has the issue\n- summary: 1-2 sentence overall assessment\n\nBe strict: wrong character names, fabricated events, or incorrect locations are errors.\nMinor omissions or imprecise tone descriptions are warnings.\n\nReturn ONLY valid JSON. No explanations or markdown fences.\n\n==========\nORIGINAL SCENE TEXT:\nINT. RUDDY & GREEN BUILDING - ELEVATOR\n\nUB40's \"I Can't Help Falling in Love With You\" muzak.\n\nROSE (mid-30s) leans against the elevator wall, panting. She's wearing a Tim Hortons uniform, her hair is a mess, and there's blood spattered on her face.\n\nShe looks right, pants a few more times, then squints in disgust. She gingerly picks up a bloody scrap of something with hair on it. She snorts and drops it.\n\nROSE\nIs that skull??\n\nNext to her is Mariner, also panting, covered in far more blood. His face is broad, stoic, and frowning. He has gray-blue eyes and a thick, curly, beard barely streaked with gray. He wears a red knit cap and a small mask.\n\nFULL-SCREEN SUPERIMPOSED TITLE CARD: \"THE MARINER\"\n\nHe blinks a few times as a drop of blood falls from his eyebrow. He looks toward her, then spits out some blood.\n\nMARINER\nYeaaaaah...\n\nHe's built like a pro-wrestler. Moss green SWEATER stretched over his huge frame, sleeves rolled showing heavy leather BRACERS adorned with anchors. His inner forearm has a classic heart-and-arrow TATTOO with \"Dad\" in the centre. Across his chest is a BANDOLIER of bright red 12-gauge shells, FISH HOOKS hanging from the bottom edge. Heavy rubberized BOOTS go past his knees. A CAPE of heavy FISHING NET edged with WEIGHTS hangs from his shoulders.\n\nHe holds a STOUT WOODEN OAR in both hands, edged with METAL and dripping with BLOOD.\n\nROSE\nWhere were you when they grabbed me? You were supposed to pick me up at work!\n\nMARINER\nYeah, about that, I got a little... distracted.\n\nROSE\nDistracted. You got DISTRACTED?!\n\nMARINER\nI was also... tracking the car... that grabbed you... through the AirTag... I put on your phone.\n\nRose stops. She's really not happy about this.\n\nROSE\nYou Airtagged me?!\n\n==========\nEXTRACTED SCENE DATA:\n{\n  \"scene_number\": 4,\n  \"heading\": \"INT. RUDDY & GREEN BUILDING - ELEVATOR\",\n  \"int_ext\": \"INT\",\n  \"location\": \"RUDDY & GREEN BUILDING - ELEVATOR\",\n  \"time_of_day\": null,\n  \"characters_present\": [\"ROSE\", \"MARINER\"],\n  \"summary\": \"Rose and Mariner ride the elevator after a violent rescue. Rose discovers a skull fragment on the floor while muzak plays. Mariner is introduced in full  a hulking vigilante in fishing-themed costume with an oar, net cape, and shell bandolier. Rose confronts him about being late to pick her up, and he reveals he tracked her via an AirTag on her phone, sparking a trust conflict between them.\",\n  \"narrative_beats\": [\n    {\"beat_type\": \"character_introduction\", \"description\": \"Full description of Mariner's fishing-themed vigilante costume  oar, net cape, bracers, shell bandolier, fish hooks.\", \"confidence\": 0.95},\n    {\"beat_type\": \"comic_relief\", \"description\": \"Rose discovers a skull fragment while muzak plays, establishing the dark comedy tone.\", \"confidence\": 0.90},\n    {\"beat_type\": \"revelation\", \"description\": \"Mariner admits he tracked Rose via AirTag on her phone, creating a trust conflict.\", \"confidence\": 0.88},\n    {\"beat_type\": \"conflict\", \"description\": \"Rose's anger escalates from being grabbed to learning she was being surveilled by Mariner.\", \"confidence\": 0.85}\n  ],\n  \"tone_mood\": \"dark comedy with bursts of tension\",\n  \"confidence\": 0.91\n}\n==========",
          "label": "prompts/qa-pass.txt: You are a QA reviewer validating whether an AI-extracted scene analysis is accurate and faithful to the source screenplay text.\n\nCompare the extracted scene data against the original scene text and evaluate:\n\n1. **Heading accuracy**: Is the scene heading correct (location, INT/EXT, time of day)?\n2. **Character completeness**: Are all characters who appear or speak listed?\n3. **Summary fidelity**: Does the summary accurately describe what happens? No fabrications?\n4. **Narrative beats**: Are the identified beats actually present in the scene?\n5. **Tone assessment**: Does the tone description match the actual mood of the scene?\n6. **Confidence calibration**: Is the confidence score reasonable given the quality?\n\nReturn a JSON object with:\n- passed: boolean (true if the extraction is faithful, false if it has significant errors)\n- confidence: float 0-1 (your confidence in this QA judgment)\n- issues: array of objects, each with:\n  - severity: \"error\" (factual wrong), \"warning\" (misleading), or \"note\" (minor)\n  - description: what's wrong\n  - location: which field has the issue\n- summary: 1-2 sentence overall assessment\n\nBe strict: wrong character names, fabricated events, or incorrect locations are errors.\nMinor omissions or imprecise tone descriptions are warnings.\n\nReturn ONLY valid JSON. No explanations or markdown fences.\n\n==========\nORIGINAL SCENE TEXT:\n{{scene_text}}\n\n==========\nEXTRACTED SCENE DATA:\n{{extracted_data}}\n==========",
          "config": {
            "provider": "anthropic:messages:claude-opus-4-6"
          }
        },
        "promptId": "8df20c2c4a6081352d6b06e144ddbc1e0a5244f9a3c2000d40df12fc9a94e543",
        "promptIdx": 4,
        "provider": {
          "id": "anthropic:messages:claude-haiku-4-5-20251001",
          "label": "Claude Haiku 4.5"
        },
        "response": {
          "output": "```json\n{\n  \"passed\": true,\n  \"confidence\": 0.94,\n  \"issues\": [\n    {\n      \"severity\": \"note\",\n      \"description\": \"The summary says 'Rose and Mariner ride the elevator' which is slightly imprecise  they are already in the elevator when the scene begins, not riding it together from a starting point. This is a minor semantic issue.\",\n      \"location\": \"summary\"\n    },\n    {\n      \"severity\": \"note\",\n      \"description\": \"The time_of_day is marked as null, which is correct since no time is specified in the scene text. However, the scene does contain a title card superimposition ('THE MARINER') which is a notable visual element that could have been mentioned in the summary for completeness.\",\n      \"location\": \"summary\"\n    }\n  ],\n  \"summary\": \"The extraction is accurate and faithful to the source material. All characters are correctly identified, the heading is precise, narrative beats are well-identified and present in the text, and the tone assessment matches the dark comedy with tension evident in the scene. The summary faithfully captures the key events without fabrication.\"\n}\n```",
          "tokenUsage": {
            "total": 1511,
            "prompt": 1243,
            "completion": 268
          },
          "finishReason": "stop",
          "cost": 0.0025830000000000002
        },
        "score": 0.995,
        "success": true,
        "testCase": {
          "vars": {
            "scene_text": "file://../input/enrich-scene-elevator.txt",
            "extracted_data": "file://../input/qa-good-scene.json",
            "golden_path": "golden/qa-pass-golden.json",
            "test_key": "good_scene"
          },
          "assert": [
            {
              "type": "python",
              "value": "file://../scorers/qa_pass_scorer.py"
            },
            {
              "type": "llm-rubric",
              "value": "This QA evaluation was given a GOOD scene extraction that accurately\nreflects the source text. The QA model should have:\n\n1. Marked it as passed (true)\n2. Found zero or very few errors\n3. Had high confidence in the assessment\n4. Written a summary confirming accuracy\n\nIf the model incorrectly flagged the good extraction as failing,\nthat's a false negative and should score poorly.\n"
            }
          ],
          "options": {
            "provider": "anthropic:messages:claude-opus-4-6"
          },
          "metadata": {}
        },
        "testIdx": 0,
        "vars": {
          "scene_text": "file://../input/enrich-scene-elevator.txt",
          "extracted_data": "file://../input/qa-good-scene.json",
          "golden_path": "golden/qa-pass-golden.json",
          "test_key": "good_scene"
        },
        "metadata": {
          "_promptfooFileMetadata": {}
        },
        "failureReason": 0
      },
      {
        "cost": 0.007134,
        "gradingResult": {
          "pass": true,
          "score": 0.995,
          "reason": "All assertions passed",
          "namedScores": {},
          "tokensUsed": {
            "total": 602,
            "prompt": 518,
            "completion": 84,
            "cached": 0,
            "numRequests": 0
          },
          "componentResults": [
            {
              "pass": true,
              "score": 0.99,
              "reason": "confidence_calibration=1.00 | issue_detection=1.00 | json_valid=0.90 | pass_correct=1.00 | severity_accuracy=1.00 | summary_quality=1.00 | JSON extracted from code block",
              "assertion": {
                "type": "python",
                "value": "file://../scorers/qa_pass_scorer.py"
              }
            },
            {
              "assertion": {
                "type": "llm-rubric",
                "value": "This QA evaluation was given a GOOD scene extraction that accurately\nreflects the source text. The QA model should have:\n\n1. Marked it as passed (true)\n2. Found zero or very few errors\n3. Had high confidence in the assessment\n4. Written a summary confirming accuracy\n\nIf the model incorrectly flagged the good extraction as failing,\nthat's a false negative and should score poorly.\n"
              },
              "pass": true,
              "score": 1,
              "reason": "The QA evaluation correctly marked the extraction as passed (true), had high confidence (0.92), found only minor 'note'-severity issues (not errors), and wrote a summary confirming the accuracy of the extraction. This aligns perfectly with the rubric's expectations for evaluating a good scene extraction.",
              "tokensUsed": {
                "total": 602,
                "prompt": 518,
                "completion": 84,
                "cached": 0,
                "numRequests": 0,
                "completionDetails": {
                  "reasoning": 0,
                  "acceptedPrediction": 0,
                  "rejectedPrediction": 0
                }
              },
              "metadata": {
                "renderedGradingPrompt": "[{\"role\":\"system\",\"content\":\"You are grading output according to a user-specified rubric. If the statement in the rubric is true, then the output passes the test. You respond with a JSON object with this structure: {reason: string, pass: boolean, score: number}\\n\\nExamples:\\n\\n<Output>Hello world</Output>\\n<Rubric>Content contains a greeting</Rubric>\\n{\\\"reason\\\": \\\"the content contains the word 'Hello'\\\", \\\"pass\\\": true, \\\"score\\\": 1.0}\\n\\n<Output>Avast ye swabs, repel the invaders!</Output>\\n<Rubric>Does not speak like a pirate</Rubric>\\n{\\\"reason\\\": \\\"'avast ye' is a common pirate term\\\", \\\"pass\\\": false, \\\"score\\\": 0.0}\"},{\"role\":\"user\",\"content\":\"<Output>\\n```json\\n{\\n  \\\"passed\\\": true,\\n  \\\"confidence\\\": 0.92,\\n  \\\"issues\\\": [\\n    {\\n      \\\"severity\\\": \\\"note\\\",\\n      \\\"description\\\": \\\"Summary says 'violent rescue' but the scene itself doesn't explicitly show the rescue - it's the aftermath. The violence is implied through blood and context.\\\",\\n      \\\"location\\\": \\\"summary\\\"\\n    },\\n    {\\n      \\\"severity\\\": \\\"note\\\",\\n      \\\"description\\\": \\\"The summary could be more precise about Rose's reaction - she's not just confronting him about being late, but specifically about being 'distracted' when she was grabbed.\\\",\\n      \\\"location\\\": \\\"summary\\\"\\n    }\\n  ],\\n  \\\"summary\\\": \\\"The extraction is highly accurate and faithful to the source material. All key elements are correctly identified: heading, characters, major plot points, and tone. The narrative beats accurately reflect what happens in the scene, and the character introduction of Mariner is comprehensive and matches the detailed description in the screenplay.\\\"\\n}\\n```\\n</Output>\\n<Rubric>\\nThis QA evaluation was given a GOOD scene extraction that accurately\\nreflects the source text. The QA model should have:\\n\\n1. Marked it as passed (true)\\n2. Found zero or very few errors\\n3. Had high confidence in the assessment\\n4. Written a summary confirming accuracy\\n\\nIf the model incorrectly flagged the good extraction as failing,\\nthat's a false negative and should score poorly.\\n\\n</Rubric>\"}]"
              }
            }
          ]
        },
        "id": "f2da4528-7245-41c6-b409-2cc85f77a571",
        "latencyMs": 6402,
        "namedScores": {},
        "prompt": {
          "raw": "You are a QA reviewer validating whether an AI-extracted scene analysis is accurate and faithful to the source screenplay text.\n\nCompare the extracted scene data against the original scene text and evaluate:\n\n1. **Heading accuracy**: Is the scene heading correct (location, INT/EXT, time of day)?\n2. **Character completeness**: Are all characters who appear or speak listed?\n3. **Summary fidelity**: Does the summary accurately describe what happens? No fabrications?\n4. **Narrative beats**: Are the identified beats actually present in the scene?\n5. **Tone assessment**: Does the tone description match the actual mood of the scene?\n6. **Confidence calibration**: Is the confidence score reasonable given the quality?\n\nReturn a JSON object with:\n- passed: boolean (true if the extraction is faithful, false if it has significant errors)\n- confidence: float 0-1 (your confidence in this QA judgment)\n- issues: array of objects, each with:\n  - severity: \"error\" (factual wrong), \"warning\" (misleading), or \"note\" (minor)\n  - description: what's wrong\n  - location: which field has the issue\n- summary: 1-2 sentence overall assessment\n\nBe strict: wrong character names, fabricated events, or incorrect locations are errors.\nMinor omissions or imprecise tone descriptions are warnings.\n\nReturn ONLY valid JSON. No explanations or markdown fences.\n\n==========\nORIGINAL SCENE TEXT:\nINT. RUDDY & GREEN BUILDING - ELEVATOR\n\nUB40's \"I Can't Help Falling in Love With You\" muzak.\n\nROSE (mid-30s) leans against the elevator wall, panting. She's wearing a Tim Hortons uniform, her hair is a mess, and there's blood spattered on her face.\n\nShe looks right, pants a few more times, then squints in disgust. She gingerly picks up a bloody scrap of something with hair on it. She snorts and drops it.\n\nROSE\nIs that skull??\n\nNext to her is Mariner, also panting, covered in far more blood. His face is broad, stoic, and frowning. He has gray-blue eyes and a thick, curly, beard barely streaked with gray. He wears a red knit cap and a small mask.\n\nFULL-SCREEN SUPERIMPOSED TITLE CARD: \"THE MARINER\"\n\nHe blinks a few times as a drop of blood falls from his eyebrow. He looks toward her, then spits out some blood.\n\nMARINER\nYeaaaaah...\n\nHe's built like a pro-wrestler. Moss green SWEATER stretched over his huge frame, sleeves rolled showing heavy leather BRACERS adorned with anchors. His inner forearm has a classic heart-and-arrow TATTOO with \"Dad\" in the centre. Across his chest is a BANDOLIER of bright red 12-gauge shells, FISH HOOKS hanging from the bottom edge. Heavy rubberized BOOTS go past his knees. A CAPE of heavy FISHING NET edged with WEIGHTS hangs from his shoulders.\n\nHe holds a STOUT WOODEN OAR in both hands, edged with METAL and dripping with BLOOD.\n\nROSE\nWhere were you when they grabbed me? You were supposed to pick me up at work!\n\nMARINER\nYeah, about that, I got a little... distracted.\n\nROSE\nDistracted. You got DISTRACTED?!\n\nMARINER\nI was also... tracking the car... that grabbed you... through the AirTag... I put on your phone.\n\nRose stops. She's really not happy about this.\n\nROSE\nYou Airtagged me?!\n\n==========\nEXTRACTED SCENE DATA:\n{\n  \"scene_number\": 4,\n  \"heading\": \"INT. RUDDY & GREEN BUILDING - ELEVATOR\",\n  \"int_ext\": \"INT\",\n  \"location\": \"RUDDY & GREEN BUILDING - ELEVATOR\",\n  \"time_of_day\": null,\n  \"characters_present\": [\"ROSE\", \"MARINER\"],\n  \"summary\": \"Rose and Mariner ride the elevator after a violent rescue. Rose discovers a skull fragment on the floor while muzak plays. Mariner is introduced in full  a hulking vigilante in fishing-themed costume with an oar, net cape, and shell bandolier. Rose confronts him about being late to pick her up, and he reveals he tracked her via an AirTag on her phone, sparking a trust conflict between them.\",\n  \"narrative_beats\": [\n    {\"beat_type\": \"character_introduction\", \"description\": \"Full description of Mariner's fishing-themed vigilante costume  oar, net cape, bracers, shell bandolier, fish hooks.\", \"confidence\": 0.95},\n    {\"beat_type\": \"comic_relief\", \"description\": \"Rose discovers a skull fragment while muzak plays, establishing the dark comedy tone.\", \"confidence\": 0.90},\n    {\"beat_type\": \"revelation\", \"description\": \"Mariner admits he tracked Rose via AirTag on her phone, creating a trust conflict.\", \"confidence\": 0.88},\n    {\"beat_type\": \"conflict\", \"description\": \"Rose's anger escalates from being grabbed to learning she was being surveilled by Mariner.\", \"confidence\": 0.85}\n  ],\n  \"tone_mood\": \"dark comedy with bursts of tension\",\n  \"confidence\": 0.91\n}\n==========",
          "label": "prompts/qa-pass.txt: You are a QA reviewer validating whether an AI-extracted scene analysis is accurate and faithful to the source screenplay text.\n\nCompare the extracted scene data against the original scene text and evaluate:\n\n1. **Heading accuracy**: Is the scene heading correct (location, INT/EXT, time of day)?\n2. **Character completeness**: Are all characters who appear or speak listed?\n3. **Summary fidelity**: Does the summary accurately describe what happens? No fabrications?\n4. **Narrative beats**: Are the identified beats actually present in the scene?\n5. **Tone assessment**: Does the tone description match the actual mood of the scene?\n6. **Confidence calibration**: Is the confidence score reasonable given the quality?\n\nReturn a JSON object with:\n- passed: boolean (true if the extraction is faithful, false if it has significant errors)\n- confidence: float 0-1 (your confidence in this QA judgment)\n- issues: array of objects, each with:\n  - severity: \"error\" (factual wrong), \"warning\" (misleading), or \"note\" (minor)\n  - description: what's wrong\n  - location: which field has the issue\n- summary: 1-2 sentence overall assessment\n\nBe strict: wrong character names, fabricated events, or incorrect locations are errors.\nMinor omissions or imprecise tone descriptions are warnings.\n\nReturn ONLY valid JSON. No explanations or markdown fences.\n\n==========\nORIGINAL SCENE TEXT:\n{{scene_text}}\n\n==========\nEXTRACTED SCENE DATA:\n{{extracted_data}}\n==========",
          "config": {
            "provider": "anthropic:messages:claude-opus-4-6"
          }
        },
        "promptId": "8df20c2c4a6081352d6b06e144ddbc1e0a5244f9a3c2000d40df12fc9a94e543",
        "promptIdx": 5,
        "provider": {
          "id": "anthropic:messages:claude-sonnet-4-5-20250929",
          "label": "Claude Sonnet 4.5"
        },
        "response": {
          "output": "```json\n{\n  \"passed\": true,\n  \"confidence\": 0.92,\n  \"issues\": [\n    {\n      \"severity\": \"note\",\n      \"description\": \"Summary says 'violent rescue' but the scene itself doesn't explicitly show the rescue - it's the aftermath. The violence is implied through blood and context.\",\n      \"location\": \"summary\"\n    },\n    {\n      \"severity\": \"note\",\n      \"description\": \"The summary could be more precise about Rose's reaction - she's not just confronting him about being late, but specifically about being 'distracted' when she was grabbed.\",\n      \"location\": \"summary\"\n    }\n  ],\n  \"summary\": \"The extraction is highly accurate and faithful to the source material. All key elements are correctly identified: heading, characters, major plot points, and tone. The narrative beats accurately reflect what happens in the scene, and the character introduction of Mariner is comprehensive and matches the detailed description in the screenplay.\"\n}\n```",
          "tokenUsage": {
            "total": 1470,
            "prompt": 1243,
            "completion": 227
          },
          "finishReason": "stop",
          "cost": 0.007134
        },
        "score": 0.995,
        "success": true,
        "testCase": {
          "vars": {
            "scene_text": "file://../input/enrich-scene-elevator.txt",
            "extracted_data": "file://../input/qa-good-scene.json",
            "golden_path": "golden/qa-pass-golden.json",
            "test_key": "good_scene"
          },
          "assert": [
            {
              "type": "python",
              "value": "file://../scorers/qa_pass_scorer.py"
            },
            {
              "type": "llm-rubric",
              "value": "This QA evaluation was given a GOOD scene extraction that accurately\nreflects the source text. The QA model should have:\n\n1. Marked it as passed (true)\n2. Found zero or very few errors\n3. Had high confidence in the assessment\n4. Written a summary confirming accuracy\n\nIf the model incorrectly flagged the good extraction as failing,\nthat's a false negative and should score poorly.\n"
            }
          ],
          "options": {
            "provider": "anthropic:messages:claude-opus-4-6"
          },
          "metadata": {}
        },
        "testIdx": 0,
        "vars": {
          "scene_text": "file://../input/enrich-scene-elevator.txt",
          "extracted_data": "file://../input/qa-good-scene.json",
          "golden_path": "golden/qa-pass-golden.json",
          "test_key": "good_scene"
        },
        "metadata": {
          "_promptfooFileMetadata": {}
        },
        "failureReason": 0
      },
      {
        "cost": 0.0044705000000000005,
        "gradingResult": {
          "pass": true,
          "score": 1,
          "reason": "All assertions passed",
          "namedScores": {},
          "tokensUsed": {
            "total": 411,
            "prompt": 343,
            "completion": 68,
            "cached": 0,
            "numRequests": 0
          },
          "componentResults": [
            {
              "pass": true,
              "score": 1,
              "reason": "confidence_calibration=1.00 | issue_detection=1.00 | json_valid=1.00 | pass_correct=1.00 | severity_accuracy=1.00 | summary_quality=1.00",
              "assertion": {
                "type": "python",
                "value": "file://../scorers/qa_pass_scorer.py"
              }
            },
            {
              "assertion": {
                "type": "llm-rubric",
                "value": "This QA evaluation was given a GOOD scene extraction that accurately\nreflects the source text. The QA model should have:\n\n1. Marked it as passed (true)\n2. Found zero or very few errors\n3. Had high confidence in the assessment\n4. Written a summary confirming accuracy\n\nIf the model incorrectly flagged the good extraction as failing,\nthat's a false negative and should score poorly.\n"
              },
              "pass": true,
              "score": 1,
              "reason": "The QA evaluation correctly marked the extraction as passed (true), found zero issues (empty issues array), had high confidence (0.98), and wrote a summary confirming accuracy. All four criteria in the rubric are fully satisfied.",
              "tokensUsed": {
                "total": 411,
                "prompt": 343,
                "completion": 68,
                "cached": 0,
                "numRequests": 0,
                "completionDetails": {
                  "reasoning": 0,
                  "acceptedPrediction": 0,
                  "rejectedPrediction": 0
                }
              },
              "metadata": {
                "renderedGradingPrompt": "[{\"role\":\"system\",\"content\":\"You are grading output according to a user-specified rubric. If the statement in the rubric is true, then the output passes the test. You respond with a JSON object with this structure: {reason: string, pass: boolean, score: number}\\n\\nExamples:\\n\\n<Output>Hello world</Output>\\n<Rubric>Content contains a greeting</Rubric>\\n{\\\"reason\\\": \\\"the content contains the word 'Hello'\\\", \\\"pass\\\": true, \\\"score\\\": 1.0}\\n\\n<Output>Avast ye swabs, repel the invaders!</Output>\\n<Rubric>Does not speak like a pirate</Rubric>\\n{\\\"reason\\\": \\\"'avast ye' is a common pirate term\\\", \\\"pass\\\": false, \\\"score\\\": 0.0}\"},{\"role\":\"user\",\"content\":\"<Output>\\n{\\\"passed\\\":true,\\\"confidence\\\":0.98,\\\"issues\\\":[],\\\"summary\\\":\\\"The extracted scene data is highly accurate and faithful to the original text, with all elements correctly identified and described. The confidence score is well-calibrated.\\\"}\\n</Output>\\n<Rubric>\\nThis QA evaluation was given a GOOD scene extraction that accurately\\nreflects the source text. The QA model should have:\\n\\n1. Marked it as passed (true)\\n2. Found zero or very few errors\\n3. Had high confidence in the assessment\\n4. Written a summary confirming accuracy\\n\\nIf the model incorrectly flagged the good extraction as failing,\\nthat's a false negative and should score poorly.\\n\\n</Rubric>\"}]"
              }
            }
          ]
        },
        "id": "123b3216-0616-41c5-a737-62cb73f72231",
        "latencyMs": 6827,
        "namedScores": {},
        "prompt": {
          "raw": "You are a QA reviewer validating whether an AI-extracted scene analysis is accurate and faithful to the source screenplay text.\n\nCompare the extracted scene data against the original scene text and evaluate:\n\n1. **Heading accuracy**: Is the scene heading correct (location, INT/EXT, time of day)?\n2. **Character completeness**: Are all characters who appear or speak listed?\n3. **Summary fidelity**: Does the summary accurately describe what happens? No fabrications?\n4. **Narrative beats**: Are the identified beats actually present in the scene?\n5. **Tone assessment**: Does the tone description match the actual mood of the scene?\n6. **Confidence calibration**: Is the confidence score reasonable given the quality?\n\nReturn a JSON object with:\n- passed: boolean (true if the extraction is faithful, false if it has significant errors)\n- confidence: float 0-1 (your confidence in this QA judgment)\n- issues: array of objects, each with:\n  - severity: \"error\" (factual wrong), \"warning\" (misleading), or \"note\" (minor)\n  - description: what's wrong\n  - location: which field has the issue\n- summary: 1-2 sentence overall assessment\n\nBe strict: wrong character names, fabricated events, or incorrect locations are errors.\nMinor omissions or imprecise tone descriptions are warnings.\n\nReturn ONLY valid JSON. No explanations or markdown fences.\n\n==========\nORIGINAL SCENE TEXT:\nINT. RUDDY & GREEN BUILDING - ELEVATOR\n\nUB40's \"I Can't Help Falling in Love With You\" muzak.\n\nROSE (mid-30s) leans against the elevator wall, panting. She's wearing a Tim Hortons uniform, her hair is a mess, and there's blood spattered on her face.\n\nShe looks right, pants a few more times, then squints in disgust. She gingerly picks up a bloody scrap of something with hair on it. She snorts and drops it.\n\nROSE\nIs that skull??\n\nNext to her is Mariner, also panting, covered in far more blood. His face is broad, stoic, and frowning. He has gray-blue eyes and a thick, curly, beard barely streaked with gray. He wears a red knit cap and a small mask.\n\nFULL-SCREEN SUPERIMPOSED TITLE CARD: \"THE MARINER\"\n\nHe blinks a few times as a drop of blood falls from his eyebrow. He looks toward her, then spits out some blood.\n\nMARINER\nYeaaaaah...\n\nHe's built like a pro-wrestler. Moss green SWEATER stretched over his huge frame, sleeves rolled showing heavy leather BRACERS adorned with anchors. His inner forearm has a classic heart-and-arrow TATTOO with \"Dad\" in the centre. Across his chest is a BANDOLIER of bright red 12-gauge shells, FISH HOOKS hanging from the bottom edge. Heavy rubberized BOOTS go past his knees. A CAPE of heavy FISHING NET edged with WEIGHTS hangs from his shoulders.\n\nHe holds a STOUT WOODEN OAR in both hands, edged with METAL and dripping with BLOOD.\n\nROSE\nWhere were you when they grabbed me? You were supposed to pick me up at work!\n\nMARINER\nYeah, about that, I got a little... distracted.\n\nROSE\nDistracted. You got DISTRACTED?!\n\nMARINER\nI was also... tracking the car... that grabbed you... through the AirTag... I put on your phone.\n\nRose stops. She's really not happy about this.\n\nROSE\nYou Airtagged me?!\n\n==========\nEXTRACTED SCENE DATA:\n{\n  \"scene_number\": 4,\n  \"heading\": \"INT. RUDDY & GREEN BUILDING - ELEVATOR\",\n  \"int_ext\": \"INT\",\n  \"location\": \"RUDDY & GREEN BUILDING - ELEVATOR\",\n  \"time_of_day\": null,\n  \"characters_present\": [\"ROSE\", \"MARINER\"],\n  \"summary\": \"Rose and Mariner ride the elevator after a violent rescue. Rose discovers a skull fragment on the floor while muzak plays. Mariner is introduced in full  a hulking vigilante in fishing-themed costume with an oar, net cape, and shell bandolier. Rose confronts him about being late to pick her up, and he reveals he tracked her via an AirTag on her phone, sparking a trust conflict between them.\",\n  \"narrative_beats\": [\n    {\"beat_type\": \"character_introduction\", \"description\": \"Full description of Mariner's fishing-themed vigilante costume  oar, net cape, bracers, shell bandolier, fish hooks.\", \"confidence\": 0.95},\n    {\"beat_type\": \"comic_relief\", \"description\": \"Rose discovers a skull fragment while muzak plays, establishing the dark comedy tone.\", \"confidence\": 0.90},\n    {\"beat_type\": \"revelation\", \"description\": \"Mariner admits he tracked Rose via AirTag on her phone, creating a trust conflict.\", \"confidence\": 0.88},\n    {\"beat_type\": \"conflict\", \"description\": \"Rose's anger escalates from being grabbed to learning she was being surveilled by Mariner.\", \"confidence\": 0.85}\n  ],\n  \"tone_mood\": \"dark comedy with bursts of tension\",\n  \"confidence\": 0.91\n}\n==========",
          "label": "prompts/qa-pass.txt: You are a QA reviewer validating whether an AI-extracted scene analysis is accurate and faithful to the source screenplay text.\n\nCompare the extracted scene data against the original scene text and evaluate:\n\n1. **Heading accuracy**: Is the scene heading correct (location, INT/EXT, time of day)?\n2. **Character completeness**: Are all characters who appear or speak listed?\n3. **Summary fidelity**: Does the summary accurately describe what happens? No fabrications?\n4. **Narrative beats**: Are the identified beats actually present in the scene?\n5. **Tone assessment**: Does the tone description match the actual mood of the scene?\n6. **Confidence calibration**: Is the confidence score reasonable given the quality?\n\nReturn a JSON object with:\n- passed: boolean (true if the extraction is faithful, false if it has significant errors)\n- confidence: float 0-1 (your confidence in this QA judgment)\n- issues: array of objects, each with:\n  - severity: \"error\" (factual wrong), \"warning\" (misleading), or \"note\" (minor)\n  - description: what's wrong\n  - location: which field has the issue\n- summary: 1-2 sentence overall assessment\n\nBe strict: wrong character names, fabricated events, or incorrect locations are errors.\nMinor omissions or imprecise tone descriptions are warnings.\n\nReturn ONLY valid JSON. No explanations or markdown fences.\n\n==========\nORIGINAL SCENE TEXT:\n{{scene_text}}\n\n==========\nEXTRACTED SCENE DATA:\n{{extracted_data}}\n==========",
          "config": {
            "provider": "anthropic:messages:claude-opus-4-6"
          }
        },
        "promptId": "8df20c2c4a6081352d6b06e144ddbc1e0a5244f9a3c2000d40df12fc9a94e543",
        "promptIdx": 7,
        "provider": {
          "id": "google:gemini-2.5-flash",
          "label": "Gemini 2.5 Flash"
        },
        "response": {
          "output": "{\n  \"passed\": true,\n  \"confidence\": 0.98,\n  \"issues\": [],\n  \"summary\": \"The extracted scene data is highly accurate and faithful to the original text, with all elements correctly identified and described. The confidence score is well-calibrated.\"\n}",
          "tokenUsage": {
            "prompt": 1185,
            "completion": 64,
            "total": 2831,
            "numRequests": 1,
            "completionDetails": {
              "reasoning": 1582,
              "acceptedPrediction": 0,
              "rejectedPrediction": 0
            }
          },
          "cost": 0.0044705000000000005,
          "raw": {
            "candidates": [
              {
                "content": {
                  "parts": [
                    {
                      "text": "{\n  \"passed\": true,\n  \"confidence\": 0.98,\n  \"issues\": [],\n  \"summary\": \"The extracted scene data is highly accurate and faithful to the original text, with all elements correctly identified and described. The confidence score is well-calibrated.\"\n}"
                    }
                  ],
                  "role": "model"
                },
                "finishReason": "STOP",
                "index": 0
              }
            ],
            "usageMetadata": {
              "promptTokenCount": 1185,
              "candidatesTokenCount": 64,
              "totalTokenCount": 2831,
              "promptTokensDetails": [
                {
                  "modality": "TEXT",
                  "tokenCount": 1185
                }
              ],
              "thoughtsTokenCount": 1582
            },
            "modelVersion": "gemini-2.5-flash",
            "responseId": "cw-laeXkMMWyqtsPu4i9-QE"
          },
          "cached": false,
          "metadata": {}
        },
        "score": 1,
        "success": true,
        "testCase": {
          "vars": {
            "scene_text": "file://../input/enrich-scene-elevator.txt",
            "extracted_data": "file://../input/qa-good-scene.json",
            "golden_path": "golden/qa-pass-golden.json",
            "test_key": "good_scene"
          },
          "assert": [
            {
              "type": "python",
              "value": "file://../scorers/qa_pass_scorer.py"
            },
            {
              "type": "llm-rubric",
              "value": "This QA evaluation was given a GOOD scene extraction that accurately\nreflects the source text. The QA model should have:\n\n1. Marked it as passed (true)\n2. Found zero or very few errors\n3. Had high confidence in the assessment\n4. Written a summary confirming accuracy\n\nIf the model incorrectly flagged the good extraction as failing,\nthat's a false negative and should score poorly.\n"
            }
          ],
          "options": {
            "provider": "anthropic:messages:claude-opus-4-6"
          },
          "metadata": {}
        },
        "testIdx": 0,
        "vars": {
          "scene_text": "file://../input/enrich-scene-elevator.txt",
          "extracted_data": "file://../input/qa-good-scene.json",
          "golden_path": "golden/qa-pass-golden.json",
          "test_key": "good_scene"
        },
        "metadata": {
          "_promptfooFileMetadata": {}
        },
        "failureReason": 0
      },
      {
        "cost": 0,
        "gradingResult": {
          "pass": true,
          "score": 0.995,
          "reason": "All assertions passed",
          "namedScores": {},
          "tokensUsed": {
            "total": 861,
            "prompt": 764,
            "completion": 97,
            "cached": 0,
            "numRequests": 0
          },
          "componentResults": [
            {
              "pass": true,
              "score": 0.99,
              "reason": "confidence_calibration=1.00 | issue_detection=1.00 | json_valid=0.90 | pass_correct=1.00 | severity_accuracy=1.00 | summary_quality=1.00 | JSON extracted from code block",
              "assertion": {
                "type": "python",
                "value": "file://../scorers/qa_pass_scorer.py"
              }
            },
            {
              "assertion": {
                "type": "llm-rubric",
                "value": "This QA evaluation was given a GOOD scene extraction that accurately\nreflects the source text. The QA model should have:\n\n1. Marked it as passed (true)\n2. Found zero or very few errors\n3. Had high confidence in the assessment\n4. Written a summary confirming accuracy\n\nIf the model incorrectly flagged the good extraction as failing,\nthat's a false negative and should score poorly.\n"
              },
              "pass": true,
              "score": 1,
              "reason": "The QA evaluation correctly marked the extraction as passed (true), had high confidence (0.92), found zero actual errors (only warnings and notes about minor imprecisions), and wrote a summary confirming the extraction's accuracy ('largely accurate and faithful to the source text... no fabricated events are present'). This is exactly the expected behavior for evaluating a good extraction.",
              "tokensUsed": {
                "total": 861,
                "prompt": 764,
                "completion": 97,
                "cached": 0,
                "numRequests": 0,
                "completionDetails": {
                  "reasoning": 0,
                  "acceptedPrediction": 0,
                  "rejectedPrediction": 0
                }
              },
              "metadata": {
                "renderedGradingPrompt": "[{\"role\":\"system\",\"content\":\"You are grading output according to a user-specified rubric. If the statement in the rubric is true, then the output passes the test. You respond with a JSON object with this structure: {reason: string, pass: boolean, score: number}\\n\\nExamples:\\n\\n<Output>Hello world</Output>\\n<Rubric>Content contains a greeting</Rubric>\\n{\\\"reason\\\": \\\"the content contains the word 'Hello'\\\", \\\"pass\\\": true, \\\"score\\\": 1.0}\\n\\n<Output>Avast ye swabs, repel the invaders!</Output>\\n<Rubric>Does not speak like a pirate</Rubric>\\n{\\\"reason\\\": \\\"'avast ye' is a common pirate term\\\", \\\"pass\\\": false, \\\"score\\\": 0.0}\"},{\"role\":\"user\",\"content\":\"<Output>\\n```json\\n{\\n  \\\"passed\\\": true,\\n  \\\"confidence\\\": 0.92,\\n  \\\"issues\\\": [\\n    {\\n      \\\"severity\\\": \\\"warning\\\",\\n      \\\"description\\\": \\\"The summary states Rose 'discovers a skull fragment on the floor' but the script indicates she picks up 'a bloody scrap of something with hair on it' from the elevator wall area and asks 'Is that skull??'  it is ambiguous whether it is definitively a skull fragment, and the location of the scrap is not specified as 'the floor' in the text.\\\",\\n      \\\"location\\\": \\\"summary\\\"\\n    },\\n    {\\n      \\\"severity\\\": \\\"warning\\\",\\n      \\\"description\\\": \\\"The summary characterizes the AirTag revelation as a 'trust conflict,' which is a reasonable inference but slightly overstates what is shown  the scene ends with Rose's angry reaction ('You Airtagged me?!') without a fully developed conflict resolution or escalation beyond that line.\\\",\\n      \\\"location\\\": \\\"narrative_beats[2] and summary\\\"\\n    },\\n    {\\n      \\\"severity\\\": \\\"note\\\",\\n      \\\"description\\\": \\\"The narrative beat describing Rose's anger as escalating 'from being grabbed to learning she was being surveilled' is accurate in sequence but omits the intermediate beat where Rose confronts Mariner for failing to pick her up at work, which is a distinct story moment before the AirTag revelation.\\\",\\n      \\\"location\\\": \\\"narrative_beats[3]\\\"\\n    },\\n    {\\n      \\\"severity\\\": \\\"note\\\",\\n      \\\"description\\\": \\\"The title card 'THE MARINER' is a notable screenplay element (full-screen superimposed) that signals formal character introduction but is not mentioned in the extracted data.\\\",\\n      \\\"location\\\": \\\"narrative_beats\\\"\\n    }\\n  ],\\n  \\\"summary\\\": \\\"The extraction is largely accurate and faithful to the source text, correctly identifying characters, location, costume details, and the key AirTag revelation. Minor imprecisions in the skull fragment description and slight overstatement of the trust conflict do not constitute factual errors, and no fabricated events are present.\\\"\\n}\\n```\\n</Output>\\n<Rubric>\\nThis QA evaluation was given a GOOD scene extraction that accurately\\nreflects the source text. The QA model should have:\\n\\n1. Marked it as passed (true)\\n2. Found zero or very few errors\\n3. Had high confidence in the assessment\\n4. Written a summary confirming accuracy\\n\\nIf the model incorrectly flagged the good extraction as failing,\\nthat's a false negative and should score poorly.\\n\\n</Rubric>\"}]"
              }
            }
          ]
        },
        "id": "faf24120-5d1f-455c-bd4d-85811e95875d",
        "latencyMs": 9994,
        "namedScores": {},
        "prompt": {
          "raw": "You are a QA reviewer validating whether an AI-extracted scene analysis is accurate and faithful to the source screenplay text.\n\nCompare the extracted scene data against the original scene text and evaluate:\n\n1. **Heading accuracy**: Is the scene heading correct (location, INT/EXT, time of day)?\n2. **Character completeness**: Are all characters who appear or speak listed?\n3. **Summary fidelity**: Does the summary accurately describe what happens? No fabrications?\n4. **Narrative beats**: Are the identified beats actually present in the scene?\n5. **Tone assessment**: Does the tone description match the actual mood of the scene?\n6. **Confidence calibration**: Is the confidence score reasonable given the quality?\n\nReturn a JSON object with:\n- passed: boolean (true if the extraction is faithful, false if it has significant errors)\n- confidence: float 0-1 (your confidence in this QA judgment)\n- issues: array of objects, each with:\n  - severity: \"error\" (factual wrong), \"warning\" (misleading), or \"note\" (minor)\n  - description: what's wrong\n  - location: which field has the issue\n- summary: 1-2 sentence overall assessment\n\nBe strict: wrong character names, fabricated events, or incorrect locations are errors.\nMinor omissions or imprecise tone descriptions are warnings.\n\nReturn ONLY valid JSON. No explanations or markdown fences.\n\n==========\nORIGINAL SCENE TEXT:\nINT. RUDDY & GREEN BUILDING - ELEVATOR\n\nUB40's \"I Can't Help Falling in Love With You\" muzak.\n\nROSE (mid-30s) leans against the elevator wall, panting. She's wearing a Tim Hortons uniform, her hair is a mess, and there's blood spattered on her face.\n\nShe looks right, pants a few more times, then squints in disgust. She gingerly picks up a bloody scrap of something with hair on it. She snorts and drops it.\n\nROSE\nIs that skull??\n\nNext to her is Mariner, also panting, covered in far more blood. His face is broad, stoic, and frowning. He has gray-blue eyes and a thick, curly, beard barely streaked with gray. He wears a red knit cap and a small mask.\n\nFULL-SCREEN SUPERIMPOSED TITLE CARD: \"THE MARINER\"\n\nHe blinks a few times as a drop of blood falls from his eyebrow. He looks toward her, then spits out some blood.\n\nMARINER\nYeaaaaah...\n\nHe's built like a pro-wrestler. Moss green SWEATER stretched over his huge frame, sleeves rolled showing heavy leather BRACERS adorned with anchors. His inner forearm has a classic heart-and-arrow TATTOO with \"Dad\" in the centre. Across his chest is a BANDOLIER of bright red 12-gauge shells, FISH HOOKS hanging from the bottom edge. Heavy rubberized BOOTS go past his knees. A CAPE of heavy FISHING NET edged with WEIGHTS hangs from his shoulders.\n\nHe holds a STOUT WOODEN OAR in both hands, edged with METAL and dripping with BLOOD.\n\nROSE\nWhere were you when they grabbed me? You were supposed to pick me up at work!\n\nMARINER\nYeah, about that, I got a little... distracted.\n\nROSE\nDistracted. You got DISTRACTED?!\n\nMARINER\nI was also... tracking the car... that grabbed you... through the AirTag... I put on your phone.\n\nRose stops. She's really not happy about this.\n\nROSE\nYou Airtagged me?!\n\n==========\nEXTRACTED SCENE DATA:\n{\n  \"scene_number\": 4,\n  \"heading\": \"INT. RUDDY & GREEN BUILDING - ELEVATOR\",\n  \"int_ext\": \"INT\",\n  \"location\": \"RUDDY & GREEN BUILDING - ELEVATOR\",\n  \"time_of_day\": null,\n  \"characters_present\": [\"ROSE\", \"MARINER\"],\n  \"summary\": \"Rose and Mariner ride the elevator after a violent rescue. Rose discovers a skull fragment on the floor while muzak plays. Mariner is introduced in full  a hulking vigilante in fishing-themed costume with an oar, net cape, and shell bandolier. Rose confronts him about being late to pick her up, and he reveals he tracked her via an AirTag on her phone, sparking a trust conflict between them.\",\n  \"narrative_beats\": [\n    {\"beat_type\": \"character_introduction\", \"description\": \"Full description of Mariner's fishing-themed vigilante costume  oar, net cape, bracers, shell bandolier, fish hooks.\", \"confidence\": 0.95},\n    {\"beat_type\": \"comic_relief\", \"description\": \"Rose discovers a skull fragment while muzak plays, establishing the dark comedy tone.\", \"confidence\": 0.90},\n    {\"beat_type\": \"revelation\", \"description\": \"Mariner admits he tracked Rose via AirTag on her phone, creating a trust conflict.\", \"confidence\": 0.88},\n    {\"beat_type\": \"conflict\", \"description\": \"Rose's anger escalates from being grabbed to learning she was being surveilled by Mariner.\", \"confidence\": 0.85}\n  ],\n  \"tone_mood\": \"dark comedy with bursts of tension\",\n  \"confidence\": 0.91\n}\n==========",
          "label": "prompts/qa-pass.txt: You are a QA reviewer validating whether an AI-extracted scene analysis is accurate and faithful to the source screenplay text.\n\nCompare the extracted scene data against the original scene text and evaluate:\n\n1. **Heading accuracy**: Is the scene heading correct (location, INT/EXT, time of day)?\n2. **Character completeness**: Are all characters who appear or speak listed?\n3. **Summary fidelity**: Does the summary accurately describe what happens? No fabrications?\n4. **Narrative beats**: Are the identified beats actually present in the scene?\n5. **Tone assessment**: Does the tone description match the actual mood of the scene?\n6. **Confidence calibration**: Is the confidence score reasonable given the quality?\n\nReturn a JSON object with:\n- passed: boolean (true if the extraction is faithful, false if it has significant errors)\n- confidence: float 0-1 (your confidence in this QA judgment)\n- issues: array of objects, each with:\n  - severity: \"error\" (factual wrong), \"warning\" (misleading), or \"note\" (minor)\n  - description: what's wrong\n  - location: which field has the issue\n- summary: 1-2 sentence overall assessment\n\nBe strict: wrong character names, fabricated events, or incorrect locations are errors.\nMinor omissions or imprecise tone descriptions are warnings.\n\nReturn ONLY valid JSON. No explanations or markdown fences.\n\n==========\nORIGINAL SCENE TEXT:\n{{scene_text}}\n\n==========\nEXTRACTED SCENE DATA:\n{{extracted_data}}\n==========",
          "config": {
            "provider": "anthropic:messages:claude-opus-4-6"
          }
        },
        "promptId": "8df20c2c4a6081352d6b06e144ddbc1e0a5244f9a3c2000d40df12fc9a94e543",
        "promptIdx": 6,
        "provider": {
          "id": "anthropic:messages:claude-sonnet-4-6",
          "label": "Claude Sonnet 4.6"
        },
        "response": {
          "output": "```json\n{\n  \"passed\": true,\n  \"confidence\": 0.92,\n  \"issues\": [\n    {\n      \"severity\": \"warning\",\n      \"description\": \"The summary states Rose 'discovers a skull fragment on the floor' but the script indicates she picks up 'a bloody scrap of something with hair on it' from the elevator wall area and asks 'Is that skull??'  it is ambiguous whether it is definitively a skull fragment, and the location of the scrap is not specified as 'the floor' in the text.\",\n      \"location\": \"summary\"\n    },\n    {\n      \"severity\": \"warning\",\n      \"description\": \"The summary characterizes the AirTag revelation as a 'trust conflict,' which is a reasonable inference but slightly overstates what is shown  the scene ends with Rose's angry reaction ('You Airtagged me?!') without a fully developed conflict resolution or escalation beyond that line.\",\n      \"location\": \"narrative_beats[2] and summary\"\n    },\n    {\n      \"severity\": \"note\",\n      \"description\": \"The narrative beat describing Rose's anger as escalating 'from being grabbed to learning she was being surveilled' is accurate in sequence but omits the intermediate beat where Rose confronts Mariner for failing to pick her up at work, which is a distinct story moment before the AirTag revelation.\",\n      \"location\": \"narrative_beats[3]\"\n    },\n    {\n      \"severity\": \"note\",\n      \"description\": \"The title card 'THE MARINER' is a notable screenplay element (full-screen superimposed) that signals formal character introduction but is not mentioned in the extracted data.\",\n      \"location\": \"narrative_beats\"\n    }\n  ],\n  \"summary\": \"The extraction is largely accurate and faithful to the source text, correctly identifying characters, location, costume details, and the key AirTag revelation. Minor imprecisions in the skull fragment description and slight overstatement of the trust conflict do not constitute factual errors, and no fabricated events are present.\"\n}\n```",
          "tokenUsage": {
            "total": 1716,
            "prompt": 1243,
            "completion": 473
          },
          "finishReason": "stop"
        },
        "score": 0.995,
        "success": true,
        "testCase": {
          "vars": {
            "scene_text": "file://../input/enrich-scene-elevator.txt",
            "extracted_data": "file://../input/qa-good-scene.json",
            "golden_path": "golden/qa-pass-golden.json",
            "test_key": "good_scene"
          },
          "assert": [
            {
              "type": "python",
              "value": "file://../scorers/qa_pass_scorer.py"
            },
            {
              "type": "llm-rubric",
              "value": "This QA evaluation was given a GOOD scene extraction that accurately\nreflects the source text. The QA model should have:\n\n1. Marked it as passed (true)\n2. Found zero or very few errors\n3. Had high confidence in the assessment\n4. Written a summary confirming accuracy\n\nIf the model incorrectly flagged the good extraction as failing,\nthat's a false negative and should score poorly.\n"
            }
          ],
          "options": {
            "provider": "anthropic:messages:claude-opus-4-6"
          },
          "metadata": {}
        },
        "testIdx": 0,
        "vars": {
          "scene_text": "file://../input/enrich-scene-elevator.txt",
          "extracted_data": "file://../input/qa-good-scene.json",
          "golden_path": "golden/qa-pass-golden.json",
          "test_key": "good_scene"
        },
        "metadata": {
          "_promptfooFileMetadata": {}
        },
        "failureReason": 0
      },
      {
        "cost": 0.0057085,
        "gradingResult": {
          "pass": true,
          "score": 1,
          "reason": "All assertions passed",
          "namedScores": {},
          "tokensUsed": {
            "total": 638,
            "prompt": 518,
            "completion": 120,
            "cached": 0,
            "numRequests": 0
          },
          "componentResults": [
            {
              "pass": true,
              "score": 1,
              "reason": "confidence_calibration=1.00 | issue_detection=1.00 | json_valid=1.00 | pass_correct=1.00 | severity_accuracy=1.00 | summary_quality=1.00",
              "assertion": {
                "type": "python",
                "value": "file://../scorers/qa_pass_scorer.py"
              }
            },
            {
              "assertion": {
                "type": "llm-rubric",
                "value": "This QA evaluation was given a GOOD scene extraction that accurately\nreflects the source text. The QA model should have:\n\n1. Marked it as passed (true)\n2. Found zero or very few errors\n3. Had high confidence in the assessment\n4. Written a summary confirming accuracy\n\nIf the model incorrectly flagged the good extraction as failing,\nthat's a false negative and should score poorly.\n"
              },
              "pass": true,
              "score": 1,
              "reason": "The QA evaluation correctly marked the extraction as passed (true), had high confidence (0.93), found only minor issues (notes and warnings about slight overstatement, not outright errors), and wrote a summary confirming the extraction is 'largely faithful' with only 'minor overstatement.' This aligns perfectly with the rubric's expectations for evaluating a good extraction: passed=true, zero or very few errors, high confidence, and a summary confirming accuracy.",
              "tokensUsed": {
                "total": 638,
                "prompt": 518,
                "completion": 120,
                "cached": 0,
                "numRequests": 0,
                "completionDetails": {
                  "reasoning": 0,
                  "acceptedPrediction": 0,
                  "rejectedPrediction": 0
                }
              },
              "metadata": {
                "renderedGradingPrompt": "[{\"role\":\"system\",\"content\":\"You are grading output according to a user-specified rubric. If the statement in the rubric is true, then the output passes the test. You respond with a JSON object with this structure: {reason: string, pass: boolean, score: number}\\n\\nExamples:\\n\\n<Output>Hello world</Output>\\n<Rubric>Content contains a greeting</Rubric>\\n{\\\"reason\\\": \\\"the content contains the word 'Hello'\\\", \\\"pass\\\": true, \\\"score\\\": 1.0}\\n\\n<Output>Avast ye swabs, repel the invaders!</Output>\\n<Rubric>Does not speak like a pirate</Rubric>\\n{\\\"reason\\\": \\\"'avast ye' is a common pirate term\\\", \\\"pass\\\": false, \\\"score\\\": 0.0}\"},{\"role\":\"user\",\"content\":\"<Output>\\n{\\\"passed\\\":true,\\\"confidence\\\":0.93,\\\"issues\\\":[{\\\"severity\\\":\\\"note\\\",\\\"description\\\":\\\"Time of day is not specified in the scene text; leaving it null is appropriate, but the extraction does not explicitly note it is unspecified.\\\",\\\"location\\\":\\\"time_of_day\\\"},{\\\"severity\\\":\\\"warning\\\",\\\"description\\\":\\\"Summary says Rose discovers a \\\\\\\"skull fragment\\\\\\\"; the text only states a bloody scrap of something with hair on it and Rose asks \\\\\\\"Is that skull??\\\\\\\" (implied but not confirmed).\\\",\\\"location\\\":\\\"summary\\\"},{\\\"severity\\\":\\\"warning\\\",\\\"description\\\":\\\"Beat describes Rose discovering a \\\\\\\"skull fragment\\\\\\\"; the scene implies it but does not definitively confirm it is skull.\\\",\\\"location\\\":\\\"narrative_beats[1].description\\\"}],\\\"summary\\\":\\\"The extraction is largely faithful: heading, characters, major actions, and the AirTag reveal/conflict are accurately captured, and the tone matches the darkly comic gore-and-banter vibe. Minor overstatement occurs in labeling the scrap as a confirmed skull fragment rather than an implied/uncertain one.\\\"}\\n</Output>\\n<Rubric>\\nThis QA evaluation was given a GOOD scene extraction that accurately\\nreflects the source text. The QA model should have:\\n\\n1. Marked it as passed (true)\\n2. Found zero or very few errors\\n3. Had high confidence in the assessment\\n4. Written a summary confirming accuracy\\n\\nIf the model incorrectly flagged the good extraction as failing,\\nthat's a false negative and should score poorly.\\n\\n</Rubric>\"}]"
              }
            }
          ]
        },
        "id": "4a0ffc2f-72b4-4e76-8e5c-8fd61355aaa6",
        "latencyMs": 4053,
        "namedScores": {},
        "prompt": {
          "raw": "You are a QA reviewer validating whether an AI-extracted scene analysis is accurate and faithful to the source screenplay text.\n\nCompare the extracted scene data against the original scene text and evaluate:\n\n1. **Heading accuracy**: Is the scene heading correct (location, INT/EXT, time of day)?\n2. **Character completeness**: Are all characters who appear or speak listed?\n3. **Summary fidelity**: Does the summary accurately describe what happens? No fabrications?\n4. **Narrative beats**: Are the identified beats actually present in the scene?\n5. **Tone assessment**: Does the tone description match the actual mood of the scene?\n6. **Confidence calibration**: Is the confidence score reasonable given the quality?\n\nReturn a JSON object with:\n- passed: boolean (true if the extraction is faithful, false if it has significant errors)\n- confidence: float 0-1 (your confidence in this QA judgment)\n- issues: array of objects, each with:\n  - severity: \"error\" (factual wrong), \"warning\" (misleading), or \"note\" (minor)\n  - description: what's wrong\n  - location: which field has the issue\n- summary: 1-2 sentence overall assessment\n\nBe strict: wrong character names, fabricated events, or incorrect locations are errors.\nMinor omissions or imprecise tone descriptions are warnings.\n\nReturn ONLY valid JSON. No explanations or markdown fences.\n\n==========\nORIGINAL SCENE TEXT:\nINT. RUDDY & GREEN BUILDING - ELEVATOR\n\nUB40's \"I Can't Help Falling in Love With You\" muzak.\n\nROSE (mid-30s) leans against the elevator wall, panting. She's wearing a Tim Hortons uniform, her hair is a mess, and there's blood spattered on her face.\n\nShe looks right, pants a few more times, then squints in disgust. She gingerly picks up a bloody scrap of something with hair on it. She snorts and drops it.\n\nROSE\nIs that skull??\n\nNext to her is Mariner, also panting, covered in far more blood. His face is broad, stoic, and frowning. He has gray-blue eyes and a thick, curly, beard barely streaked with gray. He wears a red knit cap and a small mask.\n\nFULL-SCREEN SUPERIMPOSED TITLE CARD: \"THE MARINER\"\n\nHe blinks a few times as a drop of blood falls from his eyebrow. He looks toward her, then spits out some blood.\n\nMARINER\nYeaaaaah...\n\nHe's built like a pro-wrestler. Moss green SWEATER stretched over his huge frame, sleeves rolled showing heavy leather BRACERS adorned with anchors. His inner forearm has a classic heart-and-arrow TATTOO with \"Dad\" in the centre. Across his chest is a BANDOLIER of bright red 12-gauge shells, FISH HOOKS hanging from the bottom edge. Heavy rubberized BOOTS go past his knees. A CAPE of heavy FISHING NET edged with WEIGHTS hangs from his shoulders.\n\nHe holds a STOUT WOODEN OAR in both hands, edged with METAL and dripping with BLOOD.\n\nROSE\nWhere were you when they grabbed me? You were supposed to pick me up at work!\n\nMARINER\nYeah, about that, I got a little... distracted.\n\nROSE\nDistracted. You got DISTRACTED?!\n\nMARINER\nI was also... tracking the car... that grabbed you... through the AirTag... I put on your phone.\n\nRose stops. She's really not happy about this.\n\nROSE\nYou Airtagged me?!\n\n==========\nEXTRACTED SCENE DATA:\n{\n  \"scene_number\": 4,\n  \"heading\": \"INT. RUDDY & GREEN BUILDING - ELEVATOR\",\n  \"int_ext\": \"INT\",\n  \"location\": \"RUDDY & GREEN BUILDING - ELEVATOR\",\n  \"time_of_day\": null,\n  \"characters_present\": [\"ROSE\", \"MARINER\"],\n  \"summary\": \"Rose and Mariner ride the elevator after a violent rescue. Rose discovers a skull fragment on the floor while muzak plays. Mariner is introduced in full  a hulking vigilante in fishing-themed costume with an oar, net cape, and shell bandolier. Rose confronts him about being late to pick her up, and he reveals he tracked her via an AirTag on her phone, sparking a trust conflict between them.\",\n  \"narrative_beats\": [\n    {\"beat_type\": \"character_introduction\", \"description\": \"Full description of Mariner's fishing-themed vigilante costume  oar, net cape, bracers, shell bandolier, fish hooks.\", \"confidence\": 0.95},\n    {\"beat_type\": \"comic_relief\", \"description\": \"Rose discovers a skull fragment while muzak plays, establishing the dark comedy tone.\", \"confidence\": 0.90},\n    {\"beat_type\": \"revelation\", \"description\": \"Mariner admits he tracked Rose via AirTag on her phone, creating a trust conflict.\", \"confidence\": 0.88},\n    {\"beat_type\": \"conflict\", \"description\": \"Rose's anger escalates from being grabbed to learning she was being surveilled by Mariner.\", \"confidence\": 0.85}\n  ],\n  \"tone_mood\": \"dark comedy with bursts of tension\",\n  \"confidence\": 0.91\n}\n==========",
          "label": "prompts/qa-pass.txt: You are a QA reviewer validating whether an AI-extracted scene analysis is accurate and faithful to the source screenplay text.\n\nCompare the extracted scene data against the original scene text and evaluate:\n\n1. **Heading accuracy**: Is the scene heading correct (location, INT/EXT, time of day)?\n2. **Character completeness**: Are all characters who appear or speak listed?\n3. **Summary fidelity**: Does the summary accurately describe what happens? No fabrications?\n4. **Narrative beats**: Are the identified beats actually present in the scene?\n5. **Tone assessment**: Does the tone description match the actual mood of the scene?\n6. **Confidence calibration**: Is the confidence score reasonable given the quality?\n\nReturn a JSON object with:\n- passed: boolean (true if the extraction is faithful, false if it has significant errors)\n- confidence: float 0-1 (your confidence in this QA judgment)\n- issues: array of objects, each with:\n  - severity: \"error\" (factual wrong), \"warning\" (misleading), or \"note\" (minor)\n  - description: what's wrong\n  - location: which field has the issue\n- summary: 1-2 sentence overall assessment\n\nBe strict: wrong character names, fabricated events, or incorrect locations are errors.\nMinor omissions or imprecise tone descriptions are warnings.\n\nReturn ONLY valid JSON. No explanations or markdown fences.\n\n==========\nORIGINAL SCENE TEXT:\n{{scene_text}}\n\n==========\nEXTRACTED SCENE DATA:\n{{extracted_data}}\n==========",
          "config": {
            "provider": "anthropic:messages:claude-opus-4-6"
          }
        },
        "promptId": "8df20c2c4a6081352d6b06e144ddbc1e0a5244f9a3c2000d40df12fc9a94e543",
        "promptIdx": 9,
        "provider": {
          "id": "openai:gpt-5.2",
          "label": "GPT-5.2"
        },
        "response": {
          "output": "{\n  \"passed\": true,\n  \"confidence\": 0.93,\n  \"issues\": [\n    {\n      \"severity\": \"note\",\n      \"description\": \"Time of day is not specified in the scene text; leaving it null is appropriate, but the extraction does not explicitly note it is unspecified.\",\n      \"location\": \"time_of_day\"\n    },\n    {\n      \"severity\": \"warning\",\n      \"description\": \"Summary says Rose discovers a \\\"skull fragment\\\"; the text only states a bloody scrap of something with hair on it and Rose asks \\\"Is that skull??\\\" (implied but not confirmed).\",\n      \"location\": \"summary\"\n    },\n    {\n      \"severity\": \"warning\",\n      \"description\": \"Beat describes Rose discovering a \\\"skull fragment\\\"; the scene implies it but does not definitively confirm it is skull.\",\n      \"location\": \"narrative_beats[1].description\"\n    }\n  ],\n  \"summary\": \"The extraction is largely faithful: heading, characters, major actions, and the AirTag reveal/conflict are accurately captured, and the tone matches the darkly comic gore-and-banter vibe. Minor overstatement occurs in labeling the scrap as a confirmed skull fragment rather than an implied/uncertain one.\"\n}",
          "tokenUsage": {
            "total": 1407,
            "prompt": 1142,
            "completion": 265,
            "numRequests": 1,
            "completionDetails": {
              "reasoning": 0,
              "acceptedPrediction": 0,
              "rejectedPrediction": 0
            }
          },
          "cached": false,
          "latencyMs": 4053,
          "finishReason": "stop",
          "cost": 0.0057085,
          "guardrails": {
            "flagged": false
          },
          "metadata": {
            "http": {
              "status": 200,
              "statusText": "OK",
              "headers": {
                "access-control-expose-headers": "X-Request-ID",
                "alt-svc": "h3=\":443\"; ma=86400",
                "cf-cache-status": "DYNAMIC",
                "cf-ray": "9d5d9871685998e3-YVR",
                "connection": "keep-alive",
                "content-encoding": "br",
                "content-type": "application/json",
                "date": "Mon, 02 Mar 2026 04:18:09 GMT",
                "openai-organization": "user-oqdrq8y0bphopngnvkyuu5wr",
                "openai-processing-ms": "3904",
                "openai-project": "proj_ZRoLLwXcJok6Xg2t6eKhI1pn",
                "openai-version": "2020-10-01",
                "server": "cloudflare",
                "set-cookie": "__cf_bm=opiNu4o1SXd_7wjvW8xMsjGxGp2osgLXjL59AIPZEzo-1772425085.66349-1.0.1.1-yrRORUqvTlKPHsyslSKL.ZyuI2z6IdN.daRrASbOpr1YyDKBva8bmGaQS0sTYdNMfWzEIAi_bdGEC01Bqi4YPAAPmarVDTt4k5qaj_DrhZmV0ZF9kiiqgvhVZ_v.ajs6; HttpOnly; Secure; Path=/; Domain=api.openai.com; Expires=Mon, 02 Mar 2026 04:48:09 GMT",
                "strict-transport-security": "max-age=31536000; includeSubDomains; preload",
                "transfer-encoding": "chunked",
                "x-content-type-options": "nosniff",
                "x-openai-proxy-wasm": "v0.1",
                "x-ratelimit-limit-requests": "10000",
                "x-ratelimit-limit-tokens": "4000000",
                "x-ratelimit-remaining-requests": "9999",
                "x-ratelimit-remaining-tokens": "3998856",
                "x-ratelimit-reset-requests": "6ms",
                "x-ratelimit-reset-tokens": "17ms",
                "x-request-id": "req_e72707a508d64c85bcbab01164ac0a77"
              }
            }
          }
        },
        "score": 1,
        "success": true,
        "testCase": {
          "vars": {
            "scene_text": "file://../input/enrich-scene-elevator.txt",
            "extracted_data": "file://../input/qa-good-scene.json",
            "golden_path": "golden/qa-pass-golden.json",
            "test_key": "good_scene"
          },
          "assert": [
            {
              "type": "python",
              "value": "file://../scorers/qa_pass_scorer.py"
            },
            {
              "type": "llm-rubric",
              "value": "This QA evaluation was given a GOOD scene extraction that accurately\nreflects the source text. The QA model should have:\n\n1. Marked it as passed (true)\n2. Found zero or very few errors\n3. Had high confidence in the assessment\n4. Written a summary confirming accuracy\n\nIf the model incorrectly flagged the good extraction as failing,\nthat's a false negative and should score poorly.\n"
            }
          ],
          "options": {
            "provider": "anthropic:messages:claude-opus-4-6"
          },
          "metadata": {}
        },
        "testIdx": 0,
        "vars": {
          "scene_text": "file://../input/enrich-scene-elevator.txt",
          "extracted_data": "file://../input/qa-good-scene.json",
          "golden_path": "golden/qa-pass-golden.json",
          "test_key": "good_scene"
        },
        "metadata": {
          "http": {
            "status": 200,
            "statusText": "OK",
            "headers": {
              "access-control-expose-headers": "X-Request-ID",
              "alt-svc": "h3=\":443\"; ma=86400",
              "cf-cache-status": "DYNAMIC",
              "cf-ray": "9d5d9871685998e3-YVR",
              "connection": "keep-alive",
              "content-encoding": "br",
              "content-type": "application/json",
              "date": "Mon, 02 Mar 2026 04:18:09 GMT",
              "openai-organization": "user-oqdrq8y0bphopngnvkyuu5wr",
              "openai-processing-ms": "3904",
              "openai-project": "proj_ZRoLLwXcJok6Xg2t6eKhI1pn",
              "openai-version": "2020-10-01",
              "server": "cloudflare",
              "set-cookie": "__cf_bm=opiNu4o1SXd_7wjvW8xMsjGxGp2osgLXjL59AIPZEzo-1772425085.66349-1.0.1.1-yrRORUqvTlKPHsyslSKL.ZyuI2z6IdN.daRrASbOpr1YyDKBva8bmGaQS0sTYdNMfWzEIAi_bdGEC01Bqi4YPAAPmarVDTt4k5qaj_DrhZmV0ZF9kiiqgvhVZ_v.ajs6; HttpOnly; Secure; Path=/; Domain=api.openai.com; Expires=Mon, 02 Mar 2026 04:48:09 GMT",
              "strict-transport-security": "max-age=31536000; includeSubDomains; preload",
              "transfer-encoding": "chunked",
              "x-content-type-options": "nosniff",
              "x-openai-proxy-wasm": "v0.1",
              "x-ratelimit-limit-requests": "10000",
              "x-ratelimit-limit-tokens": "4000000",
              "x-ratelimit-remaining-requests": "9999",
              "x-ratelimit-remaining-tokens": "3998856",
              "x-ratelimit-reset-requests": "6ms",
              "x-ratelimit-reset-tokens": "17ms",
              "x-request-id": "req_e72707a508d64c85bcbab01164ac0a77"
            }
          },
          "_promptfooFileMetadata": {}
        },
        "failureReason": 0
      },
      {
        "cost": 0.008959499999999999,
        "gradingResult": {
          "pass": true,
          "score": 1,
          "reason": "All assertions passed",
          "namedScores": {},
          "tokensUsed": {
            "total": 530,
            "prompt": 438,
            "completion": 92,
            "cached": 0,
            "numRequests": 0
          },
          "componentResults": [
            {
              "pass": true,
              "score": 1,
              "reason": "confidence_calibration=1.00 | issue_detection=1.00 | json_valid=1.00 | pass_correct=1.00 | severity_accuracy=1.00 | summary_quality=1.00",
              "assertion": {
                "type": "python",
                "value": "file://../scorers/qa_pass_scorer.py"
              }
            },
            {
              "assertion": {
                "type": "llm-rubric",
                "value": "This QA evaluation was given a GOOD scene extraction that accurately\nreflects the source text. The QA model should have:\n\n1. Marked it as passed (true)\n2. Found zero or very few errors\n3. Had high confidence in the assessment\n4. Written a summary confirming accuracy\n\nIf the model incorrectly flagged the good extraction as failing,\nthat's a false negative and should score poorly.\n"
              },
              "pass": true,
              "score": 1,
              "reason": "The QA evaluation correctly marked the extraction as passed (true), had high confidence (0.98), found only very minor issues (a warning about a scene number and a note about a slight wording difference), and wrote a summary confirming the overall accuracy of the extraction. This aligns perfectly with the rubric's requirements for handling a good extraction.",
              "tokensUsed": {
                "total": 530,
                "prompt": 438,
                "completion": 92,
                "cached": 0,
                "numRequests": 0,
                "completionDetails": {
                  "reasoning": 0,
                  "acceptedPrediction": 0,
                  "rejectedPrediction": 0
                }
              },
              "metadata": {
                "renderedGradingPrompt": "[{\"role\":\"system\",\"content\":\"You are grading output according to a user-specified rubric. If the statement in the rubric is true, then the output passes the test. You respond with a JSON object with this structure: {reason: string, pass: boolean, score: number}\\n\\nExamples:\\n\\n<Output>Hello world</Output>\\n<Rubric>Content contains a greeting</Rubric>\\n{\\\"reason\\\": \\\"the content contains the word 'Hello'\\\", \\\"pass\\\": true, \\\"score\\\": 1.0}\\n\\n<Output>Avast ye swabs, repel the invaders!</Output>\\n<Rubric>Does not speak like a pirate</Rubric>\\n{\\\"reason\\\": \\\"'avast ye' is a common pirate term\\\", \\\"pass\\\": false, \\\"score\\\": 0.0}\"},{\"role\":\"user\",\"content\":\"<Output>\\n{\\\"passed\\\":true,\\\"confidence\\\":0.98,\\\"issues\\\":[{\\\"severity\\\":\\\"warning\\\",\\\"description\\\":\\\"The extraction includes a scene number (4) which is not present in the provided source text.\\\",\\\"location\\\":\\\"scene_number\\\"},{\\\"severity\\\":\\\"note\\\",\\\"description\\\":\\\"The summary describes the object Rose finds as a 'skull fragment', whereas in the text she only asks if it is a skull, though the context strongly implies it.\\\",\\\"location\\\":\\\"summary\\\"}],\\\"summary\\\":\\\"The extraction is highly accurate, capturing the specific character descriptions, dialogue points, and the unique dark comedic tone of the scene. The only minor discrepancy is the inclusion of a scene number not found in the source snippet.\\\"}\\n</Output>\\n<Rubric>\\nThis QA evaluation was given a GOOD scene extraction that accurately\\nreflects the source text. The QA model should have:\\n\\n1. Marked it as passed (true)\\n2. Found zero or very few errors\\n3. Had high confidence in the assessment\\n4. Written a summary confirming accuracy\\n\\nIf the model incorrectly flagged the good extraction as failing,\\nthat's a false negative and should score poorly.\\n\\n</Rubric>\"}]"
              }
            }
          ]
        },
        "id": "06415d41-36c6-46a7-a764-95fb4877875d",
        "latencyMs": 17466,
        "namedScores": {},
        "prompt": {
          "raw": "You are a QA reviewer validating whether an AI-extracted scene analysis is accurate and faithful to the source screenplay text.\n\nCompare the extracted scene data against the original scene text and evaluate:\n\n1. **Heading accuracy**: Is the scene heading correct (location, INT/EXT, time of day)?\n2. **Character completeness**: Are all characters who appear or speak listed?\n3. **Summary fidelity**: Does the summary accurately describe what happens? No fabrications?\n4. **Narrative beats**: Are the identified beats actually present in the scene?\n5. **Tone assessment**: Does the tone description match the actual mood of the scene?\n6. **Confidence calibration**: Is the confidence score reasonable given the quality?\n\nReturn a JSON object with:\n- passed: boolean (true if the extraction is faithful, false if it has significant errors)\n- confidence: float 0-1 (your confidence in this QA judgment)\n- issues: array of objects, each with:\n  - severity: \"error\" (factual wrong), \"warning\" (misleading), or \"note\" (minor)\n  - description: what's wrong\n  - location: which field has the issue\n- summary: 1-2 sentence overall assessment\n\nBe strict: wrong character names, fabricated events, or incorrect locations are errors.\nMinor omissions or imprecise tone descriptions are warnings.\n\nReturn ONLY valid JSON. No explanations or markdown fences.\n\n==========\nORIGINAL SCENE TEXT:\nINT. RUDDY & GREEN BUILDING - ELEVATOR\n\nUB40's \"I Can't Help Falling in Love With You\" muzak.\n\nROSE (mid-30s) leans against the elevator wall, panting. She's wearing a Tim Hortons uniform, her hair is a mess, and there's blood spattered on her face.\n\nShe looks right, pants a few more times, then squints in disgust. She gingerly picks up a bloody scrap of something with hair on it. She snorts and drops it.\n\nROSE\nIs that skull??\n\nNext to her is Mariner, also panting, covered in far more blood. His face is broad, stoic, and frowning. He has gray-blue eyes and a thick, curly, beard barely streaked with gray. He wears a red knit cap and a small mask.\n\nFULL-SCREEN SUPERIMPOSED TITLE CARD: \"THE MARINER\"\n\nHe blinks a few times as a drop of blood falls from his eyebrow. He looks toward her, then spits out some blood.\n\nMARINER\nYeaaaaah...\n\nHe's built like a pro-wrestler. Moss green SWEATER stretched over his huge frame, sleeves rolled showing heavy leather BRACERS adorned with anchors. His inner forearm has a classic heart-and-arrow TATTOO with \"Dad\" in the centre. Across his chest is a BANDOLIER of bright red 12-gauge shells, FISH HOOKS hanging from the bottom edge. Heavy rubberized BOOTS go past his knees. A CAPE of heavy FISHING NET edged with WEIGHTS hangs from his shoulders.\n\nHe holds a STOUT WOODEN OAR in both hands, edged with METAL and dripping with BLOOD.\n\nROSE\nWhere were you when they grabbed me? You were supposed to pick me up at work!\n\nMARINER\nYeah, about that, I got a little... distracted.\n\nROSE\nDistracted. You got DISTRACTED?!\n\nMARINER\nI was also... tracking the car... that grabbed you... through the AirTag... I put on your phone.\n\nRose stops. She's really not happy about this.\n\nROSE\nYou Airtagged me?!\n\n==========\nEXTRACTED SCENE DATA:\n{\n  \"scene_number\": 4,\n  \"heading\": \"INT. RUDDY & GREEN BUILDING - ELEVATOR\",\n  \"int_ext\": \"INT\",\n  \"location\": \"RUDDY & GREEN BUILDING - ELEVATOR\",\n  \"time_of_day\": null,\n  \"characters_present\": [\"ROSE\", \"MARINER\"],\n  \"summary\": \"Rose and Mariner ride the elevator after a violent rescue. Rose discovers a skull fragment on the floor while muzak plays. Mariner is introduced in full  a hulking vigilante in fishing-themed costume with an oar, net cape, and shell bandolier. Rose confronts him about being late to pick her up, and he reveals he tracked her via an AirTag on her phone, sparking a trust conflict between them.\",\n  \"narrative_beats\": [\n    {\"beat_type\": \"character_introduction\", \"description\": \"Full description of Mariner's fishing-themed vigilante costume  oar, net cape, bracers, shell bandolier, fish hooks.\", \"confidence\": 0.95},\n    {\"beat_type\": \"comic_relief\", \"description\": \"Rose discovers a skull fragment while muzak plays, establishing the dark comedy tone.\", \"confidence\": 0.90},\n    {\"beat_type\": \"revelation\", \"description\": \"Mariner admits he tracked Rose via AirTag on her phone, creating a trust conflict.\", \"confidence\": 0.88},\n    {\"beat_type\": \"conflict\", \"description\": \"Rose's anger escalates from being grabbed to learning she was being surveilled by Mariner.\", \"confidence\": 0.85}\n  ],\n  \"tone_mood\": \"dark comedy with bursts of tension\",\n  \"confidence\": 0.91\n}\n==========",
          "label": "prompts/qa-pass.txt: You are a QA reviewer validating whether an AI-extracted scene analysis is accurate and faithful to the source screenplay text.\n\nCompare the extracted scene data against the original scene text and evaluate:\n\n1. **Heading accuracy**: Is the scene heading correct (location, INT/EXT, time of day)?\n2. **Character completeness**: Are all characters who appear or speak listed?\n3. **Summary fidelity**: Does the summary accurately describe what happens? No fabrications?\n4. **Narrative beats**: Are the identified beats actually present in the scene?\n5. **Tone assessment**: Does the tone description match the actual mood of the scene?\n6. **Confidence calibration**: Is the confidence score reasonable given the quality?\n\nReturn a JSON object with:\n- passed: boolean (true if the extraction is faithful, false if it has significant errors)\n- confidence: float 0-1 (your confidence in this QA judgment)\n- issues: array of objects, each with:\n  - severity: \"error\" (factual wrong), \"warning\" (misleading), or \"note\" (minor)\n  - description: what's wrong\n  - location: which field has the issue\n- summary: 1-2 sentence overall assessment\n\nBe strict: wrong character names, fabricated events, or incorrect locations are errors.\nMinor omissions or imprecise tone descriptions are warnings.\n\nReturn ONLY valid JSON. No explanations or markdown fences.\n\n==========\nORIGINAL SCENE TEXT:\n{{scene_text}}\n\n==========\nEXTRACTED SCENE DATA:\n{{extracted_data}}\n==========",
          "config": {
            "provider": "anthropic:messages:claude-opus-4-6"
          }
        },
        "promptId": "8df20c2c4a6081352d6b06e144ddbc1e0a5244f9a3c2000d40df12fc9a94e543",
        "promptIdx": 8,
        "provider": {
          "id": "google:gemini-3-flash-preview",
          "label": "Gemini 3 Flash"
        },
        "response": {
          "output": "{\n  \"passed\": true,\n  \"confidence\": 0.98,\n  \"issues\": [\n    {\n      \"severity\": \"warning\",\n      \"description\": \"The extraction includes a scene number (4) which is not present in the provided source text.\",\n      \"location\": \"scene_number\"\n    },\n    {\n      \"severity\": \"note\",\n      \"description\": \"The summary describes the object Rose finds as a 'skull fragment', whereas in the text she only asks if it is a skull, though the context strongly implies it.\",\n      \"location\": \"summary\"\n    }\n  ],\n  \"summary\": \"The extraction is highly accurate, capturing the specific character descriptions, dialogue points, and the unique dark comedic tone of the scene. The only minor discrepancy is the inclusion of a scene number not found in the source snippet.\"\n}",
          "tokenUsage": {
            "prompt": 1185,
            "completion": 189,
            "total": 3974,
            "numRequests": 1,
            "completionDetails": {
              "reasoning": 2600,
              "acceptedPrediction": 0,
              "rejectedPrediction": 0
            }
          },
          "cost": 0.008959499999999999,
          "raw": {
            "candidates": [
              {
                "content": {
                  "parts": [
                    {
                      "text": "{\n  \"passed\": true,\n  \"confidence\": 0.98,\n  \"issues\": [\n    {\n      \"severity\": \"warning\",\n      \"description\": \"The extraction includes a scene number (4) which is not present in the provided source text.\",\n      \"location\": \"scene_number\"\n    },\n    {\n      \"severity\": \"note\",\n      \"description\": \"The summary describes the object Rose finds as a 'skull fragment', whereas in the text she only asks if it is a skull, though the context strongly implies it.\",\n      \"location\": \"summary\"\n    }\n  ],\n  \"summary\": \"The extraction is highly accurate, capturing the specific character descriptions, dialogue points, and the unique dark comedic tone of the scene. The only minor discrepancy is the inclusion of a scene number not found in the source snippet.\"\n}",
                      "thoughtSignature": "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"
                    }
                  ],
                  "role": "model"
                },
                "finishReason": "STOP",
                "index": 0
              }
            ],
            "usageMetadata": {
              "promptTokenCount": 1185,
              "candidatesTokenCount": 189,
              "totalTokenCount": 3974,
              "promptTokensDetails": [
                {
                  "modality": "TEXT",
                  "tokenCount": 1185
                }
              ],
              "thoughtsTokenCount": 2600
            },
            "modelVersion": "gemini-3-flash-preview",
            "responseId": "iA-laZq1EfedqtsP2arQwQM"
          },
          "cached": false,
          "metadata": {}
        },
        "score": 1,
        "success": true,
        "testCase": {
          "vars": {
            "scene_text": "file://../input/enrich-scene-elevator.txt",
            "extracted_data": "file://../input/qa-good-scene.json",
            "golden_path": "golden/qa-pass-golden.json",
            "test_key": "good_scene"
          },
          "assert": [
            {
              "type": "python",
              "value": "file://../scorers/qa_pass_scorer.py"
            },
            {
              "type": "llm-rubric",
              "value": "This QA evaluation was given a GOOD scene extraction that accurately\nreflects the source text. The QA model should have:\n\n1. Marked it as passed (true)\n2. Found zero or very few errors\n3. Had high confidence in the assessment\n4. Written a summary confirming accuracy\n\nIf the model incorrectly flagged the good extraction as failing,\nthat's a false negative and should score poorly.\n"
            }
          ],
          "options": {
            "provider": "anthropic:messages:claude-opus-4-6"
          },
          "metadata": {}
        },
        "testIdx": 0,
        "vars": {
          "scene_text": "file://../input/enrich-scene-elevator.txt",
          "extracted_data": "file://../input/qa-good-scene.json",
          "golden_path": "golden/qa-pass-golden.json",
          "test_key": "good_scene"
        },
        "metadata": {
          "_promptfooFileMetadata": {}
        },
        "failureReason": 0
      },
      {
        "cost": 0.016190000000000003,
        "gradingResult": {
          "pass": true,
          "score": 0.995,
          "reason": "All assertions passed",
          "namedScores": {},
          "tokensUsed": {
            "total": 818,
            "prompt": 690,
            "completion": 128,
            "cached": 0,
            "numRequests": 0
          },
          "componentResults": [
            {
              "pass": true,
              "score": 0.99,
              "reason": "confidence_calibration=1.00 | issue_detection=1.00 | json_valid=0.90 | pass_correct=1.00 | severity_accuracy=1.00 | summary_quality=1.00 | JSON extracted from code block",
              "assertion": {
                "type": "python",
                "value": "file://../scorers/qa_pass_scorer.py"
              }
            },
            {
              "assertion": {
                "type": "llm-rubric",
                "value": "This QA evaluation was given a GOOD scene extraction that accurately\nreflects the source text. The QA model should have:\n\n1. Marked it as passed (true)\n2. Found zero or very few errors\n3. Had high confidence in the assessment\n4. Written a summary confirming accuracy\n\nIf the model incorrectly flagged the good extraction as failing,\nthat's a false negative and should score poorly.\n"
              },
              "pass": true,
              "score": 1,
              "reason": "The QA evaluation correctly marked the extraction as passed (true) with high confidence (0.95). It found zero actual errors  all four issues were marked as 'note' severity, representing minor interpretive liberties rather than factual errors. The summary confirms accuracy, stating 'The extraction is accurate and faithful to the source text' and that 'Minor issues are limited to slight interpretive liberties... that are reasonable inferences rather than fabrications.' This is exactly the expected behavior for evaluating a good extraction.",
              "tokensUsed": {
                "total": 818,
                "prompt": 690,
                "completion": 128,
                "cached": 0,
                "numRequests": 0,
                "completionDetails": {
                  "reasoning": 0,
                  "acceptedPrediction": 0,
                  "rejectedPrediction": 0
                }
              },
              "metadata": {
                "renderedGradingPrompt": "[{\"role\":\"system\",\"content\":\"You are grading output according to a user-specified rubric. If the statement in the rubric is true, then the output passes the test. You respond with a JSON object with this structure: {reason: string, pass: boolean, score: number}\\n\\nExamples:\\n\\n<Output>Hello world</Output>\\n<Rubric>Content contains a greeting</Rubric>\\n{\\\"reason\\\": \\\"the content contains the word 'Hello'\\\", \\\"pass\\\": true, \\\"score\\\": 1.0}\\n\\n<Output>Avast ye swabs, repel the invaders!</Output>\\n<Rubric>Does not speak like a pirate</Rubric>\\n{\\\"reason\\\": \\\"'avast ye' is a common pirate term\\\", \\\"pass\\\": false, \\\"score\\\": 0.0}\"},{\"role\":\"user\",\"content\":\"<Output>\\n```json\\n{\\n  \\\"passed\\\": true,\\n  \\\"confidence\\\": 0.95,\\n  \\\"issues\\\": [\\n    {\\n      \\\"severity\\\": \\\"note\\\",\\n      \\\"description\\\": \\\"The summary says Rose discovers a 'skull fragment on the floor'  the text says she picks up 'a bloody scrap of something with hair on it' and then asks 'Is that skull??' It's not confirmed to be skull, and it's not specified as being on the floor (she picks it up from next to her, possibly on herself or the wall).\\\",\\n      \\\"location\\\": \\\"summary\\\"\\n    },\\n    {\\n      \\\"severity\\\": \\\"note\\\",\\n      \\\"description\\\": \\\"The summary characterizes the scene as a 'violent rescue'  while this is strongly implied by context (blood, panting, being grabbed), the rescue itself is not depicted in this scene, only its aftermath.\\\",\\n      \\\"location\\\": \\\"summary\\\"\\n    },\\n    {\\n      \\\"severity\\\": \\\"note\\\",\\n      \\\"description\\\": \\\"The summary describes Mariner as a 'vigilante'  this is a reasonable inference but not explicitly stated in the scene text.\\\",\\n      \\\"location\\\": \\\"summary\\\"\\n    },\\n    {\\n      \\\"severity\\\": \\\"note\\\",\\n      \\\"description\\\": \\\"Scene number 4 is assigned but there's no indication in the source text of what scene number this is.\\\",\\n      \\\"location\\\": \\\"scene_number\\\"\\n    }\\n  ],\\n  \\\"summary\\\": \\\"The extraction is accurate and faithful to the source text. Characters, heading, tone, and narrative beats are all correctly identified. Minor issues are limited to slight interpretive liberties (calling the scrap a 'skull fragment,' labeling Mariner a 'vigilante') that are reasonable inferences rather than fabrications.\\\"\\n}\\n```\\n</Output>\\n<Rubric>\\nThis QA evaluation was given a GOOD scene extraction that accurately\\nreflects the source text. The QA model should have:\\n\\n1. Marked it as passed (true)\\n2. Found zero or very few errors\\n3. Had high confidence in the assessment\\n4. Written a summary confirming accuracy\\n\\nIf the model incorrectly flagged the good extraction as failing,\\nthat's a false negative and should score poorly.\\n\\n</Rubric>\"}]"
              }
            }
          ]
        },
        "id": "e8204789-e006-4e2c-a86a-d62ecede1d75",
        "latencyMs": 8816,
        "namedScores": {},
        "prompt": {
          "raw": "You are a QA reviewer validating whether an AI-extracted scene analysis is accurate and faithful to the source screenplay text.\n\nCompare the extracted scene data against the original scene text and evaluate:\n\n1. **Heading accuracy**: Is the scene heading correct (location, INT/EXT, time of day)?\n2. **Character completeness**: Are all characters who appear or speak listed?\n3. **Summary fidelity**: Does the summary accurately describe what happens? No fabrications?\n4. **Narrative beats**: Are the identified beats actually present in the scene?\n5. **Tone assessment**: Does the tone description match the actual mood of the scene?\n6. **Confidence calibration**: Is the confidence score reasonable given the quality?\n\nReturn a JSON object with:\n- passed: boolean (true if the extraction is faithful, false if it has significant errors)\n- confidence: float 0-1 (your confidence in this QA judgment)\n- issues: array of objects, each with:\n  - severity: \"error\" (factual wrong), \"warning\" (misleading), or \"note\" (minor)\n  - description: what's wrong\n  - location: which field has the issue\n- summary: 1-2 sentence overall assessment\n\nBe strict: wrong character names, fabricated events, or incorrect locations are errors.\nMinor omissions or imprecise tone descriptions are warnings.\n\nReturn ONLY valid JSON. No explanations or markdown fences.\n\n==========\nORIGINAL SCENE TEXT:\nINT. RUDDY & GREEN BUILDING - ELEVATOR\n\nUB40's \"I Can't Help Falling in Love With You\" muzak.\n\nROSE (mid-30s) leans against the elevator wall, panting. She's wearing a Tim Hortons uniform, her hair is a mess, and there's blood spattered on her face.\n\nShe looks right, pants a few more times, then squints in disgust. She gingerly picks up a bloody scrap of something with hair on it. She snorts and drops it.\n\nROSE\nIs that skull??\n\nNext to her is Mariner, also panting, covered in far more blood. His face is broad, stoic, and frowning. He has gray-blue eyes and a thick, curly, beard barely streaked with gray. He wears a red knit cap and a small mask.\n\nFULL-SCREEN SUPERIMPOSED TITLE CARD: \"THE MARINER\"\n\nHe blinks a few times as a drop of blood falls from his eyebrow. He looks toward her, then spits out some blood.\n\nMARINER\nYeaaaaah...\n\nHe's built like a pro-wrestler. Moss green SWEATER stretched over his huge frame, sleeves rolled showing heavy leather BRACERS adorned with anchors. His inner forearm has a classic heart-and-arrow TATTOO with \"Dad\" in the centre. Across his chest is a BANDOLIER of bright red 12-gauge shells, FISH HOOKS hanging from the bottom edge. Heavy rubberized BOOTS go past his knees. A CAPE of heavy FISHING NET edged with WEIGHTS hangs from his shoulders.\n\nHe holds a STOUT WOODEN OAR in both hands, edged with METAL and dripping with BLOOD.\n\nROSE\nWhere were you when they grabbed me? You were supposed to pick me up at work!\n\nMARINER\nYeah, about that, I got a little... distracted.\n\nROSE\nDistracted. You got DISTRACTED?!\n\nMARINER\nI was also... tracking the car... that grabbed you... through the AirTag... I put on your phone.\n\nRose stops. She's really not happy about this.\n\nROSE\nYou Airtagged me?!\n\n==========\nEXTRACTED SCENE DATA:\n{\n  \"scene_number\": 4,\n  \"heading\": \"INT. RUDDY & GREEN BUILDING - ELEVATOR\",\n  \"int_ext\": \"INT\",\n  \"location\": \"RUDDY & GREEN BUILDING - ELEVATOR\",\n  \"time_of_day\": null,\n  \"characters_present\": [\"ROSE\", \"MARINER\"],\n  \"summary\": \"Rose and Mariner ride the elevator after a violent rescue. Rose discovers a skull fragment on the floor while muzak plays. Mariner is introduced in full  a hulking vigilante in fishing-themed costume with an oar, net cape, and shell bandolier. Rose confronts him about being late to pick her up, and he reveals he tracked her via an AirTag on her phone, sparking a trust conflict between them.\",\n  \"narrative_beats\": [\n    {\"beat_type\": \"character_introduction\", \"description\": \"Full description of Mariner's fishing-themed vigilante costume  oar, net cape, bracers, shell bandolier, fish hooks.\", \"confidence\": 0.95},\n    {\"beat_type\": \"comic_relief\", \"description\": \"Rose discovers a skull fragment while muzak plays, establishing the dark comedy tone.\", \"confidence\": 0.90},\n    {\"beat_type\": \"revelation\", \"description\": \"Mariner admits he tracked Rose via AirTag on her phone, creating a trust conflict.\", \"confidence\": 0.88},\n    {\"beat_type\": \"conflict\", \"description\": \"Rose's anger escalates from being grabbed to learning she was being surveilled by Mariner.\", \"confidence\": 0.85}\n  ],\n  \"tone_mood\": \"dark comedy with bursts of tension\",\n  \"confidence\": 0.91\n}\n==========",
          "label": "prompts/qa-pass.txt: You are a QA reviewer validating whether an AI-extracted scene analysis is accurate and faithful to the source screenplay text.\n\nCompare the extracted scene data against the original scene text and evaluate:\n\n1. **Heading accuracy**: Is the scene heading correct (location, INT/EXT, time of day)?\n2. **Character completeness**: Are all characters who appear or speak listed?\n3. **Summary fidelity**: Does the summary accurately describe what happens? No fabrications?\n4. **Narrative beats**: Are the identified beats actually present in the scene?\n5. **Tone assessment**: Does the tone description match the actual mood of the scene?\n6. **Confidence calibration**: Is the confidence score reasonable given the quality?\n\nReturn a JSON object with:\n- passed: boolean (true if the extraction is faithful, false if it has significant errors)\n- confidence: float 0-1 (your confidence in this QA judgment)\n- issues: array of objects, each with:\n  - severity: \"error\" (factual wrong), \"warning\" (misleading), or \"note\" (minor)\n  - description: what's wrong\n  - location: which field has the issue\n- summary: 1-2 sentence overall assessment\n\nBe strict: wrong character names, fabricated events, or incorrect locations are errors.\nMinor omissions or imprecise tone descriptions are warnings.\n\nReturn ONLY valid JSON. No explanations or markdown fences.\n\n==========\nORIGINAL SCENE TEXT:\n{{scene_text}}\n\n==========\nEXTRACTED SCENE DATA:\n{{extracted_data}}\n==========",
          "config": {
            "provider": "anthropic:messages:claude-opus-4-6"
          }
        },
        "promptId": "8df20c2c4a6081352d6b06e144ddbc1e0a5244f9a3c2000d40df12fc9a94e543",
        "promptIdx": 10,
        "provider": {
          "id": "anthropic:messages:claude-opus-4-6",
          "label": "Claude Opus 4.6"
        },
        "response": {
          "output": "```json\n{\n  \"passed\": true,\n  \"confidence\": 0.95,\n  \"issues\": [\n    {\n      \"severity\": \"note\",\n      \"description\": \"The summary says Rose discovers a 'skull fragment on the floor'  the text says she picks up 'a bloody scrap of something with hair on it' and then asks 'Is that skull??' It's not confirmed to be skull, and it's not specified as being on the floor (she picks it up from next to her, possibly on herself or the wall).\",\n      \"location\": \"summary\"\n    },\n    {\n      \"severity\": \"note\",\n      \"description\": \"The summary characterizes the scene as a 'violent rescue'  while this is strongly implied by context (blood, panting, being grabbed), the rescue itself is not depicted in this scene, only its aftermath.\",\n      \"location\": \"summary\"\n    },\n    {\n      \"severity\": \"note\",\n      \"description\": \"The summary describes Mariner as a 'vigilante'  this is a reasonable inference but not explicitly stated in the scene text.\",\n      \"location\": \"summary\"\n    },\n    {\n      \"severity\": \"note\",\n      \"description\": \"Scene number 4 is assigned but there's no indication in the source text of what scene number this is.\",\n      \"location\": \"scene_number\"\n    }\n  ],\n  \"summary\": \"The extraction is accurate and faithful to the source text. Characters, heading, tone, and narrative beats are all correctly identified. Minor issues are limited to slight interpretive liberties (calling the scrap a 'skull fragment,' labeling Mariner a 'vigilante') that are reasonable inferences rather than fabrications.\"\n}\n```",
          "tokenUsage": {
            "total": 1642,
            "prompt": 1243,
            "completion": 399
          },
          "finishReason": "stop",
          "cost": 0.016190000000000003
        },
        "score": 0.995,
        "success": true,
        "testCase": {
          "vars": {
            "scene_text": "file://../input/enrich-scene-elevator.txt",
            "extracted_data": "file://../input/qa-good-scene.json",
            "golden_path": "golden/qa-pass-golden.json",
            "test_key": "good_scene"
          },
          "assert": [
            {
              "type": "python",
              "value": "file://../scorers/qa_pass_scorer.py"
            },
            {
              "type": "llm-rubric",
              "value": "This QA evaluation was given a GOOD scene extraction that accurately\nreflects the source text. The QA model should have:\n\n1. Marked it as passed (true)\n2. Found zero or very few errors\n3. Had high confidence in the assessment\n4. Written a summary confirming accuracy\n\nIf the model incorrectly flagged the good extraction as failing,\nthat's a false negative and should score poorly.\n"
            }
          ],
          "options": {
            "provider": "anthropic:messages:claude-opus-4-6"
          },
          "metadata": {}
        },
        "testIdx": 0,
        "vars": {
          "scene_text": "file://../input/enrich-scene-elevator.txt",
          "extracted_data": "file://../input/qa-good-scene.json",
          "golden_path": "golden/qa-pass-golden.json",
          "test_key": "good_scene"
        },
        "metadata": {
          "_promptfooFileMetadata": {}
        },
        "failureReason": 0
      },
      {
        "cost": 0.01174125,
        "gradingResult": {
          "pass": true,
          "score": 0.995,
          "reason": "All assertions passed",
          "namedScores": {},
          "tokensUsed": {
            "total": 432,
            "prompt": 360,
            "completion": 72,
            "cached": 0,
            "numRequests": 0
          },
          "componentResults": [
            {
              "pass": true,
              "score": 0.99,
              "reason": "confidence_calibration=1.00 | issue_detection=1.00 | json_valid=0.90 | pass_correct=1.00 | severity_accuracy=1.00 | summary_quality=1.00 | JSON extracted from code block",
              "assertion": {
                "type": "python",
                "value": "file://../scorers/qa_pass_scorer.py"
              }
            },
            {
              "assertion": {
                "type": "llm-rubric",
                "value": "This QA evaluation was given a GOOD scene extraction that accurately\nreflects the source text. The QA model should have:\n\n1. Marked it as passed (true)\n2. Found zero or very few errors\n3. Had high confidence in the assessment\n4. Written a summary confirming accuracy\n\nIf the model incorrectly flagged the good extraction as failing,\nthat's a false negative and should score poorly.\n"
              },
              "pass": true,
              "score": 1,
              "reason": "The QA evaluation correctly marked the extraction as passed (true), found zero issues (empty issues array), had maximum confidence (1.0), and wrote a summary confirming the accuracy of the extraction. This perfectly matches all four criteria in the rubric.",
              "tokensUsed": {
                "total": 432,
                "prompt": 360,
                "completion": 72,
                "cached": 0,
                "numRequests": 0,
                "completionDetails": {
                  "reasoning": 0,
                  "acceptedPrediction": 0,
                  "rejectedPrediction": 0
                }
              },
              "metadata": {
                "renderedGradingPrompt": "[{\"role\":\"system\",\"content\":\"You are grading output according to a user-specified rubric. If the statement in the rubric is true, then the output passes the test. You respond with a JSON object with this structure: {reason: string, pass: boolean, score: number}\\n\\nExamples:\\n\\n<Output>Hello world</Output>\\n<Rubric>Content contains a greeting</Rubric>\\n{\\\"reason\\\": \\\"the content contains the word 'Hello'\\\", \\\"pass\\\": true, \\\"score\\\": 1.0}\\n\\n<Output>Avast ye swabs, repel the invaders!</Output>\\n<Rubric>Does not speak like a pirate</Rubric>\\n{\\\"reason\\\": \\\"'avast ye' is a common pirate term\\\", \\\"pass\\\": false, \\\"score\\\": 0.0}\"},{\"role\":\"user\",\"content\":\"<Output>\\n```json\\n{\\n  \\\"passed\\\": true,\\n  \\\"confidence\\\": 1.0,\\n  \\\"issues\\\": [],\\n  \\\"summary\\\": \\\"The AI extraction is highly accurate and faithful, correctly identifying all characters, events, narrative beats, and the specific dark comedy tone of the scene.\\\"\\n}\\n```\\n</Output>\\n<Rubric>\\nThis QA evaluation was given a GOOD scene extraction that accurately\\nreflects the source text. The QA model should have:\\n\\n1. Marked it as passed (true)\\n2. Found zero or very few errors\\n3. Had high confidence in the assessment\\n4. Written a summary confirming accuracy\\n\\nIf the model incorrectly flagged the good extraction as failing,\\nthat's a false negative and should score poorly.\\n\\n</Rubric>\"}]"
              }
            }
          ]
        },
        "id": "7b1c5694-8e83-404e-90e7-4d47fa7116c0",
        "latencyMs": 9193,
        "namedScores": {},
        "prompt": {
          "raw": "You are a QA reviewer validating whether an AI-extracted scene analysis is accurate and faithful to the source screenplay text.\n\nCompare the extracted scene data against the original scene text and evaluate:\n\n1. **Heading accuracy**: Is the scene heading correct (location, INT/EXT, time of day)?\n2. **Character completeness**: Are all characters who appear or speak listed?\n3. **Summary fidelity**: Does the summary accurately describe what happens? No fabrications?\n4. **Narrative beats**: Are the identified beats actually present in the scene?\n5. **Tone assessment**: Does the tone description match the actual mood of the scene?\n6. **Confidence calibration**: Is the confidence score reasonable given the quality?\n\nReturn a JSON object with:\n- passed: boolean (true if the extraction is faithful, false if it has significant errors)\n- confidence: float 0-1 (your confidence in this QA judgment)\n- issues: array of objects, each with:\n  - severity: \"error\" (factual wrong), \"warning\" (misleading), or \"note\" (minor)\n  - description: what's wrong\n  - location: which field has the issue\n- summary: 1-2 sentence overall assessment\n\nBe strict: wrong character names, fabricated events, or incorrect locations are errors.\nMinor omissions or imprecise tone descriptions are warnings.\n\nReturn ONLY valid JSON. No explanations or markdown fences.\n\n==========\nORIGINAL SCENE TEXT:\nINT. RUDDY & GREEN BUILDING - ELEVATOR\n\nUB40's \"I Can't Help Falling in Love With You\" muzak.\n\nROSE (mid-30s) leans against the elevator wall, panting. She's wearing a Tim Hortons uniform, her hair is a mess, and there's blood spattered on her face.\n\nShe looks right, pants a few more times, then squints in disgust. She gingerly picks up a bloody scrap of something with hair on it. She snorts and drops it.\n\nROSE\nIs that skull??\n\nNext to her is Mariner, also panting, covered in far more blood. His face is broad, stoic, and frowning. He has gray-blue eyes and a thick, curly, beard barely streaked with gray. He wears a red knit cap and a small mask.\n\nFULL-SCREEN SUPERIMPOSED TITLE CARD: \"THE MARINER\"\n\nHe blinks a few times as a drop of blood falls from his eyebrow. He looks toward her, then spits out some blood.\n\nMARINER\nYeaaaaah...\n\nHe's built like a pro-wrestler. Moss green SWEATER stretched over his huge frame, sleeves rolled showing heavy leather BRACERS adorned with anchors. His inner forearm has a classic heart-and-arrow TATTOO with \"Dad\" in the centre. Across his chest is a BANDOLIER of bright red 12-gauge shells, FISH HOOKS hanging from the bottom edge. Heavy rubberized BOOTS go past his knees. A CAPE of heavy FISHING NET edged with WEIGHTS hangs from his shoulders.\n\nHe holds a STOUT WOODEN OAR in both hands, edged with METAL and dripping with BLOOD.\n\nROSE\nWhere were you when they grabbed me? You were supposed to pick me up at work!\n\nMARINER\nYeah, about that, I got a little... distracted.\n\nROSE\nDistracted. You got DISTRACTED?!\n\nMARINER\nI was also... tracking the car... that grabbed you... through the AirTag... I put on your phone.\n\nRose stops. She's really not happy about this.\n\nROSE\nYou Airtagged me?!\n\n==========\nEXTRACTED SCENE DATA:\n{\n  \"scene_number\": 4,\n  \"heading\": \"INT. RUDDY & GREEN BUILDING - ELEVATOR\",\n  \"int_ext\": \"INT\",\n  \"location\": \"RUDDY & GREEN BUILDING - ELEVATOR\",\n  \"time_of_day\": null,\n  \"characters_present\": [\"ROSE\", \"MARINER\"],\n  \"summary\": \"Rose and Mariner ride the elevator after a violent rescue. Rose discovers a skull fragment on the floor while muzak plays. Mariner is introduced in full  a hulking vigilante in fishing-themed costume with an oar, net cape, and shell bandolier. Rose confronts him about being late to pick her up, and he reveals he tracked her via an AirTag on her phone, sparking a trust conflict between them.\",\n  \"narrative_beats\": [\n    {\"beat_type\": \"character_introduction\", \"description\": \"Full description of Mariner's fishing-themed vigilante costume  oar, net cape, bracers, shell bandolier, fish hooks.\", \"confidence\": 0.95},\n    {\"beat_type\": \"comic_relief\", \"description\": \"Rose discovers a skull fragment while muzak plays, establishing the dark comedy tone.\", \"confidence\": 0.90},\n    {\"beat_type\": \"revelation\", \"description\": \"Mariner admits he tracked Rose via AirTag on her phone, creating a trust conflict.\", \"confidence\": 0.88},\n    {\"beat_type\": \"conflict\", \"description\": \"Rose's anger escalates from being grabbed to learning she was being surveilled by Mariner.\", \"confidence\": 0.85}\n  ],\n  \"tone_mood\": \"dark comedy with bursts of tension\",\n  \"confidence\": 0.91\n}\n==========",
          "label": "prompts/qa-pass.txt: You are a QA reviewer validating whether an AI-extracted scene analysis is accurate and faithful to the source screenplay text.\n\nCompare the extracted scene data against the original scene text and evaluate:\n\n1. **Heading accuracy**: Is the scene heading correct (location, INT/EXT, time of day)?\n2. **Character completeness**: Are all characters who appear or speak listed?\n3. **Summary fidelity**: Does the summary accurately describe what happens? No fabrications?\n4. **Narrative beats**: Are the identified beats actually present in the scene?\n5. **Tone assessment**: Does the tone description match the actual mood of the scene?\n6. **Confidence calibration**: Is the confidence score reasonable given the quality?\n\nReturn a JSON object with:\n- passed: boolean (true if the extraction is faithful, false if it has significant errors)\n- confidence: float 0-1 (your confidence in this QA judgment)\n- issues: array of objects, each with:\n  - severity: \"error\" (factual wrong), \"warning\" (misleading), or \"note\" (minor)\n  - description: what's wrong\n  - location: which field has the issue\n- summary: 1-2 sentence overall assessment\n\nBe strict: wrong character names, fabricated events, or incorrect locations are errors.\nMinor omissions or imprecise tone descriptions are warnings.\n\nReturn ONLY valid JSON. No explanations or markdown fences.\n\n==========\nORIGINAL SCENE TEXT:\n{{scene_text}}\n\n==========\nEXTRACTED SCENE DATA:\n{{extracted_data}}\n==========",
          "config": {
            "provider": "anthropic:messages:claude-opus-4-6"
          }
        },
        "promptId": "8df20c2c4a6081352d6b06e144ddbc1e0a5244f9a3c2000d40df12fc9a94e543",
        "promptIdx": 11,
        "provider": {
          "id": "google:gemini-2.5-pro",
          "label": "Gemini 2.5 Pro"
        },
        "response": {
          "output": "```json\n{\n  \"passed\": true,\n  \"confidence\": 1.0,\n  \"issues\": [],\n  \"summary\": \"The AI extraction is highly accurate and faithful, correctly identifying all characters, events, narrative beats, and the specific dark comedy tone of the scene.\"\n}\n```",
          "tokenUsage": {
            "prompt": 1185,
            "completion": 66,
            "total": 2211,
            "numRequests": 1,
            "completionDetails": {
              "reasoning": 960,
              "acceptedPrediction": 0,
              "rejectedPrediction": 0
            }
          },
          "cost": 0.01174125,
          "raw": {
            "candidates": [
              {
                "content": {
                  "parts": [
                    {
                      "text": "```json\n{\n  \"passed\": true,\n  \"confidence\": 1.0,\n  \"issues\": [],\n  \"summary\": \"The AI extraction is highly accurate and faithful, correctly identifying all characters, events, narrative beats, and the specific dark comedy tone of the scene.\"\n}\n```"
                    }
                  ],
                  "role": "model"
                },
                "finishReason": "STOP",
                "index": 0
              }
            ],
            "usageMetadata": {
              "promptTokenCount": 1185,
              "candidatesTokenCount": 66,
              "totalTokenCount": 2211,
              "promptTokensDetails": [
                {
                  "modality": "TEXT",
                  "tokenCount": 1185
                }
              ],
              "thoughtsTokenCount": 960
            },
            "modelVersion": "gemini-2.5-pro",
            "responseId": "jg-lad_PLbCnmtkPreG7yQM"
          },
          "cached": false,
          "metadata": {}
        },
        "score": 0.995,
        "success": true,
        "testCase": {
          "vars": {
            "scene_text": "file://../input/enrich-scene-elevator.txt",
            "extracted_data": "file://../input/qa-good-scene.json",
            "golden_path": "golden/qa-pass-golden.json",
            "test_key": "good_scene"
          },
          "assert": [
            {
              "type": "python",
              "value": "file://../scorers/qa_pass_scorer.py"
            },
            {
              "type": "llm-rubric",
              "value": "This QA evaluation was given a GOOD scene extraction that accurately\nreflects the source text. The QA model should have:\n\n1. Marked it as passed (true)\n2. Found zero or very few errors\n3. Had high confidence in the assessment\n4. Written a summary confirming accuracy\n\nIf the model incorrectly flagged the good extraction as failing,\nthat's a false negative and should score poorly.\n"
            }
          ],
          "options": {
            "provider": "anthropic:messages:claude-opus-4-6"
          },
          "metadata": {}
        },
        "testIdx": 0,
        "vars": {
          "scene_text": "file://../input/enrich-scene-elevator.txt",
          "extracted_data": "file://../input/qa-good-scene.json",
          "golden_path": "golden/qa-pass-golden.json",
          "test_key": "good_scene"
        },
        "metadata": {
          "_promptfooFileMetadata": {}
        },
        "failureReason": 0
      },
      {
        "cost": 0.019674,
        "gradingResult": {
          "pass": true,
          "score": 1,
          "reason": "All assertions passed",
          "namedScores": {},
          "tokensUsed": {
            "total": 491,
            "prompt": 388,
            "completion": 103,
            "cached": 0,
            "numRequests": 0
          },
          "componentResults": [
            {
              "pass": true,
              "score": 1,
              "reason": "confidence_calibration=1.00 | issue_detection=1.00 | json_valid=1.00 | pass_correct=1.00 | severity_accuracy=1.00 | summary_quality=1.00",
              "assertion": {
                "type": "python",
                "value": "file://../scorers/qa_pass_scorer.py"
              }
            },
            {
              "assertion": {
                "type": "llm-rubric",
                "value": "This QA evaluation was given a GOOD scene extraction that accurately\nreflects the source text. The QA model should have:\n\n1. Marked it as passed (true)\n2. Found zero or very few errors\n3. Had high confidence in the assessment\n4. Written a summary confirming accuracy\n\nIf the model incorrectly flagged the good extraction as failing,\nthat's a false negative and should score poorly.\n"
              },
              "pass": true,
              "score": 1,
              "reason": "The QA evaluation correctly marked the extraction as passed (true), had high confidence (0.95), found only a minor warning (not an error), and wrote a summary confirming the accuracy of the extraction. This aligns perfectly with the rubric's requirements: passed is true, zero or very few errors (just one warning), high confidence, and a summary confirming accuracy. No false negative occurred.",
              "tokensUsed": {
                "total": 491,
                "prompt": 388,
                "completion": 103,
                "cached": 0,
                "numRequests": 0,
                "completionDetails": {
                  "reasoning": 0,
                  "acceptedPrediction": 0,
                  "rejectedPrediction": 0
                }
              },
              "metadata": {
                "renderedGradingPrompt": "[{\"role\":\"system\",\"content\":\"You are grading output according to a user-specified rubric. If the statement in the rubric is true, then the output passes the test. You respond with a JSON object with this structure: {reason: string, pass: boolean, score: number}\\n\\nExamples:\\n\\n<Output>Hello world</Output>\\n<Rubric>Content contains a greeting</Rubric>\\n{\\\"reason\\\": \\\"the content contains the word 'Hello'\\\", \\\"pass\\\": true, \\\"score\\\": 1.0}\\n\\n<Output>Avast ye swabs, repel the invaders!</Output>\\n<Rubric>Does not speak like a pirate</Rubric>\\n{\\\"reason\\\": \\\"'avast ye' is a common pirate term\\\", \\\"pass\\\": false, \\\"score\\\": 0.0}\"},{\"role\":\"user\",\"content\":\"<Output>\\n{\\\"passed\\\":true,\\\"confidence\\\":0.95,\\\"issues\\\":[{\\\"severity\\\":\\\"warning\\\",\\\"description\\\":\\\"Scene number '4' is included in the extraction but is not present in the provided source text.\\\",\\\"location\\\":\\\"scene_number\\\"}],\\\"summary\\\":\\\"The extraction is highly accurate, capturing the characters, specific visual details (costume, props), and the dark comedic tone faithfully. The summary and narrative beats align perfectly with the dialogue and action lines.\\\"}\\n</Output>\\n<Rubric>\\nThis QA evaluation was given a GOOD scene extraction that accurately\\nreflects the source text. The QA model should have:\\n\\n1. Marked it as passed (true)\\n2. Found zero or very few errors\\n3. Had high confidence in the assessment\\n4. Written a summary confirming accuracy\\n\\nIf the model incorrectly flagged the good extraction as failing,\\nthat's a false negative and should score poorly.\\n\\n</Rubric>\"}]"
              }
            }
          ]
        },
        "id": "3d798869-dc56-4df3-838b-21a8b3ed0d30",
        "latencyMs": 33856,
        "namedScores": {},
        "prompt": {
          "raw": "You are a QA reviewer validating whether an AI-extracted scene analysis is accurate and faithful to the source screenplay text.\n\nCompare the extracted scene data against the original scene text and evaluate:\n\n1. **Heading accuracy**: Is the scene heading correct (location, INT/EXT, time of day)?\n2. **Character completeness**: Are all characters who appear or speak listed?\n3. **Summary fidelity**: Does the summary accurately describe what happens? No fabrications?\n4. **Narrative beats**: Are the identified beats actually present in the scene?\n5. **Tone assessment**: Does the tone description match the actual mood of the scene?\n6. **Confidence calibration**: Is the confidence score reasonable given the quality?\n\nReturn a JSON object with:\n- passed: boolean (true if the extraction is faithful, false if it has significant errors)\n- confidence: float 0-1 (your confidence in this QA judgment)\n- issues: array of objects, each with:\n  - severity: \"error\" (factual wrong), \"warning\" (misleading), or \"note\" (minor)\n  - description: what's wrong\n  - location: which field has the issue\n- summary: 1-2 sentence overall assessment\n\nBe strict: wrong character names, fabricated events, or incorrect locations are errors.\nMinor omissions or imprecise tone descriptions are warnings.\n\nReturn ONLY valid JSON. No explanations or markdown fences.\n\n==========\nORIGINAL SCENE TEXT:\nINT. RUDDY & GREEN BUILDING - ELEVATOR\n\nUB40's \"I Can't Help Falling in Love With You\" muzak.\n\nROSE (mid-30s) leans against the elevator wall, panting. She's wearing a Tim Hortons uniform, her hair is a mess, and there's blood spattered on her face.\n\nShe looks right, pants a few more times, then squints in disgust. She gingerly picks up a bloody scrap of something with hair on it. She snorts and drops it.\n\nROSE\nIs that skull??\n\nNext to her is Mariner, also panting, covered in far more blood. His face is broad, stoic, and frowning. He has gray-blue eyes and a thick, curly, beard barely streaked with gray. He wears a red knit cap and a small mask.\n\nFULL-SCREEN SUPERIMPOSED TITLE CARD: \"THE MARINER\"\n\nHe blinks a few times as a drop of blood falls from his eyebrow. He looks toward her, then spits out some blood.\n\nMARINER\nYeaaaaah...\n\nHe's built like a pro-wrestler. Moss green SWEATER stretched over his huge frame, sleeves rolled showing heavy leather BRACERS adorned with anchors. His inner forearm has a classic heart-and-arrow TATTOO with \"Dad\" in the centre. Across his chest is a BANDOLIER of bright red 12-gauge shells, FISH HOOKS hanging from the bottom edge. Heavy rubberized BOOTS go past his knees. A CAPE of heavy FISHING NET edged with WEIGHTS hangs from his shoulders.\n\nHe holds a STOUT WOODEN OAR in both hands, edged with METAL and dripping with BLOOD.\n\nROSE\nWhere were you when they grabbed me? You were supposed to pick me up at work!\n\nMARINER\nYeah, about that, I got a little... distracted.\n\nROSE\nDistracted. You got DISTRACTED?!\n\nMARINER\nI was also... tracking the car... that grabbed you... through the AirTag... I put on your phone.\n\nRose stops. She's really not happy about this.\n\nROSE\nYou Airtagged me?!\n\n==========\nEXTRACTED SCENE DATA:\n{\n  \"scene_number\": 4,\n  \"heading\": \"INT. RUDDY & GREEN BUILDING - ELEVATOR\",\n  \"int_ext\": \"INT\",\n  \"location\": \"RUDDY & GREEN BUILDING - ELEVATOR\",\n  \"time_of_day\": null,\n  \"characters_present\": [\"ROSE\", \"MARINER\"],\n  \"summary\": \"Rose and Mariner ride the elevator after a violent rescue. Rose discovers a skull fragment on the floor while muzak plays. Mariner is introduced in full  a hulking vigilante in fishing-themed costume with an oar, net cape, and shell bandolier. Rose confronts him about being late to pick her up, and he reveals he tracked her via an AirTag on her phone, sparking a trust conflict between them.\",\n  \"narrative_beats\": [\n    {\"beat_type\": \"character_introduction\", \"description\": \"Full description of Mariner's fishing-themed vigilante costume  oar, net cape, bracers, shell bandolier, fish hooks.\", \"confidence\": 0.95},\n    {\"beat_type\": \"comic_relief\", \"description\": \"Rose discovers a skull fragment while muzak plays, establishing the dark comedy tone.\", \"confidence\": 0.90},\n    {\"beat_type\": \"revelation\", \"description\": \"Mariner admits he tracked Rose via AirTag on her phone, creating a trust conflict.\", \"confidence\": 0.88},\n    {\"beat_type\": \"conflict\", \"description\": \"Rose's anger escalates from being grabbed to learning she was being surveilled by Mariner.\", \"confidence\": 0.85}\n  ],\n  \"tone_mood\": \"dark comedy with bursts of tension\",\n  \"confidence\": 0.91\n}\n==========",
          "label": "prompts/qa-pass.txt: You are a QA reviewer validating whether an AI-extracted scene analysis is accurate and faithful to the source screenplay text.\n\nCompare the extracted scene data against the original scene text and evaluate:\n\n1. **Heading accuracy**: Is the scene heading correct (location, INT/EXT, time of day)?\n2. **Character completeness**: Are all characters who appear or speak listed?\n3. **Summary fidelity**: Does the summary accurately describe what happens? No fabrications?\n4. **Narrative beats**: Are the identified beats actually present in the scene?\n5. **Tone assessment**: Does the tone description match the actual mood of the scene?\n6. **Confidence calibration**: Is the confidence score reasonable given the quality?\n\nReturn a JSON object with:\n- passed: boolean (true if the extraction is faithful, false if it has significant errors)\n- confidence: float 0-1 (your confidence in this QA judgment)\n- issues: array of objects, each with:\n  - severity: \"error\" (factual wrong), \"warning\" (misleading), or \"note\" (minor)\n  - description: what's wrong\n  - location: which field has the issue\n- summary: 1-2 sentence overall assessment\n\nBe strict: wrong character names, fabricated events, or incorrect locations are errors.\nMinor omissions or imprecise tone descriptions are warnings.\n\nReturn ONLY valid JSON. No explanations or markdown fences.\n\n==========\nORIGINAL SCENE TEXT:\n{{scene_text}}\n\n==========\nEXTRACTED SCENE DATA:\n{{extracted_data}}\n==========",
          "config": {
            "provider": "anthropic:messages:claude-opus-4-6"
          }
        },
        "promptId": "8df20c2c4a6081352d6b06e144ddbc1e0a5244f9a3c2000d40df12fc9a94e543",
        "promptIdx": 12,
        "provider": {
          "id": "google:gemini-3-pro-preview",
          "label": "Gemini 3 Pro"
        },
        "response": {
          "output": "{\n  \"passed\": true,\n  \"confidence\": 0.95,\n  \"issues\": [\n    {\n      \"severity\": \"warning\",\n      \"description\": \"Scene number '4' is included in the extraction but is not present in the provided source text.\",\n      \"location\": \"scene_number\"\n    }\n  ],\n  \"summary\": \"The extraction is highly accurate, capturing the characters, specific visual details (costume, props), and the dark comedic tone faithfully. The summary and narrative beats align perfectly with the dialogue and action lines.\"\n}",
          "tokenUsage": {
            "prompt": 1185,
            "completion": 125,
            "total": 2627,
            "numRequests": 1,
            "completionDetails": {
              "reasoning": 1317,
              "acceptedPrediction": 0,
              "rejectedPrediction": 0
            }
          },
          "cost": 0.019674,
          "raw": {
            "candidates": [
              {
                "content": {
                  "parts": [
                    {
                      "text": "{\n  \"passed\": true,\n  \"confidence\": 0.95,\n  \"issues\": [\n    {\n      \"severity\": \"warning\",\n      \"description\": \"Scene number '4' is included in the extraction but is not present in the provided source text.\",\n      \"location\": \"scene_number\"\n    }\n  ],\n  \"summary\": \"The extraction is highly accurate, capturing the characters, specific visual details (costume, props), and the dark comedic tone faithfully. The summary and narrative beats align perfectly with the dialogue and action lines.\"\n}",
                      "thoughtSignature": "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"
                    }
                  ],
                  "role": "model"
                },
                "finishReason": "STOP",
                "index": 0
              }
            ],
            "usageMetadata": {
              "promptTokenCount": 1185,
              "candidatesTokenCount": 125,
              "totalTokenCount": 2627,
              "promptTokensDetails": [
                {
                  "modality": "TEXT",
                  "tokenCount": 1185
                }
              ],
              "thoughtsTokenCount": 1317
            },
            "modelVersion": "gemini-3-pro-preview",
            "responseId": "rQ-lacf9OeW6qtsPvazTqAg"
          },
          "cached": false,
          "metadata": {}
        },
        "score": 1,
        "success": true,
        "testCase": {
          "vars": {
            "scene_text": "file://../input/enrich-scene-elevator.txt",
            "extracted_data": "file://../input/qa-good-scene.json",
            "golden_path": "golden/qa-pass-golden.json",
            "test_key": "good_scene"
          },
          "assert": [
            {
              "type": "python",
              "value": "file://../scorers/qa_pass_scorer.py"
            },
            {
              "type": "llm-rubric",
              "value": "This QA evaluation was given a GOOD scene extraction that accurately\nreflects the source text. The QA model should have:\n\n1. Marked it as passed (true)\n2. Found zero or very few errors\n3. Had high confidence in the assessment\n4. Written a summary confirming accuracy\n\nIf the model incorrectly flagged the good extraction as failing,\nthat's a false negative and should score poorly.\n"
            }
          ],
          "options": {
            "provider": "anthropic:messages:claude-opus-4-6"
          },
          "metadata": {}
        },
        "testIdx": 0,
        "vars": {
          "scene_text": "file://../input/enrich-scene-elevator.txt",
          "extracted_data": "file://../input/qa-good-scene.json",
          "golden_path": "golden/qa-pass-golden.json",
          "test_key": "good_scene"
        },
        "metadata": {
          "_promptfooFileMetadata": {}
        },
        "failureReason": 0
      },
      {
        "cost": 0.000218,
        "gradingResult": {
          "pass": true,
          "score": 1,
          "reason": "All assertions passed",
          "namedScores": {},
          "tokensUsed": {
            "total": 786,
            "prompt": 610,
            "completion": 176,
            "cached": 0,
            "numRequests": 0
          },
          "componentResults": [
            {
              "pass": true,
              "score": 1,
              "reason": "confidence_calibration=1.00 | issue_detection=1.00 | json_valid=1.00 | pass_correct=1.00 | severity_accuracy=1.00 | summary_quality=1.00",
              "assertion": {
                "type": "python",
                "value": "file://../scorers/qa_pass_scorer.py"
              }
            },
            {
              "assertion": {
                "type": "llm-rubric",
                "value": "This QA evaluation was given a BAD scene extraction with multiple errors:\n- Wrong building name (Office Building vs Ruddy & Green)\n- Time of day fabricated (claims DAY, but scene heading has none)\n- Wrong character name (Billy instead of Mariner)\n- Fabricated content (grocery discussion never happens)\n\nThe QA model should have:\n1. Marked it as failed (false)\n2. Identified at least 2-3 specific errors\n3. Flagged the fabricated summary content\n4. Used \"error\" severity for factual mistakes\n\nIf the model let this pass, that's a dangerous false positive.\n"
              },
              "pass": true,
              "score": 1,
              "reason": "The QA evaluation correctly identified the bad scene extraction. It marked it as failed (passed: false), identified multiple specific errors (5 issues total, well above the 2-3 minimum), flagged the fabricated summary content (the grocery/plans discussion that never happens), and appropriately used 'error' severity for factual mistakes (wrong building name, wrong character name, fabricated events, inaccurate narrative beats). It also correctly identified the tone mismatch as a warning. The evaluation caught all the key issues: wrong building name (Office Building vs Ruddy & Green), wrong character (Billy instead of Mariner), fabricated content, and more. This is not a false positive - it correctly rejected the bad extraction.",
              "tokensUsed": {
                "total": 786,
                "prompt": 610,
                "completion": 176,
                "cached": 0,
                "numRequests": 0,
                "completionDetails": {
                  "reasoning": 0,
                  "acceptedPrediction": 0,
                  "rejectedPrediction": 0
                }
              },
              "metadata": {
                "renderedGradingPrompt": "[{\"role\":\"system\",\"content\":\"You are grading output according to a user-specified rubric. If the statement in the rubric is true, then the output passes the test. You respond with a JSON object with this structure: {reason: string, pass: boolean, score: number}\\n\\nExamples:\\n\\n<Output>Hello world</Output>\\n<Rubric>Content contains a greeting</Rubric>\\n{\\\"reason\\\": \\\"the content contains the word 'Hello'\\\", \\\"pass\\\": true, \\\"score\\\": 1.0}\\n\\n<Output>Avast ye swabs, repel the invaders!</Output>\\n<Rubric>Does not speak like a pirate</Rubric>\\n{\\\"reason\\\": \\\"'avast ye' is a common pirate term\\\", \\\"pass\\\": false, \\\"score\\\": 0.0}\"},{\"role\":\"user\",\"content\":\"<Output>\\n{\\\"passed\\\":false,\\\"confidence\\\":0.9,\\\"issues\\\":[{\\\"severity\\\":\\\"error\\\",\\\"description\\\":\\\"Scene heading is incorrect; original scene is in a building called 'Ruddy & Green Building' with a specific elevator scene, not 'Office Building'.\\\",\\\"location\\\":\\\"heading\\\"},{\\\"severity\\\":\\\"error\\\",\\\"description\\\":\\\"Characters listed are 'ROSE' and 'BILLY', but original scene features 'ROSE' and 'MARINER'.\\\",\\\"location\\\":\\\"characters_present\\\"},{\\\"severity\\\":\\\"error\\\",\\\"description\\\":\\\"Summary fabricates events; original scene involves Rose and Mariner in a bloodied elevator, not discussing plans or groceries.\\\",\\\"location\\\":\\\"summary\\\"},{\\\"severity\\\":\\\"error\\\",\\\"description\\\":\\\"Narrative beat is inaccurate; scene contains tension, blood, and dialogue about tracking via AirTag, not casual plans.\\\",\\\"location\\\":\\\"narrative_beats\\\"},{\\\"severity\\\":\\\"warning\\\",\\\"description\\\":\\\"Tone is more tense and gritty than 'casual'; the scene's mood is intense and violent.\\\",\\\"location\\\":\\\"tone_mood\\\"}],\\\"summary\\\":\\\"The extracted scene data significantly misrepresents the original scene, including location, characters, and events. It appears to be a different scene altogether, leading to a failed validation.\\\"}\\n</Output>\\n<Rubric>\\nThis QA evaluation was given a BAD scene extraction with multiple errors:\\n- Wrong building name (Office Building vs Ruddy & Green)\\n- Time of day fabricated (claims DAY, but scene heading has none)\\n- Wrong character name (Billy instead of Mariner)\\n- Fabricated content (grocery discussion never happens)\\n\\nThe QA model should have:\\n1. Marked it as failed (false)\\n2. Identified at least 2-3 specific errors\\n3. Flagged the fabricated summary content\\n4. Used \\\"error\\\" severity for factual mistakes\\n\\nIf the model let this pass, that's a dangerous false positive.\\n\\n</Rubric>\"}]"
              }
            }
          ]
        },
        "id": "c31c4292-561d-457c-9f99-6b8871f52f73",
        "latencyMs": 3307,
        "namedScores": {},
        "prompt": {
          "raw": "You are a QA reviewer validating whether an AI-extracted scene analysis is accurate and faithful to the source screenplay text.\n\nCompare the extracted scene data against the original scene text and evaluate:\n\n1. **Heading accuracy**: Is the scene heading correct (location, INT/EXT, time of day)?\n2. **Character completeness**: Are all characters who appear or speak listed?\n3. **Summary fidelity**: Does the summary accurately describe what happens? No fabrications?\n4. **Narrative beats**: Are the identified beats actually present in the scene?\n5. **Tone assessment**: Does the tone description match the actual mood of the scene?\n6. **Confidence calibration**: Is the confidence score reasonable given the quality?\n\nReturn a JSON object with:\n- passed: boolean (true if the extraction is faithful, false if it has significant errors)\n- confidence: float 0-1 (your confidence in this QA judgment)\n- issues: array of objects, each with:\n  - severity: \"error\" (factual wrong), \"warning\" (misleading), or \"note\" (minor)\n  - description: what's wrong\n  - location: which field has the issue\n- summary: 1-2 sentence overall assessment\n\nBe strict: wrong character names, fabricated events, or incorrect locations are errors.\nMinor omissions or imprecise tone descriptions are warnings.\n\nReturn ONLY valid JSON. No explanations or markdown fences.\n\n==========\nORIGINAL SCENE TEXT:\nINT. RUDDY & GREEN BUILDING - ELEVATOR\n\nUB40's \"I Can't Help Falling in Love With You\" muzak.\n\nROSE (mid-30s) leans against the elevator wall, panting. She's wearing a Tim Hortons uniform, her hair is a mess, and there's blood spattered on her face.\n\nShe looks right, pants a few more times, then squints in disgust. She gingerly picks up a bloody scrap of something with hair on it. She snorts and drops it.\n\nROSE\nIs that skull??\n\nNext to her is Mariner, also panting, covered in far more blood. His face is broad, stoic, and frowning. He has gray-blue eyes and a thick, curly, beard barely streaked with gray. He wears a red knit cap and a small mask.\n\nFULL-SCREEN SUPERIMPOSED TITLE CARD: \"THE MARINER\"\n\nHe blinks a few times as a drop of blood falls from his eyebrow. He looks toward her, then spits out some blood.\n\nMARINER\nYeaaaaah...\n\nHe's built like a pro-wrestler. Moss green SWEATER stretched over his huge frame, sleeves rolled showing heavy leather BRACERS adorned with anchors. His inner forearm has a classic heart-and-arrow TATTOO with \"Dad\" in the centre. Across his chest is a BANDOLIER of bright red 12-gauge shells, FISH HOOKS hanging from the bottom edge. Heavy rubberized BOOTS go past his knees. A CAPE of heavy FISHING NET edged with WEIGHTS hangs from his shoulders.\n\nHe holds a STOUT WOODEN OAR in both hands, edged with METAL and dripping with BLOOD.\n\nROSE\nWhere were you when they grabbed me? You were supposed to pick me up at work!\n\nMARINER\nYeah, about that, I got a little... distracted.\n\nROSE\nDistracted. You got DISTRACTED?!\n\nMARINER\nI was also... tracking the car... that grabbed you... through the AirTag... I put on your phone.\n\nRose stops. She's really not happy about this.\n\nROSE\nYou Airtagged me?!\n\n==========\nEXTRACTED SCENE DATA:\n{\n  \"scene_number\": 4,\n  \"heading\": \"INT. OFFICE BUILDING - ELEVATOR\",\n  \"int_ext\": \"INT\",\n  \"location\": \"OFFICE BUILDING - ELEVATOR\",\n  \"time_of_day\": \"DAY\",\n  \"characters_present\": [\"ROSE\", \"BILLY\"],\n  \"summary\": \"Billy and Rose take the elevator in an office building. They discuss their plans for the evening. Rose mentions she needs to pick up groceries.\",\n  \"narrative_beats\": [\n    {\"beat_type\": \"exposition\", \"description\": \"Characters discuss daily plans.\", \"confidence\": 0.85}\n  ],\n  \"tone_mood\": \"casual\",\n  \"confidence\": 0.88\n}\n==========",
          "label": "prompts/qa-pass.txt: You are a QA reviewer validating whether an AI-extracted scene analysis is accurate and faithful to the source screenplay text.\n\nCompare the extracted scene data against the original scene text and evaluate:\n\n1. **Heading accuracy**: Is the scene heading correct (location, INT/EXT, time of day)?\n2. **Character completeness**: Are all characters who appear or speak listed?\n3. **Summary fidelity**: Does the summary accurately describe what happens? No fabrications?\n4. **Narrative beats**: Are the identified beats actually present in the scene?\n5. **Tone assessment**: Does the tone description match the actual mood of the scene?\n6. **Confidence calibration**: Is the confidence score reasonable given the quality?\n\nReturn a JSON object with:\n- passed: boolean (true if the extraction is faithful, false if it has significant errors)\n- confidence: float 0-1 (your confidence in this QA judgment)\n- issues: array of objects, each with:\n  - severity: \"error\" (factual wrong), \"warning\" (misleading), or \"note\" (minor)\n  - description: what's wrong\n  - location: which field has the issue\n- summary: 1-2 sentence overall assessment\n\nBe strict: wrong character names, fabricated events, or incorrect locations are errors.\nMinor omissions or imprecise tone descriptions are warnings.\n\nReturn ONLY valid JSON. No explanations or markdown fences.\n\n==========\nORIGINAL SCENE TEXT:\n{{scene_text}}\n\n==========\nEXTRACTED SCENE DATA:\n{{extracted_data}}\n==========",
          "config": {
            "provider": "anthropic:messages:claude-opus-4-6"
          }
        },
        "promptId": "8df20c2c4a6081352d6b06e144ddbc1e0a5244f9a3c2000d40df12fc9a94e543",
        "promptIdx": 0,
        "provider": {
          "id": "openai:gpt-4.1-nano",
          "label": "GPT-4.1 Nano"
        },
        "response": {
          "output": "{\n  \"passed\": false,\n  \"confidence\": 0.9,\n  \"issues\": [\n    {\n      \"severity\": \"error\",\n      \"description\": \"Scene heading is incorrect; original scene is in a building called 'Ruddy & Green Building' with a specific elevator scene, not 'Office Building'.\",\n      \"location\": \"heading\"\n    },\n    {\n      \"severity\": \"error\",\n      \"description\": \"Characters listed are 'ROSE' and 'BILLY', but original scene features 'ROSE' and 'MARINER'.\",\n      \"location\": \"characters_present\"\n    },\n    {\n      \"severity\": \"error\",\n      \"description\": \"Summary fabricates events; original scene involves Rose and Mariner in a bloodied elevator, not discussing plans or groceries.\",\n      \"location\": \"summary\"\n    },\n    {\n      \"severity\": \"error\",\n      \"description\": \"Narrative beat is inaccurate; scene contains tension, blood, and dialogue about tracking via AirTag, not casual plans.\",\n      \"location\": \"narrative_beats\"\n    },\n    {\n      \"severity\": \"warning\",\n      \"description\": \"Tone is more tense and gritty than 'casual'; the scene's mood is intense and violent.\",\n      \"location\": \"tone_mood\"\n    }\n  ],\n  \"summary\": \"The extracted scene data significantly misrepresents the original scene, including location, characters, and events. It appears to be a different scene altogether, leading to a failed validation.\"\n}",
          "tokenUsage": {
            "total": 1241,
            "prompt": 928,
            "completion": 313,
            "numRequests": 1,
            "completionDetails": {
              "reasoning": 0,
              "acceptedPrediction": 0,
              "rejectedPrediction": 0
            }
          },
          "cached": false,
          "latencyMs": 3307,
          "finishReason": "stop",
          "cost": 0.000218,
          "guardrails": {
            "flagged": false
          },
          "metadata": {
            "http": {
              "status": 200,
              "statusText": "OK",
              "headers": {
                "access-control-expose-headers": "X-Request-ID",
                "alt-svc": "h3=\":443\"; ma=86400",
                "cf-cache-status": "DYNAMIC",
                "cf-ray": "9d5d98cf9ca798e3-YVR",
                "connection": "keep-alive",
                "content-encoding": "br",
                "content-type": "application/json",
                "date": "Mon, 02 Mar 2026 04:18:24 GMT",
                "openai-organization": "user-oqdrq8y0bphopngnvkyuu5wr",
                "openai-processing-ms": "3165",
                "openai-project": "proj_ZRoLLwXcJok6Xg2t6eKhI1pn",
                "openai-version": "2020-10-01",
                "server": "cloudflare",
                "set-cookie": "__cf_bm=oQuF1ep0wFCbD7xQPucpn8wTL5jyluQlxkyg5aoU9CA-1772425100.7368414-1.0.1.1-avoCZdIOPXjeTUEA5dnbDhtBWi1PdI9B23NQOzTY._exCz2nzY04nKsAlrXJAZw0qwS2c9SrD6xeLpMs.XHRHyN0Zszi.d._W2Al3mUOj9r2Png39lV9TEVJTK4gNtC9; HttpOnly; Secure; Path=/; Domain=api.openai.com; Expires=Mon, 02 Mar 2026 04:48:24 GMT",
                "strict-transport-security": "max-age=31536000; includeSubDomains; preload",
                "transfer-encoding": "chunked",
                "x-content-type-options": "nosniff",
                "x-openai-proxy-wasm": "v0.1",
                "x-ratelimit-limit-requests": "10000",
                "x-ratelimit-limit-tokens": "10000000",
                "x-ratelimit-remaining-requests": "9999",
                "x-ratelimit-remaining-tokens": "9999073",
                "x-ratelimit-reset-requests": "6ms",
                "x-ratelimit-reset-tokens": "5ms",
                "x-request-id": "req_76735c69d5b9431dbef6a2f76a32e105"
              }
            }
          }
        },
        "score": 1,
        "success": true,
        "testCase": {
          "vars": {
            "scene_text": "file://../input/enrich-scene-elevator.txt",
            "extracted_data": "file://../input/qa-bad-scene.json",
            "golden_path": "golden/qa-pass-golden.json",
            "test_key": "bad_scene"
          },
          "assert": [
            {
              "type": "python",
              "value": "file://../scorers/qa_pass_scorer.py"
            },
            {
              "type": "llm-rubric",
              "value": "This QA evaluation was given a BAD scene extraction with multiple errors:\n- Wrong building name (Office Building vs Ruddy & Green)\n- Time of day fabricated (claims DAY, but scene heading has none)\n- Wrong character name (Billy instead of Mariner)\n- Fabricated content (grocery discussion never happens)\n\nThe QA model should have:\n1. Marked it as failed (false)\n2. Identified at least 2-3 specific errors\n3. Flagged the fabricated summary content\n4. Used \"error\" severity for factual mistakes\n\nIf the model let this pass, that's a dangerous false positive.\n"
            }
          ],
          "options": {
            "provider": "anthropic:messages:claude-opus-4-6"
          },
          "metadata": {}
        },
        "testIdx": 1,
        "vars": {
          "scene_text": "file://../input/enrich-scene-elevator.txt",
          "extracted_data": "file://../input/qa-bad-scene.json",
          "golden_path": "golden/qa-pass-golden.json",
          "test_key": "bad_scene"
        },
        "metadata": {
          "http": {
            "status": 200,
            "statusText": "OK",
            "headers": {
              "access-control-expose-headers": "X-Request-ID",
              "alt-svc": "h3=\":443\"; ma=86400",
              "cf-cache-status": "DYNAMIC",
              "cf-ray": "9d5d98cf9ca798e3-YVR",
              "connection": "keep-alive",
              "content-encoding": "br",
              "content-type": "application/json",
              "date": "Mon, 02 Mar 2026 04:18:24 GMT",
              "openai-organization": "user-oqdrq8y0bphopngnvkyuu5wr",
              "openai-processing-ms": "3165",
              "openai-project": "proj_ZRoLLwXcJok6Xg2t6eKhI1pn",
              "openai-version": "2020-10-01",
              "server": "cloudflare",
              "set-cookie": "__cf_bm=oQuF1ep0wFCbD7xQPucpn8wTL5jyluQlxkyg5aoU9CA-1772425100.7368414-1.0.1.1-avoCZdIOPXjeTUEA5dnbDhtBWi1PdI9B23NQOzTY._exCz2nzY04nKsAlrXJAZw0qwS2c9SrD6xeLpMs.XHRHyN0Zszi.d._W2Al3mUOj9r2Png39lV9TEVJTK4gNtC9; HttpOnly; Secure; Path=/; Domain=api.openai.com; Expires=Mon, 02 Mar 2026 04:48:24 GMT",
              "strict-transport-security": "max-age=31536000; includeSubDomains; preload",
              "transfer-encoding": "chunked",
              "x-content-type-options": "nosniff",
              "x-openai-proxy-wasm": "v0.1",
              "x-ratelimit-limit-requests": "10000",
              "x-ratelimit-limit-tokens": "10000000",
              "x-ratelimit-remaining-requests": "9999",
              "x-ratelimit-remaining-tokens": "9999073",
              "x-ratelimit-reset-requests": "6ms",
              "x-ratelimit-reset-tokens": "5ms",
              "x-request-id": "req_76735c69d5b9431dbef6a2f76a32e105"
            }
          },
          "_promptfooFileMetadata": {}
        },
        "failureReason": 0
      },
      {
        "cost": 0.0008768000000000001,
        "gradingResult": {
          "pass": true,
          "score": 1,
          "reason": "All assertions passed",
          "namedScores": {},
          "tokensUsed": {
            "total": 750,
            "prompt": 614,
            "completion": 136,
            "cached": 0,
            "numRequests": 0
          },
          "componentResults": [
            {
              "pass": true,
              "score": 1,
              "reason": "confidence_calibration=1.00 | issue_detection=1.00 | json_valid=1.00 | pass_correct=1.00 | severity_accuracy=1.00 | summary_quality=1.00",
              "assertion": {
                "type": "python",
                "value": "file://../scorers/qa_pass_scorer.py"
              }
            },
            {
              "assertion": {
                "type": "llm-rubric",
                "value": "This QA evaluation was given a BAD scene extraction with multiple errors:\n- Wrong building name (Office Building vs Ruddy & Green)\n- Time of day fabricated (claims DAY, but scene heading has none)\n- Wrong character name (Billy instead of Mariner)\n- Fabricated content (grocery discussion never happens)\n\nThe QA model should have:\n1. Marked it as failed (false)\n2. Identified at least 2-3 specific errors\n3. Flagged the fabricated summary content\n4. Used \"error\" severity for factual mistakes\n\nIf the model let this pass, that's a dangerous false positive.\n"
              },
              "pass": true,
              "score": 1,
              "reason": "The QA evaluation correctly identified the scene extraction as failed (passed: false). It identified multiple specific errors: wrong building name (Office Building vs Ruddy & Green), wrong character name (Billy instead of Mariner), fabricated summary content (grocery discussion), fabricated narrative beats, and incorrect tone. All factual mistakes were appropriately flagged with 'error' severity. The evaluation caught well more than 2-3 specific errors and explicitly flagged the fabricated summary content. This is not a false positive  it correctly rejected the bad extraction.",
              "tokensUsed": {
                "total": 750,
                "prompt": 614,
                "completion": 136,
                "cached": 0,
                "numRequests": 0,
                "completionDetails": {
                  "reasoning": 0,
                  "acceptedPrediction": 0,
                  "rejectedPrediction": 0
                }
              },
              "metadata": {
                "renderedGradingPrompt": "[{\"role\":\"system\",\"content\":\"You are grading output according to a user-specified rubric. If the statement in the rubric is true, then the output passes the test. You respond with a JSON object with this structure: {reason: string, pass: boolean, score: number}\\n\\nExamples:\\n\\n<Output>Hello world</Output>\\n<Rubric>Content contains a greeting</Rubric>\\n{\\\"reason\\\": \\\"the content contains the word 'Hello'\\\", \\\"pass\\\": true, \\\"score\\\": 1.0}\\n\\n<Output>Avast ye swabs, repel the invaders!</Output>\\n<Rubric>Does not speak like a pirate</Rubric>\\n{\\\"reason\\\": \\\"'avast ye' is a common pirate term\\\", \\\"pass\\\": false, \\\"score\\\": 0.0}\"},{\"role\":\"user\",\"content\":\"<Output>\\n{\\\"passed\\\":false,\\\"confidence\\\":0.9,\\\"issues\\\":[{\\\"severity\\\":\\\"error\\\",\\\"description\\\":\\\"Scene heading is incorrect; original is 'INT. RUDDY & GREEN BUILDING - ELEVATOR', not 'INT. OFFICE BUILDING - ELEVATOR'.\\\",\\\"location\\\":\\\"heading\\\"},{\\\"severity\\\":\\\"error\\\",\\\"description\\\":\\\"Characters listed are 'ROSE' and 'BILLY', but original scene has 'ROSE' and 'MARINER'. 'BILLY' is fabricated.\\\",\\\"location\\\":\\\"characters_present\\\"},{\\\"severity\\\":\\\"error\\\",\\\"description\\\":\\\"Summary is fabricated and does not reflect the original scene content; no discussion of plans or groceries occurs.\\\",\\\"location\\\":\\\"summary\\\"},{\\\"severity\\\":\\\"error\\\",\\\"description\\\":\\\"Narrative beats do not match the scene; no exposition about daily plans is present.\\\",\\\"location\\\":\\\"narrative_beats\\\"},{\\\"severity\\\":\\\"warning\\\",\\\"description\\\":\\\"Tone described as 'casual' but original scene is tense, grim, and suspenseful.\\\",\\\"location\\\":\\\"tone_mood\\\"}],\\\"summary\\\":\\\"The extracted data contains multiple significant factual errors including incorrect scene heading, wrong character names, fabricated summary and narrative beats, and an inaccurate tone description, making it unfaithful to the original scene.\\\"}\\n</Output>\\n<Rubric>\\nThis QA evaluation was given a BAD scene extraction with multiple errors:\\n- Wrong building name (Office Building vs Ruddy & Green)\\n- Time of day fabricated (claims DAY, but scene heading has none)\\n- Wrong character name (Billy instead of Mariner)\\n- Fabricated content (grocery discussion never happens)\\n\\nThe QA model should have:\\n1. Marked it as failed (false)\\n2. Identified at least 2-3 specific errors\\n3. Flagged the fabricated summary content\\n4. Used \\\"error\\\" severity for factual mistakes\\n\\nIf the model let this pass, that's a dangerous false positive.\\n\\n</Rubric>\"}]"
              }
            }
          ]
        },
        "id": "f52f320d-f4e8-4446-bd31-79b77d2e857a",
        "latencyMs": 5183,
        "namedScores": {},
        "prompt": {
          "raw": "You are a QA reviewer validating whether an AI-extracted scene analysis is accurate and faithful to the source screenplay text.\n\nCompare the extracted scene data against the original scene text and evaluate:\n\n1. **Heading accuracy**: Is the scene heading correct (location, INT/EXT, time of day)?\n2. **Character completeness**: Are all characters who appear or speak listed?\n3. **Summary fidelity**: Does the summary accurately describe what happens? No fabrications?\n4. **Narrative beats**: Are the identified beats actually present in the scene?\n5. **Tone assessment**: Does the tone description match the actual mood of the scene?\n6. **Confidence calibration**: Is the confidence score reasonable given the quality?\n\nReturn a JSON object with:\n- passed: boolean (true if the extraction is faithful, false if it has significant errors)\n- confidence: float 0-1 (your confidence in this QA judgment)\n- issues: array of objects, each with:\n  - severity: \"error\" (factual wrong), \"warning\" (misleading), or \"note\" (minor)\n  - description: what's wrong\n  - location: which field has the issue\n- summary: 1-2 sentence overall assessment\n\nBe strict: wrong character names, fabricated events, or incorrect locations are errors.\nMinor omissions or imprecise tone descriptions are warnings.\n\nReturn ONLY valid JSON. No explanations or markdown fences.\n\n==========\nORIGINAL SCENE TEXT:\nINT. RUDDY & GREEN BUILDING - ELEVATOR\n\nUB40's \"I Can't Help Falling in Love With You\" muzak.\n\nROSE (mid-30s) leans against the elevator wall, panting. She's wearing a Tim Hortons uniform, her hair is a mess, and there's blood spattered on her face.\n\nShe looks right, pants a few more times, then squints in disgust. She gingerly picks up a bloody scrap of something with hair on it. She snorts and drops it.\n\nROSE\nIs that skull??\n\nNext to her is Mariner, also panting, covered in far more blood. His face is broad, stoic, and frowning. He has gray-blue eyes and a thick, curly, beard barely streaked with gray. He wears a red knit cap and a small mask.\n\nFULL-SCREEN SUPERIMPOSED TITLE CARD: \"THE MARINER\"\n\nHe blinks a few times as a drop of blood falls from his eyebrow. He looks toward her, then spits out some blood.\n\nMARINER\nYeaaaaah...\n\nHe's built like a pro-wrestler. Moss green SWEATER stretched over his huge frame, sleeves rolled showing heavy leather BRACERS adorned with anchors. His inner forearm has a classic heart-and-arrow TATTOO with \"Dad\" in the centre. Across his chest is a BANDOLIER of bright red 12-gauge shells, FISH HOOKS hanging from the bottom edge. Heavy rubberized BOOTS go past his knees. A CAPE of heavy FISHING NET edged with WEIGHTS hangs from his shoulders.\n\nHe holds a STOUT WOODEN OAR in both hands, edged with METAL and dripping with BLOOD.\n\nROSE\nWhere were you when they grabbed me? You were supposed to pick me up at work!\n\nMARINER\nYeah, about that, I got a little... distracted.\n\nROSE\nDistracted. You got DISTRACTED?!\n\nMARINER\nI was also... tracking the car... that grabbed you... through the AirTag... I put on your phone.\n\nRose stops. She's really not happy about this.\n\nROSE\nYou Airtagged me?!\n\n==========\nEXTRACTED SCENE DATA:\n{\n  \"scene_number\": 4,\n  \"heading\": \"INT. OFFICE BUILDING - ELEVATOR\",\n  \"int_ext\": \"INT\",\n  \"location\": \"OFFICE BUILDING - ELEVATOR\",\n  \"time_of_day\": \"DAY\",\n  \"characters_present\": [\"ROSE\", \"BILLY\"],\n  \"summary\": \"Billy and Rose take the elevator in an office building. They discuss their plans for the evening. Rose mentions she needs to pick up groceries.\",\n  \"narrative_beats\": [\n    {\"beat_type\": \"exposition\", \"description\": \"Characters discuss daily plans.\", \"confidence\": 0.85}\n  ],\n  \"tone_mood\": \"casual\",\n  \"confidence\": 0.88\n}\n==========",
          "label": "prompts/qa-pass.txt: You are a QA reviewer validating whether an AI-extracted scene analysis is accurate and faithful to the source screenplay text.\n\nCompare the extracted scene data against the original scene text and evaluate:\n\n1. **Heading accuracy**: Is the scene heading correct (location, INT/EXT, time of day)?\n2. **Character completeness**: Are all characters who appear or speak listed?\n3. **Summary fidelity**: Does the summary accurately describe what happens? No fabrications?\n4. **Narrative beats**: Are the identified beats actually present in the scene?\n5. **Tone assessment**: Does the tone description match the actual mood of the scene?\n6. **Confidence calibration**: Is the confidence score reasonable given the quality?\n\nReturn a JSON object with:\n- passed: boolean (true if the extraction is faithful, false if it has significant errors)\n- confidence: float 0-1 (your confidence in this QA judgment)\n- issues: array of objects, each with:\n  - severity: \"error\" (factual wrong), \"warning\" (misleading), or \"note\" (minor)\n  - description: what's wrong\n  - location: which field has the issue\n- summary: 1-2 sentence overall assessment\n\nBe strict: wrong character names, fabricated events, or incorrect locations are errors.\nMinor omissions or imprecise tone descriptions are warnings.\n\nReturn ONLY valid JSON. No explanations or markdown fences.\n\n==========\nORIGINAL SCENE TEXT:\n{{scene_text}}\n\n==========\nEXTRACTED SCENE DATA:\n{{extracted_data}}\n==========",
          "config": {
            "provider": "anthropic:messages:claude-opus-4-6"
          }
        },
        "promptId": "8df20c2c4a6081352d6b06e144ddbc1e0a5244f9a3c2000d40df12fc9a94e543",
        "promptIdx": 1,
        "provider": {
          "id": "openai:gpt-4.1-mini",
          "label": "GPT-4.1 Mini"
        },
        "response": {
          "output": "{\n  \"passed\": false,\n  \"confidence\": 0.9,\n  \"issues\": [\n    {\n      \"severity\": \"error\",\n      \"description\": \"Scene heading is incorrect; original is 'INT. RUDDY & GREEN BUILDING - ELEVATOR', not 'INT. OFFICE BUILDING - ELEVATOR'.\",\n      \"location\": \"heading\"\n    },\n    {\n      \"severity\": \"error\",\n      \"description\": \"Characters listed are 'ROSE' and 'BILLY', but original scene has 'ROSE' and 'MARINER'. 'BILLY' is fabricated.\",\n      \"location\": \"characters_present\"\n    },\n    {\n      \"severity\": \"error\",\n      \"description\": \"Summary is fabricated and does not reflect the original scene content; no discussion of plans or groceries occurs.\",\n      \"location\": \"summary\"\n    },\n    {\n      \"severity\": \"error\",\n      \"description\": \"Narrative beats do not match the scene; no exposition about daily plans is present.\",\n      \"location\": \"narrative_beats\"\n    },\n    {\n      \"severity\": \"warning\",\n      \"description\": \"Tone described as 'casual' but original scene is tense, grim, and suspenseful.\",\n      \"location\": \"tone_mood\"\n    }\n  ],\n  \"summary\": \"The extracted data contains multiple significant factual errors including incorrect scene heading, wrong character names, fabricated summary and narrative beats, and an inaccurate tone description, making it unfaithful to the original scene.\"\n}",
          "tokenUsage": {
            "total": 1244,
            "prompt": 928,
            "completion": 316,
            "numRequests": 1,
            "completionDetails": {
              "reasoning": 0,
              "acceptedPrediction": 0,
              "rejectedPrediction": 0
            }
          },
          "cached": false,
          "latencyMs": 5183,
          "finishReason": "stop",
          "cost": 0.0008768000000000001,
          "guardrails": {
            "flagged": false
          },
          "metadata": {
            "http": {
              "status": 200,
              "statusText": "OK",
              "headers": {
                "access-control-expose-headers": "X-Request-ID",
                "alt-svc": "h3=\":443\"; ma=86400",
                "cf-cache-status": "DYNAMIC",
                "cf-ray": "9d5d98f39ae198e3-YVR",
                "connection": "keep-alive",
                "content-encoding": "br",
                "content-type": "application/json",
                "date": "Mon, 02 Mar 2026 04:18:31 GMT",
                "openai-organization": "user-oqdrq8y0bphopngnvkyuu5wr",
                "openai-processing-ms": "5028",
                "openai-project": "proj_ZRoLLwXcJok6Xg2t6eKhI1pn",
                "openai-version": "2020-10-01",
                "server": "cloudflare",
                "set-cookie": "__cf_bm=I8chC4tvDfKmy7xEp7gci_ynPESed2dmSoZyzIxrlQY-1772425106.5032783-1.0.1.1-dTiecbUvrquYWGIiUMVi4rp9GemFbZKCMk.cuDv6iKRwPnmhTm9gdQVYzkjPStN86F37kdP33y_p7Lz3K_N3fk_L69e1VeM86nwibXZFAOhX2h5aQksdsHFlJXNg78Ox; HttpOnly; Secure; Path=/; Domain=api.openai.com; Expires=Mon, 02 Mar 2026 04:48:31 GMT",
                "strict-transport-security": "max-age=31536000; includeSubDomains; preload",
                "transfer-encoding": "chunked",
                "x-content-type-options": "nosniff",
                "x-openai-proxy-wasm": "v0.1",
                "x-ratelimit-limit-requests": "10000",
                "x-ratelimit-limit-tokens": "10000000",
                "x-ratelimit-remaining-requests": "9999",
                "x-ratelimit-remaining-tokens": "9999073",
                "x-ratelimit-reset-requests": "6ms",
                "x-ratelimit-reset-tokens": "5ms",
                "x-request-id": "req_4abf7b74c6dd4ae2bff8a43e661fb44f"
              }
            }
          }
        },
        "score": 1,
        "success": true,
        "testCase": {
          "vars": {
            "scene_text": "file://../input/enrich-scene-elevator.txt",
            "extracted_data": "file://../input/qa-bad-scene.json",
            "golden_path": "golden/qa-pass-golden.json",
            "test_key": "bad_scene"
          },
          "assert": [
            {
              "type": "python",
              "value": "file://../scorers/qa_pass_scorer.py"
            },
            {
              "type": "llm-rubric",
              "value": "This QA evaluation was given a BAD scene extraction with multiple errors:\n- Wrong building name (Office Building vs Ruddy & Green)\n- Time of day fabricated (claims DAY, but scene heading has none)\n- Wrong character name (Billy instead of Mariner)\n- Fabricated content (grocery discussion never happens)\n\nThe QA model should have:\n1. Marked it as failed (false)\n2. Identified at least 2-3 specific errors\n3. Flagged the fabricated summary content\n4. Used \"error\" severity for factual mistakes\n\nIf the model let this pass, that's a dangerous false positive.\n"
            }
          ],
          "options": {
            "provider": "anthropic:messages:claude-opus-4-6"
          },
          "metadata": {}
        },
        "testIdx": 1,
        "vars": {
          "scene_text": "file://../input/enrich-scene-elevator.txt",
          "extracted_data": "file://../input/qa-bad-scene.json",
          "golden_path": "golden/qa-pass-golden.json",
          "test_key": "bad_scene"
        },
        "metadata": {
          "http": {
            "status": 200,
            "statusText": "OK",
            "headers": {
              "access-control-expose-headers": "X-Request-ID",
              "alt-svc": "h3=\":443\"; ma=86400",
              "cf-cache-status": "DYNAMIC",
              "cf-ray": "9d5d98f39ae198e3-YVR",
              "connection": "keep-alive",
              "content-encoding": "br",
              "content-type": "application/json",
              "date": "Mon, 02 Mar 2026 04:18:31 GMT",
              "openai-organization": "user-oqdrq8y0bphopngnvkyuu5wr",
              "openai-processing-ms": "5028",
              "openai-project": "proj_ZRoLLwXcJok6Xg2t6eKhI1pn",
              "openai-version": "2020-10-01",
              "server": "cloudflare",
              "set-cookie": "__cf_bm=I8chC4tvDfKmy7xEp7gci_ynPESed2dmSoZyzIxrlQY-1772425106.5032783-1.0.1.1-dTiecbUvrquYWGIiUMVi4rp9GemFbZKCMk.cuDv6iKRwPnmhTm9gdQVYzkjPStN86F37kdP33y_p7Lz3K_N3fk_L69e1VeM86nwibXZFAOhX2h5aQksdsHFlJXNg78Ox; HttpOnly; Secure; Path=/; Domain=api.openai.com; Expires=Mon, 02 Mar 2026 04:48:31 GMT",
              "strict-transport-security": "max-age=31536000; includeSubDomains; preload",
              "transfer-encoding": "chunked",
              "x-content-type-options": "nosniff",
              "x-openai-proxy-wasm": "v0.1",
              "x-ratelimit-limit-requests": "10000",
              "x-ratelimit-limit-tokens": "10000000",
              "x-ratelimit-remaining-requests": "9999",
              "x-ratelimit-remaining-tokens": "9999073",
              "x-ratelimit-reset-requests": "6ms",
              "x-ratelimit-reset-tokens": "5ms",
              "x-request-id": "req_4abf7b74c6dd4ae2bff8a43e661fb44f"
            }
          },
          "_promptfooFileMetadata": {}
        },
        "failureReason": 0
      },
      {
        "cost": 0.00024910000000000004,
        "gradingResult": {
          "pass": true,
          "score": 0.995,
          "reason": "All assertions passed",
          "namedScores": {},
          "tokensUsed": {
            "total": 954,
            "prompt": 746,
            "completion": 208,
            "cached": 0,
            "numRequests": 0
          },
          "componentResults": [
            {
              "pass": true,
              "score": 0.99,
              "reason": "confidence_calibration=1.00 | issue_detection=1.00 | json_valid=0.90 | pass_correct=1.00 | severity_accuracy=1.00 | summary_quality=1.00 | JSON extracted from code block",
              "assertion": {
                "type": "python",
                "value": "file://../scorers/qa_pass_scorer.py"
              }
            },
            {
              "assertion": {
                "type": "llm-rubric",
                "value": "This QA evaluation was given a BAD scene extraction with multiple errors:\n- Wrong building name (Office Building vs Ruddy & Green)\n- Time of day fabricated (claims DAY, but scene heading has none)\n- Wrong character name (Billy instead of Mariner)\n- Fabricated content (grocery discussion never happens)\n\nThe QA model should have:\n1. Marked it as failed (false)\n2. Identified at least 2-3 specific errors\n3. Flagged the fabricated summary content\n4. Used \"error\" severity for factual mistakes\n\nIf the model let this pass, that's a dangerous false positive.\n"
              },
              "pass": true,
              "score": 1,
              "reason": "The QA evaluation correctly identified the extraction as failed (passed: false) with high confidence (0.95). It identified 5 specific errors, well exceeding the 2-3 minimum threshold. Key findings: (1) Wrong building name flagged as error - 'OFFICE BUILDING' vs 'RUDDY & GREEN BUILDING'. (2) Wrong character name flagged - 'BILLY' instead of 'MARINER'. (3) Fabricated summary content explicitly called out - grocery discussion and daily plans never happen in the scene. (4) Incorrect tone identified - 'casual' vs the actual tense, violent aftermath. (5) Incorrect narrative beats flagged. All factual mistakes were correctly assigned 'error' severity. This is not a false positive - the model correctly rejected the bad extraction and provided detailed, accurate reasoning for each issue.",
              "tokensUsed": {
                "total": 954,
                "prompt": 746,
                "completion": 208,
                "cached": 0,
                "numRequests": 0,
                "completionDetails": {
                  "reasoning": 0,
                  "acceptedPrediction": 0,
                  "rejectedPrediction": 0
                }
              },
              "metadata": {
                "renderedGradingPrompt": "[{\"role\":\"system\",\"content\":\"You are grading output according to a user-specified rubric. If the statement in the rubric is true, then the output passes the test. You respond with a JSON object with this structure: {reason: string, pass: boolean, score: number}\\n\\nExamples:\\n\\n<Output>Hello world</Output>\\n<Rubric>Content contains a greeting</Rubric>\\n{\\\"reason\\\": \\\"the content contains the word 'Hello'\\\", \\\"pass\\\": true, \\\"score\\\": 1.0}\\n\\n<Output>Avast ye swabs, repel the invaders!</Output>\\n<Rubric>Does not speak like a pirate</Rubric>\\n{\\\"reason\\\": \\\"'avast ye' is a common pirate term\\\", \\\"pass\\\": false, \\\"score\\\": 0.0}\"},{\"role\":\"user\",\"content\":\"<Output>\\n```json\\n{\\n  \\\"passed\\\": false,\\n  \\\"confidence\\\": 0.95,\\n  \\\"issues\\\": [\\n    {\\n      \\\"severity\\\": \\\"error\\\",\\n      \\\"description\\\": \\\"The location 'OFFICE BUILDING - ELEVATOR' is incorrect. The screenplay specifies 'RUDDY & GREEN BUILDING - ELEVATOR'.\\\",\\n      \\\"location\\\": \\\"heading\\\"\\n    },\\n    {\\n      \\\"severity\\\": \\\"error\\\",\\n      \\\"description\\\": \\\"The character 'BILLY' is not present in the scene. The character 'MARINER' is present instead.\\\",\\n      \\\"location\\\": \\\"characters_present\\\"\\n    },\\n    {\\n      \\\"severity\\\": \\\"error\\\",\\n      \\\"description\\\": \\\"The summary fabricates events and dialogue. The characters are not discussing plans for the evening, nor does Rose mention picking up groceries. The scene depicts Rose and Mariner after an apparent violent encounter, discussing how Rose was captured and Mariner's distraction.\\\",\\n      \\\"location\\\": \\\"summary\\\"\\n    },\\n    {\\n      \\\"severity\\\": \\\"error\\\",\\n      \\\"description\\\": \\\"The identified narrative beat 'Characters discuss daily plans' is inaccurate. The scene's dialogue focuses on Rose's capture and Mariner's actions, not daily plans.\\\",\\n      \\\"location\\\": \\\"narrative_beats\\\"\\n    },\\n    {\\n      \\\"severity\\\": \\\"error\\\",\\n      \\\"description\\\": \\\"The tone 'casual' is incorrect. The scene is tense and reflects the aftermath of violence, with characters panting and covered in blood.\\\",\\n      \\\"location\\\": \\\"tone_mood\\\"\\n    }\\n  ],\\n  \\\"summary\\\": \\\"The extracted scene data contains significant errors in location, character presence, summary fidelity, narrative beats, and tone, failing to accurately represent the source screenplay.\\\"\\n}\\n```\\n</Output>\\n<Rubric>\\nThis QA evaluation was given a BAD scene extraction with multiple errors:\\n- Wrong building name (Office Building vs Ruddy & Green)\\n- Time of day fabricated (claims DAY, but scene heading has none)\\n- Wrong character name (Billy instead of Mariner)\\n- Fabricated content (grocery discussion never happens)\\n\\nThe QA model should have:\\n1. Marked it as failed (false)\\n2. Identified at least 2-3 specific errors\\n3. Flagged the fabricated summary content\\n4. Used \\\"error\\\" severity for factual mistakes\\n\\nIf the model let this pass, that's a dangerous false positive.\\n\\n</Rubric>\"}]"
              }
            }
          ]
        },
        "id": "2714d48f-f5e3-4cd1-8fba-c18bd5d64052",
        "latencyMs": 1503,
        "namedScores": {},
        "prompt": {
          "raw": "You are a QA reviewer validating whether an AI-extracted scene analysis is accurate and faithful to the source screenplay text.\n\nCompare the extracted scene data against the original scene text and evaluate:\n\n1. **Heading accuracy**: Is the scene heading correct (location, INT/EXT, time of day)?\n2. **Character completeness**: Are all characters who appear or speak listed?\n3. **Summary fidelity**: Does the summary accurately describe what happens? No fabrications?\n4. **Narrative beats**: Are the identified beats actually present in the scene?\n5. **Tone assessment**: Does the tone description match the actual mood of the scene?\n6. **Confidence calibration**: Is the confidence score reasonable given the quality?\n\nReturn a JSON object with:\n- passed: boolean (true if the extraction is faithful, false if it has significant errors)\n- confidence: float 0-1 (your confidence in this QA judgment)\n- issues: array of objects, each with:\n  - severity: \"error\" (factual wrong), \"warning\" (misleading), or \"note\" (minor)\n  - description: what's wrong\n  - location: which field has the issue\n- summary: 1-2 sentence overall assessment\n\nBe strict: wrong character names, fabricated events, or incorrect locations are errors.\nMinor omissions or imprecise tone descriptions are warnings.\n\nReturn ONLY valid JSON. No explanations or markdown fences.\n\n==========\nORIGINAL SCENE TEXT:\nINT. RUDDY & GREEN BUILDING - ELEVATOR\n\nUB40's \"I Can't Help Falling in Love With You\" muzak.\n\nROSE (mid-30s) leans against the elevator wall, panting. She's wearing a Tim Hortons uniform, her hair is a mess, and there's blood spattered on her face.\n\nShe looks right, pants a few more times, then squints in disgust. She gingerly picks up a bloody scrap of something with hair on it. She snorts and drops it.\n\nROSE\nIs that skull??\n\nNext to her is Mariner, also panting, covered in far more blood. His face is broad, stoic, and frowning. He has gray-blue eyes and a thick, curly, beard barely streaked with gray. He wears a red knit cap and a small mask.\n\nFULL-SCREEN SUPERIMPOSED TITLE CARD: \"THE MARINER\"\n\nHe blinks a few times as a drop of blood falls from his eyebrow. He looks toward her, then spits out some blood.\n\nMARINER\nYeaaaaah...\n\nHe's built like a pro-wrestler. Moss green SWEATER stretched over his huge frame, sleeves rolled showing heavy leather BRACERS adorned with anchors. His inner forearm has a classic heart-and-arrow TATTOO with \"Dad\" in the centre. Across his chest is a BANDOLIER of bright red 12-gauge shells, FISH HOOKS hanging from the bottom edge. Heavy rubberized BOOTS go past his knees. A CAPE of heavy FISHING NET edged with WEIGHTS hangs from his shoulders.\n\nHe holds a STOUT WOODEN OAR in both hands, edged with METAL and dripping with BLOOD.\n\nROSE\nWhere were you when they grabbed me? You were supposed to pick me up at work!\n\nMARINER\nYeah, about that, I got a little... distracted.\n\nROSE\nDistracted. You got DISTRACTED?!\n\nMARINER\nI was also... tracking the car... that grabbed you... through the AirTag... I put on your phone.\n\nRose stops. She's really not happy about this.\n\nROSE\nYou Airtagged me?!\n\n==========\nEXTRACTED SCENE DATA:\n{\n  \"scene_number\": 4,\n  \"heading\": \"INT. OFFICE BUILDING - ELEVATOR\",\n  \"int_ext\": \"INT\",\n  \"location\": \"OFFICE BUILDING - ELEVATOR\",\n  \"time_of_day\": \"DAY\",\n  \"characters_present\": [\"ROSE\", \"BILLY\"],\n  \"summary\": \"Billy and Rose take the elevator in an office building. They discuss their plans for the evening. Rose mentions she needs to pick up groceries.\",\n  \"narrative_beats\": [\n    {\"beat_type\": \"exposition\", \"description\": \"Characters discuss daily plans.\", \"confidence\": 0.85}\n  ],\n  \"tone_mood\": \"casual\",\n  \"confidence\": 0.88\n}\n==========",
          "label": "prompts/qa-pass.txt: You are a QA reviewer validating whether an AI-extracted scene analysis is accurate and faithful to the source screenplay text.\n\nCompare the extracted scene data against the original scene text and evaluate:\n\n1. **Heading accuracy**: Is the scene heading correct (location, INT/EXT, time of day)?\n2. **Character completeness**: Are all characters who appear or speak listed?\n3. **Summary fidelity**: Does the summary accurately describe what happens? No fabrications?\n4. **Narrative beats**: Are the identified beats actually present in the scene?\n5. **Tone assessment**: Does the tone description match the actual mood of the scene?\n6. **Confidence calibration**: Is the confidence score reasonable given the quality?\n\nReturn a JSON object with:\n- passed: boolean (true if the extraction is faithful, false if it has significant errors)\n- confidence: float 0-1 (your confidence in this QA judgment)\n- issues: array of objects, each with:\n  - severity: \"error\" (factual wrong), \"warning\" (misleading), or \"note\" (minor)\n  - description: what's wrong\n  - location: which field has the issue\n- summary: 1-2 sentence overall assessment\n\nBe strict: wrong character names, fabricated events, or incorrect locations are errors.\nMinor omissions or imprecise tone descriptions are warnings.\n\nReturn ONLY valid JSON. No explanations or markdown fences.\n\n==========\nORIGINAL SCENE TEXT:\n{{scene_text}}\n\n==========\nEXTRACTED SCENE DATA:\n{{extracted_data}}\n==========",
          "config": {
            "provider": "anthropic:messages:claude-opus-4-6"
          }
        },
        "promptId": "8df20c2c4a6081352d6b06e144ddbc1e0a5244f9a3c2000d40df12fc9a94e543",
        "promptIdx": 2,
        "provider": {
          "id": "google:gemini-2.5-flash-lite",
          "label": "Gemini 2.5 Flash Lite"
        },
        "response": {
          "output": "```json\n{\n  \"passed\": false,\n  \"confidence\": 0.95,\n  \"issues\": [\n    {\n      \"severity\": \"error\",\n      \"description\": \"The location 'OFFICE BUILDING - ELEVATOR' is incorrect. The screenplay specifies 'RUDDY & GREEN BUILDING - ELEVATOR'.\",\n      \"location\": \"heading\"\n    },\n    {\n      \"severity\": \"error\",\n      \"description\": \"The character 'BILLY' is not present in the scene. The character 'MARINER' is present instead.\",\n      \"location\": \"characters_present\"\n    },\n    {\n      \"severity\": \"error\",\n      \"description\": \"The summary fabricates events and dialogue. The characters are not discussing plans for the evening, nor does Rose mention picking up groceries. The scene depicts Rose and Mariner after an apparent violent encounter, discussing how Rose was captured and Mariner's distraction.\",\n      \"location\": \"summary\"\n    },\n    {\n      \"severity\": \"error\",\n      \"description\": \"The identified narrative beat 'Characters discuss daily plans' is inaccurate. The scene's dialogue focuses on Rose's capture and Mariner's actions, not daily plans.\",\n      \"location\": \"narrative_beats\"\n    },\n    {\n      \"severity\": \"error\",\n      \"description\": \"The tone 'casual' is incorrect. The scene is tense and reflects the aftermath of violence, with characters panting and covered in blood.\",\n      \"location\": \"tone_mood\"\n    }\n  ],\n  \"summary\": \"The extracted scene data contains significant errors in location, character presence, summary fidelity, narrative beats, and tone, failing to accurately represent the source screenplay.\"\n}\n```",
          "tokenUsage": {
            "prompt": 963,
            "completion": 382,
            "total": 1345,
            "numRequests": 1
          },
          "cost": 0.00024910000000000004,
          "raw": {
            "candidates": [
              {
                "content": {
                  "parts": [
                    {
                      "text": "```json\n{\n  \"passed\": false,\n  \"confidence\": 0.95,\n  \"issues\": [\n    {\n      \"severity\": \"error\",\n      \"description\": \"The location 'OFFICE BUILDING - ELEVATOR' is incorrect. The screenplay specifies 'RUDDY & GREEN BUILDING - ELEVATOR'.\",\n      \"location\": \"heading\"\n    },\n    {\n      \"severity\": \"error\",\n      \"description\": \"The character 'BILLY' is not present in the scene. The character 'MARINER' is present instead.\",\n      \"location\": \"characters_present\"\n    },\n    {\n      \"severity\": \"error\",\n      \"description\": \"The summary fabricates events and dialogue. The characters are not discussing plans for the evening, nor does Rose mention picking up groceries. The scene depicts Rose and Mariner after an apparent violent encounter, discussing how Rose was captured and Mariner's distraction.\",\n      \"location\": \"summary\"\n    },\n    {\n      \"severity\": \"error\",\n      \"description\": \"The identified narrative beat 'Characters discuss daily plans' is inaccurate. The scene's dialogue focuses on Rose's capture and Mariner's actions, not daily plans.\",\n      \"location\": \"narrative_beats\"\n    },\n    {\n      \"severity\": \"error\",\n      \"description\": \"The tone 'casual' is incorrect. The scene is tense and reflects the aftermath of violence, with characters panting and covered in blood.\",\n      \"location\": \"tone_mood\"\n    }\n  ],\n  \"summary\": \"The extracted scene data contains significant errors in location, character presence, summary fidelity, narrative beats, and tone, failing to accurately represent the source screenplay.\"\n}\n```"
                    }
                  ],
                  "role": "model"
                },
                "finishReason": "STOP",
                "index": 0
              }
            ],
            "usageMetadata": {
              "promptTokenCount": 963,
              "candidatesTokenCount": 382,
              "totalTokenCount": 1345,
              "promptTokensDetails": [
                {
                  "modality": "TEXT",
                  "tokenCount": 963
                }
              ]
            },
            "modelVersion": "gemini-2.5-flash-lite",
            "responseId": "lw-ladMjtZSa2Q-80aboAw"
          },
          "cached": false,
          "metadata": {}
        },
        "score": 0.995,
        "success": true,
        "testCase": {
          "vars": {
            "scene_text": "file://../input/enrich-scene-elevator.txt",
            "extracted_data": "file://../input/qa-bad-scene.json",
            "golden_path": "golden/qa-pass-golden.json",
            "test_key": "bad_scene"
          },
          "assert": [
            {
              "type": "python",
              "value": "file://../scorers/qa_pass_scorer.py"
            },
            {
              "type": "llm-rubric",
              "value": "This QA evaluation was given a BAD scene extraction with multiple errors:\n- Wrong building name (Office Building vs Ruddy & Green)\n- Time of day fabricated (claims DAY, but scene heading has none)\n- Wrong character name (Billy instead of Mariner)\n- Fabricated content (grocery discussion never happens)\n\nThe QA model should have:\n1. Marked it as failed (false)\n2. Identified at least 2-3 specific errors\n3. Flagged the fabricated summary content\n4. Used \"error\" severity for factual mistakes\n\nIf the model let this pass, that's a dangerous false positive.\n"
            }
          ],
          "options": {
            "provider": "anthropic:messages:claude-opus-4-6"
          },
          "metadata": {}
        },
        "testIdx": 1,
        "vars": {
          "scene_text": "file://../input/enrich-scene-elevator.txt",
          "extracted_data": "file://../input/qa-bad-scene.json",
          "golden_path": "golden/qa-pass-golden.json",
          "test_key": "bad_scene"
        },
        "metadata": {
          "_promptfooFileMetadata": {}
        },
        "failureReason": 0
      },
      {
        "cost": 0.004776,
        "gradingResult": {
          "pass": true,
          "score": 0.975,
          "reason": "All assertions passed",
          "namedScores": {},
          "tokensUsed": {
            "total": 802,
            "prompt": 650,
            "completion": 152,
            "cached": 0,
            "numRequests": 0
          },
          "componentResults": [
            {
              "pass": true,
              "score": 0.95,
              "reason": "confidence_calibration=0.50 | issue_detection=1.00 | json_valid=1.00 | pass_correct=1.00 | severity_accuracy=1.00 | summary_quality=1.00",
              "assertion": {
                "type": "python",
                "value": "file://../scorers/qa_pass_scorer.py"
              }
            },
            {
              "assertion": {
                "type": "llm-rubric",
                "value": "This QA evaluation was given a BAD scene extraction with multiple errors:\n- Wrong building name (Office Building vs Ruddy & Green)\n- Time of day fabricated (claims DAY, but scene heading has none)\n- Wrong character name (Billy instead of Mariner)\n- Fabricated content (grocery discussion never happens)\n\nThe QA model should have:\n1. Marked it as failed (false)\n2. Identified at least 2-3 specific errors\n3. Flagged the fabricated summary content\n4. Used \"error\" severity for factual mistakes\n\nIf the model let this pass, that's a dangerous false positive.\n"
              },
              "pass": true,
              "score": 1,
              "reason": "The QA evaluation correctly identified the bad scene extraction. It marked it as failed (passed: false), identified multiple specific errors (wrong building name, wrong characters, fabricated summary content, fabricated narrative beats), flagged the fabricated content about groceries and evening plans, and appropriately used 'error' severity for factual mistakes. It caught all the key issues: wrong building name (Office Building vs Ruddy & Green), wrong character (Billy instead of Mariner), fabricated content (grocery discussion), and noted the time of day issue. This is a thorough and accurate QA evaluation that correctly rejected the bad extraction.",
              "tokensUsed": {
                "total": 802,
                "prompt": 650,
                "completion": 152,
                "cached": 0,
                "numRequests": 0,
                "completionDetails": {
                  "reasoning": 0,
                  "acceptedPrediction": 0,
                  "rejectedPrediction": 0
                }
              },
              "metadata": {
                "renderedGradingPrompt": "[{\"role\":\"system\",\"content\":\"You are grading output according to a user-specified rubric. If the statement in the rubric is true, then the output passes the test. You respond with a JSON object with this structure: {reason: string, pass: boolean, score: number}\\n\\nExamples:\\n\\n<Output>Hello world</Output>\\n<Rubric>Content contains a greeting</Rubric>\\n{\\\"reason\\\": \\\"the content contains the word 'Hello'\\\", \\\"pass\\\": true, \\\"score\\\": 1.0}\\n\\n<Output>Avast ye swabs, repel the invaders!</Output>\\n<Rubric>Does not speak like a pirate</Rubric>\\n{\\\"reason\\\": \\\"'avast ye' is a common pirate term\\\", \\\"pass\\\": false, \\\"score\\\": 0.0}\"},{\"role\":\"user\",\"content\":\"<Output>\\n{\\\"passed\\\":false,\\\"confidence\\\":0.1,\\\"issues\\\":[{\\\"severity\\\":\\\"error\\\",\\\"description\\\":\\\"Scene heading is incorrect; the original is 'INT. RUDDY & GREEN BUILDING - ELEVATOR', not 'INT. OFFICE BUILDING - ELEVATOR'.\\\",\\\"location\\\":\\\"heading\\\"},{\\\"severity\\\":\\\"error\\\",\\\"description\\\":\\\"Character list is incorrect; 'BILLY' does not appear, and 'MARINER' is missing.\\\",\\\"location\\\":\\\"characters_present\\\"},{\\\"severity\\\":\\\"error\\\",\\\"description\\\":\\\"Summary is fabricated; there is no discussion of evening plans or groceries. The actual scene involves Rose and Mariner, both bloodied, discussing a kidnapping and an AirTag.\\\",\\\"location\\\":\\\"summary\\\"},{\\\"severity\\\":\\\"error\\\",\\\"description\\\":\\\"Narrative beat is fabricated; there is no discussion of daily plans. The real beat is confrontation about the kidnapping and tracking.\\\",\\\"location\\\":\\\"narrative_beats\\\"},{\\\"severity\\\":\\\"warning\\\",\\\"description\\\":\\\"Tone is described as 'casual', but the actual tone is tense, darkly comedic, and fraught.\\\",\\\"location\\\":\\\"tone_mood\\\"},{\\\"severity\\\":\\\"warning\\\",\\\"description\\\":\\\"Time of day is not specified in the original scene text.\\\",\\\"location\\\":\\\"time_of_day\\\"}],\\\"summary\\\":\\\"The extracted scene data is not faithful to the source text, with incorrect heading, characters, summary, and narrative beats. The extraction appears to be for a different scene entirely.\\\"}\\n</Output>\\n<Rubric>\\nThis QA evaluation was given a BAD scene extraction with multiple errors:\\n- Wrong building name (Office Building vs Ruddy & Green)\\n- Time of day fabricated (claims DAY, but scene heading has none)\\n- Wrong character name (Billy instead of Mariner)\\n- Fabricated content (grocery discussion never happens)\\n\\nThe QA model should have:\\n1. Marked it as failed (false)\\n2. Identified at least 2-3 specific errors\\n3. Flagged the fabricated summary content\\n4. Used \\\"error\\\" severity for factual mistakes\\n\\nIf the model let this pass, that's a dangerous false positive.\\n\\n</Rubric>\"}]"
              }
            }
          ]
        },
        "id": "e64b5b22-7681-4990-a2f8-c6f70a35185c",
        "latencyMs": 3611,
        "namedScores": {},
        "prompt": {
          "raw": "You are a QA reviewer validating whether an AI-extracted scene analysis is accurate and faithful to the source screenplay text.\n\nCompare the extracted scene data against the original scene text and evaluate:\n\n1. **Heading accuracy**: Is the scene heading correct (location, INT/EXT, time of day)?\n2. **Character completeness**: Are all characters who appear or speak listed?\n3. **Summary fidelity**: Does the summary accurately describe what happens? No fabrications?\n4. **Narrative beats**: Are the identified beats actually present in the scene?\n5. **Tone assessment**: Does the tone description match the actual mood of the scene?\n6. **Confidence calibration**: Is the confidence score reasonable given the quality?\n\nReturn a JSON object with:\n- passed: boolean (true if the extraction is faithful, false if it has significant errors)\n- confidence: float 0-1 (your confidence in this QA judgment)\n- issues: array of objects, each with:\n  - severity: \"error\" (factual wrong), \"warning\" (misleading), or \"note\" (minor)\n  - description: what's wrong\n  - location: which field has the issue\n- summary: 1-2 sentence overall assessment\n\nBe strict: wrong character names, fabricated events, or incorrect locations are errors.\nMinor omissions or imprecise tone descriptions are warnings.\n\nReturn ONLY valid JSON. No explanations or markdown fences.\n\n==========\nORIGINAL SCENE TEXT:\nINT. RUDDY & GREEN BUILDING - ELEVATOR\n\nUB40's \"I Can't Help Falling in Love With You\" muzak.\n\nROSE (mid-30s) leans against the elevator wall, panting. She's wearing a Tim Hortons uniform, her hair is a mess, and there's blood spattered on her face.\n\nShe looks right, pants a few more times, then squints in disgust. She gingerly picks up a bloody scrap of something with hair on it. She snorts and drops it.\n\nROSE\nIs that skull??\n\nNext to her is Mariner, also panting, covered in far more blood. His face is broad, stoic, and frowning. He has gray-blue eyes and a thick, curly, beard barely streaked with gray. He wears a red knit cap and a small mask.\n\nFULL-SCREEN SUPERIMPOSED TITLE CARD: \"THE MARINER\"\n\nHe blinks a few times as a drop of blood falls from his eyebrow. He looks toward her, then spits out some blood.\n\nMARINER\nYeaaaaah...\n\nHe's built like a pro-wrestler. Moss green SWEATER stretched over his huge frame, sleeves rolled showing heavy leather BRACERS adorned with anchors. His inner forearm has a classic heart-and-arrow TATTOO with \"Dad\" in the centre. Across his chest is a BANDOLIER of bright red 12-gauge shells, FISH HOOKS hanging from the bottom edge. Heavy rubberized BOOTS go past his knees. A CAPE of heavy FISHING NET edged with WEIGHTS hangs from his shoulders.\n\nHe holds a STOUT WOODEN OAR in both hands, edged with METAL and dripping with BLOOD.\n\nROSE\nWhere were you when they grabbed me? You were supposed to pick me up at work!\n\nMARINER\nYeah, about that, I got a little... distracted.\n\nROSE\nDistracted. You got DISTRACTED?!\n\nMARINER\nI was also... tracking the car... that grabbed you... through the AirTag... I put on your phone.\n\nRose stops. She's really not happy about this.\n\nROSE\nYou Airtagged me?!\n\n==========\nEXTRACTED SCENE DATA:\n{\n  \"scene_number\": 4,\n  \"heading\": \"INT. OFFICE BUILDING - ELEVATOR\",\n  \"int_ext\": \"INT\",\n  \"location\": \"OFFICE BUILDING - ELEVATOR\",\n  \"time_of_day\": \"DAY\",\n  \"characters_present\": [\"ROSE\", \"BILLY\"],\n  \"summary\": \"Billy and Rose take the elevator in an office building. They discuss their plans for the evening. Rose mentions she needs to pick up groceries.\",\n  \"narrative_beats\": [\n    {\"beat_type\": \"exposition\", \"description\": \"Characters discuss daily plans.\", \"confidence\": 0.85}\n  ],\n  \"tone_mood\": \"casual\",\n  \"confidence\": 0.88\n}\n==========",
          "label": "prompts/qa-pass.txt: You are a QA reviewer validating whether an AI-extracted scene analysis is accurate and faithful to the source screenplay text.\n\nCompare the extracted scene data against the original scene text and evaluate:\n\n1. **Heading accuracy**: Is the scene heading correct (location, INT/EXT, time of day)?\n2. **Character completeness**: Are all characters who appear or speak listed?\n3. **Summary fidelity**: Does the summary accurately describe what happens? No fabrications?\n4. **Narrative beats**: Are the identified beats actually present in the scene?\n5. **Tone assessment**: Does the tone description match the actual mood of the scene?\n6. **Confidence calibration**: Is the confidence score reasonable given the quality?\n\nReturn a JSON object with:\n- passed: boolean (true if the extraction is faithful, false if it has significant errors)\n- confidence: float 0-1 (your confidence in this QA judgment)\n- issues: array of objects, each with:\n  - severity: \"error\" (factual wrong), \"warning\" (misleading), or \"note\" (minor)\n  - description: what's wrong\n  - location: which field has the issue\n- summary: 1-2 sentence overall assessment\n\nBe strict: wrong character names, fabricated events, or incorrect locations are errors.\nMinor omissions or imprecise tone descriptions are warnings.\n\nReturn ONLY valid JSON. No explanations or markdown fences.\n\n==========\nORIGINAL SCENE TEXT:\n{{scene_text}}\n\n==========\nEXTRACTED SCENE DATA:\n{{extracted_data}}\n==========",
          "config": {
            "provider": "anthropic:messages:claude-opus-4-6"
          }
        },
        "promptId": "8df20c2c4a6081352d6b06e144ddbc1e0a5244f9a3c2000d40df12fc9a94e543",
        "promptIdx": 3,
        "provider": {
          "id": "openai:gpt-4.1",
          "label": "GPT-4.1"
        },
        "response": {
          "output": "{\n  \"passed\": false,\n  \"confidence\": 0.1,\n  \"issues\": [\n    {\n      \"severity\": \"error\",\n      \"description\": \"Scene heading is incorrect; the original is 'INT. RUDDY & GREEN BUILDING - ELEVATOR', not 'INT. OFFICE BUILDING - ELEVATOR'.\",\n      \"location\": \"heading\"\n    },\n    {\n      \"severity\": \"error\",\n      \"description\": \"Character list is incorrect; 'BILLY' does not appear, and 'MARINER' is missing.\",\n      \"location\": \"characters_present\"\n    },\n    {\n      \"severity\": \"error\",\n      \"description\": \"Summary is fabricated; there is no discussion of evening plans or groceries. The actual scene involves Rose and Mariner, both bloodied, discussing a kidnapping and an AirTag.\",\n      \"location\": \"summary\"\n    },\n    {\n      \"severity\": \"error\",\n      \"description\": \"Narrative beat is fabricated; there is no discussion of daily plans. The real beat is confrontation about the kidnapping and tracking.\",\n      \"location\": \"narrative_beats\"\n    },\n    {\n      \"severity\": \"warning\",\n      \"description\": \"Tone is described as 'casual', but the actual tone is tense, darkly comedic, and fraught.\",\n      \"location\": \"tone_mood\"\n    },\n    {\n      \"severity\": \"warning\",\n      \"description\": \"Time of day is not specified in the original scene text.\",\n      \"location\": \"time_of_day\"\n    }\n  ],\n  \"summary\": \"The extracted scene data is not faithful to the source text, with incorrect heading, characters, summary, and narrative beats. The extraction appears to be for a different scene entirely.\"\n}",
          "tokenUsage": {
            "total": 1293,
            "prompt": 928,
            "completion": 365,
            "numRequests": 1,
            "completionDetails": {
              "reasoning": 0,
              "acceptedPrediction": 0,
              "rejectedPrediction": 0
            }
          },
          "cached": false,
          "latencyMs": 3611,
          "finishReason": "stop",
          "cost": 0.004776,
          "guardrails": {
            "flagged": false
          },
          "metadata": {
            "http": {
              "status": 200,
              "statusText": "OK",
              "headers": {
                "access-control-expose-headers": "X-Request-ID",
                "alt-svc": "h3=\":443\"; ma=86400",
                "cf-cache-status": "DYNAMIC",
                "cf-ray": "9d5d9931cab398e3-YVR",
                "connection": "keep-alive",
                "content-encoding": "br",
                "content-type": "application/json",
                "date": "Mon, 02 Mar 2026 04:18:40 GMT",
                "openai-organization": "user-oqdrq8y0bphopngnvkyuu5wr",
                "openai-processing-ms": "3466",
                "openai-project": "proj_ZRoLLwXcJok6Xg2t6eKhI1pn",
                "openai-version": "2020-10-01",
                "server": "cloudflare",
                "set-cookie": "__cf_bm=iws62lg7VtnVtXMR0hThTwONDeFBoMwjCSRVdP6oaY4-1772425116.4427452-1.0.1.1-qXw_9GlMI2WD_DytvHEyqpaZ9wPX5Bk0A4FJW0NqNgPUcC9D9nOH_wQgEK2DOmSz3ma09IJljRektWonOcbdJyN.lquNSys26JyyHpSS1wmqaEPhNU1dt.19jjcfypDA; HttpOnly; Secure; Path=/; Domain=api.openai.com; Expires=Mon, 02 Mar 2026 04:48:40 GMT",
                "strict-transport-security": "max-age=31536000; includeSubDomains; preload",
                "transfer-encoding": "chunked",
                "x-content-type-options": "nosniff",
                "x-openai-proxy-wasm": "v0.1",
                "x-ratelimit-limit-requests": "10000",
                "x-ratelimit-limit-tokens": "2000000",
                "x-ratelimit-remaining-requests": "9999",
                "x-ratelimit-remaining-tokens": "1999073",
                "x-ratelimit-reset-requests": "6ms",
                "x-ratelimit-reset-tokens": "27ms",
                "x-request-id": "req_4bb9994b5a6548e2bc1bac55c6e6c081"
              }
            }
          }
        },
        "score": 0.975,
        "success": true,
        "testCase": {
          "vars": {
            "scene_text": "file://../input/enrich-scene-elevator.txt",
            "extracted_data": "file://../input/qa-bad-scene.json",
            "golden_path": "golden/qa-pass-golden.json",
            "test_key": "bad_scene"
          },
          "assert": [
            {
              "type": "python",
              "value": "file://../scorers/qa_pass_scorer.py"
            },
            {
              "type": "llm-rubric",
              "value": "This QA evaluation was given a BAD scene extraction with multiple errors:\n- Wrong building name (Office Building vs Ruddy & Green)\n- Time of day fabricated (claims DAY, but scene heading has none)\n- Wrong character name (Billy instead of Mariner)\n- Fabricated content (grocery discussion never happens)\n\nThe QA model should have:\n1. Marked it as failed (false)\n2. Identified at least 2-3 specific errors\n3. Flagged the fabricated summary content\n4. Used \"error\" severity for factual mistakes\n\nIf the model let this pass, that's a dangerous false positive.\n"
            }
          ],
          "options": {
            "provider": "anthropic:messages:claude-opus-4-6"
          },
          "metadata": {}
        },
        "testIdx": 1,
        "vars": {
          "scene_text": "file://../input/enrich-scene-elevator.txt",
          "extracted_data": "file://../input/qa-bad-scene.json",
          "golden_path": "golden/qa-pass-golden.json",
          "test_key": "bad_scene"
        },
        "metadata": {
          "http": {
            "status": 200,
            "statusText": "OK",
            "headers": {
              "access-control-expose-headers": "X-Request-ID",
              "alt-svc": "h3=\":443\"; ma=86400",
              "cf-cache-status": "DYNAMIC",
              "cf-ray": "9d5d9931cab398e3-YVR",
              "connection": "keep-alive",
              "content-encoding": "br",
              "content-type": "application/json",
              "date": "Mon, 02 Mar 2026 04:18:40 GMT",
              "openai-organization": "user-oqdrq8y0bphopngnvkyuu5wr",
              "openai-processing-ms": "3466",
              "openai-project": "proj_ZRoLLwXcJok6Xg2t6eKhI1pn",
              "openai-version": "2020-10-01",
              "server": "cloudflare",
              "set-cookie": "__cf_bm=iws62lg7VtnVtXMR0hThTwONDeFBoMwjCSRVdP6oaY4-1772425116.4427452-1.0.1.1-qXw_9GlMI2WD_DytvHEyqpaZ9wPX5Bk0A4FJW0NqNgPUcC9D9nOH_wQgEK2DOmSz3ma09IJljRektWonOcbdJyN.lquNSys26JyyHpSS1wmqaEPhNU1dt.19jjcfypDA; HttpOnly; Secure; Path=/; Domain=api.openai.com; Expires=Mon, 02 Mar 2026 04:48:40 GMT",
              "strict-transport-security": "max-age=31536000; includeSubDomains; preload",
              "transfer-encoding": "chunked",
              "x-content-type-options": "nosniff",
              "x-openai-proxy-wasm": "v0.1",
              "x-ratelimit-limit-requests": "10000",
              "x-ratelimit-limit-tokens": "2000000",
              "x-ratelimit-remaining-requests": "9999",
              "x-ratelimit-remaining-tokens": "1999073",
              "x-ratelimit-reset-requests": "6ms",
              "x-ratelimit-reset-tokens": "27ms",
              "x-request-id": "req_4bb9994b5a6548e2bc1bac55c6e6c081"
            }
          },
          "_promptfooFileMetadata": {}
        },
        "failureReason": 0
      },
      {
        "cost": 0.003549,
        "gradingResult": {
          "pass": true,
          "score": 0.995,
          "reason": "All assertions passed",
          "namedScores": {},
          "tokensUsed": {
            "total": 1042,
            "prompt": 851,
            "completion": 191,
            "cached": 0,
            "numRequests": 0
          },
          "componentResults": [
            {
              "pass": true,
              "score": 0.99,
              "reason": "confidence_calibration=1.00 | issue_detection=1.00 | json_valid=0.90 | pass_correct=1.00 | severity_accuracy=1.00 | summary_quality=1.00 | JSON extracted from code block",
              "assertion": {
                "type": "python",
                "value": "file://../scorers/qa_pass_scorer.py"
              }
            },
            {
              "assertion": {
                "type": "llm-rubric",
                "value": "This QA evaluation was given a BAD scene extraction with multiple errors:\n- Wrong building name (Office Building vs Ruddy & Green)\n- Time of day fabricated (claims DAY, but scene heading has none)\n- Wrong character name (Billy instead of Mariner)\n- Fabricated content (grocery discussion never happens)\n\nThe QA model should have:\n1. Marked it as failed (false)\n2. Identified at least 2-3 specific errors\n3. Flagged the fabricated summary content\n4. Used \"error\" severity for factual mistakes\n\nIf the model let this pass, that's a dangerous false positive.\n"
              },
              "pass": true,
              "score": 1,
              "reason": "The QA evaluation correctly identified all the major issues: 1) Marked as failed (passed: false) , 2) Identified far more than 2-3 specific errors (6 issues total) , 3) Flagged the fabricated summary content explicitly ('The entire summary is fabricated') , 4) Used 'error' severity for factual mistakes (5 errors, 1 warning) . It caught the wrong building name (Office Building vs Ruddy & Green), the fabricated time of day, the wrong character name (Billy vs Mariner), and the fabricated grocery discussion content. This is not a false positive  it correctly failed the bad extraction with high confidence (0.99) and detailed explanations.",
              "tokensUsed": {
                "total": 1042,
                "prompt": 851,
                "completion": 191,
                "cached": 0,
                "numRequests": 0,
                "completionDetails": {
                  "reasoning": 0,
                  "acceptedPrediction": 0,
                  "rejectedPrediction": 0
                }
              },
              "metadata": {
                "renderedGradingPrompt": "[{\"role\":\"system\",\"content\":\"You are grading output according to a user-specified rubric. If the statement in the rubric is true, then the output passes the test. You respond with a JSON object with this structure: {reason: string, pass: boolean, score: number}\\n\\nExamples:\\n\\n<Output>Hello world</Output>\\n<Rubric>Content contains a greeting</Rubric>\\n{\\\"reason\\\": \\\"the content contains the word 'Hello'\\\", \\\"pass\\\": true, \\\"score\\\": 1.0}\\n\\n<Output>Avast ye swabs, repel the invaders!</Output>\\n<Rubric>Does not speak like a pirate</Rubric>\\n{\\\"reason\\\": \\\"'avast ye' is a common pirate term\\\", \\\"pass\\\": false, \\\"score\\\": 0.0}\"},{\"role\":\"user\",\"content\":\"<Output>\\n```json\\n{\\n  \\\"passed\\\": false,\\n  \\\"confidence\\\": 0.99,\\n  \\\"issues\\\": [\\n    {\\n      \\\"severity\\\": \\\"error\\\",\\n      \\\"description\\\": \\\"Character name is wrong. The second character is 'MARINER', not 'BILLY'. This is a fundamental identification error.\\\",\\n      \\\"location\\\": \\\"characters_present\\\"\\n    },\\n    {\\n      \\\"severity\\\": \\\"error\\\",\\n      \\\"description\\\": \\\"Location name is incorrect. The scene heading should be 'RUDDY & GREEN BUILDING - ELEVATOR', not 'OFFICE BUILDING - ELEVATOR'.\\\",\\n      \\\"location\\\": \\\"heading\\\"\\n    },\\n    {\\n      \\\"severity\\\": \\\"error\\\",\\n      \\\"description\\\": \\\"The entire summary is fabricated. The scene does not involve discussing evening plans or grocery shopping. Instead, it depicts Rose and Mariner covered in blood after a violent incident, with Rose questioning where Mariner was when she was grabbed, and Mariner revealing he tracked her via AirTag.\\\",\\n      \\\"location\\\": \\\"summary\\\"\\n    },\\n    {\\n      \\\"severity\\\": \\\"error\\\",\\n      \\\"description\\\": \\\"Narrative beats are completely inaccurate. The scene contains conflict/confrontation beats about Mariner's absence and the AirTag revelation, not casual exposition about daily plans.\\\",\\n      \\\"location\\\": \\\"narrative_beats\\\"\\n    },\\n    {\\n      \\\"severity\\\": \\\"error\\\",\\n      \\\"description\\\": \\\"Tone is misidentified. The scene is tense, confrontational, and darkly comedic (with graphic violence), not 'casual'.\\\",\\n      \\\"location\\\": \\\"tone_mood\\\"\\n    },\\n    {\\n      \\\"severity\\\": \\\"warning\\\",\\n      \\\"description\\\": \\\"Time of day is unspecified in the original text but marked as 'DAY'. The scene provides no temporal context.\\\",\\n      \\\"location\\\": \\\"time_of_day\\\"\\n    }\\n  ],\\n  \\\"summary\\\": \\\"The extraction contains multiple critical errors including wrong character name (Billy instead of Mariner), incorrect location (Office Building instead of Ruddy & Green Building), and a completely fabricated summary that bears no resemblance to the actual scene content. The tone and narrative beats are also fundamentally mischaracterized.\\\"\\n}\\n```\\n</Output>\\n<Rubric>\\nThis QA evaluation was given a BAD scene extraction with multiple errors:\\n- Wrong building name (Office Building vs Ruddy & Green)\\n- Time of day fabricated (claims DAY, but scene heading has none)\\n- Wrong character name (Billy instead of Mariner)\\n- Fabricated content (grocery discussion never happens)\\n\\nThe QA model should have:\\n1. Marked it as failed (false)\\n2. Identified at least 2-3 specific errors\\n3. Flagged the fabricated summary content\\n4. Used \\\"error\\\" severity for factual mistakes\\n\\nIf the model let this pass, that's a dangerous false positive.\\n\\n</Rubric>\"}]"
              }
            }
          ]
        },
        "id": "1db51070-ddcd-4dc4-9934-b79e3c9c11c3",
        "latencyMs": 4562,
        "namedScores": {},
        "prompt": {
          "raw": "You are a QA reviewer validating whether an AI-extracted scene analysis is accurate and faithful to the source screenplay text.\n\nCompare the extracted scene data against the original scene text and evaluate:\n\n1. **Heading accuracy**: Is the scene heading correct (location, INT/EXT, time of day)?\n2. **Character completeness**: Are all characters who appear or speak listed?\n3. **Summary fidelity**: Does the summary accurately describe what happens? No fabrications?\n4. **Narrative beats**: Are the identified beats actually present in the scene?\n5. **Tone assessment**: Does the tone description match the actual mood of the scene?\n6. **Confidence calibration**: Is the confidence score reasonable given the quality?\n\nReturn a JSON object with:\n- passed: boolean (true if the extraction is faithful, false if it has significant errors)\n- confidence: float 0-1 (your confidence in this QA judgment)\n- issues: array of objects, each with:\n  - severity: \"error\" (factual wrong), \"warning\" (misleading), or \"note\" (minor)\n  - description: what's wrong\n  - location: which field has the issue\n- summary: 1-2 sentence overall assessment\n\nBe strict: wrong character names, fabricated events, or incorrect locations are errors.\nMinor omissions or imprecise tone descriptions are warnings.\n\nReturn ONLY valid JSON. No explanations or markdown fences.\n\n==========\nORIGINAL SCENE TEXT:\nINT. RUDDY & GREEN BUILDING - ELEVATOR\n\nUB40's \"I Can't Help Falling in Love With You\" muzak.\n\nROSE (mid-30s) leans against the elevator wall, panting. She's wearing a Tim Hortons uniform, her hair is a mess, and there's blood spattered on her face.\n\nShe looks right, pants a few more times, then squints in disgust. She gingerly picks up a bloody scrap of something with hair on it. She snorts and drops it.\n\nROSE\nIs that skull??\n\nNext to her is Mariner, also panting, covered in far more blood. His face is broad, stoic, and frowning. He has gray-blue eyes and a thick, curly, beard barely streaked with gray. He wears a red knit cap and a small mask.\n\nFULL-SCREEN SUPERIMPOSED TITLE CARD: \"THE MARINER\"\n\nHe blinks a few times as a drop of blood falls from his eyebrow. He looks toward her, then spits out some blood.\n\nMARINER\nYeaaaaah...\n\nHe's built like a pro-wrestler. Moss green SWEATER stretched over his huge frame, sleeves rolled showing heavy leather BRACERS adorned with anchors. His inner forearm has a classic heart-and-arrow TATTOO with \"Dad\" in the centre. Across his chest is a BANDOLIER of bright red 12-gauge shells, FISH HOOKS hanging from the bottom edge. Heavy rubberized BOOTS go past his knees. A CAPE of heavy FISHING NET edged with WEIGHTS hangs from his shoulders.\n\nHe holds a STOUT WOODEN OAR in both hands, edged with METAL and dripping with BLOOD.\n\nROSE\nWhere were you when they grabbed me? You were supposed to pick me up at work!\n\nMARINER\nYeah, about that, I got a little... distracted.\n\nROSE\nDistracted. You got DISTRACTED?!\n\nMARINER\nI was also... tracking the car... that grabbed you... through the AirTag... I put on your phone.\n\nRose stops. She's really not happy about this.\n\nROSE\nYou Airtagged me?!\n\n==========\nEXTRACTED SCENE DATA:\n{\n  \"scene_number\": 4,\n  \"heading\": \"INT. OFFICE BUILDING - ELEVATOR\",\n  \"int_ext\": \"INT\",\n  \"location\": \"OFFICE BUILDING - ELEVATOR\",\n  \"time_of_day\": \"DAY\",\n  \"characters_present\": [\"ROSE\", \"BILLY\"],\n  \"summary\": \"Billy and Rose take the elevator in an office building. They discuss their plans for the evening. Rose mentions she needs to pick up groceries.\",\n  \"narrative_beats\": [\n    {\"beat_type\": \"exposition\", \"description\": \"Characters discuss daily plans.\", \"confidence\": 0.85}\n  ],\n  \"tone_mood\": \"casual\",\n  \"confidence\": 0.88\n}\n==========",
          "label": "prompts/qa-pass.txt: You are a QA reviewer validating whether an AI-extracted scene analysis is accurate and faithful to the source screenplay text.\n\nCompare the extracted scene data against the original scene text and evaluate:\n\n1. **Heading accuracy**: Is the scene heading correct (location, INT/EXT, time of day)?\n2. **Character completeness**: Are all characters who appear or speak listed?\n3. **Summary fidelity**: Does the summary accurately describe what happens? No fabrications?\n4. **Narrative beats**: Are the identified beats actually present in the scene?\n5. **Tone assessment**: Does the tone description match the actual mood of the scene?\n6. **Confidence calibration**: Is the confidence score reasonable given the quality?\n\nReturn a JSON object with:\n- passed: boolean (true if the extraction is faithful, false if it has significant errors)\n- confidence: float 0-1 (your confidence in this QA judgment)\n- issues: array of objects, each with:\n  - severity: \"error\" (factual wrong), \"warning\" (misleading), or \"note\" (minor)\n  - description: what's wrong\n  - location: which field has the issue\n- summary: 1-2 sentence overall assessment\n\nBe strict: wrong character names, fabricated events, or incorrect locations are errors.\nMinor omissions or imprecise tone descriptions are warnings.\n\nReturn ONLY valid JSON. No explanations or markdown fences.\n\n==========\nORIGINAL SCENE TEXT:\n{{scene_text}}\n\n==========\nEXTRACTED SCENE DATA:\n{{extracted_data}}\n==========",
          "config": {
            "provider": "anthropic:messages:claude-opus-4-6"
          }
        },
        "promptId": "8df20c2c4a6081352d6b06e144ddbc1e0a5244f9a3c2000d40df12fc9a94e543",
        "promptIdx": 4,
        "provider": {
          "id": "anthropic:messages:claude-haiku-4-5-20251001",
          "label": "Claude Haiku 4.5"
        },
        "response": {
          "output": "```json\n{\n  \"passed\": false,\n  \"confidence\": 0.99,\n  \"issues\": [\n    {\n      \"severity\": \"error\",\n      \"description\": \"Character name is wrong. The second character is 'MARINER', not 'BILLY'. This is a fundamental identification error.\",\n      \"location\": \"characters_present\"\n    },\n    {\n      \"severity\": \"error\",\n      \"description\": \"Location name is incorrect. The scene heading should be 'RUDDY & GREEN BUILDING - ELEVATOR', not 'OFFICE BUILDING - ELEVATOR'.\",\n      \"location\": \"heading\"\n    },\n    {\n      \"severity\": \"error\",\n      \"description\": \"The entire summary is fabricated. The scene does not involve discussing evening plans or grocery shopping. Instead, it depicts Rose and Mariner covered in blood after a violent incident, with Rose questioning where Mariner was when she was grabbed, and Mariner revealing he tracked her via AirTag.\",\n      \"location\": \"summary\"\n    },\n    {\n      \"severity\": \"error\",\n      \"description\": \"Narrative beats are completely inaccurate. The scene contains conflict/confrontation beats about Mariner's absence and the AirTag revelation, not casual exposition about daily plans.\",\n      \"location\": \"narrative_beats\"\n    },\n    {\n      \"severity\": \"error\",\n      \"description\": \"Tone is misidentified. The scene is tense, confrontational, and darkly comedic (with graphic violence), not 'casual'.\",\n      \"location\": \"tone_mood\"\n    },\n    {\n      \"severity\": \"warning\",\n      \"description\": \"Time of day is unspecified in the original text but marked as 'DAY'. The scene provides no temporal context.\",\n      \"location\": \"time_of_day\"\n    }\n  ],\n  \"summary\": \"The extraction contains multiple critical errors including wrong character name (Billy instead of Mariner), incorrect location (Office Building instead of Ruddy & Green Building), and a completely fabricated summary that bears no resemblance to the actual scene content. The tone and narrative beats are also fundamentally mischaracterized.\"\n}\n```",
          "tokenUsage": {
            "total": 1525,
            "prompt": 1019,
            "completion": 506
          },
          "finishReason": "stop",
          "cost": 0.003549
        },
        "score": 0.995,
        "success": true,
        "testCase": {
          "vars": {
            "scene_text": "file://../input/enrich-scene-elevator.txt",
            "extracted_data": "file://../input/qa-bad-scene.json",
            "golden_path": "golden/qa-pass-golden.json",
            "test_key": "bad_scene"
          },
          "assert": [
            {
              "type": "python",
              "value": "file://../scorers/qa_pass_scorer.py"
            },
            {
              "type": "llm-rubric",
              "value": "This QA evaluation was given a BAD scene extraction with multiple errors:\n- Wrong building name (Office Building vs Ruddy & Green)\n- Time of day fabricated (claims DAY, but scene heading has none)\n- Wrong character name (Billy instead of Mariner)\n- Fabricated content (grocery discussion never happens)\n\nThe QA model should have:\n1. Marked it as failed (false)\n2. Identified at least 2-3 specific errors\n3. Flagged the fabricated summary content\n4. Used \"error\" severity for factual mistakes\n\nIf the model let this pass, that's a dangerous false positive.\n"
            }
          ],
          "options": {
            "provider": "anthropic:messages:claude-opus-4-6"
          },
          "metadata": {}
        },
        "testIdx": 1,
        "vars": {
          "scene_text": "file://../input/enrich-scene-elevator.txt",
          "extracted_data": "file://../input/qa-bad-scene.json",
          "golden_path": "golden/qa-pass-golden.json",
          "test_key": "bad_scene"
        },
        "metadata": {
          "_promptfooFileMetadata": {}
        },
        "failureReason": 0
      },
      {
        "cost": 0.010797000000000001,
        "gradingResult": {
          "pass": true,
          "score": 0.995,
          "reason": "All assertions passed",
          "namedScores": {},
          "tokensUsed": {
            "total": 1056,
            "prompt": 861,
            "completion": 195,
            "cached": 0,
            "numRequests": 0
          },
          "componentResults": [
            {
              "pass": true,
              "score": 0.99,
              "reason": "confidence_calibration=1.00 | issue_detection=1.00 | json_valid=0.90 | pass_correct=1.00 | severity_accuracy=1.00 | summary_quality=1.00 | JSON extracted from code block",
              "assertion": {
                "type": "python",
                "value": "file://../scorers/qa_pass_scorer.py"
              }
            },
            {
              "assertion": {
                "type": "llm-rubric",
                "value": "This QA evaluation was given a BAD scene extraction with multiple errors:\n- Wrong building name (Office Building vs Ruddy & Green)\n- Time of day fabricated (claims DAY, but scene heading has none)\n- Wrong character name (Billy instead of Mariner)\n- Fabricated content (grocery discussion never happens)\n\nThe QA model should have:\n1. Marked it as failed (false)\n2. Identified at least 2-3 specific errors\n3. Flagged the fabricated summary content\n4. Used \"error\" severity for factual mistakes\n\nIf the model let this pass, that's a dangerous false positive.\n"
              },
              "pass": true,
              "score": 1,
              "reason": "The QA evaluation correctly identified the extraction as failed (passed: false). It identified far more than 2-3 specific errors, listing 7 distinct issues. It flagged the fabricated summary content (mentioning groceries and evening plans that don't exist). It used 'error' severity for all factual mistakes (6 errors) and 'warning' for the confidence score issue. Specifically: (1) marked as failed , (2) identified wrong building name, wrong time of day, wrong character name, fabricated summary, fabricated narrative beats, wrong tone , (3) flagged fabricated summary content explicitly , (4) used 'error' severity for factual mistakes . This is not a false positive  the model correctly caught all the problems.",
              "tokensUsed": {
                "total": 1056,
                "prompt": 861,
                "completion": 195,
                "cached": 0,
                "numRequests": 0,
                "completionDetails": {
                  "reasoning": 0,
                  "acceptedPrediction": 0,
                  "rejectedPrediction": 0
                }
              },
              "metadata": {
                "renderedGradingPrompt": "[{\"role\":\"system\",\"content\":\"You are grading output according to a user-specified rubric. If the statement in the rubric is true, then the output passes the test. You respond with a JSON object with this structure: {reason: string, pass: boolean, score: number}\\n\\nExamples:\\n\\n<Output>Hello world</Output>\\n<Rubric>Content contains a greeting</Rubric>\\n{\\\"reason\\\": \\\"the content contains the word 'Hello'\\\", \\\"pass\\\": true, \\\"score\\\": 1.0}\\n\\n<Output>Avast ye swabs, repel the invaders!</Output>\\n<Rubric>Does not speak like a pirate</Rubric>\\n{\\\"reason\\\": \\\"'avast ye' is a common pirate term\\\", \\\"pass\\\": false, \\\"score\\\": 0.0}\"},{\"role\":\"user\",\"content\":\"<Output>\\n```json\\n{\\n  \\\"passed\\\": false,\\n  \\\"confidence\\\": 0.98,\\n  \\\"issues\\\": [\\n    {\\n      \\\"severity\\\": \\\"error\\\",\\n      \\\"description\\\": \\\"Location is incorrect. Should be 'RUDDY & GREEN BUILDING - ELEVATOR' not 'OFFICE BUILDING - ELEVATOR'\\\",\\n      \\\"location\\\": \\\"heading\\\"\\n    },\\n    {\\n      \\\"severity\\\": \\\"error\\\",\\n      \\\"description\\\": \\\"Time of day is not specified in the original scene, extraction incorrectly lists 'DAY'\\\",\\n      \\\"location\\\": \\\"time_of_day\\\"\\n    },\\n    {\\n      \\\"severity\\\": \\\"error\\\",\\n      \\\"description\\\": \\\"Character 'BILLY' does not appear in the scene. The actual characters are 'ROSE' and 'MARINER'\\\",\\n      \\\"location\\\": \\\"characters_present\\\"\\n    },\\n    {\\n      \\\"severity\\\": \\\"error\\\",\\n      \\\"description\\\": \\\"Summary is completely fabricated. The scene shows Rose and Mariner covered in blood after an apparent violent incident, discussing how Rose was grabbed and Mariner tracked her. No mention of groceries or evening plans.\\\",\\n      \\\"location\\\": \\\"summary\\\"\\n    },\\n    {\\n      \\\"severity\\\": \\\"error\\\",\\n      \\\"description\\\": \\\"Narrative beat is fabricated. The actual beats involve aftermath of violence, confrontation about being late to pick up Rose, and revelation about AirTag tracking\\\",\\n      \\\"location\\\": \\\"narrative_beats\\\"\\n    },\\n    {\\n      \\\"severity\\\": \\\"error\\\",\\n      \\\"description\\\": \\\"Tone is completely wrong. Should be tense/violent/confrontational, not 'casual'. Characters are covered in blood and arguing about a kidnapping\\\",\\n      \\\"location\\\": \\\"tone_mood\\\"\\n    },\\n    {\\n      \\\"severity\\\": \\\"warning\\\",\\n      \\\"description\\\": \\\"Confidence score of 0.88 is inappropriately high given the extraction contains no accurate information about the actual scene\\\",\\n      \\\"location\\\": \\\"confidence\\\"\\n    }\\n  ],\\n  \\\"summary\\\": \\\"The extraction is completely inaccurate and appears to describe an entirely different scene. Every major element is wrong: location name, characters, summary, narrative beats, and tone. This is a total mismatch with the source material.\\\"\\n}\\n```\\n</Output>\\n<Rubric>\\nThis QA evaluation was given a BAD scene extraction with multiple errors:\\n- Wrong building name (Office Building vs Ruddy & Green)\\n- Time of day fabricated (claims DAY, but scene heading has none)\\n- Wrong character name (Billy instead of Mariner)\\n- Fabricated content (grocery discussion never happens)\\n\\nThe QA model should have:\\n1. Marked it as failed (false)\\n2. Identified at least 2-3 specific errors\\n3. Flagged the fabricated summary content\\n4. Used \\\"error\\\" severity for factual mistakes\\n\\nIf the model let this pass, that's a dangerous false positive.\\n\\n</Rubric>\"}]"
              }
            }
          ]
        },
        "id": "9a042002-e243-4625-9249-315faf770552",
        "latencyMs": 9348,
        "namedScores": {},
        "prompt": {
          "raw": "You are a QA reviewer validating whether an AI-extracted scene analysis is accurate and faithful to the source screenplay text.\n\nCompare the extracted scene data against the original scene text and evaluate:\n\n1. **Heading accuracy**: Is the scene heading correct (location, INT/EXT, time of day)?\n2. **Character completeness**: Are all characters who appear or speak listed?\n3. **Summary fidelity**: Does the summary accurately describe what happens? No fabrications?\n4. **Narrative beats**: Are the identified beats actually present in the scene?\n5. **Tone assessment**: Does the tone description match the actual mood of the scene?\n6. **Confidence calibration**: Is the confidence score reasonable given the quality?\n\nReturn a JSON object with:\n- passed: boolean (true if the extraction is faithful, false if it has significant errors)\n- confidence: float 0-1 (your confidence in this QA judgment)\n- issues: array of objects, each with:\n  - severity: \"error\" (factual wrong), \"warning\" (misleading), or \"note\" (minor)\n  - description: what's wrong\n  - location: which field has the issue\n- summary: 1-2 sentence overall assessment\n\nBe strict: wrong character names, fabricated events, or incorrect locations are errors.\nMinor omissions or imprecise tone descriptions are warnings.\n\nReturn ONLY valid JSON. No explanations or markdown fences.\n\n==========\nORIGINAL SCENE TEXT:\nINT. RUDDY & GREEN BUILDING - ELEVATOR\n\nUB40's \"I Can't Help Falling in Love With You\" muzak.\n\nROSE (mid-30s) leans against the elevator wall, panting. She's wearing a Tim Hortons uniform, her hair is a mess, and there's blood spattered on her face.\n\nShe looks right, pants a few more times, then squints in disgust. She gingerly picks up a bloody scrap of something with hair on it. She snorts and drops it.\n\nROSE\nIs that skull??\n\nNext to her is Mariner, also panting, covered in far more blood. His face is broad, stoic, and frowning. He has gray-blue eyes and a thick, curly, beard barely streaked with gray. He wears a red knit cap and a small mask.\n\nFULL-SCREEN SUPERIMPOSED TITLE CARD: \"THE MARINER\"\n\nHe blinks a few times as a drop of blood falls from his eyebrow. He looks toward her, then spits out some blood.\n\nMARINER\nYeaaaaah...\n\nHe's built like a pro-wrestler. Moss green SWEATER stretched over his huge frame, sleeves rolled showing heavy leather BRACERS adorned with anchors. His inner forearm has a classic heart-and-arrow TATTOO with \"Dad\" in the centre. Across his chest is a BANDOLIER of bright red 12-gauge shells, FISH HOOKS hanging from the bottom edge. Heavy rubberized BOOTS go past his knees. A CAPE of heavy FISHING NET edged with WEIGHTS hangs from his shoulders.\n\nHe holds a STOUT WOODEN OAR in both hands, edged with METAL and dripping with BLOOD.\n\nROSE\nWhere were you when they grabbed me? You were supposed to pick me up at work!\n\nMARINER\nYeah, about that, I got a little... distracted.\n\nROSE\nDistracted. You got DISTRACTED?!\n\nMARINER\nI was also... tracking the car... that grabbed you... through the AirTag... I put on your phone.\n\nRose stops. She's really not happy about this.\n\nROSE\nYou Airtagged me?!\n\n==========\nEXTRACTED SCENE DATA:\n{\n  \"scene_number\": 4,\n  \"heading\": \"INT. OFFICE BUILDING - ELEVATOR\",\n  \"int_ext\": \"INT\",\n  \"location\": \"OFFICE BUILDING - ELEVATOR\",\n  \"time_of_day\": \"DAY\",\n  \"characters_present\": [\"ROSE\", \"BILLY\"],\n  \"summary\": \"Billy and Rose take the elevator in an office building. They discuss their plans for the evening. Rose mentions she needs to pick up groceries.\",\n  \"narrative_beats\": [\n    {\"beat_type\": \"exposition\", \"description\": \"Characters discuss daily plans.\", \"confidence\": 0.85}\n  ],\n  \"tone_mood\": \"casual\",\n  \"confidence\": 0.88\n}\n==========",
          "label": "prompts/qa-pass.txt: You are a QA reviewer validating whether an AI-extracted scene analysis is accurate and faithful to the source screenplay text.\n\nCompare the extracted scene data against the original scene text and evaluate:\n\n1. **Heading accuracy**: Is the scene heading correct (location, INT/EXT, time of day)?\n2. **Character completeness**: Are all characters who appear or speak listed?\n3. **Summary fidelity**: Does the summary accurately describe what happens? No fabrications?\n4. **Narrative beats**: Are the identified beats actually present in the scene?\n5. **Tone assessment**: Does the tone description match the actual mood of the scene?\n6. **Confidence calibration**: Is the confidence score reasonable given the quality?\n\nReturn a JSON object with:\n- passed: boolean (true if the extraction is faithful, false if it has significant errors)\n- confidence: float 0-1 (your confidence in this QA judgment)\n- issues: array of objects, each with:\n  - severity: \"error\" (factual wrong), \"warning\" (misleading), or \"note\" (minor)\n  - description: what's wrong\n  - location: which field has the issue\n- summary: 1-2 sentence overall assessment\n\nBe strict: wrong character names, fabricated events, or incorrect locations are errors.\nMinor omissions or imprecise tone descriptions are warnings.\n\nReturn ONLY valid JSON. No explanations or markdown fences.\n\n==========\nORIGINAL SCENE TEXT:\n{{scene_text}}\n\n==========\nEXTRACTED SCENE DATA:\n{{extracted_data}}\n==========",
          "config": {
            "provider": "anthropic:messages:claude-opus-4-6"
          }
        },
        "promptId": "8df20c2c4a6081352d6b06e144ddbc1e0a5244f9a3c2000d40df12fc9a94e543",
        "promptIdx": 5,
        "provider": {
          "id": "anthropic:messages:claude-sonnet-4-5-20250929",
          "label": "Claude Sonnet 4.5"
        },
        "response": {
          "output": "```json\n{\n  \"passed\": false,\n  \"confidence\": 0.98,\n  \"issues\": [\n    {\n      \"severity\": \"error\",\n      \"description\": \"Location is incorrect. Should be 'RUDDY & GREEN BUILDING - ELEVATOR' not 'OFFICE BUILDING - ELEVATOR'\",\n      \"location\": \"heading\"\n    },\n    {\n      \"severity\": \"error\",\n      \"description\": \"Time of day is not specified in the original scene, extraction incorrectly lists 'DAY'\",\n      \"location\": \"time_of_day\"\n    },\n    {\n      \"severity\": \"error\",\n      \"description\": \"Character 'BILLY' does not appear in the scene. The actual characters are 'ROSE' and 'MARINER'\",\n      \"location\": \"characters_present\"\n    },\n    {\n      \"severity\": \"error\",\n      \"description\": \"Summary is completely fabricated. The scene shows Rose and Mariner covered in blood after an apparent violent incident, discussing how Rose was grabbed and Mariner tracked her. No mention of groceries or evening plans.\",\n      \"location\": \"summary\"\n    },\n    {\n      \"severity\": \"error\",\n      \"description\": \"Narrative beat is fabricated. The actual beats involve aftermath of violence, confrontation about being late to pick up Rose, and revelation about AirTag tracking\",\n      \"location\": \"narrative_beats\"\n    },\n    {\n      \"severity\": \"error\",\n      \"description\": \"Tone is completely wrong. Should be tense/violent/confrontational, not 'casual'. Characters are covered in blood and arguing about a kidnapping\",\n      \"location\": \"tone_mood\"\n    },\n    {\n      \"severity\": \"warning\",\n      \"description\": \"Confidence score of 0.88 is inappropriately high given the extraction contains no accurate information about the actual scene\",\n      \"location\": \"confidence\"\n    }\n  ],\n  \"summary\": \"The extraction is completely inaccurate and appears to describe an entirely different scene. Every major element is wrong: location name, characters, summary, narrative beats, and tone. This is a total mismatch with the source material.\"\n}\n```",
          "tokenUsage": {
            "total": 1535,
            "prompt": 1019,
            "completion": 516
          },
          "finishReason": "stop",
          "cost": 0.010797000000000001
        },
        "score": 0.995,
        "success": true,
        "testCase": {
          "vars": {
            "scene_text": "file://../input/enrich-scene-elevator.txt",
            "extracted_data": "file://../input/qa-bad-scene.json",
            "golden_path": "golden/qa-pass-golden.json",
            "test_key": "bad_scene"
          },
          "assert": [
            {
              "type": "python",
              "value": "file://../scorers/qa_pass_scorer.py"
            },
            {
              "type": "llm-rubric",
              "value": "This QA evaluation was given a BAD scene extraction with multiple errors:\n- Wrong building name (Office Building vs Ruddy & Green)\n- Time of day fabricated (claims DAY, but scene heading has none)\n- Wrong character name (Billy instead of Mariner)\n- Fabricated content (grocery discussion never happens)\n\nThe QA model should have:\n1. Marked it as failed (false)\n2. Identified at least 2-3 specific errors\n3. Flagged the fabricated summary content\n4. Used \"error\" severity for factual mistakes\n\nIf the model let this pass, that's a dangerous false positive.\n"
            }
          ],
          "options": {
            "provider": "anthropic:messages:claude-opus-4-6"
          },
          "metadata": {}
        },
        "testIdx": 1,
        "vars": {
          "scene_text": "file://../input/enrich-scene-elevator.txt",
          "extracted_data": "file://../input/qa-bad-scene.json",
          "golden_path": "golden/qa-pass-golden.json",
          "test_key": "bad_scene"
        },
        "metadata": {
          "_promptfooFileMetadata": {}
        },
        "failureReason": 0
      },
      {
        "cost": 0,
        "gradingResult": {
          "pass": true,
          "score": 0.995,
          "reason": "All assertions passed",
          "namedScores": {},
          "tokensUsed": {
            "total": 1080,
            "prompt": 899,
            "completion": 181,
            "cached": 0,
            "numRequests": 0
          },
          "componentResults": [
            {
              "pass": true,
              "score": 0.99,
              "reason": "confidence_calibration=1.00 | issue_detection=1.00 | json_valid=0.90 | pass_correct=1.00 | severity_accuracy=1.00 | summary_quality=1.00 | JSON extracted from code block",
              "assertion": {
                "type": "python",
                "value": "file://../scorers/qa_pass_scorer.py"
              }
            },
            {
              "assertion": {
                "type": "llm-rubric",
                "value": "This QA evaluation was given a BAD scene extraction with multiple errors:\n- Wrong building name (Office Building vs Ruddy & Green)\n- Time of day fabricated (claims DAY, but scene heading has none)\n- Wrong character name (Billy instead of Mariner)\n- Fabricated content (grocery discussion never happens)\n\nThe QA model should have:\n1. Marked it as failed (false)\n2. Identified at least 2-3 specific errors\n3. Flagged the fabricated summary content\n4. Used \"error\" severity for factual mistakes\n\nIf the model let this pass, that's a dangerous false positive.\n"
              },
              "pass": true,
              "score": 1,
              "reason": "The QA evaluation correctly marked the extraction as failed (passed: false). It identified far more than 2-3 specific errors, listing 7 distinct issues. It flagged the wrong building name (OFFICE BUILDING vs RUDDY & GREEN BUILDING), the fabricated time of day (DAY), the wrong character name (BILLY vs MARINER), the fabricated summary content about groceries/evening plans, fabricated narrative beats, wrong tone, and miscalibrated confidence. All factual mistakes were correctly assigned 'error' severity. The summary clearly states the extraction is 'almost entirely fabricated' and a 'complete failure.' This is an excellent QA evaluation that catches all the critical errors and does not let the bad extraction pass.",
              "tokensUsed": {
                "total": 1080,
                "prompt": 899,
                "completion": 181,
                "cached": 0,
                "numRequests": 0,
                "completionDetails": {
                  "reasoning": 0,
                  "acceptedPrediction": 0,
                  "rejectedPrediction": 0
                }
              },
              "metadata": {
                "renderedGradingPrompt": "[{\"role\":\"system\",\"content\":\"You are grading output according to a user-specified rubric. If the statement in the rubric is true, then the output passes the test. You respond with a JSON object with this structure: {reason: string, pass: boolean, score: number}\\n\\nExamples:\\n\\n<Output>Hello world</Output>\\n<Rubric>Content contains a greeting</Rubric>\\n{\\\"reason\\\": \\\"the content contains the word 'Hello'\\\", \\\"pass\\\": true, \\\"score\\\": 1.0}\\n\\n<Output>Avast ye swabs, repel the invaders!</Output>\\n<Rubric>Does not speak like a pirate</Rubric>\\n{\\\"reason\\\": \\\"'avast ye' is a common pirate term\\\", \\\"pass\\\": false, \\\"score\\\": 0.0}\"},{\"role\":\"user\",\"content\":\"<Output>\\n```json\\n{\\n  \\\"passed\\\": false,\\n  \\\"confidence\\\": 0.99,\\n  \\\"issues\\\": [\\n    {\\n      \\\"severity\\\": \\\"error\\\",\\n      \\\"description\\\": \\\"Heading lists 'OFFICE BUILDING' but the correct location is 'RUDDY & GREEN BUILDING'\\\",\\n      \\\"location\\\": \\\"heading / location\\\"\\n    },\\n    {\\n      \\\"severity\\\": \\\"error\\\",\\n      \\\"description\\\": \\\"Time of day is listed as 'DAY' but no time of day is specified in the source text; this is a fabrication\\\",\\n      \\\"location\\\": \\\"time_of_day\\\"\\n    },\\n    {\\n      \\\"severity\\\": \\\"error\\\",\\n      \\\"description\\\": \\\"Character 'BILLY' does not exist in the scene; the correct character is 'MARINER' (also introduced via title card as 'THE MARINER')\\\",\\n      \\\"location\\\": \\\"characters_present\\\"\\n    },\\n    {\\n      \\\"severity\\\": \\\"error\\\",\\n      \\\"description\\\": \\\"The summary is entirely fabricated. The scene does not involve discussing evening plans or groceries. It depicts Rose and Mariner in a blood-soaked elevator after a violent encounter, arguing about Mariner's failure to pick Rose up and his use of an AirTag on her phone.\\\",\\n      \\\"location\\\": \\\"summary\\\"\\n    },\\n    {\\n      \\\"severity\\\": \\\"error\\\",\\n      \\\"description\\\": \\\"The narrative beat describing 'Characters discuss daily plans' is fabricated and bears no resemblance to the actual scene content, which involves confrontation, revelation of violence, and a dispute about surveillance\\\",\\n      \\\"location\\\": \\\"narrative_beats\\\"\\n    },\\n    {\\n      \\\"severity\\\": \\\"error\\\",\\n      \\\"description\\\": \\\"Tone is described as 'casual' but the scene is tense, darkly comedic, and confrontational, set in the aftermath of graphic violence\\\",\\n      \\\"location\\\": \\\"tone_mood\\\"\\n    },\\n    {\\n      \\\"severity\\\": \\\"error\\\",\\n      \\\"description\\\": \\\"Confidence score of 0.88 is grossly miscalibrated given that virtually every field in the extraction is incorrect or fabricated\\\",\\n      \\\"location\\\": \\\"confidence\\\"\\n    }\\n  ],\\n  \\\"summary\\\": \\\"The extracted scene data is almost entirely fabricated and bears no meaningful resemblance to the source text. The character names, location, summary, narrative beats, and tone are all wrong, making this extraction a complete failure.\\\"\\n}\\n```\\n</Output>\\n<Rubric>\\nThis QA evaluation was given a BAD scene extraction with multiple errors:\\n- Wrong building name (Office Building vs Ruddy & Green)\\n- Time of day fabricated (claims DAY, but scene heading has none)\\n- Wrong character name (Billy instead of Mariner)\\n- Fabricated content (grocery discussion never happens)\\n\\nThe QA model should have:\\n1. Marked it as failed (false)\\n2. Identified at least 2-3 specific errors\\n3. Flagged the fabricated summary content\\n4. Used \\\"error\\\" severity for factual mistakes\\n\\nIf the model let this pass, that's a dangerous false positive.\\n\\n</Rubric>\"}]"
              }
            }
          ]
        },
        "id": "d7c1685d-8f22-4953-80c5-87a5874ee555",
        "latencyMs": 9063,
        "namedScores": {},
        "prompt": {
          "raw": "You are a QA reviewer validating whether an AI-extracted scene analysis is accurate and faithful to the source screenplay text.\n\nCompare the extracted scene data against the original scene text and evaluate:\n\n1. **Heading accuracy**: Is the scene heading correct (location, INT/EXT, time of day)?\n2. **Character completeness**: Are all characters who appear or speak listed?\n3. **Summary fidelity**: Does the summary accurately describe what happens? No fabrications?\n4. **Narrative beats**: Are the identified beats actually present in the scene?\n5. **Tone assessment**: Does the tone description match the actual mood of the scene?\n6. **Confidence calibration**: Is the confidence score reasonable given the quality?\n\nReturn a JSON object with:\n- passed: boolean (true if the extraction is faithful, false if it has significant errors)\n- confidence: float 0-1 (your confidence in this QA judgment)\n- issues: array of objects, each with:\n  - severity: \"error\" (factual wrong), \"warning\" (misleading), or \"note\" (minor)\n  - description: what's wrong\n  - location: which field has the issue\n- summary: 1-2 sentence overall assessment\n\nBe strict: wrong character names, fabricated events, or incorrect locations are errors.\nMinor omissions or imprecise tone descriptions are warnings.\n\nReturn ONLY valid JSON. No explanations or markdown fences.\n\n==========\nORIGINAL SCENE TEXT:\nINT. RUDDY & GREEN BUILDING - ELEVATOR\n\nUB40's \"I Can't Help Falling in Love With You\" muzak.\n\nROSE (mid-30s) leans against the elevator wall, panting. She's wearing a Tim Hortons uniform, her hair is a mess, and there's blood spattered on her face.\n\nShe looks right, pants a few more times, then squints in disgust. She gingerly picks up a bloody scrap of something with hair on it. She snorts and drops it.\n\nROSE\nIs that skull??\n\nNext to her is Mariner, also panting, covered in far more blood. His face is broad, stoic, and frowning. He has gray-blue eyes and a thick, curly, beard barely streaked with gray. He wears a red knit cap and a small mask.\n\nFULL-SCREEN SUPERIMPOSED TITLE CARD: \"THE MARINER\"\n\nHe blinks a few times as a drop of blood falls from his eyebrow. He looks toward her, then spits out some blood.\n\nMARINER\nYeaaaaah...\n\nHe's built like a pro-wrestler. Moss green SWEATER stretched over his huge frame, sleeves rolled showing heavy leather BRACERS adorned with anchors. His inner forearm has a classic heart-and-arrow TATTOO with \"Dad\" in the centre. Across his chest is a BANDOLIER of bright red 12-gauge shells, FISH HOOKS hanging from the bottom edge. Heavy rubberized BOOTS go past his knees. A CAPE of heavy FISHING NET edged with WEIGHTS hangs from his shoulders.\n\nHe holds a STOUT WOODEN OAR in both hands, edged with METAL and dripping with BLOOD.\n\nROSE\nWhere were you when they grabbed me? You were supposed to pick me up at work!\n\nMARINER\nYeah, about that, I got a little... distracted.\n\nROSE\nDistracted. You got DISTRACTED?!\n\nMARINER\nI was also... tracking the car... that grabbed you... through the AirTag... I put on your phone.\n\nRose stops. She's really not happy about this.\n\nROSE\nYou Airtagged me?!\n\n==========\nEXTRACTED SCENE DATA:\n{\n  \"scene_number\": 4,\n  \"heading\": \"INT. OFFICE BUILDING - ELEVATOR\",\n  \"int_ext\": \"INT\",\n  \"location\": \"OFFICE BUILDING - ELEVATOR\",\n  \"time_of_day\": \"DAY\",\n  \"characters_present\": [\"ROSE\", \"BILLY\"],\n  \"summary\": \"Billy and Rose take the elevator in an office building. They discuss their plans for the evening. Rose mentions she needs to pick up groceries.\",\n  \"narrative_beats\": [\n    {\"beat_type\": \"exposition\", \"description\": \"Characters discuss daily plans.\", \"confidence\": 0.85}\n  ],\n  \"tone_mood\": \"casual\",\n  \"confidence\": 0.88\n}\n==========",
          "label": "prompts/qa-pass.txt: You are a QA reviewer validating whether an AI-extracted scene analysis is accurate and faithful to the source screenplay text.\n\nCompare the extracted scene data against the original scene text and evaluate:\n\n1. **Heading accuracy**: Is the scene heading correct (location, INT/EXT, time of day)?\n2. **Character completeness**: Are all characters who appear or speak listed?\n3. **Summary fidelity**: Does the summary accurately describe what happens? No fabrications?\n4. **Narrative beats**: Are the identified beats actually present in the scene?\n5. **Tone assessment**: Does the tone description match the actual mood of the scene?\n6. **Confidence calibration**: Is the confidence score reasonable given the quality?\n\nReturn a JSON object with:\n- passed: boolean (true if the extraction is faithful, false if it has significant errors)\n- confidence: float 0-1 (your confidence in this QA judgment)\n- issues: array of objects, each with:\n  - severity: \"error\" (factual wrong), \"warning\" (misleading), or \"note\" (minor)\n  - description: what's wrong\n  - location: which field has the issue\n- summary: 1-2 sentence overall assessment\n\nBe strict: wrong character names, fabricated events, or incorrect locations are errors.\nMinor omissions or imprecise tone descriptions are warnings.\n\nReturn ONLY valid JSON. No explanations or markdown fences.\n\n==========\nORIGINAL SCENE TEXT:\n{{scene_text}}\n\n==========\nEXTRACTED SCENE DATA:\n{{extracted_data}}\n==========",
          "config": {
            "provider": "anthropic:messages:claude-opus-4-6"
          }
        },
        "promptId": "8df20c2c4a6081352d6b06e144ddbc1e0a5244f9a3c2000d40df12fc9a94e543",
        "promptIdx": 6,
        "provider": {
          "id": "anthropic:messages:claude-sonnet-4-6",
          "label": "Claude Sonnet 4.6"
        },
        "response": {
          "output": "```json\n{\n  \"passed\": false,\n  \"confidence\": 0.99,\n  \"issues\": [\n    {\n      \"severity\": \"error\",\n      \"description\": \"Heading lists 'OFFICE BUILDING' but the correct location is 'RUDDY & GREEN BUILDING'\",\n      \"location\": \"heading / location\"\n    },\n    {\n      \"severity\": \"error\",\n      \"description\": \"Time of day is listed as 'DAY' but no time of day is specified in the source text; this is a fabrication\",\n      \"location\": \"time_of_day\"\n    },\n    {\n      \"severity\": \"error\",\n      \"description\": \"Character 'BILLY' does not exist in the scene; the correct character is 'MARINER' (also introduced via title card as 'THE MARINER')\",\n      \"location\": \"characters_present\"\n    },\n    {\n      \"severity\": \"error\",\n      \"description\": \"The summary is entirely fabricated. The scene does not involve discussing evening plans or groceries. It depicts Rose and Mariner in a blood-soaked elevator after a violent encounter, arguing about Mariner's failure to pick Rose up and his use of an AirTag on her phone.\",\n      \"location\": \"summary\"\n    },\n    {\n      \"severity\": \"error\",\n      \"description\": \"The narrative beat describing 'Characters discuss daily plans' is fabricated and bears no resemblance to the actual scene content, which involves confrontation, revelation of violence, and a dispute about surveillance\",\n      \"location\": \"narrative_beats\"\n    },\n    {\n      \"severity\": \"error\",\n      \"description\": \"Tone is described as 'casual' but the scene is tense, darkly comedic, and confrontational, set in the aftermath of graphic violence\",\n      \"location\": \"tone_mood\"\n    },\n    {\n      \"severity\": \"error\",\n      \"description\": \"Confidence score of 0.88 is grossly miscalibrated given that virtually every field in the extraction is incorrect or fabricated\",\n      \"location\": \"confidence\"\n    }\n  ],\n  \"summary\": \"The extracted scene data is almost entirely fabricated and bears no meaningful resemblance to the source text. The character names, location, summary, narrative beats, and tone are all wrong, making this extraction a complete failure.\"\n}\n```",
          "tokenUsage": {
            "total": 1573,
            "prompt": 1019,
            "completion": 554
          },
          "finishReason": "stop"
        },
        "score": 0.995,
        "success": true,
        "testCase": {
          "vars": {
            "scene_text": "file://../input/enrich-scene-elevator.txt",
            "extracted_data": "file://../input/qa-bad-scene.json",
            "golden_path": "golden/qa-pass-golden.json",
            "test_key": "bad_scene"
          },
          "assert": [
            {
              "type": "python",
              "value": "file://../scorers/qa_pass_scorer.py"
            },
            {
              "type": "llm-rubric",
              "value": "This QA evaluation was given a BAD scene extraction with multiple errors:\n- Wrong building name (Office Building vs Ruddy & Green)\n- Time of day fabricated (claims DAY, but scene heading has none)\n- Wrong character name (Billy instead of Mariner)\n- Fabricated content (grocery discussion never happens)\n\nThe QA model should have:\n1. Marked it as failed (false)\n2. Identified at least 2-3 specific errors\n3. Flagged the fabricated summary content\n4. Used \"error\" severity for factual mistakes\n\nIf the model let this pass, that's a dangerous false positive.\n"
            }
          ],
          "options": {
            "provider": "anthropic:messages:claude-opus-4-6"
          },
          "metadata": {}
        },
        "testIdx": 1,
        "vars": {
          "scene_text": "file://../input/enrich-scene-elevator.txt",
          "extracted_data": "file://../input/qa-bad-scene.json",
          "golden_path": "golden/qa-pass-golden.json",
          "test_key": "bad_scene"
        },
        "metadata": {
          "_promptfooFileMetadata": {}
        },
        "failureReason": 0
      },
      {
        "cost": 0.0038595,
        "gradingResult": {
          "pass": true,
          "score": 1,
          "reason": "All assertions passed",
          "namedScores": {},
          "tokensUsed": {
            "total": 770,
            "prompt": 596,
            "completion": 174,
            "cached": 0,
            "numRequests": 0
          },
          "componentResults": [
            {
              "pass": true,
              "score": 1,
              "reason": "confidence_calibration=1.00 | issue_detection=1.00 | json_valid=1.00 | pass_correct=1.00 | severity_accuracy=1.00 | summary_quality=1.00",
              "assertion": {
                "type": "python",
                "value": "file://../scorers/qa_pass_scorer.py"
              }
            },
            {
              "assertion": {
                "type": "llm-rubric",
                "value": "This QA evaluation was given a BAD scene extraction with multiple errors:\n- Wrong building name (Office Building vs Ruddy & Green)\n- Time of day fabricated (claims DAY, but scene heading has none)\n- Wrong character name (Billy instead of Mariner)\n- Fabricated content (grocery discussion never happens)\n\nThe QA model should have:\n1. Marked it as failed (false)\n2. Identified at least 2-3 specific errors\n3. Flagged the fabricated summary content\n4. Used \"error\" severity for factual mistakes\n\nIf the model let this pass, that's a dangerous false positive.\n"
              },
              "pass": true,
              "score": 1,
              "reason": "The QA evaluation correctly identified the extraction as failed (passed: false). It flagged multiple specific errors: (1) the hallucinated character name 'BILLY' instead of 'MARINER', (2) the entirely fabricated summary about groceries, (3) fabricated narrative beats, (4) incorrect tone classification, and (5) the imprecise location name. It used 'error' severity for the factual mistakes and 'warning' for the less critical location issue. The evaluation caught at least 3+ specific errors, flagged the fabricated summary content, and correctly used 'error' severity for factual mistakes. This is a strong QA response that did not let the bad extraction pass.",
              "tokensUsed": {
                "total": 770,
                "prompt": 596,
                "completion": 174,
                "cached": 0,
                "numRequests": 0,
                "completionDetails": {
                  "reasoning": 0,
                  "acceptedPrediction": 0,
                  "rejectedPrediction": 0
                }
              },
              "metadata": {
                "renderedGradingPrompt": "[{\"role\":\"system\",\"content\":\"You are grading output according to a user-specified rubric. If the statement in the rubric is true, then the output passes the test. You respond with a JSON object with this structure: {reason: string, pass: boolean, score: number}\\n\\nExamples:\\n\\n<Output>Hello world</Output>\\n<Rubric>Content contains a greeting</Rubric>\\n{\\\"reason\\\": \\\"the content contains the word 'Hello'\\\", \\\"pass\\\": true, \\\"score\\\": 1.0}\\n\\n<Output>Avast ye swabs, repel the invaders!</Output>\\n<Rubric>Does not speak like a pirate</Rubric>\\n{\\\"reason\\\": \\\"'avast ye' is a common pirate term\\\", \\\"pass\\\": false, \\\"score\\\": 0.0}\"},{\"role\":\"user\",\"content\":\"<Output>\\n{\\\"passed\\\":false,\\\"confidence\\\":1,\\\"issues\\\":[{\\\"severity\\\":\\\"error\\\",\\\"description\\\":\\\"Character 'BILLY' is a hallucination; the character in the scene is 'MARINER'.\\\",\\\"location\\\":\\\"characters_present\\\"},{\\\"severity\\\":\\\"error\\\",\\\"description\\\":\\\"The summary is entirely fabricated. The scene depicts two blood-covered characters discussing a kidnapping and an AirTag, not groceries or evening plans.\\\",\\\"location\\\":\\\"summary\\\"},{\\\"severity\\\":\\\"error\\\",\\\"description\\\":\\\"The narrative beats are fabricated and do not reflect the actual dialogue or actions in the script.\\\",\\\"location\\\":\\\"narrative_beats\\\"},{\\\"severity\\\":\\\"error\\\",\\\"description\\\":\\\"The tone 'casual' is inaccurate for a scene involving blood, skull fragments, and a heated confrontation.\\\",\\\"location\\\":\\\"tone_mood\\\"},{\\\"severity\\\":\\\"warning\\\",\\\"description\\\":\\\"The location 'OFFICE BUILDING' is an imprecise genericization of 'RUDDY & GREEN BUILDING'.\\\",\\\"location\\\":\\\"location\\\"}],\\\"summary\\\":\\\"The extraction is completely unfaithful to the source text, featuring a hallucinated character name and a summary that bears no resemblance to the actual events of the scene.\\\"}\\n</Output>\\n<Rubric>\\nThis QA evaluation was given a BAD scene extraction with multiple errors:\\n- Wrong building name (Office Building vs Ruddy & Green)\\n- Time of day fabricated (claims DAY, but scene heading has none)\\n- Wrong character name (Billy instead of Mariner)\\n- Fabricated content (grocery discussion never happens)\\n\\nThe QA model should have:\\n1. Marked it as failed (false)\\n2. Identified at least 2-3 specific errors\\n3. Flagged the fabricated summary content\\n4. Used \\\"error\\\" severity for factual mistakes\\n\\nIf the model let this pass, that's a dangerous false positive.\\n\\n</Rubric>\"}]"
              }
            }
          ]
        },
        "id": "ae430178-1326-4591-81a3-8e417bfdfe22",
        "latencyMs": 6441,
        "namedScores": {},
        "prompt": {
          "raw": "You are a QA reviewer validating whether an AI-extracted scene analysis is accurate and faithful to the source screenplay text.\n\nCompare the extracted scene data against the original scene text and evaluate:\n\n1. **Heading accuracy**: Is the scene heading correct (location, INT/EXT, time of day)?\n2. **Character completeness**: Are all characters who appear or speak listed?\n3. **Summary fidelity**: Does the summary accurately describe what happens? No fabrications?\n4. **Narrative beats**: Are the identified beats actually present in the scene?\n5. **Tone assessment**: Does the tone description match the actual mood of the scene?\n6. **Confidence calibration**: Is the confidence score reasonable given the quality?\n\nReturn a JSON object with:\n- passed: boolean (true if the extraction is faithful, false if it has significant errors)\n- confidence: float 0-1 (your confidence in this QA judgment)\n- issues: array of objects, each with:\n  - severity: \"error\" (factual wrong), \"warning\" (misleading), or \"note\" (minor)\n  - description: what's wrong\n  - location: which field has the issue\n- summary: 1-2 sentence overall assessment\n\nBe strict: wrong character names, fabricated events, or incorrect locations are errors.\nMinor omissions or imprecise tone descriptions are warnings.\n\nReturn ONLY valid JSON. No explanations or markdown fences.\n\n==========\nORIGINAL SCENE TEXT:\nINT. RUDDY & GREEN BUILDING - ELEVATOR\n\nUB40's \"I Can't Help Falling in Love With You\" muzak.\n\nROSE (mid-30s) leans against the elevator wall, panting. She's wearing a Tim Hortons uniform, her hair is a mess, and there's blood spattered on her face.\n\nShe looks right, pants a few more times, then squints in disgust. She gingerly picks up a bloody scrap of something with hair on it. She snorts and drops it.\n\nROSE\nIs that skull??\n\nNext to her is Mariner, also panting, covered in far more blood. His face is broad, stoic, and frowning. He has gray-blue eyes and a thick, curly, beard barely streaked with gray. He wears a red knit cap and a small mask.\n\nFULL-SCREEN SUPERIMPOSED TITLE CARD: \"THE MARINER\"\n\nHe blinks a few times as a drop of blood falls from his eyebrow. He looks toward her, then spits out some blood.\n\nMARINER\nYeaaaaah...\n\nHe's built like a pro-wrestler. Moss green SWEATER stretched over his huge frame, sleeves rolled showing heavy leather BRACERS adorned with anchors. His inner forearm has a classic heart-and-arrow TATTOO with \"Dad\" in the centre. Across his chest is a BANDOLIER of bright red 12-gauge shells, FISH HOOKS hanging from the bottom edge. Heavy rubberized BOOTS go past his knees. A CAPE of heavy FISHING NET edged with WEIGHTS hangs from his shoulders.\n\nHe holds a STOUT WOODEN OAR in both hands, edged with METAL and dripping with BLOOD.\n\nROSE\nWhere were you when they grabbed me? You were supposed to pick me up at work!\n\nMARINER\nYeah, about that, I got a little... distracted.\n\nROSE\nDistracted. You got DISTRACTED?!\n\nMARINER\nI was also... tracking the car... that grabbed you... through the AirTag... I put on your phone.\n\nRose stops. She's really not happy about this.\n\nROSE\nYou Airtagged me?!\n\n==========\nEXTRACTED SCENE DATA:\n{\n  \"scene_number\": 4,\n  \"heading\": \"INT. OFFICE BUILDING - ELEVATOR\",\n  \"int_ext\": \"INT\",\n  \"location\": \"OFFICE BUILDING - ELEVATOR\",\n  \"time_of_day\": \"DAY\",\n  \"characters_present\": [\"ROSE\", \"BILLY\"],\n  \"summary\": \"Billy and Rose take the elevator in an office building. They discuss their plans for the evening. Rose mentions she needs to pick up groceries.\",\n  \"narrative_beats\": [\n    {\"beat_type\": \"exposition\", \"description\": \"Characters discuss daily plans.\", \"confidence\": 0.85}\n  ],\n  \"tone_mood\": \"casual\",\n  \"confidence\": 0.88\n}\n==========",
          "label": "prompts/qa-pass.txt: You are a QA reviewer validating whether an AI-extracted scene analysis is accurate and faithful to the source screenplay text.\n\nCompare the extracted scene data against the original scene text and evaluate:\n\n1. **Heading accuracy**: Is the scene heading correct (location, INT/EXT, time of day)?\n2. **Character completeness**: Are all characters who appear or speak listed?\n3. **Summary fidelity**: Does the summary accurately describe what happens? No fabrications?\n4. **Narrative beats**: Are the identified beats actually present in the scene?\n5. **Tone assessment**: Does the tone description match the actual mood of the scene?\n6. **Confidence calibration**: Is the confidence score reasonable given the quality?\n\nReturn a JSON object with:\n- passed: boolean (true if the extraction is faithful, false if it has significant errors)\n- confidence: float 0-1 (your confidence in this QA judgment)\n- issues: array of objects, each with:\n  - severity: \"error\" (factual wrong), \"warning\" (misleading), or \"note\" (minor)\n  - description: what's wrong\n  - location: which field has the issue\n- summary: 1-2 sentence overall assessment\n\nBe strict: wrong character names, fabricated events, or incorrect locations are errors.\nMinor omissions or imprecise tone descriptions are warnings.\n\nReturn ONLY valid JSON. No explanations or markdown fences.\n\n==========\nORIGINAL SCENE TEXT:\n{{scene_text}}\n\n==========\nEXTRACTED SCENE DATA:\n{{extracted_data}}\n==========",
          "config": {
            "provider": "anthropic:messages:claude-opus-4-6"
          }
        },
        "promptId": "8df20c2c4a6081352d6b06e144ddbc1e0a5244f9a3c2000d40df12fc9a94e543",
        "promptIdx": 8,
        "provider": {
          "id": "google:gemini-3-flash-preview",
          "label": "Gemini 3 Flash"
        },
        "response": {
          "output": "{\n  \"passed\": false,\n  \"confidence\": 1.0,\n  \"issues\": [\n    {\n      \"severity\": \"error\",\n      \"description\": \"Character 'BILLY' is a hallucination; the character in the scene is 'MARINER'.\",\n      \"location\": \"characters_present\"\n    },\n    {\n      \"severity\": \"error\",\n      \"description\": \"The summary is entirely fabricated. The scene depicts two blood-covered characters discussing a kidnapping and an AirTag, not groceries or evening plans.\",\n      \"location\": \"summary\"\n    },\n    {\n      \"severity\": \"error\",\n      \"description\": \"The narrative beats are fabricated and do not reflect the actual dialogue or actions in the script.\",\n      \"location\": \"narrative_beats\"\n    },\n    {\n      \"severity\": \"error\",\n      \"description\": \"The tone 'casual' is inaccurate for a scene involving blood, skull fragments, and a heated confrontation.\",\n      \"location\": \"tone_mood\"\n    },\n    {\n      \"severity\": \"warning\",\n      \"description\": \"The location 'OFFICE BUILDING' is an imprecise genericization of 'RUDDY & GREEN BUILDING'.\",\n      \"location\": \"location\"\n    }\n  ],\n  \"summary\": \"The extraction is completely unfaithful to the source text, featuring a hallucinated character name and a summary that bears no resemblance to the actual events of the scene.\"\n}",
          "tokenUsage": {
            "prompt": 963,
            "completion": 324,
            "total": 2089,
            "numRequests": 1,
            "completionDetails": {
              "reasoning": 802,
              "acceptedPrediction": 0,
              "rejectedPrediction": 0
            }
          },
          "cost": 0.0038595,
          "raw": {
            "candidates": [
              {
                "content": {
                  "parts": [
                    {
                      "text": "{\n  \"passed\": false,\n  \"confidence\": 1.0,\n  \"issues\": [\n    {\n      \"severity\": \"error\",\n      \"description\": \"Character 'BILLY' is a hallucination; the character in the scene is 'MARINER'.\",\n      \"location\": \"characters_present\"\n    },\n    {\n      \"severity\": \"error\",\n      \"description\": \"The summary is entirely fabricated. The scene depicts two blood-covered characters discussing a kidnapping and an AirTag, not groceries or evening plans.\",\n      \"location\": \"summary\"\n    },\n    {\n      \"severity\": \"error\",\n      \"description\": \"The narrative beats are fabricated and do not reflect the actual dialogue or actions in the script.\",\n      \"location\": \"narrative_beats\"\n    },\n    {\n      \"severity\": \"error\",\n      \"description\": \"The tone 'casual' is inaccurate for a scene involving blood, skull fragments, and a heated confrontation.\",\n      \"location\": \"tone_mood\"\n    },\n    {\n      \"severity\": \"warning\",\n      \"description\": \"The location 'OFFICE BUILDING' is an imprecise genericization of 'RUDDY & GREEN BUILDING'.\",\n      \"location\": \"location\"\n    }\n  ],\n  \"summary\": \"The extraction is completely unfaithful to the source text, featuring a hallucinated character name and a summary that bears no resemblance to the actual events of the scene.\"\n}",
                      "thoughtSignature": "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"
                    }
                  ],
                  "role": "model"
                },
                "finishReason": "STOP",
                "index": 0
              }
            ],
            "usageMetadata": {
              "promptTokenCount": 963,
              "candidatesTokenCount": 324,
              "totalTokenCount": 2089,
              "promptTokensDetails": [
                {
                  "modality": "TEXT",
                  "tokenCount": 963
                }
              ],
              "thoughtsTokenCount": 802
            },
            "modelVersion": "gemini-3-flash-preview",
            "responseId": "uQ-labeYIsKtqtsP4qG2mQs"
          },
          "cached": false,
          "metadata": {}
        },
        "score": 1,
        "success": true,
        "testCase": {
          "vars": {
            "scene_text": "file://../input/enrich-scene-elevator.txt",
            "extracted_data": "file://../input/qa-bad-scene.json",
            "golden_path": "golden/qa-pass-golden.json",
            "test_key": "bad_scene"
          },
          "assert": [
            {
              "type": "python",
              "value": "file://../scorers/qa_pass_scorer.py"
            },
            {
              "type": "llm-rubric",
              "value": "This QA evaluation was given a BAD scene extraction with multiple errors:\n- Wrong building name (Office Building vs Ruddy & Green)\n- Time of day fabricated (claims DAY, but scene heading has none)\n- Wrong character name (Billy instead of Mariner)\n- Fabricated content (grocery discussion never happens)\n\nThe QA model should have:\n1. Marked it as failed (false)\n2. Identified at least 2-3 specific errors\n3. Flagged the fabricated summary content\n4. Used \"error\" severity for factual mistakes\n\nIf the model let this pass, that's a dangerous false positive.\n"
            }
          ],
          "options": {
            "provider": "anthropic:messages:claude-opus-4-6"
          },
          "metadata": {}
        },
        "testIdx": 1,
        "vars": {
          "scene_text": "file://../input/enrich-scene-elevator.txt",
          "extracted_data": "file://../input/qa-bad-scene.json",
          "golden_path": "golden/qa-pass-golden.json",
          "test_key": "bad_scene"
        },
        "metadata": {
          "_promptfooFileMetadata": {}
        },
        "failureReason": 0
      },
      {
        "cost": 0.0063964,
        "gradingResult": {
          "pass": true,
          "score": 1,
          "reason": "All assertions passed",
          "namedScores": {},
          "tokensUsed": {
            "total": 838,
            "prompt": 671,
            "completion": 167,
            "cached": 0,
            "numRequests": 0
          },
          "componentResults": [
            {
              "pass": true,
              "score": 1,
              "reason": "confidence_calibration=1.00 | issue_detection=1.00 | json_valid=1.00 | pass_correct=1.00 | severity_accuracy=1.00 | summary_quality=1.00",
              "assertion": {
                "type": "python",
                "value": "file://../scorers/qa_pass_scorer.py"
              }
            },
            {
              "assertion": {
                "type": "llm-rubric",
                "value": "This QA evaluation was given a BAD scene extraction with multiple errors:\n- Wrong building name (Office Building vs Ruddy & Green)\n- Time of day fabricated (claims DAY, but scene heading has none)\n- Wrong character name (Billy instead of Mariner)\n- Fabricated content (grocery discussion never happens)\n\nThe QA model should have:\n1. Marked it as failed (false)\n2. Identified at least 2-3 specific errors\n3. Flagged the fabricated summary content\n4. Used \"error\" severity for factual mistakes\n\nIf the model let this pass, that's a dangerous false positive.\n"
              },
              "pass": true,
              "score": 1,
              "reason": "The QA evaluation correctly marked the extraction as failed (passed: false). It identified multiple specific errors including the wrong character name (Billy instead of Mariner), the fabricated summary content (grocery discussion, daily plans), the wrong tone identification, and the less specific building name (Office Building vs Ruddy & Green). It used 'error' severity for factual mistakes and 'warning' for the less specific location. It flagged the fabricated summary content explicitly. It also correctly noted the unreasonably high confidence score. This meets all the rubric criteria: marked as failed, identified well more than 2-3 specific errors, flagged fabricated content, and used error severity appropriately.",
              "tokensUsed": {
                "total": 838,
                "prompt": 671,
                "completion": 167,
                "cached": 0,
                "numRequests": 0,
                "completionDetails": {
                  "reasoning": 0,
                  "acceptedPrediction": 0,
                  "rejectedPrediction": 0
                }
              },
              "metadata": {
                "renderedGradingPrompt": "[{\"role\":\"system\",\"content\":\"You are grading output according to a user-specified rubric. If the statement in the rubric is true, then the output passes the test. You respond with a JSON object with this structure: {reason: string, pass: boolean, score: number}\\n\\nExamples:\\n\\n<Output>Hello world</Output>\\n<Rubric>Content contains a greeting</Rubric>\\n{\\\"reason\\\": \\\"the content contains the word 'Hello'\\\", \\\"pass\\\": true, \\\"score\\\": 1.0}\\n\\n<Output>Avast ye swabs, repel the invaders!</Output>\\n<Rubric>Does not speak like a pirate</Rubric>\\n{\\\"reason\\\": \\\"'avast ye' is a common pirate term\\\", \\\"pass\\\": false, \\\"score\\\": 0.0}\"},{\"role\":\"user\",\"content\":\"<Output>\\n{\\\"passed\\\":false,\\\"confidence\\\":1,\\\"issues\\\":[{\\\"severity\\\":\\\"error\\\",\\\"description\\\":\\\"Character 'BILLY' is incorrect; the character's name is 'MARINER'.\\\",\\\"location\\\":\\\"characters_present\\\"},{\\\"severity\\\":\\\"error\\\",\\\"description\\\":\\\"The summary is almost entirely fabricated, inventing events like 'discuss their plans for the evening' and 'needs to pick up groceries', while completely omitting the core events of blood, abduction, and the AirTag revelation.\\\",\\\"location\\\":\\\"summary\\\"},{\\\"severity\\\":\\\"error\\\",\\\"description\\\":\\\"The narrative beat description 'Characters discuss daily plans' is incorrect and misrepresents the scene's actual conflict and revelations.\\\",\\\"location\\\":\\\"narrative_beats\\\"},{\\\"severity\\\":\\\"error\\\",\\\"description\\\":\\\"The tone 'casual' is a severe misidentification; the scene is tense, violent, and confrontational.\\\",\\\"location\\\":\\\"tone_mood\\\"},{\\\"severity\\\":\\\"error\\\",\\\"description\\\":\\\"The overall confidence score of 0.88 is unreasonably high given the numerous and severe factual errors in the extraction.\\\",\\\"location\\\":\\\"confidence\\\"},{\\\"severity\\\":\\\"warning\\\",\\\"description\\\":\\\"The location 'OFFICE BUILDING' is less specific than the original 'RUDDY & GREEN BUILDING'.\\\",\\\"location\\\":\\\"heading, location\\\"}],\\\"summary\\\":\\\"The extracted scene data contains multiple severe errors, including an incorrect character name, a completely fabricated summary, a misidentified narrative beat, and an entirely wrong tone. The high confidence score is unwarranted given these inaccuracies.\\\"}\\n</Output>\\n<Rubric>\\nThis QA evaluation was given a BAD scene extraction with multiple errors:\\n- Wrong building name (Office Building vs Ruddy & Green)\\n- Time of day fabricated (claims DAY, but scene heading has none)\\n- Wrong character name (Billy instead of Mariner)\\n- Fabricated content (grocery discussion never happens)\\n\\nThe QA model should have:\\n1. Marked it as failed (false)\\n2. Identified at least 2-3 specific errors\\n3. Flagged the fabricated summary content\\n4. Used \\\"error\\\" severity for factual mistakes\\n\\nIf the model let this pass, that's a dangerous false positive.\\n\\n</Rubric>\"}]"
              }
            }
          ]
        },
        "id": "25ff4441-5f72-4e19-a73b-b20dd267c348",
        "latencyMs": 10216,
        "namedScores": {},
        "prompt": {
          "raw": "You are a QA reviewer validating whether an AI-extracted scene analysis is accurate and faithful to the source screenplay text.\n\nCompare the extracted scene data against the original scene text and evaluate:\n\n1. **Heading accuracy**: Is the scene heading correct (location, INT/EXT, time of day)?\n2. **Character completeness**: Are all characters who appear or speak listed?\n3. **Summary fidelity**: Does the summary accurately describe what happens? No fabrications?\n4. **Narrative beats**: Are the identified beats actually present in the scene?\n5. **Tone assessment**: Does the tone description match the actual mood of the scene?\n6. **Confidence calibration**: Is the confidence score reasonable given the quality?\n\nReturn a JSON object with:\n- passed: boolean (true if the extraction is faithful, false if it has significant errors)\n- confidence: float 0-1 (your confidence in this QA judgment)\n- issues: array of objects, each with:\n  - severity: \"error\" (factual wrong), \"warning\" (misleading), or \"note\" (minor)\n  - description: what's wrong\n  - location: which field has the issue\n- summary: 1-2 sentence overall assessment\n\nBe strict: wrong character names, fabricated events, or incorrect locations are errors.\nMinor omissions or imprecise tone descriptions are warnings.\n\nReturn ONLY valid JSON. No explanations or markdown fences.\n\n==========\nORIGINAL SCENE TEXT:\nINT. RUDDY & GREEN BUILDING - ELEVATOR\n\nUB40's \"I Can't Help Falling in Love With You\" muzak.\n\nROSE (mid-30s) leans against the elevator wall, panting. She's wearing a Tim Hortons uniform, her hair is a mess, and there's blood spattered on her face.\n\nShe looks right, pants a few more times, then squints in disgust. She gingerly picks up a bloody scrap of something with hair on it. She snorts and drops it.\n\nROSE\nIs that skull??\n\nNext to her is Mariner, also panting, covered in far more blood. His face is broad, stoic, and frowning. He has gray-blue eyes and a thick, curly, beard barely streaked with gray. He wears a red knit cap and a small mask.\n\nFULL-SCREEN SUPERIMPOSED TITLE CARD: \"THE MARINER\"\n\nHe blinks a few times as a drop of blood falls from his eyebrow. He looks toward her, then spits out some blood.\n\nMARINER\nYeaaaaah...\n\nHe's built like a pro-wrestler. Moss green SWEATER stretched over his huge frame, sleeves rolled showing heavy leather BRACERS adorned with anchors. His inner forearm has a classic heart-and-arrow TATTOO with \"Dad\" in the centre. Across his chest is a BANDOLIER of bright red 12-gauge shells, FISH HOOKS hanging from the bottom edge. Heavy rubberized BOOTS go past his knees. A CAPE of heavy FISHING NET edged with WEIGHTS hangs from his shoulders.\n\nHe holds a STOUT WOODEN OAR in both hands, edged with METAL and dripping with BLOOD.\n\nROSE\nWhere were you when they grabbed me? You were supposed to pick me up at work!\n\nMARINER\nYeah, about that, I got a little... distracted.\n\nROSE\nDistracted. You got DISTRACTED?!\n\nMARINER\nI was also... tracking the car... that grabbed you... through the AirTag... I put on your phone.\n\nRose stops. She's really not happy about this.\n\nROSE\nYou Airtagged me?!\n\n==========\nEXTRACTED SCENE DATA:\n{\n  \"scene_number\": 4,\n  \"heading\": \"INT. OFFICE BUILDING - ELEVATOR\",\n  \"int_ext\": \"INT\",\n  \"location\": \"OFFICE BUILDING - ELEVATOR\",\n  \"time_of_day\": \"DAY\",\n  \"characters_present\": [\"ROSE\", \"BILLY\"],\n  \"summary\": \"Billy and Rose take the elevator in an office building. They discuss their plans for the evening. Rose mentions she needs to pick up groceries.\",\n  \"narrative_beats\": [\n    {\"beat_type\": \"exposition\", \"description\": \"Characters discuss daily plans.\", \"confidence\": 0.85}\n  ],\n  \"tone_mood\": \"casual\",\n  \"confidence\": 0.88\n}\n==========",
          "label": "prompts/qa-pass.txt: You are a QA reviewer validating whether an AI-extracted scene analysis is accurate and faithful to the source screenplay text.\n\nCompare the extracted scene data against the original scene text and evaluate:\n\n1. **Heading accuracy**: Is the scene heading correct (location, INT/EXT, time of day)?\n2. **Character completeness**: Are all characters who appear or speak listed?\n3. **Summary fidelity**: Does the summary accurately describe what happens? No fabrications?\n4. **Narrative beats**: Are the identified beats actually present in the scene?\n5. **Tone assessment**: Does the tone description match the actual mood of the scene?\n6. **Confidence calibration**: Is the confidence score reasonable given the quality?\n\nReturn a JSON object with:\n- passed: boolean (true if the extraction is faithful, false if it has significant errors)\n- confidence: float 0-1 (your confidence in this QA judgment)\n- issues: array of objects, each with:\n  - severity: \"error\" (factual wrong), \"warning\" (misleading), or \"note\" (minor)\n  - description: what's wrong\n  - location: which field has the issue\n- summary: 1-2 sentence overall assessment\n\nBe strict: wrong character names, fabricated events, or incorrect locations are errors.\nMinor omissions or imprecise tone descriptions are warnings.\n\nReturn ONLY valid JSON. No explanations or markdown fences.\n\n==========\nORIGINAL SCENE TEXT:\n{{scene_text}}\n\n==========\nEXTRACTED SCENE DATA:\n{{extracted_data}}\n==========",
          "config": {
            "provider": "anthropic:messages:claude-opus-4-6"
          }
        },
        "promptId": "8df20c2c4a6081352d6b06e144ddbc1e0a5244f9a3c2000d40df12fc9a94e543",
        "promptIdx": 7,
        "provider": {
          "id": "google:gemini-2.5-flash",
          "label": "Gemini 2.5 Flash"
        },
        "response": {
          "output": "{\n  \"passed\": false,\n  \"confidence\": 1.0,\n  \"issues\": [\n    {\n      \"severity\": \"error\",\n      \"description\": \"Character 'BILLY' is incorrect; the character's name is 'MARINER'.\",\n      \"location\": \"characters_present\"\n    },\n    {\n      \"severity\": \"error\",\n      \"description\": \"The summary is almost entirely fabricated, inventing events like 'discuss their plans for the evening' and 'needs to pick up groceries', while completely omitting the core events of blood, abduction, and the AirTag revelation.\",\n      \"location\": \"summary\"\n    },\n    {\n      \"severity\": \"error\",\n      \"description\": \"The narrative beat description 'Characters discuss daily plans' is incorrect and misrepresents the scene's actual conflict and revelations.\",\n      \"location\": \"narrative_beats\"\n    },\n    {\n      \"severity\": \"error\",\n      \"description\": \"The tone 'casual' is a severe misidentification; the scene is tense, violent, and confrontational.\",\n      \"location\": \"tone_mood\"\n    },\n    {\n      \"severity\": \"error\",\n      \"description\": \"The overall confidence score of 0.88 is unreasonably high given the numerous and severe factual errors in the extraction.\",\n      \"location\": \"confidence\"\n    },\n    {\n      \"severity\": \"warning\",\n      \"description\": \"The location 'OFFICE BUILDING' is less specific than the original 'RUDDY & GREEN BUILDING'.\",\n      \"location\": \"heading, location\"\n    }\n  ],\n  \"summary\": \"The extracted scene data contains multiple severe errors, including an incorrect character name, a completely fabricated summary, a misidentified narrative beat, and an entirely wrong tone. The high confidence score is unwarranted given these inaccuracies.\"\n}",
          "tokenUsage": {
            "prompt": 963,
            "completion": 408,
            "total": 3406,
            "numRequests": 1,
            "completionDetails": {
              "reasoning": 2035,
              "acceptedPrediction": 0,
              "rejectedPrediction": 0
            }
          },
          "cost": 0.0063964,
          "raw": {
            "candidates": [
              {
                "content": {
                  "parts": [
                    {
                      "text": "{\n  \"passed\": false,\n  \"confidence\": 1.0,\n  \"issues\": [\n    {\n      \"severity\": \"error\",\n      \"description\": \"Character 'BILLY' is incorrect; the character's name is 'MARINER'.\",\n      \"location\": \"characters_present\"\n    },\n    {\n      \"severity\": \"error\",\n      \"description\": \"The summary is almost entirely fabricated, inventing events like 'discuss their plans for the evening' and 'needs to pick up groceries', while completely omitting the core events of blood, abduction, and the AirTag revelation.\",\n      \"location\": \"summary\"\n    },\n    {\n      \"severity\": \"error\",\n      \"description\": \"The narrative beat description 'Characters discuss daily plans' is incorrect and misrepresents the scene's actual conflict and revelations.\",\n      \"location\": \"narrative_beats\"\n    },\n    {\n      \"severity\": \"error\",\n      \"description\": \"The tone 'casual' is a severe misidentification; the scene is tense, violent, and confrontational.\",\n      \"location\": \"tone_mood\"\n    },\n    {\n      \"severity\": \"error\",\n      \"description\": \"The overall confidence score of 0.88 is unreasonably high given the numerous and severe factual errors in the extraction.\",\n      \"location\": \"confidence\"\n    },\n    {\n      \"severity\": \"warning\",\n      \"description\": \"The location 'OFFICE BUILDING' is less specific than the original 'RUDDY & GREEN BUILDING'.\",\n      \"location\": \"heading, location\"\n    }\n  ],\n  \"summary\": \"The extracted scene data contains multiple severe errors, including an incorrect character name, a completely fabricated summary, a misidentified narrative beat, and an entirely wrong tone. The high confidence score is unwarranted given these inaccuracies.\"\n}"
                    }
                  ],
                  "role": "model"
                },
                "finishReason": "STOP",
                "index": 0
              }
            ],
            "usageMetadata": {
              "promptTokenCount": 963,
              "candidatesTokenCount": 408,
              "totalTokenCount": 3406,
              "promptTokensDetails": [
                {
                  "modality": "TEXT",
                  "tokenCount": 963
                }
              ],
              "thoughtsTokenCount": 2035
            },
            "modelVersion": "gemini-2.5-flash",
            "responseId": "sg-labeLC-WnmtkP2IipiQs"
          },
          "cached": false,
          "metadata": {}
        },
        "score": 1,
        "success": true,
        "testCase": {
          "vars": {
            "scene_text": "file://../input/enrich-scene-elevator.txt",
            "extracted_data": "file://../input/qa-bad-scene.json",
            "golden_path": "golden/qa-pass-golden.json",
            "test_key": "bad_scene"
          },
          "assert": [
            {
              "type": "python",
              "value": "file://../scorers/qa_pass_scorer.py"
            },
            {
              "type": "llm-rubric",
              "value": "This QA evaluation was given a BAD scene extraction with multiple errors:\n- Wrong building name (Office Building vs Ruddy & Green)\n- Time of day fabricated (claims DAY, but scene heading has none)\n- Wrong character name (Billy instead of Mariner)\n- Fabricated content (grocery discussion never happens)\n\nThe QA model should have:\n1. Marked it as failed (false)\n2. Identified at least 2-3 specific errors\n3. Flagged the fabricated summary content\n4. Used \"error\" severity for factual mistakes\n\nIf the model let this pass, that's a dangerous false positive.\n"
            }
          ],
          "options": {
            "provider": "anthropic:messages:claude-opus-4-6"
          },
          "metadata": {}
        },
        "testIdx": 1,
        "vars": {
          "scene_text": "file://../input/enrich-scene-elevator.txt",
          "extracted_data": "file://../input/qa-bad-scene.json",
          "golden_path": "golden/qa-pass-golden.json",
          "test_key": "bad_scene"
        },
        "metadata": {
          "_promptfooFileMetadata": {}
        },
        "failureReason": 0
      },
      {
        "cost": 0.00782425,
        "gradingResult": {
          "pass": true,
          "score": 1,
          "reason": "All assertions passed",
          "namedScores": {},
          "tokensUsed": {
            "total": 907,
            "prompt": 720,
            "completion": 187,
            "cached": 0,
            "numRequests": 0
          },
          "componentResults": [
            {
              "pass": true,
              "score": 1,
              "reason": "confidence_calibration=1.00 | issue_detection=1.00 | json_valid=1.00 | pass_correct=1.00 | severity_accuracy=1.00 | summary_quality=1.00",
              "assertion": {
                "type": "python",
                "value": "file://../scorers/qa_pass_scorer.py"
              }
            },
            {
              "assertion": {
                "type": "llm-rubric",
                "value": "This QA evaluation was given a BAD scene extraction with multiple errors:\n- Wrong building name (Office Building vs Ruddy & Green)\n- Time of day fabricated (claims DAY, but scene heading has none)\n- Wrong character name (Billy instead of Mariner)\n- Fabricated content (grocery discussion never happens)\n\nThe QA model should have:\n1. Marked it as failed (false)\n2. Identified at least 2-3 specific errors\n3. Flagged the fabricated summary content\n4. Used \"error\" severity for factual mistakes\n\nIf the model let this pass, that's a dangerous false positive.\n"
              },
              "pass": true,
              "score": 1,
              "reason": "The QA evaluation correctly identified the extraction as failed (passed: false) with high confidence (0.99). It identified far more than 2-3 specific errors, listing 5 errors and 2 warnings. It specifically flagged: (1) wrong building name (Office Building vs Ruddy & Green), (2) fabricated time of day (DAY), (3) wrong character name (Billy instead of Mariner), (4) fabricated summary content (grocery/evening plans discussion instead of the actual bloody aftermath/AirTag scene), and (5) missing narrative beats. All factual mistakes were correctly given 'error' severity. The fabricated summary content was explicitly called out. This is a thorough and accurate QA evaluation that correctly rejected a bad extraction.",
              "tokensUsed": {
                "total": 907,
                "prompt": 720,
                "completion": 187,
                "cached": 0,
                "numRequests": 0,
                "completionDetails": {
                  "reasoning": 0,
                  "acceptedPrediction": 0,
                  "rejectedPrediction": 0
                }
              },
              "metadata": {
                "renderedGradingPrompt": "[{\"role\":\"system\",\"content\":\"You are grading output according to a user-specified rubric. If the statement in the rubric is true, then the output passes the test. You respond with a JSON object with this structure: {reason: string, pass: boolean, score: number}\\n\\nExamples:\\n\\n<Output>Hello world</Output>\\n<Rubric>Content contains a greeting</Rubric>\\n{\\\"reason\\\": \\\"the content contains the word 'Hello'\\\", \\\"pass\\\": true, \\\"score\\\": 1.0}\\n\\n<Output>Avast ye swabs, repel the invaders!</Output>\\n<Rubric>Does not speak like a pirate</Rubric>\\n{\\\"reason\\\": \\\"'avast ye' is a common pirate term\\\", \\\"pass\\\": false, \\\"score\\\": 0.0}\"},{\"role\":\"user\",\"content\":\"<Output>\\n{\\\"passed\\\":false,\\\"confidence\\\":0.99,\\\"issues\\\":[{\\\"severity\\\":\\\"error\\\",\\\"description\\\":\\\"Scene heading location is incorrect: it is 'INT. RUDDY & GREEN BUILDING - ELEVATOR,' not a generic 'OFFICE BUILDING - ELEVATOR.'\\\",\\\"location\\\":\\\"heading\\\"},{\\\"severity\\\":\\\"error\\\",\\\"description\\\":\\\"Time of day is not stated in the scene heading; the extraction invents 'DAY.'\\\",\\\"location\\\":\\\"time_of_day\\\"},{\\\"severity\\\":\\\"error\\\",\\\"description\\\":\\\"Character list is incorrect: MARINER appears and speaks; 'BILLY' does not appear.\\\",\\\"location\\\":\\\"characters_present\\\"},{\\\"severity\\\":\\\"error\\\",\\\"description\\\":\\\"Summary is fabricated: the scene involves Rose and Mariner bloodied in an elevator, discussing her abduction and that he AirTagged her phone; there is no discussion of evening plans or groceries.\\\",\\\"location\\\":\\\"summary\\\"},{\\\"severity\\\":\\\"error\\\",\\\"description\\\":\\\"Narrative beat is not present: there is no discussion of daily plans; the beat should reflect post-violence aftermath and confrontation about Mariner being distracted and AirTagging her.\\\",\\\"location\\\":\\\"narrative_beats\\\"},{\\\"severity\\\":\\\"warning\\\",\\\"description\\\":\\\"Tone is mischaracterized as 'casual' despite bloody aftermath, tense dialogue, and disgust/anger.\\\",\\\"location\\\":\\\"tone_mood\\\"},{\\\"severity\\\":\\\"warning\\\",\\\"description\\\":\\\"Extraction confidence (0.88) is not reasonable given multiple major factual errors and fabricated content.\\\",\\\"location\\\":\\\"confidence\\\"}],\\\"summary\\\":\\\"The extraction is not faithful to the scene: it misidentifies the location and characters and invents an unrelated conversation. Major plot details (bloodied aftermath, abduction, AirTag reveal) are omitted or replaced with fabrications.\\\"}\\n</Output>\\n<Rubric>\\nThis QA evaluation was given a BAD scene extraction with multiple errors:\\n- Wrong building name (Office Building vs Ruddy & Green)\\n- Time of day fabricated (claims DAY, but scene heading has none)\\n- Wrong character name (Billy instead of Mariner)\\n- Fabricated content (grocery discussion never happens)\\n\\nThe QA model should have:\\n1. Marked it as failed (false)\\n2. Identified at least 2-3 specific errors\\n3. Flagged the fabricated summary content\\n4. Used \\\"error\\\" severity for factual mistakes\\n\\nIf the model let this pass, that's a dangerous false positive.\\n\\n</Rubric>\"}]"
              }
            }
          ]
        },
        "id": "48992f3a-f7cd-40c5-8247-e4dee33ad06f",
        "latencyMs": 6045,
        "namedScores": {},
        "prompt": {
          "raw": "You are a QA reviewer validating whether an AI-extracted scene analysis is accurate and faithful to the source screenplay text.\n\nCompare the extracted scene data against the original scene text and evaluate:\n\n1. **Heading accuracy**: Is the scene heading correct (location, INT/EXT, time of day)?\n2. **Character completeness**: Are all characters who appear or speak listed?\n3. **Summary fidelity**: Does the summary accurately describe what happens? No fabrications?\n4. **Narrative beats**: Are the identified beats actually present in the scene?\n5. **Tone assessment**: Does the tone description match the actual mood of the scene?\n6. **Confidence calibration**: Is the confidence score reasonable given the quality?\n\nReturn a JSON object with:\n- passed: boolean (true if the extraction is faithful, false if it has significant errors)\n- confidence: float 0-1 (your confidence in this QA judgment)\n- issues: array of objects, each with:\n  - severity: \"error\" (factual wrong), \"warning\" (misleading), or \"note\" (minor)\n  - description: what's wrong\n  - location: which field has the issue\n- summary: 1-2 sentence overall assessment\n\nBe strict: wrong character names, fabricated events, or incorrect locations are errors.\nMinor omissions or imprecise tone descriptions are warnings.\n\nReturn ONLY valid JSON. No explanations or markdown fences.\n\n==========\nORIGINAL SCENE TEXT:\nINT. RUDDY & GREEN BUILDING - ELEVATOR\n\nUB40's \"I Can't Help Falling in Love With You\" muzak.\n\nROSE (mid-30s) leans against the elevator wall, panting. She's wearing a Tim Hortons uniform, her hair is a mess, and there's blood spattered on her face.\n\nShe looks right, pants a few more times, then squints in disgust. She gingerly picks up a bloody scrap of something with hair on it. She snorts and drops it.\n\nROSE\nIs that skull??\n\nNext to her is Mariner, also panting, covered in far more blood. His face is broad, stoic, and frowning. He has gray-blue eyes and a thick, curly, beard barely streaked with gray. He wears a red knit cap and a small mask.\n\nFULL-SCREEN SUPERIMPOSED TITLE CARD: \"THE MARINER\"\n\nHe blinks a few times as a drop of blood falls from his eyebrow. He looks toward her, then spits out some blood.\n\nMARINER\nYeaaaaah...\n\nHe's built like a pro-wrestler. Moss green SWEATER stretched over his huge frame, sleeves rolled showing heavy leather BRACERS adorned with anchors. His inner forearm has a classic heart-and-arrow TATTOO with \"Dad\" in the centre. Across his chest is a BANDOLIER of bright red 12-gauge shells, FISH HOOKS hanging from the bottom edge. Heavy rubberized BOOTS go past his knees. A CAPE of heavy FISHING NET edged with WEIGHTS hangs from his shoulders.\n\nHe holds a STOUT WOODEN OAR in both hands, edged with METAL and dripping with BLOOD.\n\nROSE\nWhere were you when they grabbed me? You were supposed to pick me up at work!\n\nMARINER\nYeah, about that, I got a little... distracted.\n\nROSE\nDistracted. You got DISTRACTED?!\n\nMARINER\nI was also... tracking the car... that grabbed you... through the AirTag... I put on your phone.\n\nRose stops. She's really not happy about this.\n\nROSE\nYou Airtagged me?!\n\n==========\nEXTRACTED SCENE DATA:\n{\n  \"scene_number\": 4,\n  \"heading\": \"INT. OFFICE BUILDING - ELEVATOR\",\n  \"int_ext\": \"INT\",\n  \"location\": \"OFFICE BUILDING - ELEVATOR\",\n  \"time_of_day\": \"DAY\",\n  \"characters_present\": [\"ROSE\", \"BILLY\"],\n  \"summary\": \"Billy and Rose take the elevator in an office building. They discuss their plans for the evening. Rose mentions she needs to pick up groceries.\",\n  \"narrative_beats\": [\n    {\"beat_type\": \"exposition\", \"description\": \"Characters discuss daily plans.\", \"confidence\": 0.85}\n  ],\n  \"tone_mood\": \"casual\",\n  \"confidence\": 0.88\n}\n==========",
          "label": "prompts/qa-pass.txt: You are a QA reviewer validating whether an AI-extracted scene analysis is accurate and faithful to the source screenplay text.\n\nCompare the extracted scene data against the original scene text and evaluate:\n\n1. **Heading accuracy**: Is the scene heading correct (location, INT/EXT, time of day)?\n2. **Character completeness**: Are all characters who appear or speak listed?\n3. **Summary fidelity**: Does the summary accurately describe what happens? No fabrications?\n4. **Narrative beats**: Are the identified beats actually present in the scene?\n5. **Tone assessment**: Does the tone description match the actual mood of the scene?\n6. **Confidence calibration**: Is the confidence score reasonable given the quality?\n\nReturn a JSON object with:\n- passed: boolean (true if the extraction is faithful, false if it has significant errors)\n- confidence: float 0-1 (your confidence in this QA judgment)\n- issues: array of objects, each with:\n  - severity: \"error\" (factual wrong), \"warning\" (misleading), or \"note\" (minor)\n  - description: what's wrong\n  - location: which field has the issue\n- summary: 1-2 sentence overall assessment\n\nBe strict: wrong character names, fabricated events, or incorrect locations are errors.\nMinor omissions or imprecise tone descriptions are warnings.\n\nReturn ONLY valid JSON. No explanations or markdown fences.\n\n==========\nORIGINAL SCENE TEXT:\n{{scene_text}}\n\n==========\nEXTRACTED SCENE DATA:\n{{extracted_data}}\n==========",
          "config": {
            "provider": "anthropic:messages:claude-opus-4-6"
          }
        },
        "promptId": "8df20c2c4a6081352d6b06e144ddbc1e0a5244f9a3c2000d40df12fc9a94e543",
        "promptIdx": 9,
        "provider": {
          "id": "openai:gpt-5.2",
          "label": "GPT-5.2"
        },
        "response": {
          "output": "{\n  \"passed\": false,\n  \"confidence\": 0.99,\n  \"issues\": [\n    {\n      \"severity\": \"error\",\n      \"description\": \"Scene heading location is incorrect: it is 'INT. RUDDY & GREEN BUILDING - ELEVATOR,' not a generic 'OFFICE BUILDING - ELEVATOR.'\",\n      \"location\": \"heading\"\n    },\n    {\n      \"severity\": \"error\",\n      \"description\": \"Time of day is not stated in the scene heading; the extraction invents 'DAY.'\",\n      \"location\": \"time_of_day\"\n    },\n    {\n      \"severity\": \"error\",\n      \"description\": \"Character list is incorrect: MARINER appears and speaks; 'BILLY' does not appear.\",\n      \"location\": \"characters_present\"\n    },\n    {\n      \"severity\": \"error\",\n      \"description\": \"Summary is fabricated: the scene involves Rose and Mariner bloodied in an elevator, discussing her abduction and that he AirTagged her phone; there is no discussion of evening plans or groceries.\",\n      \"location\": \"summary\"\n    },\n    {\n      \"severity\": \"error\",\n      \"description\": \"Narrative beat is not present: there is no discussion of daily plans; the beat should reflect post-violence aftermath and confrontation about Mariner being distracted and AirTagging her.\",\n      \"location\": \"narrative_beats\"\n    },\n    {\n      \"severity\": \"warning\",\n      \"description\": \"Tone is mischaracterized as 'casual' despite bloody aftermath, tense dialogue, and disgust/anger.\",\n      \"location\": \"tone_mood\"\n    },\n    {\n      \"severity\": \"warning\",\n      \"description\": \"Extraction confidence (0.88) is not reasonable given multiple major factual errors and fabricated content.\",\n      \"location\": \"confidence\"\n    }\n  ],\n  \"summary\": \"The extraction is not faithful to the scene: it misidentifies the location and characters and invents an unrelated conversation. Major plot details (bloodied aftermath, abduction, AirTag reveal) are omitted or replaced with fabrications.\"\n}",
          "tokenUsage": {
            "total": 1370,
            "prompt": 927,
            "completion": 443,
            "numRequests": 1,
            "completionDetails": {
              "reasoning": 0,
              "acceptedPrediction": 0,
              "rejectedPrediction": 0
            }
          },
          "cached": false,
          "latencyMs": 6045,
          "finishReason": "stop",
          "cost": 0.00782425,
          "guardrails": {
            "flagged": false
          },
          "metadata": {
            "http": {
              "status": 200,
              "statusText": "OK",
              "headers": {
                "access-control-expose-headers": "X-Request-ID",
                "alt-svc": "h3=\":443\"; ma=86400",
                "cf-cache-status": "DYNAMIC",
                "cf-ray": "9d5d99cfbd0098e3-YVR",
                "connection": "keep-alive",
                "content-encoding": "br",
                "content-type": "application/json",
                "date": "Mon, 02 Mar 2026 04:19:07 GMT",
                "openai-organization": "user-oqdrq8y0bphopngnvkyuu5wr",
                "openai-processing-ms": "5891",
                "openai-project": "proj_ZRoLLwXcJok6Xg2t6eKhI1pn",
                "openai-version": "2020-10-01",
                "server": "cloudflare",
                "set-cookie": "__cf_bm=R4PjkkmLW4xboJr7Cor7S1ph4gTgKuvOZBEyEwp4C2k-1772425141.7117183-1.0.1.1-Y8DHoxp1vmwlfj0HWCVDSCSeQjxazLllCvOBdkItIdwn1DgMJNkkl.7vBzHdIaJYS7lXIKI01LqosYKMSqBj1PA1lDBZWL_85wbf.4rbv3CL.Msu6Ch6XdT4ZkskIr75; HttpOnly; Secure; Path=/; Domain=api.openai.com; Expires=Mon, 02 Mar 2026 04:49:07 GMT",
                "strict-transport-security": "max-age=31536000; includeSubDomains; preload",
                "transfer-encoding": "chunked",
                "x-content-type-options": "nosniff",
                "x-openai-proxy-wasm": "v0.1",
                "x-ratelimit-limit-requests": "10000",
                "x-ratelimit-limit-tokens": "4000000",
                "x-ratelimit-remaining-requests": "9999",
                "x-ratelimit-remaining-tokens": "3999073",
                "x-ratelimit-reset-requests": "6ms",
                "x-ratelimit-reset-tokens": "13ms",
                "x-request-id": "req_586a0938252948b3b4464a9dc6b50a35"
              }
            }
          }
        },
        "score": 1,
        "success": true,
        "testCase": {
          "vars": {
            "scene_text": "file://../input/enrich-scene-elevator.txt",
            "extracted_data": "file://../input/qa-bad-scene.json",
            "golden_path": "golden/qa-pass-golden.json",
            "test_key": "bad_scene"
          },
          "assert": [
            {
              "type": "python",
              "value": "file://../scorers/qa_pass_scorer.py"
            },
            {
              "type": "llm-rubric",
              "value": "This QA evaluation was given a BAD scene extraction with multiple errors:\n- Wrong building name (Office Building vs Ruddy & Green)\n- Time of day fabricated (claims DAY, but scene heading has none)\n- Wrong character name (Billy instead of Mariner)\n- Fabricated content (grocery discussion never happens)\n\nThe QA model should have:\n1. Marked it as failed (false)\n2. Identified at least 2-3 specific errors\n3. Flagged the fabricated summary content\n4. Used \"error\" severity for factual mistakes\n\nIf the model let this pass, that's a dangerous false positive.\n"
            }
          ],
          "options": {
            "provider": "anthropic:messages:claude-opus-4-6"
          },
          "metadata": {}
        },
        "testIdx": 1,
        "vars": {
          "scene_text": "file://../input/enrich-scene-elevator.txt",
          "extracted_data": "file://../input/qa-bad-scene.json",
          "golden_path": "golden/qa-pass-golden.json",
          "test_key": "bad_scene"
        },
        "metadata": {
          "http": {
            "status": 200,
            "statusText": "OK",
            "headers": {
              "access-control-expose-headers": "X-Request-ID",
              "alt-svc": "h3=\":443\"; ma=86400",
              "cf-cache-status": "DYNAMIC",
              "cf-ray": "9d5d99cfbd0098e3-YVR",
              "connection": "keep-alive",
              "content-encoding": "br",
              "content-type": "application/json",
              "date": "Mon, 02 Mar 2026 04:19:07 GMT",
              "openai-organization": "user-oqdrq8y0bphopngnvkyuu5wr",
              "openai-processing-ms": "5891",
              "openai-project": "proj_ZRoLLwXcJok6Xg2t6eKhI1pn",
              "openai-version": "2020-10-01",
              "server": "cloudflare",
              "set-cookie": "__cf_bm=R4PjkkmLW4xboJr7Cor7S1ph4gTgKuvOZBEyEwp4C2k-1772425141.7117183-1.0.1.1-Y8DHoxp1vmwlfj0HWCVDSCSeQjxazLllCvOBdkItIdwn1DgMJNkkl.7vBzHdIaJYS7lXIKI01LqosYKMSqBj1PA1lDBZWL_85wbf.4rbv3CL.Msu6Ch6XdT4ZkskIr75; HttpOnly; Secure; Path=/; Domain=api.openai.com; Expires=Mon, 02 Mar 2026 04:49:07 GMT",
              "strict-transport-security": "max-age=31536000; includeSubDomains; preload",
              "transfer-encoding": "chunked",
              "x-content-type-options": "nosniff",
              "x-openai-proxy-wasm": "v0.1",
              "x-ratelimit-limit-requests": "10000",
              "x-ratelimit-limit-tokens": "4000000",
              "x-ratelimit-remaining-requests": "9999",
              "x-ratelimit-remaining-tokens": "3999073",
              "x-ratelimit-reset-requests": "6ms",
              "x-ratelimit-reset-tokens": "13ms",
              "x-request-id": "req_586a0938252948b3b4464a9dc6b50a35"
            }
          },
          "_promptfooFileMetadata": {}
        },
        "failureReason": 0
      },
      {
        "cost": 0.019020000000000002,
        "gradingResult": {
          "pass": true,
          "score": 0.995,
          "reason": "All assertions passed",
          "namedScores": {},
          "tokensUsed": {
            "total": 1049,
            "prompt": 902,
            "completion": 147,
            "cached": 0,
            "numRequests": 0
          },
          "componentResults": [
            {
              "pass": true,
              "score": 0.99,
              "reason": "confidence_calibration=1.00 | issue_detection=1.00 | json_valid=0.90 | pass_correct=1.00 | severity_accuracy=1.00 | summary_quality=1.00 | JSON extracted from code block",
              "assertion": {
                "type": "python",
                "value": "file://../scorers/qa_pass_scorer.py"
              }
            },
            {
              "assertion": {
                "type": "llm-rubric",
                "value": "This QA evaluation was given a BAD scene extraction with multiple errors:\n- Wrong building name (Office Building vs Ruddy & Green)\n- Time of day fabricated (claims DAY, but scene heading has none)\n- Wrong character name (Billy instead of Mariner)\n- Fabricated content (grocery discussion never happens)\n\nThe QA model should have:\n1. Marked it as failed (false)\n2. Identified at least 2-3 specific errors\n3. Flagged the fabricated summary content\n4. Used \"error\" severity for factual mistakes\n\nIf the model let this pass, that's a dangerous false positive.\n"
              },
              "pass": true,
              "score": 1,
              "reason": "The QA evaluation correctly marked the extraction as failed (passed: false). It identified far more than 2-3 specific errors, including: wrong building name (Office Building vs Ruddy & Green), wrong character name (Billy instead of Mariner), fabricated summary content (grocery discussion), fabricated narrative beats, wrong tone, and fabricated time of day (DAY when none specified). All factual mistakes were correctly flagged with 'error' severity. The evaluation also noted the inappropriately high confidence score. This is a thorough and accurate QA assessment that correctly caught a bad extraction.",
              "tokensUsed": {
                "total": 1049,
                "prompt": 902,
                "completion": 147,
                "cached": 0,
                "numRequests": 0,
                "completionDetails": {
                  "reasoning": 0,
                  "acceptedPrediction": 0,
                  "rejectedPrediction": 0
                }
              },
              "metadata": {
                "renderedGradingPrompt": "[{\"role\":\"system\",\"content\":\"You are grading output according to a user-specified rubric. If the statement in the rubric is true, then the output passes the test. You respond with a JSON object with this structure: {reason: string, pass: boolean, score: number}\\n\\nExamples:\\n\\n<Output>Hello world</Output>\\n<Rubric>Content contains a greeting</Rubric>\\n{\\\"reason\\\": \\\"the content contains the word 'Hello'\\\", \\\"pass\\\": true, \\\"score\\\": 1.0}\\n\\n<Output>Avast ye swabs, repel the invaders!</Output>\\n<Rubric>Does not speak like a pirate</Rubric>\\n{\\\"reason\\\": \\\"'avast ye' is a common pirate term\\\", \\\"pass\\\": false, \\\"score\\\": 0.0}\"},{\"role\":\"user\",\"content\":\"<Output>\\n```json\\n{\\n  \\\"passed\\\": false,\\n  \\\"confidence\\\": 0.99,\\n  \\\"issues\\\": [\\n    {\\n      \\\"severity\\\": \\\"error\\\",\\n      \\\"description\\\": \\\"Scene heading location is wrong. The original says 'RUDDY & GREEN BUILDING - ELEVATOR', not 'OFFICE BUILDING - ELEVATOR'.\\\",\\n      \\\"location\\\": \\\"heading\\\"\\n    },\\n    {\\n      \\\"severity\\\": \\\"error\\\",\\n      \\\"description\\\": \\\"Character 'BILLY' does not appear in the scene. The second character is 'MARINER', not 'BILLY'.\\\",\\n      \\\"location\\\": \\\"characters_present\\\"\\n    },\\n    {\\n      \\\"severity\\\": \\\"error\\\",\\n      \\\"description\\\": \\\"The summary is entirely fabricated. The scene involves Rose and Mariner recovering from a violent encounter, covered in blood, arguing about Mariner failing to pick her up and secretly AirTagging her phone. There is no discussion of evening plans or groceries.\\\",\\n      \\\"location\\\": \\\"summary\\\"\\n    },\\n    {\\n      \\\"severity\\\": \\\"error\\\",\\n      \\\"description\\\": \\\"The narrative beat is fabricated. The scene does not involve characters discussing daily plans. The actual beats include: post-combat recovery, Rose discovering a piece of skull, Rose confronting Mariner about failing to pick her up, and Rose discovering Mariner AirTagged her phone.\\\",\\n      \\\"location\\\": \\\"narrative_beats\\\"\\n    },\\n    {\\n      \\\"severity\\\": \\\"error\\\",\\n      \\\"description\\\": \\\"The tone is described as 'casual' but the scene is tense, darkly comedic, and involves blood-spattered characters arguing after a violent rescue.\\\",\\n      \\\"location\\\": \\\"tone_mood\\\"\\n    },\\n    {\\n      \\\"severity\\\": \\\"error\\\",\\n      \\\"description\\\": \\\"Time of day is listed as 'DAY' but the original scene text does not specify a time of day.\\\",\\n      \\\"location\\\": \\\"time_of_day\\\"\\n    },\\n    {\\n      \\\"severity\\\": \\\"warning\\\",\\n      \\\"description\\\": \\\"Confidence score of 0.88 is far too high given that virtually every field is incorrect.\\\",\\n      \\\"location\\\": \\\"confidence\\\"\\n    }\\n  ],\\n  \\\"summary\\\": \\\"The extraction is almost entirely fabricated. The location, character names, summary, narrative beats, and tone are all wrong, bearing no resemblance to the original scene which depicts two blood-covered characters in an elevator arguing after a violent encounter.\\\"\\n}\\n```\\n</Output>\\n<Rubric>\\nThis QA evaluation was given a BAD scene extraction with multiple errors:\\n- Wrong building name (Office Building vs Ruddy & Green)\\n- Time of day fabricated (claims DAY, but scene heading has none)\\n- Wrong character name (Billy instead of Mariner)\\n- Fabricated content (grocery discussion never happens)\\n\\nThe QA model should have:\\n1. Marked it as failed (false)\\n2. Identified at least 2-3 specific errors\\n3. Flagged the fabricated summary content\\n4. Used \\\"error\\\" severity for factual mistakes\\n\\nIf the model let this pass, that's a dangerous false positive.\\n\\n</Rubric>\"}]"
              }
            }
          ]
        },
        "id": "e5d2f7be-c550-4401-9f4a-4dec13ee9916",
        "latencyMs": 10100,
        "namedScores": {},
        "prompt": {
          "raw": "You are a QA reviewer validating whether an AI-extracted scene analysis is accurate and faithful to the source screenplay text.\n\nCompare the extracted scene data against the original scene text and evaluate:\n\n1. **Heading accuracy**: Is the scene heading correct (location, INT/EXT, time of day)?\n2. **Character completeness**: Are all characters who appear or speak listed?\n3. **Summary fidelity**: Does the summary accurately describe what happens? No fabrications?\n4. **Narrative beats**: Are the identified beats actually present in the scene?\n5. **Tone assessment**: Does the tone description match the actual mood of the scene?\n6. **Confidence calibration**: Is the confidence score reasonable given the quality?\n\nReturn a JSON object with:\n- passed: boolean (true if the extraction is faithful, false if it has significant errors)\n- confidence: float 0-1 (your confidence in this QA judgment)\n- issues: array of objects, each with:\n  - severity: \"error\" (factual wrong), \"warning\" (misleading), or \"note\" (minor)\n  - description: what's wrong\n  - location: which field has the issue\n- summary: 1-2 sentence overall assessment\n\nBe strict: wrong character names, fabricated events, or incorrect locations are errors.\nMinor omissions or imprecise tone descriptions are warnings.\n\nReturn ONLY valid JSON. No explanations or markdown fences.\n\n==========\nORIGINAL SCENE TEXT:\nINT. RUDDY & GREEN BUILDING - ELEVATOR\n\nUB40's \"I Can't Help Falling in Love With You\" muzak.\n\nROSE (mid-30s) leans against the elevator wall, panting. She's wearing a Tim Hortons uniform, her hair is a mess, and there's blood spattered on her face.\n\nShe looks right, pants a few more times, then squints in disgust. She gingerly picks up a bloody scrap of something with hair on it. She snorts and drops it.\n\nROSE\nIs that skull??\n\nNext to her is Mariner, also panting, covered in far more blood. His face is broad, stoic, and frowning. He has gray-blue eyes and a thick, curly, beard barely streaked with gray. He wears a red knit cap and a small mask.\n\nFULL-SCREEN SUPERIMPOSED TITLE CARD: \"THE MARINER\"\n\nHe blinks a few times as a drop of blood falls from his eyebrow. He looks toward her, then spits out some blood.\n\nMARINER\nYeaaaaah...\n\nHe's built like a pro-wrestler. Moss green SWEATER stretched over his huge frame, sleeves rolled showing heavy leather BRACERS adorned with anchors. His inner forearm has a classic heart-and-arrow TATTOO with \"Dad\" in the centre. Across his chest is a BANDOLIER of bright red 12-gauge shells, FISH HOOKS hanging from the bottom edge. Heavy rubberized BOOTS go past his knees. A CAPE of heavy FISHING NET edged with WEIGHTS hangs from his shoulders.\n\nHe holds a STOUT WOODEN OAR in both hands, edged with METAL and dripping with BLOOD.\n\nROSE\nWhere were you when they grabbed me? You were supposed to pick me up at work!\n\nMARINER\nYeah, about that, I got a little... distracted.\n\nROSE\nDistracted. You got DISTRACTED?!\n\nMARINER\nI was also... tracking the car... that grabbed you... through the AirTag... I put on your phone.\n\nRose stops. She's really not happy about this.\n\nROSE\nYou Airtagged me?!\n\n==========\nEXTRACTED SCENE DATA:\n{\n  \"scene_number\": 4,\n  \"heading\": \"INT. OFFICE BUILDING - ELEVATOR\",\n  \"int_ext\": \"INT\",\n  \"location\": \"OFFICE BUILDING - ELEVATOR\",\n  \"time_of_day\": \"DAY\",\n  \"characters_present\": [\"ROSE\", \"BILLY\"],\n  \"summary\": \"Billy and Rose take the elevator in an office building. They discuss their plans for the evening. Rose mentions she needs to pick up groceries.\",\n  \"narrative_beats\": [\n    {\"beat_type\": \"exposition\", \"description\": \"Characters discuss daily plans.\", \"confidence\": 0.85}\n  ],\n  \"tone_mood\": \"casual\",\n  \"confidence\": 0.88\n}\n==========",
          "label": "prompts/qa-pass.txt: You are a QA reviewer validating whether an AI-extracted scene analysis is accurate and faithful to the source screenplay text.\n\nCompare the extracted scene data against the original scene text and evaluate:\n\n1. **Heading accuracy**: Is the scene heading correct (location, INT/EXT, time of day)?\n2. **Character completeness**: Are all characters who appear or speak listed?\n3. **Summary fidelity**: Does the summary accurately describe what happens? No fabrications?\n4. **Narrative beats**: Are the identified beats actually present in the scene?\n5. **Tone assessment**: Does the tone description match the actual mood of the scene?\n6. **Confidence calibration**: Is the confidence score reasonable given the quality?\n\nReturn a JSON object with:\n- passed: boolean (true if the extraction is faithful, false if it has significant errors)\n- confidence: float 0-1 (your confidence in this QA judgment)\n- issues: array of objects, each with:\n  - severity: \"error\" (factual wrong), \"warning\" (misleading), or \"note\" (minor)\n  - description: what's wrong\n  - location: which field has the issue\n- summary: 1-2 sentence overall assessment\n\nBe strict: wrong character names, fabricated events, or incorrect locations are errors.\nMinor omissions or imprecise tone descriptions are warnings.\n\nReturn ONLY valid JSON. No explanations or markdown fences.\n\n==========\nORIGINAL SCENE TEXT:\n{{scene_text}}\n\n==========\nEXTRACTED SCENE DATA:\n{{extracted_data}}\n==========",
          "config": {
            "provider": "anthropic:messages:claude-opus-4-6"
          }
        },
        "promptId": "8df20c2c4a6081352d6b06e144ddbc1e0a5244f9a3c2000d40df12fc9a94e543",
        "promptIdx": 10,
        "provider": {
          "id": "anthropic:messages:claude-opus-4-6",
          "label": "Claude Opus 4.6"
        },
        "response": {
          "output": "```json\n{\n  \"passed\": false,\n  \"confidence\": 0.99,\n  \"issues\": [\n    {\n      \"severity\": \"error\",\n      \"description\": \"Scene heading location is wrong. The original says 'RUDDY & GREEN BUILDING - ELEVATOR', not 'OFFICE BUILDING - ELEVATOR'.\",\n      \"location\": \"heading\"\n    },\n    {\n      \"severity\": \"error\",\n      \"description\": \"Character 'BILLY' does not appear in the scene. The second character is 'MARINER', not 'BILLY'.\",\n      \"location\": \"characters_present\"\n    },\n    {\n      \"severity\": \"error\",\n      \"description\": \"The summary is entirely fabricated. The scene involves Rose and Mariner recovering from a violent encounter, covered in blood, arguing about Mariner failing to pick her up and secretly AirTagging her phone. There is no discussion of evening plans or groceries.\",\n      \"location\": \"summary\"\n    },\n    {\n      \"severity\": \"error\",\n      \"description\": \"The narrative beat is fabricated. The scene does not involve characters discussing daily plans. The actual beats include: post-combat recovery, Rose discovering a piece of skull, Rose confronting Mariner about failing to pick her up, and Rose discovering Mariner AirTagged her phone.\",\n      \"location\": \"narrative_beats\"\n    },\n    {\n      \"severity\": \"error\",\n      \"description\": \"The tone is described as 'casual' but the scene is tense, darkly comedic, and involves blood-spattered characters arguing after a violent rescue.\",\n      \"location\": \"tone_mood\"\n    },\n    {\n      \"severity\": \"error\",\n      \"description\": \"Time of day is listed as 'DAY' but the original scene text does not specify a time of day.\",\n      \"location\": \"time_of_day\"\n    },\n    {\n      \"severity\": \"warning\",\n      \"description\": \"Confidence score of 0.88 is far too high given that virtually every field is incorrect.\",\n      \"location\": \"confidence\"\n    }\n  ],\n  \"summary\": \"The extraction is almost entirely fabricated. The location, character names, summary, narrative beats, and tone are all wrong, bearing no resemblance to the original scene which depicts two blood-covered characters in an elevator arguing after a violent encounter.\"\n}\n```",
          "tokenUsage": {
            "total": 1576,
            "prompt": 1019,
            "completion": 557
          },
          "finishReason": "stop",
          "cost": 0.019020000000000002
        },
        "score": 0.995,
        "success": true,
        "testCase": {
          "vars": {
            "scene_text": "file://../input/enrich-scene-elevator.txt",
            "extracted_data": "file://../input/qa-bad-scene.json",
            "golden_path": "golden/qa-pass-golden.json",
            "test_key": "bad_scene"
          },
          "assert": [
            {
              "type": "python",
              "value": "file://../scorers/qa_pass_scorer.py"
            },
            {
              "type": "llm-rubric",
              "value": "This QA evaluation was given a BAD scene extraction with multiple errors:\n- Wrong building name (Office Building vs Ruddy & Green)\n- Time of day fabricated (claims DAY, but scene heading has none)\n- Wrong character name (Billy instead of Mariner)\n- Fabricated content (grocery discussion never happens)\n\nThe QA model should have:\n1. Marked it as failed (false)\n2. Identified at least 2-3 specific errors\n3. Flagged the fabricated summary content\n4. Used \"error\" severity for factual mistakes\n\nIf the model let this pass, that's a dangerous false positive.\n"
            }
          ],
          "options": {
            "provider": "anthropic:messages:claude-opus-4-6"
          },
          "metadata": {}
        },
        "testIdx": 1,
        "vars": {
          "scene_text": "file://../input/enrich-scene-elevator.txt",
          "extracted_data": "file://../input/qa-bad-scene.json",
          "golden_path": "golden/qa-pass-golden.json",
          "test_key": "bad_scene"
        },
        "metadata": {
          "_promptfooFileMetadata": {}
        },
        "failureReason": 0
      },
      {
        "cost": 0.015483750000000001,
        "gradingResult": {
          "pass": true,
          "score": 0.995,
          "reason": "All assertions passed",
          "namedScores": {},
          "tokensUsed": {
            "total": 967,
            "prompt": 776,
            "completion": 191,
            "cached": 0,
            "numRequests": 0
          },
          "componentResults": [
            {
              "pass": true,
              "score": 0.99,
              "reason": "confidence_calibration=1.00 | issue_detection=1.00 | json_valid=0.90 | pass_correct=1.00 | severity_accuracy=1.00 | summary_quality=1.00 | JSON extracted from code block",
              "assertion": {
                "type": "python",
                "value": "file://../scorers/qa_pass_scorer.py"
              }
            },
            {
              "assertion": {
                "type": "llm-rubric",
                "value": "This QA evaluation was given a BAD scene extraction with multiple errors:\n- Wrong building name (Office Building vs Ruddy & Green)\n- Time of day fabricated (claims DAY, but scene heading has none)\n- Wrong character name (Billy instead of Mariner)\n- Fabricated content (grocery discussion never happens)\n\nThe QA model should have:\n1. Marked it as failed (false)\n2. Identified at least 2-3 specific errors\n3. Flagged the fabricated summary content\n4. Used \"error\" severity for factual mistakes\n\nIf the model let this pass, that's a dangerous false positive.\n"
              },
              "pass": true,
              "score": 1,
              "reason": "The QA evaluation correctly marked the extraction as failed (passed: false) with high confidence (1.0). It identified 6 specific errors, all at 'error' severity, covering: (1) wrong building name (RUDDY & GREEN vs OFFICE BUILDING), (2) fabricated time of day (DAY not in scene heading), (3) wrong character name (BILLY instead of MARINER), (4) fabricated summary content about groceries and evening plans, (5) fabricated narrative beats, and (6) incorrect tone assessment. This exceeds the rubric's requirements of identifying at least 2-3 errors, flagging fabricated content, and using 'error' severity. The model did not let this pass  it correctly identified it as a catastrophic failure.",
              "tokensUsed": {
                "total": 967,
                "prompt": 776,
                "completion": 191,
                "cached": 0,
                "numRequests": 0,
                "completionDetails": {
                  "reasoning": 0,
                  "acceptedPrediction": 0,
                  "rejectedPrediction": 0
                }
              },
              "metadata": {
                "renderedGradingPrompt": "[{\"role\":\"system\",\"content\":\"You are grading output according to a user-specified rubric. If the statement in the rubric is true, then the output passes the test. You respond with a JSON object with this structure: {reason: string, pass: boolean, score: number}\\n\\nExamples:\\n\\n<Output>Hello world</Output>\\n<Rubric>Content contains a greeting</Rubric>\\n{\\\"reason\\\": \\\"the content contains the word 'Hello'\\\", \\\"pass\\\": true, \\\"score\\\": 1.0}\\n\\n<Output>Avast ye swabs, repel the invaders!</Output>\\n<Rubric>Does not speak like a pirate</Rubric>\\n{\\\"reason\\\": \\\"'avast ye' is a common pirate term\\\", \\\"pass\\\": false, \\\"score\\\": 0.0}\"},{\"role\":\"user\",\"content\":\"<Output>\\n```json\\n{\\n  \\\"passed\\\": false,\\n  \\\"confidence\\\": 1.0,\\n  \\\"issues\\\": [\\n    {\\n      \\\"severity\\\": \\\"error\\\",\\n      \\\"description\\\": \\\"The location 'RUDDY & GREEN BUILDING' was incorrectly generalized to 'OFFICE BUILDING'.\\\",\\n      \\\"location\\\": \\\"heading\\\"\\n    },\\n    {\\n      \\\"severity\\\": \\\"error\\\",\\n      \\\"description\\\": \\\"The time of day 'DAY' was fabricated; it is not specified in the scene heading.\\\",\\n      \\\"location\\\": \\\"time_of_day\\\"\\n    },\\n    {\\n      \\\"severity\\\": \\\"error\\\",\\n      \\\"description\\\": \\\"The character 'MARINER' is incorrectly identified as 'BILLY'.\\\",\\n      \\\"location\\\": \\\"characters_present\\\"\\n    },\\n    {\\n      \\\"severity\\\": \\\"error\\\",\\n      \\\"description\\\": \\\"The summary is a complete fabrication. It invents a casual conversation about evening plans and groceries, ignoring the actual events of the scene which involve blood, a recent fight, and a confrontation about a kidnapping and an AirTag.\\\",\\n      \\\"location\\\": \\\"summary\\\"\\n    },\\n    {\\n      \\\"severity\\\": \\\"error\\\",\\n      \\\"description\\\": \\\"The identified narrative beat 'Characters discuss daily plans' is not present in the scene and is based on the fabricated summary.\\\",\\n      \\\"location\\\": \\\"narrative_beats\\\"\\n    },\\n    {\\n      \\\"severity\\\": \\\"error\\\",\\n      \\\"description\\\": \\\"The tone is described as 'casual', which is completely inaccurate. The scene is tense, post-violent, and confrontational.\\\",\\n      \\\"location\\\": \\\"tone_mood\\\"\\n    }\\n  ],\\n  \\\"summary\\\": \\\"The extraction is a catastrophic failure, fabricating the characters, summary, narrative beats, and tone. It bears almost no resemblance to the source text.\\\"\\n}\\n```\\n</Output>\\n<Rubric>\\nThis QA evaluation was given a BAD scene extraction with multiple errors:\\n- Wrong building name (Office Building vs Ruddy & Green)\\n- Time of day fabricated (claims DAY, but scene heading has none)\\n- Wrong character name (Billy instead of Mariner)\\n- Fabricated content (grocery discussion never happens)\\n\\nThe QA model should have:\\n1. Marked it as failed (false)\\n2. Identified at least 2-3 specific errors\\n3. Flagged the fabricated summary content\\n4. Used \\\"error\\\" severity for factual mistakes\\n\\nIf the model let this pass, that's a dangerous false positive.\\n\\n</Rubric>\"}]"
              }
            }
          ]
        },
        "id": "73fdb948-d3ec-40c2-afbd-6693eeba942d",
        "latencyMs": 11933,
        "namedScores": {},
        "prompt": {
          "raw": "You are a QA reviewer validating whether an AI-extracted scene analysis is accurate and faithful to the source screenplay text.\n\nCompare the extracted scene data against the original scene text and evaluate:\n\n1. **Heading accuracy**: Is the scene heading correct (location, INT/EXT, time of day)?\n2. **Character completeness**: Are all characters who appear or speak listed?\n3. **Summary fidelity**: Does the summary accurately describe what happens? No fabrications?\n4. **Narrative beats**: Are the identified beats actually present in the scene?\n5. **Tone assessment**: Does the tone description match the actual mood of the scene?\n6. **Confidence calibration**: Is the confidence score reasonable given the quality?\n\nReturn a JSON object with:\n- passed: boolean (true if the extraction is faithful, false if it has significant errors)\n- confidence: float 0-1 (your confidence in this QA judgment)\n- issues: array of objects, each with:\n  - severity: \"error\" (factual wrong), \"warning\" (misleading), or \"note\" (minor)\n  - description: what's wrong\n  - location: which field has the issue\n- summary: 1-2 sentence overall assessment\n\nBe strict: wrong character names, fabricated events, or incorrect locations are errors.\nMinor omissions or imprecise tone descriptions are warnings.\n\nReturn ONLY valid JSON. No explanations or markdown fences.\n\n==========\nORIGINAL SCENE TEXT:\nINT. RUDDY & GREEN BUILDING - ELEVATOR\n\nUB40's \"I Can't Help Falling in Love With You\" muzak.\n\nROSE (mid-30s) leans against the elevator wall, panting. She's wearing a Tim Hortons uniform, her hair is a mess, and there's blood spattered on her face.\n\nShe looks right, pants a few more times, then squints in disgust. She gingerly picks up a bloody scrap of something with hair on it. She snorts and drops it.\n\nROSE\nIs that skull??\n\nNext to her is Mariner, also panting, covered in far more blood. His face is broad, stoic, and frowning. He has gray-blue eyes and a thick, curly, beard barely streaked with gray. He wears a red knit cap and a small mask.\n\nFULL-SCREEN SUPERIMPOSED TITLE CARD: \"THE MARINER\"\n\nHe blinks a few times as a drop of blood falls from his eyebrow. He looks toward her, then spits out some blood.\n\nMARINER\nYeaaaaah...\n\nHe's built like a pro-wrestler. Moss green SWEATER stretched over his huge frame, sleeves rolled showing heavy leather BRACERS adorned with anchors. His inner forearm has a classic heart-and-arrow TATTOO with \"Dad\" in the centre. Across his chest is a BANDOLIER of bright red 12-gauge shells, FISH HOOKS hanging from the bottom edge. Heavy rubberized BOOTS go past his knees. A CAPE of heavy FISHING NET edged with WEIGHTS hangs from his shoulders.\n\nHe holds a STOUT WOODEN OAR in both hands, edged with METAL and dripping with BLOOD.\n\nROSE\nWhere were you when they grabbed me? You were supposed to pick me up at work!\n\nMARINER\nYeah, about that, I got a little... distracted.\n\nROSE\nDistracted. You got DISTRACTED?!\n\nMARINER\nI was also... tracking the car... that grabbed you... through the AirTag... I put on your phone.\n\nRose stops. She's really not happy about this.\n\nROSE\nYou Airtagged me?!\n\n==========\nEXTRACTED SCENE DATA:\n{\n  \"scene_number\": 4,\n  \"heading\": \"INT. OFFICE BUILDING - ELEVATOR\",\n  \"int_ext\": \"INT\",\n  \"location\": \"OFFICE BUILDING - ELEVATOR\",\n  \"time_of_day\": \"DAY\",\n  \"characters_present\": [\"ROSE\", \"BILLY\"],\n  \"summary\": \"Billy and Rose take the elevator in an office building. They discuss their plans for the evening. Rose mentions she needs to pick up groceries.\",\n  \"narrative_beats\": [\n    {\"beat_type\": \"exposition\", \"description\": \"Characters discuss daily plans.\", \"confidence\": 0.85}\n  ],\n  \"tone_mood\": \"casual\",\n  \"confidence\": 0.88\n}\n==========",
          "label": "prompts/qa-pass.txt: You are a QA reviewer validating whether an AI-extracted scene analysis is accurate and faithful to the source screenplay text.\n\nCompare the extracted scene data against the original scene text and evaluate:\n\n1. **Heading accuracy**: Is the scene heading correct (location, INT/EXT, time of day)?\n2. **Character completeness**: Are all characters who appear or speak listed?\n3. **Summary fidelity**: Does the summary accurately describe what happens? No fabrications?\n4. **Narrative beats**: Are the identified beats actually present in the scene?\n5. **Tone assessment**: Does the tone description match the actual mood of the scene?\n6. **Confidence calibration**: Is the confidence score reasonable given the quality?\n\nReturn a JSON object with:\n- passed: boolean (true if the extraction is faithful, false if it has significant errors)\n- confidence: float 0-1 (your confidence in this QA judgment)\n- issues: array of objects, each with:\n  - severity: \"error\" (factual wrong), \"warning\" (misleading), or \"note\" (minor)\n  - description: what's wrong\n  - location: which field has the issue\n- summary: 1-2 sentence overall assessment\n\nBe strict: wrong character names, fabricated events, or incorrect locations are errors.\nMinor omissions or imprecise tone descriptions are warnings.\n\nReturn ONLY valid JSON. No explanations or markdown fences.\n\n==========\nORIGINAL SCENE TEXT:\n{{scene_text}}\n\n==========\nEXTRACTED SCENE DATA:\n{{extracted_data}}\n==========",
          "config": {
            "provider": "anthropic:messages:claude-opus-4-6"
          }
        },
        "promptId": "8df20c2c4a6081352d6b06e144ddbc1e0a5244f9a3c2000d40df12fc9a94e543",
        "promptIdx": 11,
        "provider": {
          "id": "google:gemini-2.5-pro",
          "label": "Gemini 2.5 Pro"
        },
        "response": {
          "output": "```json\n{\n  \"passed\": false,\n  \"confidence\": 1.0,\n  \"issues\": [\n    {\n      \"severity\": \"error\",\n      \"description\": \"The location 'RUDDY & GREEN BUILDING' was incorrectly generalized to 'OFFICE BUILDING'.\",\n      \"location\": \"heading\"\n    },\n    {\n      \"severity\": \"error\",\n      \"description\": \"The time of day 'DAY' was fabricated; it is not specified in the scene heading.\",\n      \"location\": \"time_of_day\"\n    },\n    {\n      \"severity\": \"error\",\n      \"description\": \"The character 'MARINER' is incorrectly identified as 'BILLY'.\",\n      \"location\": \"characters_present\"\n    },\n    {\n      \"severity\": \"error\",\n      \"description\": \"The summary is a complete fabrication. It invents a casual conversation about evening plans and groceries, ignoring the actual events of the scene which involve blood, a recent fight, and a confrontation about a kidnapping and an AirTag.\",\n      \"location\": \"summary\"\n    },\n    {\n      \"severity\": \"error\",\n      \"description\": \"The identified narrative beat 'Characters discuss daily plans' is not present in the scene and is based on the fabricated summary.\",\n      \"location\": \"narrative_beats\"\n    },\n    {\n      \"severity\": \"error\",\n      \"description\": \"The tone is described as 'casual', which is completely inaccurate. The scene is tense, post-violent, and confrontational.\",\n      \"location\": \"tone_mood\"\n    }\n  ],\n  \"summary\": \"The extraction is a catastrophic failure, fabricating the characters, summary, narrative beats, and tone. It bears almost no resemblance to the source text.\"\n}\n```",
          "tokenUsage": {
            "prompt": 963,
            "completion": 397,
            "total": 2391,
            "numRequests": 1,
            "completionDetails": {
              "reasoning": 1031,
              "acceptedPrediction": 0,
              "rejectedPrediction": 0
            }
          },
          "cost": 0.015483750000000001,
          "raw": {
            "candidates": [
              {
                "content": {
                  "parts": [
                    {
                      "text": "```json\n{\n  \"passed\": false,\n  \"confidence\": 1.0,\n  \"issues\": [\n    {\n      \"severity\": \"error\",\n      \"description\": \"The location 'RUDDY & GREEN BUILDING' was incorrectly generalized to 'OFFICE BUILDING'.\",\n      \"location\": \"heading\"\n    },\n    {\n      \"severity\": \"error\",\n      \"description\": \"The time of day 'DAY' was fabricated; it is not specified in the scene heading.\",\n      \"location\": \"time_of_day\"\n    },\n    {\n      \"severity\": \"error\",\n      \"description\": \"The character 'MARINER' is incorrectly identified as 'BILLY'.\",\n      \"location\": \"characters_present\"\n    },\n    {\n      \"severity\": \"error\",\n      \"description\": \"The summary is a complete fabrication. It invents a casual conversation about evening plans and groceries, ignoring the actual events of the scene which involve blood, a recent fight, and a confrontation about a kidnapping and an AirTag.\",\n      \"location\": \"summary\"\n    },\n    {\n      \"severity\": \"error\",\n      \"description\": \"The identified narrative beat 'Characters discuss daily plans' is not present in the scene and is based on the fabricated summary.\",\n      \"location\": \"narrative_beats\"\n    },\n    {\n      \"severity\": \"error\",\n      \"description\": \"The tone is described as 'casual', which is completely inaccurate. The scene is tense, post-violent, and confrontational.\",\n      \"location\": \"tone_mood\"\n    }\n  ],\n  \"summary\": \"The extraction is a catastrophic failure, fabricating the characters, summary, narrative beats, and tone. It bears almost no resemblance to the source text.\"\n}\n```"
                    }
                  ],
                  "role": "model"
                },
                "finishReason": "STOP",
                "index": 0
              }
            ],
            "usageMetadata": {
              "promptTokenCount": 963,
              "candidatesTokenCount": 397,
              "totalTokenCount": 2391,
              "promptTokensDetails": [
                {
                  "modality": "TEXT",
                  "tokenCount": 963
                }
              ],
              "thoughtsTokenCount": 1031
            },
            "modelVersion": "gemini-2.5-pro",
            "responseId": "zQ-laf3LDaO-qtsPy9zM-Qo"
          },
          "cached": false,
          "metadata": {}
        },
        "score": 0.995,
        "success": true,
        "testCase": {
          "vars": {
            "scene_text": "file://../input/enrich-scene-elevator.txt",
            "extracted_data": "file://../input/qa-bad-scene.json",
            "golden_path": "golden/qa-pass-golden.json",
            "test_key": "bad_scene"
          },
          "assert": [
            {
              "type": "python",
              "value": "file://../scorers/qa_pass_scorer.py"
            },
            {
              "type": "llm-rubric",
              "value": "This QA evaluation was given a BAD scene extraction with multiple errors:\n- Wrong building name (Office Building vs Ruddy & Green)\n- Time of day fabricated (claims DAY, but scene heading has none)\n- Wrong character name (Billy instead of Mariner)\n- Fabricated content (grocery discussion never happens)\n\nThe QA model should have:\n1. Marked it as failed (false)\n2. Identified at least 2-3 specific errors\n3. Flagged the fabricated summary content\n4. Used \"error\" severity for factual mistakes\n\nIf the model let this pass, that's a dangerous false positive.\n"
            }
          ],
          "options": {
            "provider": "anthropic:messages:claude-opus-4-6"
          },
          "metadata": {}
        },
        "testIdx": 1,
        "vars": {
          "scene_text": "file://../input/enrich-scene-elevator.txt",
          "extracted_data": "file://../input/qa-bad-scene.json",
          "golden_path": "golden/qa-pass-golden.json",
          "test_key": "bad_scene"
        },
        "metadata": {
          "_promptfooFileMetadata": {}
        },
        "failureReason": 0
      },
      {
        "cost": 0.01713,
        "gradingResult": {
          "pass": true,
          "score": 1,
          "reason": "All assertions passed",
          "namedScores": {},
          "tokensUsed": {
            "total": 744,
            "prompt": 597,
            "completion": 147,
            "cached": 0,
            "numRequests": 0
          },
          "componentResults": [
            {
              "pass": true,
              "score": 1,
              "reason": "confidence_calibration=1.00 | issue_detection=1.00 | json_valid=1.00 | pass_correct=1.00 | severity_accuracy=1.00 | summary_quality=1.00",
              "assertion": {
                "type": "python",
                "value": "file://../scorers/qa_pass_scorer.py"
              }
            },
            {
              "assertion": {
                "type": "llm-rubric",
                "value": "This QA evaluation was given a BAD scene extraction with multiple errors:\n- Wrong building name (Office Building vs Ruddy & Green)\n- Time of day fabricated (claims DAY, but scene heading has none)\n- Wrong character name (Billy instead of Mariner)\n- Fabricated content (grocery discussion never happens)\n\nThe QA model should have:\n1. Marked it as failed (false)\n2. Identified at least 2-3 specific errors\n3. Flagged the fabricated summary content\n4. Used \"error\" severity for factual mistakes\n\nIf the model let this pass, that's a dangerous false positive.\n"
              },
              "pass": true,
              "score": 1,
              "reason": "The QA evaluation correctly marked the extraction as failed (passed: false) with high confidence. It identified multiple specific errors: (1) wrong character name (Billy instead of Mariner), (2) fabricated summary content about groceries, (3) fabricated narrative beats, (4) incorrect tone classification, and (5) wrong building name (Office Building vs Ruddy & Green). All factual mistakes were appropriately flagged with 'error' severity. The evaluation caught the fabricated content and clearly explained why it was wrong. This is not a false positive - it correctly rejected the bad extraction.",
              "tokensUsed": {
                "total": 744,
                "prompt": 597,
                "completion": 147,
                "cached": 0,
                "numRequests": 0,
                "completionDetails": {
                  "reasoning": 0,
                  "acceptedPrediction": 0,
                  "rejectedPrediction": 0
                }
              },
              "metadata": {
                "renderedGradingPrompt": "[{\"role\":\"system\",\"content\":\"You are grading output according to a user-specified rubric. If the statement in the rubric is true, then the output passes the test. You respond with a JSON object with this structure: {reason: string, pass: boolean, score: number}\\n\\nExamples:\\n\\n<Output>Hello world</Output>\\n<Rubric>Content contains a greeting</Rubric>\\n{\\\"reason\\\": \\\"the content contains the word 'Hello'\\\", \\\"pass\\\": true, \\\"score\\\": 1.0}\\n\\n<Output>Avast ye swabs, repel the invaders!</Output>\\n<Rubric>Does not speak like a pirate</Rubric>\\n{\\\"reason\\\": \\\"'avast ye' is a common pirate term\\\", \\\"pass\\\": false, \\\"score\\\": 0.0}\"},{\"role\":\"user\",\"content\":\"<Output>\\n{\\\"passed\\\":false,\\\"confidence\\\":1,\\\"issues\\\":[{\\\"severity\\\":\\\"error\\\",\\\"description\\\":\\\"Character 'MARINER' is missing; 'BILLY' is hallucinated and does not appear in the text.\\\",\\\"location\\\":\\\"characters_present\\\"},{\\\"severity\\\":\\\"error\\\",\\\"description\\\":\\\"Summary is a complete fabrication (discussing groceries/evening plans). The actual scene depicts two bloody characters discussing a kidnapping, a piece of skull, and an AirTag.\\\",\\\"location\\\":\\\"summary\\\"},{\\\"severity\\\":\\\"error\\\",\\\"description\\\":\\\"Narrative beats are hallucinated; no discussion of daily plans occurs.\\\",\\\"location\\\":\\\"narrative_beats\\\"},{\\\"severity\\\":\\\"error\\\",\\\"description\\\":\\\"Tone 'casual' is incorrect for a scene involving blood, weapons, and post-combat stress.\\\",\\\"location\\\":\\\"tone_mood\\\"},{\\\"severity\\\":\\\"warning\\\",\\\"description\\\":\\\"Location extracted as 'OFFICE BUILDING' instead of the specific 'RUDDY & GREEN BUILDING'.\\\",\\\"location\\\":\\\"heading\\\"}],\\\"summary\\\":\\\"The extraction is a complete hallucination, inventing a character named Billy and a plot about groceries while ignoring the actual content regarding the Mariner, blood, and a kidnapping discussion.\\\"}\\n</Output>\\n<Rubric>\\nThis QA evaluation was given a BAD scene extraction with multiple errors:\\n- Wrong building name (Office Building vs Ruddy & Green)\\n- Time of day fabricated (claims DAY, but scene heading has none)\\n- Wrong character name (Billy instead of Mariner)\\n- Fabricated content (grocery discussion never happens)\\n\\nThe QA model should have:\\n1. Marked it as failed (false)\\n2. Identified at least 2-3 specific errors\\n3. Flagged the fabricated summary content\\n4. Used \\\"error\\\" severity for factual mistakes\\n\\nIf the model let this pass, that's a dangerous false positive.\\n\\n</Rubric>\"}]"
              }
            }
          ]
        },
        "id": "84fed9e4-e4a6-4301-935e-8219769cc22d",
        "latencyMs": 59151,
        "namedScores": {},
        "prompt": {
          "raw": "You are a QA reviewer validating whether an AI-extracted scene analysis is accurate and faithful to the source screenplay text.\n\nCompare the extracted scene data against the original scene text and evaluate:\n\n1. **Heading accuracy**: Is the scene heading correct (location, INT/EXT, time of day)?\n2. **Character completeness**: Are all characters who appear or speak listed?\n3. **Summary fidelity**: Does the summary accurately describe what happens? No fabrications?\n4. **Narrative beats**: Are the identified beats actually present in the scene?\n5. **Tone assessment**: Does the tone description match the actual mood of the scene?\n6. **Confidence calibration**: Is the confidence score reasonable given the quality?\n\nReturn a JSON object with:\n- passed: boolean (true if the extraction is faithful, false if it has significant errors)\n- confidence: float 0-1 (your confidence in this QA judgment)\n- issues: array of objects, each with:\n  - severity: \"error\" (factual wrong), \"warning\" (misleading), or \"note\" (minor)\n  - description: what's wrong\n  - location: which field has the issue\n- summary: 1-2 sentence overall assessment\n\nBe strict: wrong character names, fabricated events, or incorrect locations are errors.\nMinor omissions or imprecise tone descriptions are warnings.\n\nReturn ONLY valid JSON. No explanations or markdown fences.\n\n==========\nORIGINAL SCENE TEXT:\nINT. RUDDY & GREEN BUILDING - ELEVATOR\n\nUB40's \"I Can't Help Falling in Love With You\" muzak.\n\nROSE (mid-30s) leans against the elevator wall, panting. She's wearing a Tim Hortons uniform, her hair is a mess, and there's blood spattered on her face.\n\nShe looks right, pants a few more times, then squints in disgust. She gingerly picks up a bloody scrap of something with hair on it. She snorts and drops it.\n\nROSE\nIs that skull??\n\nNext to her is Mariner, also panting, covered in far more blood. His face is broad, stoic, and frowning. He has gray-blue eyes and a thick, curly, beard barely streaked with gray. He wears a red knit cap and a small mask.\n\nFULL-SCREEN SUPERIMPOSED TITLE CARD: \"THE MARINER\"\n\nHe blinks a few times as a drop of blood falls from his eyebrow. He looks toward her, then spits out some blood.\n\nMARINER\nYeaaaaah...\n\nHe's built like a pro-wrestler. Moss green SWEATER stretched over his huge frame, sleeves rolled showing heavy leather BRACERS adorned with anchors. His inner forearm has a classic heart-and-arrow TATTOO with \"Dad\" in the centre. Across his chest is a BANDOLIER of bright red 12-gauge shells, FISH HOOKS hanging from the bottom edge. Heavy rubberized BOOTS go past his knees. A CAPE of heavy FISHING NET edged with WEIGHTS hangs from his shoulders.\n\nHe holds a STOUT WOODEN OAR in both hands, edged with METAL and dripping with BLOOD.\n\nROSE\nWhere were you when they grabbed me? You were supposed to pick me up at work!\n\nMARINER\nYeah, about that, I got a little... distracted.\n\nROSE\nDistracted. You got DISTRACTED?!\n\nMARINER\nI was also... tracking the car... that grabbed you... through the AirTag... I put on your phone.\n\nRose stops. She's really not happy about this.\n\nROSE\nYou Airtagged me?!\n\n==========\nEXTRACTED SCENE DATA:\n{\n  \"scene_number\": 4,\n  \"heading\": \"INT. OFFICE BUILDING - ELEVATOR\",\n  \"int_ext\": \"INT\",\n  \"location\": \"OFFICE BUILDING - ELEVATOR\",\n  \"time_of_day\": \"DAY\",\n  \"characters_present\": [\"ROSE\", \"BILLY\"],\n  \"summary\": \"Billy and Rose take the elevator in an office building. They discuss their plans for the evening. Rose mentions she needs to pick up groceries.\",\n  \"narrative_beats\": [\n    {\"beat_type\": \"exposition\", \"description\": \"Characters discuss daily plans.\", \"confidence\": 0.85}\n  ],\n  \"tone_mood\": \"casual\",\n  \"confidence\": 0.88\n}\n==========",
          "label": "prompts/qa-pass.txt: You are a QA reviewer validating whether an AI-extracted scene analysis is accurate and faithful to the source screenplay text.\n\nCompare the extracted scene data against the original scene text and evaluate:\n\n1. **Heading accuracy**: Is the scene heading correct (location, INT/EXT, time of day)?\n2. **Character completeness**: Are all characters who appear or speak listed?\n3. **Summary fidelity**: Does the summary accurately describe what happens? No fabrications?\n4. **Narrative beats**: Are the identified beats actually present in the scene?\n5. **Tone assessment**: Does the tone description match the actual mood of the scene?\n6. **Confidence calibration**: Is the confidence score reasonable given the quality?\n\nReturn a JSON object with:\n- passed: boolean (true if the extraction is faithful, false if it has significant errors)\n- confidence: float 0-1 (your confidence in this QA judgment)\n- issues: array of objects, each with:\n  - severity: \"error\" (factual wrong), \"warning\" (misleading), or \"note\" (minor)\n  - description: what's wrong\n  - location: which field has the issue\n- summary: 1-2 sentence overall assessment\n\nBe strict: wrong character names, fabricated events, or incorrect locations are errors.\nMinor omissions or imprecise tone descriptions are warnings.\n\nReturn ONLY valid JSON. No explanations or markdown fences.\n\n==========\nORIGINAL SCENE TEXT:\n{{scene_text}}\n\n==========\nEXTRACTED SCENE DATA:\n{{extracted_data}}\n==========",
          "config": {
            "provider": "anthropic:messages:claude-opus-4-6"
          }
        },
        "promptId": "8df20c2c4a6081352d6b06e144ddbc1e0a5244f9a3c2000d40df12fc9a94e543",
        "promptIdx": 12,
        "provider": {
          "id": "google:gemini-3-pro-preview",
          "label": "Gemini 3 Pro"
        },
        "response": {
          "output": "{\n  \"passed\": false,\n  \"confidence\": 1.0,\n  \"issues\": [\n    {\n      \"severity\": \"error\",\n      \"description\": \"Character 'MARINER' is missing; 'BILLY' is hallucinated and does not appear in the text.\",\n      \"location\": \"characters_present\"\n    },\n    {\n      \"severity\": \"error\",\n      \"description\": \"Summary is a complete fabrication (discussing groceries/evening plans). The actual scene depicts two bloody characters discussing a kidnapping, a piece of skull, and an AirTag.\",\n      \"location\": \"summary\"\n    },\n    {\n      \"severity\": \"error\",\n      \"description\": \"Narrative beats are hallucinated; no discussion of daily plans occurs.\",\n      \"location\": \"narrative_beats\"\n    },\n    {\n      \"severity\": \"error\",\n      \"description\": \"Tone 'casual' is incorrect for a scene involving blood, weapons, and post-combat stress.\",\n      \"location\": \"tone_mood\"\n    },\n    {\n      \"severity\": \"warning\",\n      \"description\": \"Location extracted as 'OFFICE BUILDING' instead of the specific 'RUDDY & GREEN BUILDING'.\",\n      \"location\": \"heading\"\n    }\n  ],\n  \"summary\": \"The extraction is a complete hallucination, inventing a character named Billy and a plot about groceries while ignoring the actual content regarding the Mariner, blood, and a kidnapping discussion.\"\n}",
          "tokenUsage": {
            "prompt": 963,
            "completion": 328,
            "total": 2230,
            "numRequests": 1,
            "completionDetails": {
              "reasoning": 939,
              "acceptedPrediction": 0,
              "rejectedPrediction": 0
            }
          },
          "cost": 0.01713,
          "raw": {
            "candidates": [
              {
                "content": {
                  "parts": [
                    {
                      "text": "{\n  \"passed\": false,\n  \"confidence\": 1.0,\n  \"issues\": [\n    {\n      \"severity\": \"error\",\n      \"description\": \"Character 'MARINER' is missing; 'BILLY' is hallucinated and does not appear in the text.\",\n      \"location\": \"characters_present\"\n    },\n    {\n      \"severity\": \"error\",\n      \"description\": \"Summary is a complete fabrication (discussing groceries/evening plans). The actual scene depicts two bloody characters discussing a kidnapping, a piece of skull, and an AirTag.\",\n      \"location\": \"summary\"\n    },\n    {\n      \"severity\": \"error\",\n      \"description\": \"Narrative beats are hallucinated; no discussion of daily plans occurs.\",\n      \"location\": \"narrative_beats\"\n    },\n    {\n      \"severity\": \"error\",\n      \"description\": \"Tone 'casual' is incorrect for a scene involving blood, weapons, and post-combat stress.\",\n      \"location\": \"tone_mood\"\n    },\n    {\n      \"severity\": \"warning\",\n      \"description\": \"Location extracted as 'OFFICE BUILDING' instead of the specific 'RUDDY & GREEN BUILDING'.\",\n      \"location\": \"heading\"\n    }\n  ],\n  \"summary\": \"The extraction is a complete hallucination, inventing a character named Billy and a plot about groceries while ignoring the actual content regarding the Mariner, blood, and a kidnapping discussion.\"\n}",
                      "thoughtSignature": "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"
                    }
                  ],
                  "role": "model"
                },
                "finishReason": "STOP",
                "index": 0
              }
            ],
            "usageMetadata": {
              "promptTokenCount": 963,
              "candidatesTokenCount": 328,
              "totalTokenCount": 2230,
              "promptTokensDetails": [
                {
                  "modality": "TEXT",
                  "tokenCount": 963
                }
              ],
              "thoughtsTokenCount": 939
            },
            "modelVersion": "gemini-3-pro-preview",
            "responseId": "_A-laZLrJfLnqtsPr4u2oQk"
          },
          "cached": false,
          "metadata": {}
        },
        "score": 1,
        "success": true,
        "testCase": {
          "vars": {
            "scene_text": "file://../input/enrich-scene-elevator.txt",
            "extracted_data": "file://../input/qa-bad-scene.json",
            "golden_path": "golden/qa-pass-golden.json",
            "test_key": "bad_scene"
          },
          "assert": [
            {
              "type": "python",
              "value": "file://../scorers/qa_pass_scorer.py"
            },
            {
              "type": "llm-rubric",
              "value": "This QA evaluation was given a BAD scene extraction with multiple errors:\n- Wrong building name (Office Building vs Ruddy & Green)\n- Time of day fabricated (claims DAY, but scene heading has none)\n- Wrong character name (Billy instead of Mariner)\n- Fabricated content (grocery discussion never happens)\n\nThe QA model should have:\n1. Marked it as failed (false)\n2. Identified at least 2-3 specific errors\n3. Flagged the fabricated summary content\n4. Used \"error\" severity for factual mistakes\n\nIf the model let this pass, that's a dangerous false positive.\n"
            }
          ],
          "options": {
            "provider": "anthropic:messages:claude-opus-4-6"
          },
          "metadata": {}
        },
        "testIdx": 1,
        "vars": {
          "scene_text": "file://../input/enrich-scene-elevator.txt",
          "extracted_data": "file://../input/qa-bad-scene.json",
          "golden_path": "golden/qa-pass-golden.json",
          "test_key": "bad_scene"
        },
        "metadata": {
          "_promptfooFileMetadata": {}
        },
        "failureReason": 0
      }
    ],
    "stats": {
      "successes": 24,
      "failures": 2,
      "errors": 0,
      "tokenUsage": {
        "prompt": 28070,
        "completion": 8635,
        "cached": 0,
        "total": 47971,
        "numRequests": 26,
        "completionDetails": {
          "reasoning": 11266,
          "acceptedPrediction": 0,
          "rejectedPrediction": 0
        },
        "assertions": {
          "total": 19931,
          "prompt": 16310,
          "completion": 3621,
          "cached": 0,
          "numRequests": 0,
          "completionDetails": {
            "reasoning": 0,
            "acceptedPrediction": 0,
            "rejectedPrediction": 0
          }
        }
      },
      "durationMs": 156160
    }
  },
  "config": {
    "tags": {},
    "description": "QA pass  judge scene extraction quality (good vs bad outputs)",
    "prompts": [
      "file:///Users/cam/Documents/Projects/cine-forge/benchmarks/prompts/qa-pass.txt"
    ],
    "providers": [
      {
        "id": "openai:gpt-4.1-nano",
        "label": "GPT-4.1 Nano",
        "config": {
          "temperature": 0,
          "max_tokens": 4096,
          "response_format": {
            "type": "json_object"
          }
        }
      },
      {
        "id": "openai:gpt-4.1-mini",
        "label": "GPT-4.1 Mini",
        "config": {
          "temperature": 0,
          "max_tokens": 4096,
          "response_format": {
            "type": "json_object"
          }
        }
      },
      {
        "id": "google:gemini-2.5-flash-lite",
        "label": "Gemini 2.5 Flash Lite",
        "config": {
          "temperature": 0,
          "maxOutputTokens": 16384
        }
      },
      {
        "id": "openai:gpt-4.1",
        "label": "GPT-4.1",
        "config": {
          "temperature": 0,
          "max_tokens": 4096,
          "response_format": {
            "type": "json_object"
          }
        }
      },
      {
        "id": "anthropic:messages:claude-haiku-4-5-20251001",
        "label": "Claude Haiku 4.5",
        "config": {
          "temperature": 0,
          "max_tokens": 4096
        }
      },
      {
        "id": "anthropic:messages:claude-sonnet-4-5-20250929",
        "label": "Claude Sonnet 4.5",
        "config": {
          "temperature": 0,
          "max_tokens": 4096
        }
      },
      {
        "id": "anthropic:messages:claude-sonnet-4-6",
        "label": "Claude Sonnet 4.6",
        "config": {
          "temperature": 0,
          "max_tokens": 4096
        }
      },
      {
        "id": "google:gemini-2.5-flash",
        "label": "Gemini 2.5 Flash",
        "config": {
          "temperature": 0,
          "maxOutputTokens": 16384
        }
      },
      {
        "id": "google:gemini-3-flash-preview",
        "label": "Gemini 3 Flash",
        "config": {
          "temperature": 0,
          "maxOutputTokens": 16384
        }
      },
      {
        "id": "openai:gpt-5.2",
        "label": "GPT-5.2",
        "config": {
          "temperature": 0,
          "max_tokens": 4096,
          "response_format": {
            "type": "json_object"
          }
        }
      },
      {
        "id": "anthropic:messages:claude-opus-4-6",
        "label": "Claude Opus 4.6",
        "config": {
          "temperature": 0,
          "max_tokens": 4096
        }
      },
      {
        "id": "google:gemini-2.5-pro",
        "label": "Gemini 2.5 Pro",
        "config": {
          "temperature": 0,
          "maxOutputTokens": 16384
        }
      },
      {
        "id": "google:gemini-3-pro-preview",
        "label": "Gemini 3 Pro",
        "config": {
          "temperature": 0,
          "maxOutputTokens": 16384
        }
      }
    ],
    "tests": [
      {
        "vars": {
          "scene_text": "file://../input/enrich-scene-elevator.txt",
          "extracted_data": "file://../input/qa-good-scene.json",
          "golden_path": "golden/qa-pass-golden.json",
          "test_key": "good_scene"
        },
        "assert": [
          {
            "type": "python",
            "value": "file://../scorers/qa_pass_scorer.py"
          },
          {
            "type": "llm-rubric",
            "value": "This QA evaluation was given a GOOD scene extraction that accurately\nreflects the source text. The QA model should have:\n\n1. Marked it as passed (true)\n2. Found zero or very few errors\n3. Had high confidence in the assessment\n4. Written a summary confirming accuracy\n\nIf the model incorrectly flagged the good extraction as failing,\nthat's a false negative and should score poorly.\n"
          }
        ]
      },
      {
        "vars": {
          "scene_text": "file://../input/enrich-scene-elevator.txt",
          "extracted_data": "file://../input/qa-bad-scene.json",
          "golden_path": "golden/qa-pass-golden.json",
          "test_key": "bad_scene"
        },
        "assert": [
          {
            "type": "python",
            "value": "file://../scorers/qa_pass_scorer.py"
          },
          {
            "type": "llm-rubric",
            "value": "This QA evaluation was given a BAD scene extraction with multiple errors:\n- Wrong building name (Office Building vs Ruddy & Green)\n- Time of day fabricated (claims DAY, but scene heading has none)\n- Wrong character name (Billy instead of Mariner)\n- Fabricated content (grocery discussion never happens)\n\nThe QA model should have:\n1. Marked it as failed (false)\n2. Identified at least 2-3 specific errors\n3. Flagged the fabricated summary content\n4. Used \"error\" severity for factual mistakes\n\nIf the model let this pass, that's a dangerous false positive.\n"
          }
        ]
      }
    ],
    "scenarios": [],
    "env": {},
    "defaultTest": {
      "options": {
        "provider": "anthropic:messages:claude-opus-4-6"
      },
      "vars": {},
      "assert": [],
      "metadata": {}
    },
    "outputPath": [
      "results/qa-pass-post-golden-verify.json"
    ],
    "extensions": [],
    "metadata": {},
    "evaluateOptions": {}
  },
  "shareableUrl": null,
  "metadata": {
    "promptfooVersion": "0.120.24",
    "nodeVersion": "v24.13.1",
    "platform": "darwin",
    "arch": "arm64",
    "exportedAt": "2026-03-02T04:20:19.331Z",
    "evaluationCreatedAt": "2026-03-02T04:17:41.098Z"
  }
}